.so bibtex.header

@Book{atamfm,
  author       = "Maureen~F. McHugh",
  title        = "After the Apocalypse",
  publisher    = "Small Beer Press",
  year         = 2011,
  address      = "Easthampton, MA",
  keywords     = "collapse, survival",
  location     = "PS 3563.C3687 A69"
}

@Book{scnn,
  author       = "Carl~N. Nightengale",
  title        = "Segregation",
  publisher    = ucp,
  year         = 2012,
  address      = chil,
  keywords     = "segregation, racial politics, city planning, colonialism",
  location     = "HD 7288.75.N54"
}

@Book{lfsdk,
  author       = "Dori Katz",
  title        = "Looking For Strangers",
  publisher    = ucp,
  year         = 2013,
  address      = chil,
  keywords     = "rememberance, holocast, world war ii, resistance",
  location     = "D 804.48.K314"
}

@Book{caimrg,
  author       = "Michael~R. Garey and David~S. Johnson",
  title        = "Computers and Intractability",
  publisher    = "W.~H. Freeman",
  year         = 1979,
  address      = nyny,
  keywords     = "computers, complexity, intractability, np-completeness,
    np-hardness, complexity proofs",
  location     = "QA 76.6 G35"
}

@Book{dja,
  author       = "John Altman",
  title        = "Deception",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2003,
  address      = nyny,
  keywords     = "mcguffins, children at play",
  location     = "PS 3601.L85 D43"
}

@Book{otbhlc,
  author       = "Hillary~L. Chute",
  title        = "Outside the Box",
  publisher    = ucp,
  year         = 2014,		  
  address      = chil,
  keywords     = "scott mccloud, charles burns, aline kominsky-crumb, daniel
    clowes, phoebe gloeckner, joe sacco, alison bechdel, francoise mouly, lynda
    barry, adrian tomine, art spiegelman, chris ware, comix, art",
  location     = "NC 1305 C48"
}

@Book{dezs,
  author       = "Zo{\" e} Sharp",
  title        = "Die Easy",
  publisher    = "Pegasus Crime",
  year         = 2013,
  address      = nyny,
  keywords     = "murrdaar, the long cold hand of revenge",
  location     = ""
}

@Book{tdjtk,
  author       = "James~T. Kloppenberg",
  title        = "Towards Democracy",
  publisher    = oup,
  year         = 2016,
  address      = nyny,
  keywords     = "democracy, enlightenment, america, french revolution,
    england, reformation",
  location     = "JC 421 K526"
}

@Book{tfob,
  author       = "Tzvetan Todorov",
  title        = "The Fear of Barbarians",
  publisher    = ucp,
  year         = 2010,
  address      = chil,
  keywords     = "civilization, islam, politics, europe, democracy, religion,
    manichaeism, world politics",
  location     = "CB 251.T5913"
}

@Book{ahateotw,
  author       = "Erin Claiborne",
  title        = "{A} Hero at the End of the World",
  publisher    = "Big Bang Press",
  year         = 2014,
  address      = "Brooklyn, N.Y.",
  keywords     = "magic, london",
  location     = "isbn-13 9780990484400"
}

@Book{tieb,
  author       = "Elif Batuman",
  title        = "The Idiot",
  publisher    = "Penguin",
  year         = 2017,
  address      = nyny,
  keywords     = "education, love, language, philosophy",
  location     = "PS 3602.A9237 I45"
}

@Book{ttjg,
  author       = "James Gleick",
  title        = "Time Travel",
  publisher    = "Pantheon",
  year         = 2016,
  address      = nyny,
  keywords     = "time travel, literature, the artistic imagination, space and
    time, time", 
  location     = "QC 173.59.S65 G54"
}

@Book{litb,
  author       = "George Saunders",
  title        = "Lincoln in the Bardo",
  publisher    = "Random House",
  year         = 2017,
  address      = nyny,
  keywords     = "the dead and how they got there, unfinished business",
  location     = "PS 3569.A7897"
}

@Book{litsus,
  author       = "Sarah Vowell",
  title        = "Lafayette in the Somewhat United States",
  publisher    = "Riverhead Books",
  year         = 2015,
  address      = nyny,
  keywords     = "revolutionary war, diplomacy, france, lafayette, washington",
  location     = "E 207.L2 V69"
}

@Book{8zal,
  author       = "Alan~R. Miller",
  title        = "8080/{Z80} Assembly Language",
  publisher    = "John Wiley \& Sons",
  year         = 1981,
  address      = nyny,
  keywords     = "number bases, logical operations, stacks, i/o, macros, system
     monitor, zilog z-80 processors, intel 8080 processors, number-base
     conversion, paper tape, magnetic tape, cp/m",
  location     = "QA 76.8.I28 M53"
}

@Book{clr2017,
  author       = "Lucinda Rosenfeld",
  title        = "Class",
  publisher    = "Little, Brown",
  year         = 2017,
  address      = nyny,
  month        = "January",
  keywords     = "schooling, social class, income stratification, family",
  location     = "813.54"
}

@Book{fuddb,
  author       = "Danielle DiMartino Booth",
  title        = "Fed Up",
  publisher    = "Portfolio",
  year         = 2017,
  address      = nyny,
  keywords     = "economics, federal reserve banks, alan greenspan, ben
    bernake, janet yellin, banks, banking, monetary policy, richard fisher,
    dallas fed",
  location     = "HG 2563.B586"
}

@Book{tifjk,
  author       = "Jason Kekulak",
  title        = "The Impossible Fortress",
  publisher    = "Simon \& Schuster",
  year         = 2017,
  address      = nyny,
  keywords     = "game programming, computer games, bad decision making, geeks,
    1980s, boys and girls together, C-64", 
  location     = "PS 3618.E57275 I47"
}

@InProceedings{rdlrr,
  author       = "Reia, Rafael and Menezes Leit{\~ a}o, Ant{\' o}nio",
  title        = "Refactoring Dynamic Languages",
  booktitle    = pot # "9th European Lisp Symposium",
  year         = 2016,
  address      = "Krak{\' o}w, Poland",
  month        = "9--10 " # may,
  keywords     = "ides, refactoring tools, novice programming, scheme, racket",
  abstract     = "Typically, beginner programmers do not master the style rules
    of the programming language they are using and, frequently, do not have yet
    the logical agility to avoid writing redundant code.  As a result, although
    their programs might be correct, they can also be improved and it is
    important for the programmer to learn about the improvements that, without
    changing the meaning of the program, simplify it or transform it to follow
    the style rules of the language.  These kinds of transformations are the
    realm of refactoring tools.  However, these tools are typically associated
    with sophisticated integrated development environments (IDEs) that are
    excessively complex for beginners.  In this paper, we present a refactoring
    tool designed for beginner programmers, which we made available in
    DrRacket, a simple and pedagogical IDE.  Our tool provides several
    refactoring operations for the typical mistakes made by beginners and is
    intended to be used as part of their learning process.", 
  location     = "978-2-9557474-0-7", 
  location     = "https://www.youtube.com/watch?v=Sx-6WpiobIU"
}

@InProceedings{dacfqc,
  author       = "Dongol, Brijesh and Hierons, Robert~M.",
  title        = "Decidability and Complexity for Quiescent Consistency",
  booktitle    = pot # "31st Annual ACM/IEEE Symposium on Logic in Computer Science (LICS '16)",
  year         = 2016,
  pages        = "116--125",
  address      = nyny,
  month        = "5--8 " # jul,
  keywords     = "quiescent consistency, concurrent objects, decidability,
    finite automata, traces, correctness, membership",
  abstract     = "Quiescent consistency is a notion of correctness for a 
    concurrent object that gives meaning to the object's behaviours in
    quiescent states, i.e., states in which none of the object's operations are
    being executed.  The condition enables greater flexibility in object design
    by allowing more behaviours to be admitted, which in turn allows the
    algorithms implementing quiescent consistent objects to be more efficient
    (when executed in a multithreaded environment).  Quiescent consistency of
    an implementation object is defined in terms of a corresponding abstract
    specification.  This gives rise to two important verification questions:
    membership (checking whether a behaviour of the implementation is allowed
    by the specification) and correctness (checking whether all behaviours of
    the implementation are allowed by the specification).  In this paper, we
    consider the membership and correctness conditions for quiescent
    consistency, as well as a restricted form that assumes an upper limit on
    the number of events between two quiescent states.  We show that the
    membership problem for unrestricted quiescent consistency is NP-complete
    and that the correctness problem is decidable, coNEXPTIME-hard, and in
    EXPSPACE.  For the restricted form, we show that membership is in PTIME,
    while correctness is PSPACE-complete.", 
  location     = "https://doi.org/10.1145/2933575.2933576"
}

		  
@InProceedings{svaet,
  author       = "Javier Castillo and Pablo Heurta and Jos{\' e} Ignacio Mart{\' \i}nez",
  title        = "An Open-Source Tool for {SystemC} to {Verilog} Automatic Translation",
  booktitle    = "",
  year         = 2007,
  OPTeditor    = "",
  pages        = "347--354",
  keywords     = "",
  abstract     = "As the complexity of electronic systems increases, new ways
    for describing these systems are proposed.  One actual trend involves the
    use of system level languages that allows the description of the whole
    system in a higher abstraction level.  This type of methodology helps a
    designer to obtain an appropriate Hw-Sw partition, where the Sw is compiled
    to the target platform and the Hw is refined to bring it down to a lower
    level of abstraction in order to be synthesized.  This last step usually
    requires the use of a translation tool that from a description of the
    system in a system level modeling language, converts it to an equivalent
    one in a standard Hardware Description Language, usually Verilog or VHDL.
    This works presents a tool that from a SystemC RTL description generates
    its equivalent Verilog code ready to be synthesized by any standard Verilog
    Synthesis Tool.", 
  OPTlocation  = ""
}

@Article{erisrp,
  author       = "McKenzie, Bruce~J. and Yeatman, Corey and de Vere, Lorraine",
  title        = "Error Repair in Shift-Reduce Parsers",
  journal      = toplas,
  year         = 1995,
  volume       = 17,
  number       = 4,
  pages        = "672--689",
  month        = jul,
  keywords     = "algorithms, languages, theory, bison, error recovery, least
    cost error recovery, shift-reduce parsers, yacc",
  abstract     = "Local error repair of strings during CFG parsing requires the
    insertion and deletion of symbols in the region of a syntax error to
    produce a string that is error free.  Rather than precalculating tables at
    parser generation time to assist in finding such repairs, this article
    shows how such repairs can be found during shift-reduce parsing by using
    the parsing tables themselves.  This results in a substantial space saving
    over methods that require precalculated tables.  Furthermore, the article
    shows how the method can be integrated with lookahead to avoid finding
    repairs that immediately result in further syntax errors.  The article
    presents the results of experiments on a version of the LALR(1)-based
    parser generator Bison to which the algorithm was added.", 
  location     = "https://doi.org/10.1145/210184.210193"
}

@Article{dmaahv,
  author       = "Veen, Arthur~H.",
  title        = "Dataflow Machine Architecture",
  journal      = surveys,
  year         = 1986,
  OPTvolume    = 18,
  number       = 4,
  pages        = "365--396",
  month        = dec,
  keywords     = "data-driven architectures, dataflow machines, data structure
    storage, parallel execution, dataflow graphs, iterative and recursive
    constructs, packet communication, code copying, tagged tokens, matching", 
  abstract     = "Dataflow machines are programmable computers of which the
    hardware is optimized for fine-grain data-driven parallel computation.  The
    principles and complications of data-driven execution are explained, as
    well as the advantages and costs of fine-grain parallelism.  A general
    model for a dataflow machine is presented and the major design options are
    discussed.  Most dataflow machines described in the literature are surveyed
    on the basis of this model and its associated technology.  For
    general-purpose computing the most promising dataflow machines are those
    that employ packet-switching communication and support general recursion.
    Such a recursion mechanism requires an extremely fast mechanism to map a
    sparsely occupied virtual space to a physical space of realistic size.  No
    solution has yet proved fully satisfactory.  A working prototype of one
    processing element is described in detail.  On the basis of experience with
    this prototype, some of the objections raised against the dataflow approach
    are discussed.  It appears that the overhead due to fine-grain parallelism
    can be made acceptable by sophisticated compiling and employing special
    hardware for the storage of data structures.  Many computing-intensive
    programs show sufficient parallelism.  In fact, a major problem is to
    restrain parallelism when machine resources tend to get overloaded.
    Another issue that requires further investigation is the distribution of
    computation and data structures over the processing elements.", 
  location     = "https://doi.org/10.1145/27633.28055"
}

@Article{aafmusde,
  author       = "Ben-Shaul, Israel~Z. and Kaiser, Gail~E. and Heineman, George~T.",
  title        = "An Architecture for Multi-User Software Development Environments",
  journal      = cs,
  year         = 1993,
  volume       = 6,
  number       = 2,
  pages        = "65--113",
  month        = "Spring",
  keywords     = "synchronization, task management, data management,
    client-server architecture, transaction and lock management, marvel,
    process modeling, visualization, software development environment",
  abstract     = "We present an architecture for multi-user software
    development environments, covering general, process-centered and rule-based
    MUSDEs.  Our architecture is founded on componentization, with particular
    concern for the capability to replace the synchronization component--to
    allow experimentation with novel concurrency control mechanisms--with
    minimal effects on other components while still supporting integration.
    The architecture has been implemented for the MARVEL SDE, and we report our
    experience replacing and tailoring several parts of the synchronization
    component as part of Marvel", 
  location     = "https://www.usenix.org/publications/compsystems/1993/spr_benshaul.pdf"
}

@Article{asossmatcn,
  author       = "Ramamurthy, Bina and Melton, Austin",
  title        = "{A} Synthesis of Software Science Measures and the Cyclomatic Number",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1116--1121",
  month        = aug,
  keywords     = "control flow, cyclomatic number, software complexity,
    software complexity measure,   software complexity metric, software
    science, structured programs",
  abstract     = "A solution is obtained to the problem of defining a software
    measure or a family of measures which simultaneously detect those aspects
    of software complexity that are detected by the software science measures
    and the cyclomatic number.  The authors present a family of measures,
    called weighted measures that is built on the software science measures by
    adding weights to certain operators and operands; the size of the weights
    is determined by a theorem which relates nesting levels and the cyclomatic
    number.  Thus, by construction the weighted measures synthesize the
    software science measures and the cyclomatic number.  Further, by applying
    the weighted measures, the software science measures, and the cyclomatic
    number to sample programs, it is shown that the weighted measures also
    synthesize in practice the software science measures and the cyclomatic
    number.", 
  location     = "https://doi.org/10.1109/32.7622"
}

@Article{apatss,
  author       = "Freitag, Burkhard and Margaria, Tiziana and Steffen, Bernhard",
  title        = "{A} Pragmatic Approach to Software Synthesis",
  journal      = sigplan # " (" # pot # "Workshop on Interface Definition Languages, IDL '94)",
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "22--34",
  month        = aug,
  keywords     = "interface definition languages, interface constraints,
    modules, parameter configuration",
  abstract     = "We present a practice oriented tool for software synthesis
    that supports the interface-correct configuration of complex systems from a
    library of reusable software components.  Besides simply checking the
    interface-correctness of a link by means of type constraints, the tool is
    also designed to propose software components for solving a (loosely)
    specified problem within a certain context.  In particular, it identifies
    possible interfacing modules that in case of an interface-conflict may
    serve for the right conversion, transformation or parameter configuration.
    We illustrate our tool, which is based on the deductive database system
    LOLA, in three application specific settings.", 
  location     = "https://doi.org/10.1145/185084.185102"
}

@Article{biatmt,
  author       = "Kiselyov, Oleg and Shan, Chung-chieh and Friedman, Daniel~P. and Sabry, Amr",
  title        = "Backtracking, Interleaving, and Terminating Monad Tansformers",
  journal      = sigplan # " (" # pot # "Tenth ACM SIGPLAN International Conference on Functional Programming, ICFP '05)",
  year         = 2005,
  volume       = 40,
  number       = 9,
  pages        = "192--203",
  month        = sep,
  keywords     = "continuations, control delimiters, haskell, logic
    programming, prolog, streams, control strucures, backtracking computations,
    cuts, monads",
  abstract     = "We design and implement a library for adding backtracking
    computations to any Haskell monad.  Inspired by logic programming, our
    library provides, in addition to the operations required by the MonadPlus
    interface, constructs for fair disjunctions, fair conjunctions,
    conditionals, pruning, and an expressive top-level interface.  Implementing
    these additional constructs is easy in models of backtracking based on
    streams, but not known to be possible in continuation-based models.  We
    show that all these additional constructs can be generically and
    monadically realized using a single primitive msplit.  We present two
    implementations of the library: one using success and failure
    continuations; and the other using control operators for manipulating
    delimited continuations.", 
  location     = "https://doi.org/10.1145/1086365.1086390"
}

@Article{tapidpl,
  author       = "Atkinson, Malcolm~P. and Buneman, O.~Peter",
  title        = "Types and Persistance in Database Programming Languages",
  journal      = surveys,
  year         = 1987,
  volume       = 19,
  number       = 2,
  pages        = "105--170",
  month        = jun,
  keywords     = "conceptual languages, databases, data models, data types,
    embedded languages, integrated languages, object-oriented programming,
    persistence, persistent languages, polymorphism, programming languages,
    type inheritance",
  abstract     = "Traditionally, the interface between a programming language
    and a database has either been through a set of relatively low-level
    subroutine calls, or it has required some form of embedding of one language
    in another.  Recently, the necessity of integrating database and
    programming language techniques has received some long-overdue recognition.
    In response, a number of attempts have been made to construct programming
    languages with completely integrated database management systems.  These
    languages, which we term database programming languages, are the subject of
    this review.  The design of these languages is still in its infancy, and
    the purpose of writing this review is to identify the areas in which
    further research is required.  In particular, we focus on the problems of
    providing a uniform type system and mechanisms for data to persist.  Of
    particular importance in solving these problems are issues of polymorphism,
    type inheritance, object identity, and the choice of structures to
    represent sets of similar values.  Our conclusion is that there are areas
    of programming language research&mdash;modules, polymorphism, persistence,
    and inheritance&mdash;that must be developed and applied to achieve the
    goal of a useful and consistent database programming language.  Other
    research areas of equal importance, such as implementation, transaction
    handling, and concurrency, are not examined here in any detail.", 
  location     = "https://doi.org/10.1145/62070.45066"
}

@Article{acilfpbs,
  author       = "Russell, James~R. and Strom, Robert~E. and Yellin, Daniel~M.",
  title        = "{A} Checkable Interface Language for Pointer-Based Structures",
  journal      = sigplan # " (" # pot # "Workshop on Interface Definition Languages, IDL '94)",
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "59--73",
  month        = aug,
  keywords     = "constraints, interface specifications, dataflow analysis,
    lattices, idls",
  abstract     = "We present a technique for analysing structural constraints
    on data aggregates in high-level languages.  Our technique includes a
    formal constraint language and a dataflow algorithm for automatically
    checking equality constraints.  The constraint language is used to augment
    the type information on program interfaces.  For example, one can specify
    that a procedure must return aggregates A and B where each element in
    aggregate A points to some element in aggregate B, and that parameter C
    will have the properties of a rooted tree both on input and output.  Our
    dataflow algorithm tracks the constraints which must apply at each
    statement in order for the procedure to satisfy its interface, and detects
    invalid programs which fail to satisfy the constraints on their interfaces.
    We apply our technique to several examples.Our work is motivated by the
    requirements for expressive interface definition languages for distributed
    systems, and by the desire to mechanically check program modules against
    their interfaces.  Our analysis techniques also yield information which may
    enable compilers and stub generators to produce better implementations.", 
  location     = "https://doi.org/10.1145/185084.185105"
}

@Article{ptvaar,
  author       = "Waters, Richard~C.",
  title        = "Program Translation via Abstraction and Reimplementation",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1207--1228",
  month        = aug,
  keywords     = "artificial intelligence, compilation, program analysis,
    programmer's apprentice, program translation, program plans, abstraction",
  abstract     = "An abstraction-and-reimplementation paradigm is presented in
    which the source program is first analyzed in order to obtain a
    programming-language-independent abstract understanding of the computation
    performed by the program as a whole.  The program is then reimplemented in
    the target language based on this understanding.  The key to this approach
    is the abstract understanding obtained.  It allows the translator to
    benefit from an appreciation of the global features of the source program
    without being distracted by what are considered irrelevant details.
    Knowledge-based translation via abstraction and reimplementation is
    described as one of the goals of the Programmer's Apprentice project.  A
    translator which translates Cobol programs into Hibol (a very-high-level
    business data processing language) has been constructed.  A computer which
    generates extremely efficient PDP-11 object code for Pascal programs has
    been designed.", 
  location     = "https://doi.org/10.1109/32.7629"
}

@Article{ptovar,
  author       = "Smith, Geoffrey and Volpano, Denniso",
  title        = "Polymorphic Typing of Variables and References",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 3,
  pages        = "254--267",
  month        = may,
  keywords     = "languages, theory, verification, assignment, references,
    variables, type systems, weakly-typed variables",
  abstract     = "In this article we consider the polymorphic type checking of
    an imperative language.  Our language contains variables, first-class
    references (pointers), and first-class functions.  Variables, as in
    traditional imperative languages, are implicitly dereferenced, and their
    addresses (L-values) are not first-class values.  Variables are easier to
    type check than references and, in many cases, lead to more general
    polymorphic types.  We present a polymorphic type system for our language
    and prove that it is sound.  Programs that use variables sometimes require
    weak types, as in Tofte's type system for Standard ML, but such weak types
    arise far less frequently with variables than with references", 
  location     = "https://doi.org/10.1145/229542.229544",
  location     = "https://users.cs.fiu.edu/~smithg/papers/toplas96.pdf"
}

@Article{ttaoop,
  author       = "Scott Danforth and Chris Tomlinson",
  title        = "Type Theories and Object-Oriented Programming",
  journal      = surveys,
  year         = 1988,
  volume       = 20,
  number       = 1,
  edition      = "29--72",
  month        = mar,
  keywords     = "languages, theory, data abstraction, inheritance,
    object-oriented programming, polymorphism, type checking, type
    interference, abstract data types, subtyping", 
  abstract     = "Object-oriented programming is becoming a popular approach to
    the construction of complex software systems.  Benefits of object
    orientation include support for modular design, code sharing, and
    extensibility.  In order to make the most of these advantages, a type
    theory for objects and their interactions should be developed to aid
    checking and controlled derivation of programs and to support early binding
    of code bodies for efficiency.  As a step in this direction, this paper
    surveys a number of existing type theories and examines the manner and
    extent to which these theories are able to represent the ideas found in
    object-oriented programming.  Of primary interest are the models provided
    by type theories for abstract data types and inheritance, and the major
    portion of this paper is devoted to these topics.  Code fragments
    illustrative of the various approaches are provided and discussed.  The
    introduction provides an overview of object-oriented programming and types
    in programming languages; the summary provides a comparative evaluation of
    the reviewed typing systems, along with suggestions for future work.", 
  location     = "https://doi.org/10.1145/62058.62060"
}

@Article{asmftsacu,
  author       = "Scott, Michael~L. and Finkel, Raphael~A.",
  title        = "{A} Simple Mechanism for Type Security Across Compilation Units",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1238--1239",
  month        = aug,
  keywords     = "type checking, link-time checking, hash codes",
  abstract     = "A simple technique is described that detects structural-type
    clashes across compilation units with an arbitrarily high degree of
    confidence.  The type of each external object is described in canonical
    form.  A hash function compresses the description into a short code.  If
    the code is embedded in a symbol-table name, then consistency can be
    checked by an ordinary linker.  For distributed programs, run-time checking
    of message types can be performed with very little overhead.",
  location     = "https://doi.org/10.1109/32.7631"
}

@Article{didfds,
  author       = "Bochmann, Gregor",
  title        = "Delay-Independent Design for Distributed Systems",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1229--1237",
  month        = aug,
  keywords     = "distributed systems, regularity, distributed synchronization,
    module interconnections",
  abstract     = "Methods of limiting the impact of communication delays on the
    logical behavior of distributed systems are considered.  It is assumed that
    a distributed system is described in terms of a number of interconnected
    modules, and each module is described in terms of its possible states and
    the possible state transitions.  Transitions may be initiated spontaneously
    by a module and may give rise to output messages, which will be received,
    after some possible delay, by another module as an input.  Otherwise,
    transitions may be initiated by received input.  If the system has the
    property called regularity, its behavior is logically independent of the
    communication delays.  A simple condition for regularity is given.  This
    condition is the basis for the implementation of counter-based
    synchronization conditions in a distributed environment.  Weaker forms of
    regularity, which make abstraction of internal operations invisible from
    the point of view of an outside observer, are also considered.  The
    application of these concepts to the design of module interfaces involving
    'collisions' and to communication including timeouts is discussed in some
    detail with examples.", 
  location     = "https://doi.org/10.1109/32.7630"
}

@Article{tcbliittofp,
  author       = "Sands, David",
  title        = "Total Correctness by Local Improvement in the Transformation of Functional Programs",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 2,
  pages        = "175--234",
  month        = mar,
  keywords     = "correctness, improvement, operational equivalence, program
    transformation, fold-unfold",
  abstract     = "The goal of program transformation is to improve efficiency
    while preserving meaning.  One of the best-known transformation techniques
    is Burstall and Darlington's unfold-fold method.  Unfortunately the
    unfold-fold method itself guarantees neither improvement in efficiency nor
    total correctness.  The correctness problem for unfold-fold is an instance
    of a strictly more general problem: transformation by locally
    equivalence-preserving steps does not necessarily preserve (global)
    equivalence.  This article presents a condition for the total correctness
    of transformations on recursive programs, which, for the first time, deals
    with higher-order functional languages (both strict and nonstrict)
    including lazy data structures.  The main technical result is an
    improvement theorem which says that if the local transformation steps are
    guided by certain optimization concerns (a fairly natural condition for a
    transformation), then correctness of the transformation follows.  The
    improvement theorem makes essential use of a formalized improvement theory;
    as a rather pleasing corollary it also guarantees that the transformed
    program is a formal improvement over the original.  The theorem has
    immediate practical consequences: it is a powerful tool for proving the
    correctness of existing transformation methods for higher-order functional
    programs, without having to ignore crucial factors such as memoization or
    folding, and it yields a simple syntactic method for guiding and
    constraining the unfold-fold method in the general case so that total
    correctness (and improvement) is always guaranteed.", 
  location     = "https://doi.org/10.1145/227699.227716"
}

@Article{bsidadp,
  author       = "C{\' e}dric Bouhours and Herv{\' e} Leblanc and Christian Percebois",
  title        = "Bad Smells in Design and Design Patterns",
  journal      = jot,
  year         = 2009,
  volume       = 8,
  number       = 3,
  pages        = "43--63",
  month        = may # "-" # jun,
  keywords     = "spoiled patterns, design patterns, design reviews",
  abstract     = {To give a consistent and more valuable property on models,
    model-driven processes should be able to reuse the expert knowledge
    generally expressed in terms of patterns.  We focus our work on the design
    stage and on the systematically use of design patterns.  Choose a good
    design pattern and ensure the correct integration of the chosen pattern are
    non trivial for a designer who wants to use them.  To help designers, we
    propose design inspection in order to detect “bad smells in design” and
    models reworking through use of design patterns.  The automatic detection
    and the explanation of the misconceptions are performed thanks to spoiled
    patterns.  A “spoiled pattern” is a pattern which allows to instantiate
    inadequate solutions for a given problem: requirements are respected, but
    architecture is improvable.}, 
  location     = "http://www.jot.fm/issues/issue_2009_05/column5.pdf"
}

@Article{ddidd,
  author       = "Edgar Knapp",
  title        = "Deadlock Detection in Distributed Databases",
  journal      = surveys,
  year         = 1987,
  volume       = 19,
  number       = 4,
  pages        = "303--328",
  month        = dec,
  keywords     = "deadlock detection, deadlock models, distributed deadlocks,
    diffusing computations, global-state detection, edge-chasing algorithms,
    path-pushing algorithms, wait-for graphs",
  abstract     = "The problem of deadlock detection in distributed systems has
    undergone extensive study.  An important application relates to distributed
    database systems.  A uniform model in which published algorithms can be
    cast is given, and the fundamental principles on which distributed deadlock
    detection schemes are based are presented.  These principles represent
    mechanisms for developing distributed algorithms in general and deadlock
    detection schemes in particular.  In addition, a hierarchy of deadlock
    models is presented; each model is characterized by the restrictions that
    are imposed upon the form resource requests can assume.  The hierarchy
    includes the well-known models of resource and communication deadlock.
    Algorithms are classified according to both the underlying principles and
    the generality of resource requests they permit.  A number of algorithms
    are discussed in detail, and their complexity in terms of the number of
    messages employed is compared.  The point is made that correctness proofs
    for such algorithms using operational arguments are cumbersome and error
    prone and, therefore, that only completely formal proofs are sufficient for
    demonstrating correctness.", 
  location     = "https://doi.org/10.1145/45075.46163"
}

@Article{idlcrt,
  author       = "Gay, David~E.",
  title        = "Interface Definition Language Conversions: Recursive Types",
  journal      = sigplan # " (" # pot # "Workshop on Interface Definition Languages, IDL '94)",
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "101--110",
  month        = aug,
  keywords     = "interface conversions, distributed computation, type models,
    type recursion, pointers",
  abstract     = "A large heterogeneous network contains many applications
    developed in different environments, each with its own incompatible
    interface definition language.  One way of dealing with this diversity is
    to define a conversion from the interfaces of one system into another, thus
    giving access from the second system to the first.  This presents a number
    of difficulties, amongst which is the different representation of recursive
    types in different languages.  This paper gives two algorithms for
    converting the representation of such recursive types between different
    styles of interface definition languages.", 
  location     = "https://doi.org/10.1145/185084.185112"
}

@Article{osam,
  author       = "Abadi, Mart{\' \i}n and Cardelli, Luca",
  title        = "On Subtyping and Matching",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 4,
  pages        = "401--423",
  month        = jul,
  keywords     = "f-bounded subtyping, subtyping, self, matching, type
    operators, type theory, object types, inheritance, binary methods,
    protocols, recursive object types, higher-order subtyping",
  abstract     = "A relation between recursive object types, called matching,
    has been proposed as a generalization of subtyping.  Unlike subtyping,
    matching does not support subsumption, but it does support inheritance of
    binary methods.  We argue that matching is a good idea, but that it should
    not be regarded as a form of F-bounded subtyping (as was originally
    intended).  We show that a new interpretation of matching as higher-order
    subtyping has better properties.  Matching turns out to be a third-order
    construction, possibly the only one to have been proposed for general use
    in programming.", 
  location     = "https://doi.org/10.1145/233561.233563"
}

@Article{cbsfcwagdm,
  author       = "Kraemer, Kenneth~L. and King, John Leslie",
  title        = "Computer-Based Systems for Cooperative Work and Group Decision Making",
  journal      = surveys,
  year         = 1988,
  volume       = 20,
  number       = 2,
  pages        = "115--146",
  month        = jun,
  keywords     = "cooperative work, group decision making, system evaluation,
    decision making",
  abstract     = "Application of computer and communications technology to
    cooperative work and group decision making has grown out of three
    traditions: computer-based communications, computer:based information
    service provision, and computer-based decision support.  This paper reviews
    the group decision support systems (GDSSs) that have been configured to
    meet the needs of groups at work, and evaluates the experience to date with
    such systems.  Progress with GDSSs has proved to be slower than originally
    anticipated because of shortcomings with available technology, poor
    integration of the various components of the computing package, and
    incomplete understanding of the nature of group decision making.
    Nevertheless, the field shows considerable promise with respect to the
    creation of tools to aid in group decision making and the development of
    sophisticated means of studying the dynamics of decision making in
    groups.", 
  location     = "https://doi.org/10.1145/46157.46158"
}

@Article{oteeoapa,
  author       = "Choi, Jong-Deok and Cytron, R. and Ferrante, J.",
  title        = "On the Efficient Engineering of Ambitious Program Analysis",
  journal      = tse,
  year         = 1994,
  volume       = 20,
  number       = 2,
  pages        = "105--114",
  month        = feb,
  keywords     = "data-flow graphs, data-flow chains, data-flow analysis,
    reaching definitions, static single assignment, compact representation,
    demand-driven computation",
  abstract     = "Recent advances in languages, software design methodologies,
    and architecture have prompted the development of improved compile-time
    methods for analyzing the effects of procedure calls, pointer references,
    and array accesses.  Such sophistication, however, generally implies that
    compilers and programming environments will experience a corresponding
    increase in the volume of analysis information, which may be difficult to
    use efficiently.  In this paper, we consider the practical accommodation of
    such information.  Our results show how to engineer a compiler such that
    its optimization phase takes time proportional to the benefit, rather than
    the size, of such information.", 
  location     = "https://doi.org/10.1109/32.265631"
}

@Article{doatfsapcp,
  author       = "De Francesco, Nicoletta and Vaglini, Gigliola",
  title        = "Description of a Tool for Specifying and Prototyping Concurrent Programs",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1554--1564",
  month        = nov,
  keywords     = "automatic programming, events, historical references,
    programming environment, rapid prototyping, specification language
  environment, specification of concurrent programs",
  abstract     = "",
  location     = ""
}

@Article{hrocosr,
  author       = "Hanan Samet",
  title        = "Hierarchical Representations of Collections of Small Rectangles",
  journal      = surveys,
  year         = 1988,
  volume       = 20,
  number       = 4,
  pages        = "271--309",
  month        = dec,
  keywords     = "cartography, geographic information systems, interval trees,
    hierarchical data structures, multidimensional data structures, plane-sweep
    methods, priority search trees, quadtrees, R-trees, rectangle intersection
    problem, rectangles, representative points, segment trees, vlsi design rule
    checking",
  abstract     = "A tutorial survey is presented of hierarchical data
    structures for representing collections of small rectangles.  Rectangles
    are often used as an approximation of shapes for which they serve as the
    minimum rectilinear enclosing object.  They arise in applications in
    cartography as well as very large-scale integration (VLSI) design rule
    checking.  The different data structures are discussed in terms of how they
    support the execution of queries involving proximity relations.  The focus
    is on intersection and subset queries.  Several types of representations
    are described.  Some are designed for use with the plane-sweep paradigm,
    which works well for static collections of rectangles.  Others are oriented
    toward dynamic collections.  In this case, one representation reduces each
    rectangle to a point in a higher multidimensional space and treats the
    problem as one involving point data.  The other representation is area
    based&mdash;that is, it depends on the physical extent of each rectangle.",
  location     = "http://dl.acm.org/citation.cfm?id=50021"
}

@Article{spbrtewpcs,
  author       = "Ceri, Stefano and Crespi-Reghizzi, Stefano and Di~Maio, Aandrea and Lavazza, Luigi~A.",
  title        = "Software Prototyping by Relational Techniques:  Experiences with Program Construction Systems",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1597--1609",
  month        = nov,
  keywords     = "ada, program construction environments, rapid prototyping,
  relational programming, target computer description",
  abstract     = "A method for designing and prototyping program construction
    systems using relational databases is presented.  Relations are the only
    data structures used inside the systems and for interfaces; programs
    extensively use relational languages, in particular relational algebra.
    Two large projects are described.  The Ada Relational Translator (ART) is
    an experimental compiler-interpreter for Ada in which all subsystems,
    including the parser, semantic analyzer, interpreter, kernel, and debugger,
    use relations as their only data structure; the relational approach has
    been pushed to the utmost to achieve fast prototyping in a student
    environment.  Multi-Micro Line (MML) is a tool set for constructing
    programs for multimicroprocessors' targets, in which relations are used for
    allocation and configuration control.  Both experiences validate the
    approach for managing teamwork in evolving projects, identify areas where
    this approach is appropriate, and raise critical issues.", 
  location     = "https://doi.org/10.1109/32.9048"
}

@Article{galfsaiovp,
  author       = "Ambler, Allen~L. and Good, Donald~I. and Browne, James~C. and Burger, Wilhelm~F. and Cohen, Richard~M. and Hoch, Charles~G. and Wells, Robert~E.",
  title        = "{GYPSY}: {A} Language for Specification and Implementation of Verifiable Programs",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design For Reliable Software)",
  year         = 1977,
  month        = mar,
  volume       = 12,
  number       = 3,
  pages        = "1--10",
  keywords     = "verification, pascal, language design, incremental
    development, specification",
  abstract     = "An introduction to the Gypsy programming and specification
    language is given.  Gypsy is a high-level programming language with
    facilities for general programming and also for systems programming that is
    oriented toward communications processing.  This includes facilities for
    concurrent processes and process synchronization.  Gypsy also contains
    facilities for detecting and processing errors that are due to the actual
    running of the program in an imperfect environment.  The specification
    facilities give a precise way of expressing the desired properties of the
    Gypsy programs.  All of the features of Gypsy are fully verifiable, either
    by formal proof or by validation at run time.  An overview of the language
    design and a detailed example program are given.", 
  location     = "https://doi.org/10.1145/390017.808306"
}

@Article{aocdics,
  author       = "Colbourn, Charles~J. and van Oorschot, Paul~C.",
  title        = "Applications of Combinatorial Designs in Computer Science",
  journal      = surveys,
  year         = 1989,
  volume       = 21,
  number       = 2,
  pages        = "223--250",
  month        = jun,
  keywords     = "algorithms, design, security, theory, authentication,
    combinatorial design, distributed consensus, file organization,
    intercommunication networks memory access, parallel algorithms, parallel
    sorting", 
  abstract     = "The theory of combinatorial designs has been used in widely
    different areas of computation concerned with the design and analysis of
    both algorithms and hardware.  Combinatorial designs capture a subtle
    balancing property that is inherent in many difficult problems and hence
    can provide a sophisticated tool for addressing these problems.  The role
    of combinatorial designs in solving many problems that are basic to the
    field of computing is explored in this paper.  Case studies of many
    applications of designs to computation are given; these constitute a first
    survey, which provides a representative sample of uses of designs.  More
    importantly, they suggest paradigms in which designs can be used profitably
    in algorithm design and analysis.", 
  location     = "https://doi.org/10.1145/66443.66446"
}

@Article{otuorefst,
  author       = "Clarke, Charles~L.~A. and Cormack, Gordon~V.",
  title        = "On the Use of Regular Expressions for Searching Text",
  journal      = toplas,
  year         = 1997,
  volume       = 19,
  number       = 3,
  pages        = "413--426",
  month        = may,
  keywords     = "specialized application languages, regular expressions,
    regular languages, sgml",
  abstract     = "The use of regular expressions for text search is widely
    known and well understood.  It is then surprising that the standard
    techniques and tools prove to be of limited use for searching structured
    text formatted with SGML or similar markup languages.  Our experience with
    structured text search has caused us to reexamine the current practice.
    The generally accepted rule of &ldquo;leftmost longest match&rdquo; is an
    unfortunate choice and is at the root of the difficulties.  We instead
    propose a rule which is semantically cleaner.  This rule is generally
    applicable to a variety of text search applications, including source code
    analysis, and has interesting properties in its own right.  We have written
    a publicly available search tool implementing the theory in the article,
    which has proved valuable in a variety of circumstances.", 
  location     = "https://doi.org/10.1145/256167.256174"
}

@Article{dcpcem,
  author       = "McDowell, Charles~E. and Helmbold, David~P.",
  title        = "Debugging Concurrent Programs",
  journal      = surveys,
  year         = 1989,
  volume       = 21,
  number       = 4,
  pages        = "593--622",
  month        = dec,
  keywords     = "distributed computing, event history, nondeterminism,
    parallel processing, probe effect, program replay, program visualization,
    static analysis",
  abstract     = "The main problems associated with debugging concurrent
    programs are increased complexity, the probe effect, nonrepeatability, and
    the lack of a synchronized global clock.  The probe effect refers to the
    fact that any attempt to observe the behavior of a distributed system may
    change the behavior of that system.  For some parallel programs, different
    executions with the same data will result in different results even without
    any attempt to observe the behavior.  Even when the behavior can be
    observed, in many systems the lack of a synchronized global clock makes the
    results of the observation difficult to interpret.  This paper discusses
    these and other problems related to debugging concurrent programs and
    presents a survey of current techniques used in debugging concurrent
    programs.  Systems using three general techniques are described:
    traditional or breakpoint style debuggers, event monitoring systems, and
    static analysis systems.  In addition, techniques for limiting, organizing,
    and displaying a large amount of data produced by the debugging systems are
    discussed.", 
  location     = "https://doi.org/10.1145/76894.76897"
}

@Article{eiaoortcipa,
  author       = "Fischer, Charles~N. and LeBlanc, Richard~J.",
  title        = "Efficient Implementation and Optimization of Run-Time Checking in {{P}}ascal",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design For Reliable Software)",
  year         = 1977,
  month        = mar,
  volume       = 12,
  number       = 3,
  pages        = "19--24",
  keywords     = "pascal, run-time check generation, run-time check
    optimization, discriminated type unions, pointers, heap management,
    by-reference parameters, programming language design",
  abstract     = "Complete run-time checking of programs is an essential tool
    for the development of reliable software.  A number of features of the
    programming language PASCAL (arrays, subranges, pointers, record variants
    (discriminated type unions), formal procedures, etc.) can require some
    checking at run-time as well as during compilation.  The problem of
    efficiently implementing such checking is considered.  Language
    modifications to simplify such checking are suggested.  The possibility of
    optimizing such checking is discussed.", 
  location     = "https://doi.org/10.1145/390018.808308"
}

@Article{notdoe,
  author       = "Popek, Gerald~J. and Horning, J.~J. and Lampson, Butler~W. and Mitchell, J.~G. and London, Ralph~L.",
  title        = "Notes on the Design of {E}uclid",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design For Reliable Software)",
  year         = 1977,
  month        = mar,
  volume       = 12,
  number       = 3,
  pages        = "11--18",
  keywords     = "euclid, verification, system programming language,
    reliability, pascal, aliasing, data encapsulation, parameterized types,
    visibility of names, machine dependencies, legality assertions, storage
    allocation, language design",
  abstract     = "Euclid is a language for writing system programs that are to
    be verified.  We believe that verification and reliability are closely
    related, because if it is hard to reason about programs using a language
    feature, it will be difficult to write programs that use it properly.  This
    paper discusses a number of issues in the design of Euclid, including such
    topics as the scope of names, aliasing, modules, type-checking, and the
    confinement of machine dependencies; it gives some of the reasons for our
    expectation that programming in Euclid will be more reliable (and will
    produce more reliable programs) than programming in Pascal, on which Euclid
    is based.", 
  location     = "https://doi.org/10.1145/800022.808307"
}

@Manual{tlt,
  title        = "The \LaTeX{}2HTML Translator",
  author       = "Nikos Drakos",
  organization = "Computer Based Learning Unit, University of Leeds",
  year         = 1996,
  month        = "7 " # jun,
  keywords     = "latex, html, documentation",
  location     = "http://www.latex2html.org/"
}

@TechReport{apapssewm,
  author       = "Ernst~W. Mayr and Richard~J. Anderson and Peter~H. Hochschild", 
  title        = "{A} Programming and Problem-Solving Seminar",
  institution  = csd # "Stanford University",
  year         = 1985,
  number       = "CS-TR-85-1072",
  address      = sca,
  month        = oct,
  keywords     = "integer bricks, scheduling, presburger arithmetic, graphics,
    parallel computation bottelnecks",
  abstract     = "This report contains edited transcripts of the discussions
    held in Stanford's course CS204, Problem Seminar, during winter quarter
    1984.  The course topics consisted of five problems coming from different
    areas of computer science.  The problems were discussed in class and solved
    and programmed by the students working in teams.", 
  location     = "http://i.stanford.edu/TR/CS-TR-85-1072.html"
}

@TechReport{mmlo,
  author       = "Sergei Romanenko and Peter Setsoft",
  title        = "Moscow {ML} Language Overview",
  institution  = "Russian Academy of Sciences",
  year         = 1996,
  address      = "Moscow, Russia",
  month        = "1 " # jul,
  keywords     = "ml, functional programming",
  abstract     = "This is a compact reference to the language implemented by
    Moscow ML, a subset of Standard ML.  For reference material on Standard ML,
    see Milner, Tofte, Harper and MacQueen: The Definition ofStandard ML, The
    MIT Press 1997.  Moscow ML implements parts of the SML Basis Library.
    Section 14 of this manual lists all structure, type, constructor, value,
    function, and exception identifiers defined by Moscow ML.", 
  location     = "https://pdfs.semanticscholar.org/b3b9/88556dbe706cf1ab8cd6e0a95c36a04ad93f.pdf"
}

@TechReport{hefim,
  author       = "Steven Deering",
  title        = "Host Extensions for {IP} Multicasting",
  institution  = "Network Working Group",
  year         = 1989,
  type         = "Request for Comment",
  number       = 1112,
  address      = "Stanford University",
  abstract     = "This memo specifies the extensions required of a host
    implementation of the Internet Protocol (IP) to support multicasting.  It
    is the recommended standard for IP multicasting in the Internet.
    Distribution of this memo is unlimited.", 
  month        = aug,
  keywords     = "ip, multicasting, host group addresses, multicast ip
    datagrams, internet group management protocol",
  location     = "https://www.rfc-editor.org/rfc/pdfrfc/rfc1112.txt.pdf"
}

@TechReport{t7p,
  author       = "David Gries",
  title        = "The 711 Problem",
  institution  = dcs # "Cornell University",
  year         = 1982,
  number       = "82-493",
  address      = "Cornell, N.Y.",
  month        = may,
  keywords     = "puzzles, pascal, saddle-back search",
  abstract     = "Write a program that, given two positive integer M and N,
    will find 4 integers, called b, c, d, and e, satisfying (1) 0 <= b, c, d, e
    <= N, (2) b + c + d + e = M, and (3) b*c*d*e = M.  Call such a tuple (b, c,
    d, e) a solution.  If no solution exist, indicate that in some fashion.",
  location     = "https://ecommons.cornell.edu/handle/1813/6333"
}

@TechReport{otctbuidtis,
  author       = "David Garlan and Gail Kaiser and David Notkin",
  title        = "On the Criteria To Be Used In Composing Tools Into Systems",
  institution  = "Tektronix Laboratories",
  year         = 1988,
  number       = "TR 88-08-09",
  month        = aug,
  keywords     = "system decomposition, tools, shared data structures, abstract
    data types"
}

@TechReport{itl,
  author       = "Christopher~W. Fraser and David~R. Hanson",
  title        = "Installing {\tt lcc}",
  institution  = "AT\&T Bell Laboratories",
  year         = 1992,
  address      = mhnj,
  month        = "15 " # sep,
  keywords     = "lcc, compilers, c",		  
  location     = "http://drh.github.io/lcc/current/doc/install.html"
}

@TechReport{tblcr,
  author       = "Piti Disyatat",
  title        = "The Bank Lending Channel Revisited",
  institution  = "Bank for International Settlements",
  year         = 2010,
  type         = "BIS Working Papers",
  number       = 297,
  address      = "Basel, Switzerland",
  month        = feb,
  keywords     = "monetary policy, bank lending,channel, bank capital, credit,
    money", 
  abstract     = "A central proposition in research on the role that banks play
    in the transmission mechanism is that monetary policy imparts a direct
    impact on deposits and that deposits, insofar as they constitute the supply
    of loanable funds, act as the driving force of bank lending.  This paper
    argues that the emphasis on policy-induced changes in deposits is
    misplaced.  A reformulation of the bank lending channel is proposed that
    works primarily through the impact of monetary policy on banks' balance
    sheet strength and risk perception.  Such a recasting implies, contrary to
    conventional wisdom, that greater reliance on market-based funding enhances
    the importance of the channel.  The framework also shows how banks,
    depending on the strength of their balance sheets, could act either as
    absorbers or amplifiers of shocks originating in the financial system.", 
  location     = "http://www.bis.org/publ/work297.htm"
}

@InBook{cafpltam,
  author       = "Luca Cardelli",
  title        = "Combinators and Functional Programming Languages",
  chapter      = "The Amber Machine",
  publisher    = "Springer",
  year         = 1986,
  editor       = "G.~Cousineau and P.-L. Curien and B.~Robinet",
  pages        = "48--70",
  volume       = 242,
  series       = lncs,
  address      = "Berlin",
  keywords     = "virtual machines",
  keywords     = "The Amber machine is a stack machine designed as an
    intermediate language for compiling higher-order languages.  The current
    version is specialized for the Amber language.  The machine supports a set
    of basic and structured data types, functional closures, signals, bitmap
    graphics, persistent objects and meta-level execution.  The latter is
    needed as the Amber compiler is entirely written in Amber (above the Amber
    machine level) and needs to switch level when executing a program it has
    just compiled.  A set of implementation strategies are admissible for this
    machine, including byte-code interpretation, threaded code interpretation
    and compilation to native code.  The current implementation is based on a
    byte-code interpreter and a onespace compacting collector, and runs on a
    Macintosh.", 
  location     = "https://doi.org/10.1007/3-540-17184-3_39"
}
