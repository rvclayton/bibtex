.so bibtex.header
		  
@string{ir95      = " (ACM SIGPLAN Workshop on Intermediate Representations, IR '95)"}
@string{sosp95    = osr # " (" # pot # "Fifteenth ACM Symposium on Operating Systems Principles)"}
@string{usenixw94 = pot # "Winter 1994 USENIX Conference"}

@Book{tdoetn,
  author       = "Tom Nichols",
  title        = "The Death of Expertise",
  publisher    = oup,
  year         = 2017,
  address      = nyny,
  keywords     = "expertise, knowledge, politics, technocracy, education,
    media, merit", 
  location     = "HM 851.N54"
}

@Book{tsrjb,
  author       = "John Brunner",
  title        = "The Shockwave Rider",
  publisher    = "Harper \& Row",
  year         = 1975,
  address      = nyny,
  keywords     = "future, networking, security, secrecy",
  location     = "PR 6052.R8"
}

@Book{srs,
  author       = "Robin Sloan",
  title        = "Sourdough",
  publisher    = fsg,
  year         = 2017,
  address      = nyny,
  keywords     = "techology, food science, breadmaking",
  location     = "PS 3619.L6278 S67"
}

@Book{snttd,
  author       = "Ian Zack",
  title        = "Say No to the Devil",
  publisher    = ucp,
  year         = 2015,
  address      = chil,
  keywords     = "blues, gary davis, guitarists, street preachers, folk music",
  location     = "ML 419.D386 Z33"
}

@Book{dicnm,
  author       = "Nancy MacLean",
  title        = "Democracy in Chains",
  publisher    = "Viking",
  year         = 2017,
  address      = nyny,
  keywords     = "libertarianism, democracy, the kochs, james buchanan, public
    choice economics, governance",
  location     = "HN 49.R33 M23"
}

@Book{plpip,
  author       = "Steve Gregory",
  title        = "Parallel Logic Programming in {PARLOG}",
  publisher    = "Addison-Wesley",
  year         = 1987,
  address      = "Wokingham, England",
  keywords     = "parallel logic programming, parlog, and/or tree model, and
    tree model, compile-time analysis",
  location     = "QA 76.73.P194 G74"
}

@Book{tghsr,
  author       = "Salman Rushdie",
  title        = "The Golden House",
  publisher    = "Random House",
  year         = 2017,
  address      = nyny,
  keywords     = "2016 us election, crime, india, visual artists",
  location     = "PR 6068.U757 G65"
}

@Book{tjgrbp,
  author       = "Robert~B. Parker",
  title        = "The Judas Goat",
  publisher    = "Houghton Mifflin",
  year         = 1978,
  address      = boma,
  keywords     = "terra, london, olympics",
  location     = "PS 3566.A686"
}

@Book{qobemh,
  author       = "Elaine~M. Hayes",
  title        = "Queen of Bebop",
  publisher    = "Ecco",
  year         = 2017,
  address      = nyny,
  keywords     = "sarah vaughan, jazz",
  location     = "ML 420.V3 H39"
}

@Book{prbp1992,
  author       = "Robert~B. Parker",
  title        = "Pastime",
  publisher    = "Berkley Books",
  year         = 1992,
  price        = "$7.99",
  address      = nyny,
  keywords     = "parents and children",
  location     = "PS 3566.A686 P34"
}

@Book{lfcib,
  author       = "Ian Bassingthwaighte",
  title        = "Live from Cairo",
  publisher    = "Scribner",
  year         = 2017,
  address      = nyny,
  keywords     = "displacement, egypt, cairo, revolution",
  location     = "PS 3602.A8492 L59"
}

@Book{ctew,
  author       = "Rubin Fine",
  title        = "Chess the Easy Way",
  publisher    = "David McKay",
  year         = 1942,
  address      = nyny,
  keywords     = "chess",
  location     = "GV 1445 F55"
}

@Book{whhrc,
  author       = "Hillary Rodham Clinton",
  title        = "What Happened",
  publisher    = "Simon \& Schuster",
  year         = 2017,
  address      = nyny,
  keywords     = "2016 election, politics, media",
  location     = "9 781501 175565"
}

@Book{rbmp,
  author       = "Michael Poore",
  title        = "Reincarnation Blues",
  publisher    = "Del Rey",
  year         = 2017,
  address      = nyny,
  keywords     = "reincarnation, death, learning, doing good",
  location     = "PS 3616.O644 R45"
}

@Book{zbb,
  author       = "Bob Berman",
  title        = "Zapped",
  publisher    = "Little, Brown",
  year         = 2017,
  address      = nyny,
  keywords     = "the electromagnetic spectrum",
  location     = "QC 358.5.B47"
}

@Book{gvrk,
  author       = "Rachel Khong",
  title        = "Goodbye, Vitamin",
  publisher    = "Henry Holt",
  year         = 2017,
  address      = nyny,
  keywords     = "alzheimer's, aimlessness",
  location     = "PS 3611.H66 G66"
}

@Book{l30mt,
  author       = "Max Tegmark",
  title        = "Life 3.0",
  publisher    = "Knopf",
  year         = 2017,
  address      = nyny,
  keywords     = "intelligence, artificial intelligence, AGI, cosmology",
  location     = "Q 334.7.T44"
}

@Book{trrmi,
  author       = "Ryan McIlvain",
  title        = "The Radicals",
  publisher    = "Hogarth",
  year         = 2018,
  address      = nyny,
  keywords     = "protest, violent action",
  location     = "PS 3613.C535 R33"
}

@Book{aaatp,
  author       = "Tim Peake",
  title        = "Ask an Astronaut",
  publisher    = "Little, Brown",
  year         = 2017,
  address      = nyny,
  keywords     = "iss, space travel, space walks, ",
  location     = ""
}

@Book{fcje,
  author       = "Jeffrey Eugenides",
  title        = "Fresh Complaint",
  publisher    = fsg,
  year         = 2017,
  address      = nyny,
  keywords     = "escape, travel, parentage, debt, dreams, separation,
    progress, artichokes, theft, duplicity",
  location     = "PS 3555.U4 A6"
}

@Book{twatp,
  author       = "Charles~C. Mann",
  title        = "The Wizard and the Prophet",
  publisher    = "Alfred~A. Knopf",
  year         = 2018,
  address      = nyny,
  keywords     = "ecology, technology, vogt, borlaug, green revolution",
  location     = "GE 56.V64 M36"
}

@Book{capfd,
  author       = "Fyodor Dostoevsky",
  title        = "Crime and Punishment",
  publisher    = "Liveright",
  year         = 2018,
  translator   = "Michael~R. Katz",
  address      = nyny,
  keywords     = "crime, punishment",
  location     = "PG 3326.P7"
}

@Book{rbds,
  title        = "Reconstruction",
  publisher    = "The Library of America",
  year         = 2018,
  editor       = "Brooks~D. Simpson",
  address      = nyny,
  keywords     = "civil war, reconstruction, politics"
}

@Book{sosv,
  author       = "Anna Yen",
  title        = "Sophia of Silicon Valley",
  publisher    = "William Morrow",
  year         = 2018,
  address      = nyny,
  keywords     = "work-life balance, entrepreneurs"
}

@Book{sdd,
  author       = "Deborah Davis",
  title        = "Strapless",
  publisher    = "Tarcher/Penguin",
  year         = 2003,
  address      = nyny,
  keywords     = "virginie amilie avegno gautreau, john singer sargent, paris
    art scene",
  location     = "ND 237.S3 D38"
}

@Book{thtc,
  author       = "T.~C. Boyle",
  title        = "The Harder They Come",
  publisher    = "Ecco",
  year         = 2015,
  address      = nyny,
  price        = "$15.88",
  keywords     = "violence, sovereign citizens, madness",
  location     = ""
}

@Book{ttmjhy,
  author       = "James Harvey Young",
  title        = "The Toadstool Millionaires",
  publisher    = pup,
  year         = 1961,
  address      = prnj,
  keywords     = "patent medicines, folk medicine",
  location     = "RM 671.A1 Y6"
}

@Book{sitg,
  author       = "Nassim Nicholas Taleb",
  title        = "Skin in the Game",
  publisher    = "Random House",
  year         = 2018,
  address      = nyny,
  keywords     = "risk, sociology, vitriol, information asymmetry, intellectuals",
  location     = "HM 1101.T35"
}

@Book{taoipij,
  author       = "Kenny~A. Hunt",
  title        = "The Art of Image Processing in Java",
  publisher    = "A.~K. Peters",
  year         = 2010,
  address      = "Natick, MA",
  keywords     = "optics, human vision, digital images, java, point processing,
    region processing, geometric operations, image printing, image display,
    frequency domain, image compression, morphological image processing",
  location     = "TA 1637.H87"
}

@Book{fpaai,
  author       = "Peter Henderson",
  title        = "Functional Programming:  Application and Implementation",
  publisher    = ph,
  year         = 1980,
  address      = ecnj,
  keywords     = "functions, programs, functional languages, functional
    programs, program representation, program interpretation, imperative
    programs, machine architectures, non-determinism, backtracking, delayed
    evaluation, higher-order functions",
  location     = "QA 76.6"
}

@Book{tpla,
  author       = "Nafkote Tamirat",
  title        = "The Parking Lot Attendant",
  publisher    = "Henry Holt",
  year         = 2018,
  address      = nyny,
  keywords     = "immigrants, duplicity",
  location     = "PS 3620.A67 P37"
}

@Book{aiapjc,
  author       = "Patrick~J. Charles",
  title        = "Armed in America",
  publisher    = "Prometheus Books",
  year         = 2018,
  address      = "Amherst, " # NY,
  keywords     = "firearms, laws and legislation, gun control, constitutional law",
  location     = "KF 3941.C49"
}

@Book{tdplgb,
  author       = "Gilad Bracha",
  title        = "The Dart Programming Language",
  publisher    = aw,
  year         = 2016,
  address      = boma,
  keywords     = "dart, reflection, type systems, object-oriented programming,
    concurrency, futures, mixins, libraries, functions, asyncrony",
  location     = "QA 76.73.D23 B73"
}

@Book{ildck,
  author       = "Chris Kraus",
  title        = "{I} Love Dick",
  publisher    = "Semiotext(e)",
  year         = 2006,
  address      = "Los Angeles, " # CA,
  keywords     = "letters, art damage",
  location     = "PS 3561.R2873 I15 2006a"
}

@Book{desic,
  author       = "Kevin Watkins",
  title        = "Discrete Event Simulation in {C}",
  publisher    = "McGraw-Hill",
  year         = 1993,
  address      = nyny,
  keywords     = "random numbers, modeling",
  location     = "QA 76.73.C15 W39"
}

@Book{smtktikbi,
  title        = "Student Modelling:  The Key to Individualized Knowledge-Based Instruction",
  publisher    = "Springer",
  year         = 1994,
  editor       = "Jim~E. Greer and Gordon~I. McCalla",
  address      = "Berlin, Germany",
  keywords     = "student models, learning",
  location     = "LB 1028.45 S74"
}

@Book{mamgc,
  author       = "Gregory Claeys",
  title        = "Marx and Marxism",
  publisher    = "Nation Books",
  year         = 2018,
  address      = nyny,
  keywords     = "marx, marxism, history, politics, economics",
  location     = ""
}

@Book{tkmg,
  author       = "Martha Grimes",
  title        = "The Knowledge",
  publisher    = "Atlantic Monthly Press",
  year         = 2018,
  address      = nyny,
  keywords     = "murrdaar, money, revenge",
  location     = "PS 3557.R48998 K67 2018b"
}

@Book{jjfd,
  author       = "Fiona Donovan",
  title        = "Jasper Johns",
  publisher    = "Thames \& Hudson",
  year         = 2017,
  address      = loen,
  keywords     = "late 20th century art",
  location     = "N 6537.J6 D66 2017"
}

@Book{tospm,
  author       = "Paolo Maurensig",
  title        = "Theory of Shadows",
  publisher    = fsg,
  year         = 2018,
  address      = nyny,
  keywords     = "chess, collaboration, history, alekhine",
  location     = "PQ 4873.A8947 T46513"
}

@Book{wbit,
  author       = "Robert Wright",
  title        = "Why Buddhism is True",
  publisher    = "Simon \& Schuster",
  year         = 2017,
  address      = nyny,
  keywords     = "buddhism, psychology, meditation, mental life",
  location     = "BQ 4050.W75 "
}

@Book{tosjb,
  author       = "Julian Barnes",
  title        = "The Only Story",
  publisher    = "Alfred~A. Knpof",
  year         = 2018,
  address      = nyny,
  keywords     = "lurv",
  location     = "PR 6052.A6657 O55"
}

@Book{atpsb,
  author       = "Naomi Prins",
  title        = "All The Presidents' Bankers",
  publisher    = "Nation Books",
  year         = 2014,
  address      = nyny,
  keywords     = "finance, capitalism, banking, regulation, politics",
  location     = "E 743.P74"
}

@Book{tslot,
  author       = "Anonymous",
  title        = "The Secret Life of Teachers",
  publisher    = ucp,
  year         = 2015,
  address      = chil,
  keywords     = "teaching, high school",
  location     = "LB 1777.3.N4 D49"
}

@Book{asfad,
  author       = "Joshua Mattson",
  title        = "A Short Film About Disappointment",
  publisher    = "Penguin",
  year         = 2018,
  address      = nyny,
  keywords     = "trauma, drama, movie reviews",
  location     = "PS 3613.A8665 S56"
}

@Book{tpots,
  author       = "Ocatvia~E. Butler",
  title        = "The Parable of the Sower",
  publisher    = "Warner Books",
  year         = 2000,
  address      = nyny,
  keywords     = "dystopia, travel, survival, spiritualism",
  location     = "PS 3552.U827 P37"
}

@Book{crs,
  author       = "Roger Scruton",
  title        = "Conservatism",
  publisher    = "All Points Books",
  year         = 2017,
  address      = nyny,
  keywords     = "conservatism, philosophy, european conservatism, socialism,
    cultural conservatism"
}

@Book{vab,
  author       = "Evelyne Bloch-Dano",
  title        = "Vegetables: {A} Biography",
  publisher    = ucp,
  year         = 2012,
  address      = chil,
  keywords     = "artichoke, jerusalem artichoke, cabbage, parsnip, carrot,
    pea, tomato, bean, pumpkin, chili pepper",
  location     = "SN 320.5.B6613"
}

@Book{tnmvl,
  author       = "Mario Vargas Llosa",
  title        = "The Neighborhood",
  publisher    = fsg,
  year         = 2016,
  address      = nyny,
  keywords     = "yellow press, corruption, high-jinks",
  location     = "PQ 8498.32.A65 C49513"
}

@Book{svyl,
  author       = "Yasha Levine",
  title        = "Surveillance Valley",
  subtitle     = "The Secret Military History of the Internet",
  publisher    = "Public Affairs",
  year         = 2018,
  address      = nyny,
  keywords     = "spying, internet, darpa, edward snowdon, jacob applebaum,
    tor, signal, the octopus",
  location     = "TK 7882.E2 L48"
}

@Book{cp1jdh,
  author       = "Jacqueline~D. Hamilton",
  title        = "{CGI} Programming 101",
  publisher    = "CGI101.COM",
  year         = 2004,
  address      = "Houston, Texas",
  edition      = "2nd",
  keywords     = "perl, cgi, www",
  location     = "QA 76.625.H36"
}

@Book{pmc,
  author       = "Margaret Cuozon",
  title        = "Paradox",
  publisher    = mitp,
  year         = 2014,
  address      = cma,
  keywords     = "paradox, philosophy, liar's paradox, sorties paradox, zeno,
    subjective probability",
  location     = "BC 199.P2 C86"
}

@Book{prarx,
  author       = "Andromeda Romano-Lax",
  title        = "Plum Rains",
  publisher    = "Soho Press",
  year         = 2018,
  address      = nyny,
  keywords     = "japan, robots, ai, immigration policies, guest workers",
  location     = "PS 3618.O59 P58"
}

@Book{hlthw,
  author       = "T.~Harry Williams",
  title        = "Huey Long",
  publisher    = "Knopf",
  year         = 1969,
  address      = nyny,
  keywords     = "huey p. long, politics, southern politics, populism",
  location     = "E 748.L86 W48"
}

@Book{erdc,
  author       = "Douglas Coupland",
  title        = "Eleanor Rigby",
  publisher    = "Bloomsbury",
  year         = 2004,
  address      = nyny,
  keywords     = "quirky people, improbable events",
  location     = "PS 3553.O855 E44"
}

@Book{ensp,
  author       = "Steven Pinker",
  title        = "Enlightenment Now",
  subtitle     = "The Case for Reason, Science, Humanism and Progress",
  publisher    = "Viking",
  year         = 2018,
  address      = nyny,
  keywords     = "enlightenment, progress, science, reason, humanism",
  location     = "HM 891.P56"
}

@Book{bth2018,
  author       = "Thor Hanson",
  title        = "Buzz",
  subtitle     = "The Nature and Necessity of Bees",
  publisher    = "Basic Books",
  year         = 2018,
  address      = nyny,
  keywords     = "bees, evolution, ecology, agriculture, social animals",
  location     = "QL 565.H36"
}

@Book{wboa,
  author       = "Joe Mungo Reed",
  title        = "We Begin Our Ascent",
  publisher    = "Simon \& Schuster",
  year         = 2018,
  address      = nyny,
  keywords     = "professional bicycling, moral quandaries, doping",
  location     = "PR 611.E2547"
}

@Book{tncoaehm,
  author       = "John Perkins",
  title        = "The New Confessions of an Economic Hit Man",
  publisher    = "Berrett-Koehler",
  year         = 2016,
  address      = "Oakland, California",
  keywords     = "economic development, loans, sovereign debt, world bank, imf,
    energy consultants, petrodollars, corruption, latin america, oil",
  location     = "UB271.U52 P47 2016"
}

@Book{htcym,
  author       = "Michael Pollan",
  title        = "How to Change Your Mind",
  subtitle     = "What the New Science of Psychedelics Teaches Us About Consciousness, Dying, Addiction, Depression, and Transcendence",
  publisher    = "Penguin",
  year         = 2018,
  address      = nyny,
  keywords     = "psychedelics, consciousness, dying, addiction, depression,
  transcendence, lsd, psilocybin",
  location     = "RM 324.8 P65"
}

@Book{wtlco,
  author       = "Chibundu Onuzo",
  title        = "Welcome to Lagos",
  publisher    = "Catapult",
  year         = 2018,
  address      = nyny,
  keywords     = "nigeria, corruption, lagos",
  location     = "https://lccn.loc.gov/2017950942"
}

@InBook{aplftcaibottamm,
  author       = "Dirk Riehle and Heinz Z{\" u}llighoven",
  title        = "Pattern Languages of Programm Design",
  chapter      = "2, {A} Pattern Language for Tool Construction and Integration Based on the Tools and Materials Metaphor",
  publisher    = "Addison-Wesley",
  year         = 1995,
  editor       = "James~O. Coplien and Douglas~C. Schmidt",
  pages        = "9-42",
  address      = rma,
  keywords     = "tool structure, object-oriented design",
  abstract     = "Why do people prefer to use certain software systems and why
    do they have problems using others? What is the quality within certain
    software that makes people soon feel familiar using it and lets them work
    efficiently? We believe that the key to this quality is found in systems
    that allow people to work according to their qualification and needs while
    using their skills and competence.  We have put together many of the things
    which have proved useful in software engineering over the last decades and
    have integrated these methods and techniques into a unifying approach - the
    Tools and Materials Metaphor.  It has guided us and other developers during
    analysis and design and has helped to envision and finally build systems of
    quality.",
  location     = "http://dirkriehle.com/computer-science/research/1994/plop-1994-tools.pdf"
}

@InBook{anacmfrtciai,
  author       = "Domenico Ferrari",
  title        = "Advances in Real-Time Systems",
  chapter      = "{A} New Admission Control Method For Real-Time Communication in an Internetwork",
  publisher    = ph,
  year         = 1995,
  address      = srnj,
  pages        = "105--116",
  keywords     = "tenet, admission control, ",
  abstract     = "Admission control is a necessary component of a real-time
    communication service.  The admission control method adopted so far in the
    Tenet approach to real-time communication was based on a very simple, not
    very realistic node model.  The method described here can be applied to a
    wide variety of node models with a wide spectrum of accuracies, and is
    therefore much more general than the previous one.  The admission control
    tests and computations for the case of the Earliest Due Date scheduling
    discipline are shown as an example of application of the new method.  The
    main advantages and drawbacks of this method are discussed; the
    predominance of the advantages is expected to be connrmed by experience
    with testbed implementations." 
}

@Article{dcmlamfic,
  author       = "Herath, Jayantha and Yamaguchi, Yoshinori and Saito, Nobuo and Yuba, Toshitsugu",
  title        = "Dataflow Computing Models, Languages, and Machines for Intelligence Computations",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 12,
  pages        = "1805--1828",
  month        = dec,
  keywords     = "architecture, dataflow, functional and logic programming,
    parallel computation, performance analysis, recursion, control flow,
    symbolic computing",
  abstract     = "The authors compare dataflow computing models, languages, and
    dataflow computing machines for numerical and nonnumerical computations.
    The high-level-language-graph transformations that must be performed to
    achieve high performance for numerical and nonnumerical programs executed
    in a dataflow computing environment are described for Lisp, using the DCBL
    transformations.  Some general problems of dataflow computing machines are
    discussed.  Performance evaluation measurements obtained by executing
    benchmark programs in the ETL nonnumerical dataflow computing environment,
    the EM-3, are presented.",
  location     = "https://doi.org/10.1109/32.9065"
}

@Article{lfegaeodtfsra,
  author       = "Selby, Richard~W. and Porter, Adam~A.",
  title        = "Learning from Examples:  Generation and Evaluation of Decision Trees for Software Resource Analysis",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 12,
  pages        = "1743--1757",
  month        = dec,
  keywords     = "analysis of variance, decision trees, measurement and
    empirical evaluation, learning from examples, machine learning, software
    effort and error analysis, software metrics",
  abstract     = "A general solution method for the automatic generation of 
    decision (or classification) trees is investigated.  The approach is to
    provide insights through in-depth empirical characterization and evaluation
    of decision trees for one problem domain, specifically, that of software
    resource data analysis.  The purpose of the decision trees is to identify
    classes of objects (software modules) that had high development effort,
    i.e.  in the uppermost quartile relative to past data.  Sixteen software
    systems ranging from 3000 to 112000 source lines have been selected for
    analysis from a NASA production environment.  The collection and analysis
    of 74 attributes (or metrics), for over 4700 objects, capture a multitude
    of information about the objects: development effort, faults, changes,
    design style, and implementation style.  A total of 9600 decision trees are
    automatically generated and evaluated.  The analysis focuses on the
    characterization and evaluation of decision tree accuracy, complexity, and
    composition.  The decision trees correctly identified 79.3% of the software
    modules that had high development effort or faults, on the average across
    all 9600 trees.  The decision trees generated from the best parameter
    combinations correctly identified 88.4% of the modules on the average.
    Visualization of the results is emphasized, and sample decision trees are
    included.", 
  location     = "https://doi.org/10.1109/32.9061"
}

@Article{paia,
  author       = "Keith~L. Clark",
  title        = "{PARLOG} and Its Applications",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 12,
  pages        = "1792--1804",
  month        = dec,
  keywords     = "communicating processes, logic programming applications,
    logic programming languages, object-oriented programming,
    parallel-programming languages, difference lists",
  abstract     = "The key concepts of the parallel logic programming language 
    PARLOG are introduced by comparing the language with Prolog.  Some
    familiarity with Prolog and with the concepts of logic programming is
    assumed.  Two major application areas of PARLOG, systems programming and
    object-oriented programming, are illustrated.  Other applications are
    briefly surveyed.", 
  location     = "https://doi.org/10.1109/32.9064"
}

@Article{fafcmdtg,
  author       = "Dujardin, Eric and Amiel, Eric and Simon, Eric",
  title        = "Fast Algorithms for Compressed Multimethod Dispatch Table Generation",
  journal      = toplas,
  year         = 1998,
  volume       = 20,
  number       = 1,
  pages        = "116--165",
  month        = jan,
  keywords     = "algorithms, language, measurement, performance, dispatch
    tables, late binding, multimethods, optimization, pole types, run-time
    dispatch", 
  abstract     = "The efficiency of dynamic dispatch is a major impediment to
    the adoption of multimethods in object-oriented languages.  In this
    article, we propose a simple multimethod dispatch scheme based on
    compressed dispatch tables.  This scheme is applicable to any
    object-oriented language using a method precedence order that satisfies a
    specific monotonous property (e.g., as Cecil and Dylan) and guarantees that
    dynamic dispatch is performed in constant time, the latter being a major
    requirement for some languages and applications.  We provide efficient
    algorithms to build the dispatch tables, provide their worst-case
    complexity, and demonstrate the effectiveness of our scheme by real
    measurements performed on two large object-oriented applications.  Finally,
    we provide a detailed comparison of our technique with other existing
    techniques.",
  location     = "https://doi.org/10.1145/271510.271521"
}

@Article{icodt,
  author       = "Sreedhar, Vugranam~C. and Gao, Guang~R. and Lee, Yong-Fong",
  title        = "Incremental Computation of Dominator Trees",
  journal      = sigplan # ir95,
  year         = 1993,
  volume       = 30,
  number       = 3,
  pages        = "1--12",
  month        = mar,
  keywords     = "dominator trees, dj-graph, incremental maintenance,
    control-flow graphs",
  abstract     = "Data flow analysis based on an incremental approach may
    require that  the dominator tree be correctly maintained at all times.
    Previous solutions to the problem of incrementally maintaining dominator
    trees were restricted to reducible flowgraphs.  In this paper we present a
    new algorithm for incrementally maintaining the dominator tree of an
    arbitrary flowgraph, either reducible or irreducible, based on a program
    representation called the DJ-graph.  For the case where an edge is
    inserted, our algorithm is also faster than previous approaches (in the
    worst case).  For the deletion case, our algorithm is likely to run fast on
    the average cases.",
  location     = "https://doi.org/10.1145/202530.202531"
}

@Article{atsfjbs,
  author       = "Stata, Raymie and Abadi, Martin",
  title        = "A Type System for {J}ava Bytecode Subroutines",
  journal      = toplas,
  year         = 1999,
  volume       = 21,
  number       = 1,
  pages        = "90--137",
  month        = jan,
  keywords     = "bytecode verification, java, typing rules",
  abstract     = "Java is typically compiled into an intermediate language,
    JVML, that is interpreted by the Java Virtual Machine.  Because mobile JVML
    code is not always trusted, a bytecode verifier enforces static constraints
    that prevent various dynamic errors.  Given the importance of the bytecode
    verifier for security, its current descriptions are inadequate.  This
    article proposes using typing rules to describe the bytecode verifier
    because they are more precise than prose, clearer than code, and easier to
    reason about than either.  JVML has a subroutine construct which is used
    for the compilation of Java's try-finally statement.  Subroutines are a
    major source of complexity for the bytecode verifier because they are not
    obviously last-in/first-out and because they require a kind of
    polymorphism.  Focusing on subroutines, we isolate an interesting, small
    subset of JVML.  We give typing rules for this subset and prove their
    correctness.  Our type system constitutes a sound basis for bytecode
    verification and a rational reconstruction of a delicate part of Sun's
    bytecode verifier.",
  location     = "https://doi.org/10.1145/314602.314606"
}

@Article{a0ailtsdp,
  author       = "Apt, Krzysztof~R. and Brunekreef, Jacob and Partington, Vincent and Schaerf, Andrea",
  title        = "Alma-0: An Imperative Language that Supports Declarative Programming",
  journal      = toplas,
  year         = 1998,
  volume       = 20,
  number       = 5,
  pages        = "1014--1066",
  month        = sep,
  keywords     = "declarative programming, imperative programming, search
    modula 2, backtracking, reversible assignment, language extensions,
    multi-paradigm programming, logic programming",
  abstract     = "We describe a small programming language, called Alma-0, that
    augments the expressive power of imperative programming with a small number
    of features inspired by the logic programming paradigm.  These additions
    encourage declarative programming and make it a more attractive solutions
    for problems involving search.  We illustrate the use of Alma-0 by
    presenting solutions to a number of classical problems, including search,
    STRIPS planning, knapsack, and Eight Queens.  These solutions are
    substantially simpler than their counterparts written in the imperative or
    in the logic programming style and can be used for different purposes
    without any modification.  We also discuss the implementation of Alma-0 and
    an operational, executable, semantics of a large subset of the language.",
  location     = "https://doi.org/10.1145/293677.293679"
}

@Article{tdmiaacs,
  author       = "Stytz, M.~R. and Frieder, G. and Frieder, O.",
  title        = "Three-Dimensional Medical Imaging: Algorithms and Computer Systems",
  journal      = surveys,
  year         = 1991,
  volume       = 23,
  number       = 4,
  pages        = "421--499",
  month        = dec,
  keywords     = "computer graphics, medical imaging, surface rendering,
    three-dimensional imaging, volume rendering, algorithms, surface
    extraction",
  abstract     = "This paper presents an introduction to the field of
    three-dimensional medical imaging.  It presents medical imaging terms and
    concepts, summarizes the basic operations performed in three-dimensional
    medical imaging, and describes sample algorithms for accomplishing these
    operations.  The paper contains a synopsis of the architectures and
    algorithms used in eight machines to render three-dimensional medical
    images, with particular emphasis paid to their distinctive contributions.
    It compares the performance of the machines along several dimensions,
    including image resolution, elapsed time to form an image, imaging
    algorithms used in the machine, and the degree of parallelism used in the
    architecture.  The paper concludes with general trends for future
    developments in this field and references on three-dimensional medical
    imaging.",
  location     = "https://doi.org/10.1145/125137.125155"
}

@Article{ehipi,
  author       = "M.~Donald MacLaren",
  title        = "Exception Handling in {PL}/{I}",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design for Reliable Software)",
  year         = 1977,
  volume       = 12,
  number       = 3,
  pages        = "101--104",
  month        = mar,
  keywords     = "pl/1, exceptional conditions, errors, interrupts, non-local
    go-tos, structured programming, code generation",
  abstract     = "The PL/I language's facilities for handling exceptional
    conditions are analyzed.  The description is based on the new PL/I
    standard.  Special attention is given to fine points which are not well
    known.  The analysis is generally critical.  It emphasizes problems in
    regards to implementation and structured programming.  A few suggestions
    for future language design are offered.",
  location     = "https://doi.org/10.1145/390017.808316"
}

@Article{wwwtiu,
  author       = "Tim Berners-Lee and Robert Cailliau and Jean-Fran{\c c}ois Groff and Bernd Pollermann",
  title        = "{W}orld-{W}ide {W}eb: The Information Universe",
  journal      = "Electronic Networking: Research, Applications and Policy",
  year         = 1992,
  volume       = 1,
  number       = 2,
  pages        = "74--82",
  month        = "Spring",
  keywords     = "information access, hypertext, document management",
  abstract     = {The World-Wide Web (W3) initiative is a practical project to
    bring a global information universe into existence using available
    technology.  This article describes the aims, data model, and protocols
    needed to implement the "web," and compares them with various contemporary
    systems.},
  location     = "www.w3.org/History/1992/ENRAP/Article_9202.txt"
}

@Article{apaffafhol,
  author       = "Ashley, J.~Michael and Dybvig, R.~Kent",
  title        = "{A} Practical and Flexible Flow Analysis for Higher-Order Languages",
  journal      = toplas,
  year         = 1998,
  volume       = 20,
  number       = 4,
  pages        = "845--868",
  month        = jul,
  keywords     = "abstract interpretation, higher-order languages, compiler
      optimizations, closures, scheme, flow analysis, data analysis",
  abstract     = "A flow analysis collects data-flow and control-flow
      information about programs.  A compiler can use this information to
      enable optimizations.  The analysis described in this article unifies and
      extends previous work on flow analysis for higher-order languages
      supporting assignment and control operators.  The analysis is abstract
      interpretation based and is parameterized over two polyvariance operators
      and a projection operator.  These operators are used to regulate the
      speed and accuracy of the analysis.  An implementation of the analysis is
      incorporated into and used in a production Scheme compiler.  The analysis
      can process any legal Scheme program without modification.  Others have
      demonstrated that a 0CFA analysis can enables the optimizations, but a
      0CFA analysis is O(n)3).  An O(n) instantiation of our analysis
      successfully enables the optimization of closure representations and
      procedure calls.  Experiments with the cheaper instantiation show that it
      is as effective as 0CFA for these optimizations.",
  location     = "https://doi.org/10.1145/291891.291898"
}

@Article{dokbswakba,
  author       = "Schoen, Eric and Smith, Reid~G. and Buchanan, Bruce~G.",
  title        = "Design of Knowledge-Based Systems with a Knowledge-Based Assistant",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 12,
  pages        = "1771--1791",
  month        = dec,
  keywords     = "knowledge acquisition, knowledge-based systems,
    object-oriented programming, structured editing, programming environments,
    user interfaces",
  abstract     = "The authors propose a model for an intelligent assistant to
    aid in building knowledge-based systems (KBSs) and discuss a preliminary
    implementation.  The assistant participates in KBS construction, including
    acquisition of an initial model of a problem domain, acquisition of control
    and task-specific inference knowledge, testing and validation, and
    long-term maintenance of encoded knowledge.  The authors present a
    hypothetical scenario in which the assistant and a KBS designer cooperate
    to create an initial domain model and then discuss five categories of
    knowledge the assistant requires to offer such help.  They discuss two
    software technologies on which the assistant is based: an object-oriented
    programming language, and a user-interface framework.",
  location     = "https://doi.org/10.1109/32.9063"
}

@Article{hslanatpas,
  author       = "Abeysundara, Bandula~W. and Kamal, Ahmed~E.",
  title        = "High-Speed Local Area Networks and Their Performance:  {A} Survey",
  journal      = surveys,
  year         = 1991,
  volume       = 23,
  number       = 2,
  pages        = "221--264",
  month        = jun,
  keywords     = "access schemes, computer networks, data communication, medium
    access protocols, optical fiber networks, simulation, bus networks, ring
    networks, tree networks",
  abstract     = "At high data transmission rates, the packet transmission time
    of a local  area network (LAN) could become comparable to or less than the
    medium propagation delay.  The performance of many LAN schemes degrades
    rapidly when the packet transmission time becomes small comparative to the
    medium propagation delay.  This paper introduces LANs and discusses the
    performance degradation of LANs at high speeds.  It surveys recently
    proposed LAN schemes designed to operate at high data rates, including
    their performance characteristics desirable in LAN medium access protocols
    are identified and discussed.  The paper serves as a tutorial for readers
    less familiar with local computer communication networks.  It also serves
    as a survey of the state-of-the-art LANs.",
  location     = "https://doi.org/10.1145/103724.103726"
}

@Article{srtropeh,
  author       = "Melliar-Smith, P.~M. and Randell, B.",
  title        = "Software Reliability: The Role of Programmed Exception Handling",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design for Reliable Software)",
  year         = 1977,
  volume       = 12,
  number       = 3,
  pages        = "95--100",
  month        = mar,
  keywords     = "failures, errors, faults, exceptions, recovery blocks,
    failure handling, reliable software design",
  abstract     = "The paper discusses the basic concepts underlying the issue
    of software reliability, and argues that programmed exception handling is
    inappropriate for dealing with suspected software errors.  Instead it is
    shown, using an example program, how exception handling can be combined
    with the recovery block structure.  The result is to improve the
    effectiveness with which problems due to anticipated faulty input data,
    hardware components, etc., are dealt with, while continuing to provide
    means for recovering from unanticipated faults, including ones due to
    residual software design errors.", 
  location     = "https://doi.org/10.1145/390018.808315"
}

@Article{acotwapi,
  author       = "Diomidis Spinellis",
  title        = "{A} Critique of the {W}indows Application Programming Interface",
  journal      = "Computer Standards \& Interfaces",
  year         = 1993,
  volume       = 20,
  number       = 1,
  pages        = "1--8",
  month        = nov,
  keywords     = "function names, naming conventions, portability, type
    systems, name-space pollution",
  abstract     = "The architecture, interface, and functionality of the Windows
    Application Programming Interface (API) make it difficult to master and use
    effectively, and contribute negatively to the safety, robustness, and
    portability of the applications developed under it.  The API is structured
    around a large and constantly evolving set of functions and is based on a
    problematic shared library implementation.  The provided interfaces are
    complicated, nonorthogonal, abuse the type system, cause name-space
    pollution, and use inconsistent naming conventions.  In addition, the
    functionality of the interface suffers from inconsistency, incompleteness,
    and inadequate documentation.  Application developers, programming tool
    vendors, and Microsoft should face the above problems and provide
    appropriate solutions.", 
  location     = "https://doi.org/10.1016/S0920-5489%2898%2900012-9"
}

@Article{aaefeis,
  author       = "Erman, Lee~D. and Lark, Jay~S. and Hayes-Roth, Frederick",
  title        = "{ABE}:  An Environment for Engineering Intelligent Systems",
  journal      = tse,
  year         = 1993,
  volume       = 14,
  number       = 12,
  pages        = "1758--1770",
  month        = dec,
  keywords     = "cooperative operating system, distributed computing,
    intelligent-systems engineering, module-oriented programming, layered
    architecture, abstract machines",
  abstract     = "The ABE multilevel architecture for developing intelligent
    systems addresses the key problems of intelligent systems engineering:
    large-scale applications and the reuse and integration of software
    components.  ABE defines a virtual machine for module-oriented programming
    and a cooperative operating system that provides access to the capabilities
    of that virtual machine.  On top of the virtual machine, ABE provides a
    number of systemdesign and development frameworks, which embody such
    programming metaphors as control flow, blackboards, and dataflow.  These
    frameworks support the construction of capabilities, including knowledge
    processing tools, which span a range from primitive modules to skeletal
    systems.  Finally, applications can be built on skeletal systems.  In
    addition, ABE supports the importation of existing software, including both
    conventional and knowledge processing tools.",
  location     = "https://doi.org/10.1109/32.9062"
}

@Article{calwdt,
  author       = "Augustsson, Lennart",
  title        = "Cayenne --- {A} Language with Dependent Types",
  journal      = sigplan,
  year         = 1999,
  volume       = 34,
  number       = 1,
  pages        = "239--250",
  month        = jan,
  keywords     = "type systems, language design, dependent types, module systems",
  abstract     = "Cayenne is a Haskell-like language.  The main difference
    between Haskell and Cayenne is that Cayenne has dependent types, i.e., the
    result type of a function may depend on the argument value, and types of
    record components (which can be types or values) may depend on other
    components.  Cayenne also combines the syntactic categories for value
    expressions and type expressions; thus reducing the number of language
    concepts.Having dependent types and combined type and value expressions
    makes the language very powerful.  It is powerful enough that a special
    module concept is unnecessary; ordinary records suffice.  It is also
    powerful enough to encode predicate logic at the type level, allowing types
    to be used as specifications of programs.  However, this power comes at a
    cost: type checking of Cayenne is undecidable.  While this may appear to be
    a steep price to pay, it seems to work well in practice.", 
  location     = "https://doi.org/10.1145/291251.289451"
}

@Article{iomad,
  author       = "Litwin, Witold and Mark, Leo and Roussopoulos, Nick",
  title        = "Interoperability of Multiple Autonomous Databases",
  journal      = surveys,
  year         = 1990,
  volume       = 22,
  number       = 3,
  pages        = "267--293",
  month        = sep,
  keywords     = "database autonomy, database interoperability without global
    schema, distributed databases, federated databases, multidatabases,
    multidatabase language",
  abstract     = "Database systems were a solution to the problem of shared
    access to heterogeneous files created by multiple autonomous applications
    in a centralized environment.  To make data usage easier, the files were
    replaced by a globally integrated database.  To a large extent, the idea
    was successful, and many databases are now accessible through local and
    long-haul networks.  Unavoidably, users now need shared access to multiple
    autonomous databases.  The question is what the corresponding methodology
    should be.  Should one reapply the database approach to create globally
    integrated distributed database systems or should a new approach be
    introduced? We argue for a new approach to solving such data management
    system problems, called multidatabase or federated systems.  These systems
    make databases interoperable, that is, usable without a globally integrated
    schema.  They preserve the autonomy of each database yet support shared
    access.  Systems of this type will be of major importance in the future.
    This paper first discusses why this is the case.  Then, it presents
    methodologies for their design.  It further shows that major commerical
    relational database systems are evolving toward multidatabase systems.  The
    paper discusses their capabilities and limitations, presents and discusses
    a set of prototypes, and, finally, presents some current research issues.", 
  location     = "https://doi.org/10.1145/96602.96608"
}

@Article{bsansa,
  author       = "Joshua~J. Arulanandham and Cristian~S. Calude and Michael~J. Dinneen",
  title        = "Beadâ€“Sort: {A} Natural Sorting Algorithm",
  journal      = "The Bulletin of the European Association for Theoretical Computer Science",
  year         = 2002,
  volume       = 76,
  pages        = "153--162",
  keywords     = "sorting, linear sorts, sorting implementations",
  abstract     = "Nature is not only a source of minerals and precious stones
    but is also a mine of algorithms.  By observing and studying natural
    phenomena, computer algorithms can be extracted.  In this note, a simple
    natural phenomenon is used to design a sorting algorithm for positive
    integers, called here Bead-Sort.  The algorithm's run-time complexity
    ranges from O(1) to O(S) (S is the sum of the input integers) depending on
    the user's perspective.  Finally, three possible implementations are
    suggested.",
  location     = "https://www.cs.auckland.ac.nz/~mjd/misc/BeadSort5.pdf"
}

@Article{cois,
  author       = "Anish Arora and Paul Attie and Michael Evangelist and Mohamed Gouda",
  title        = "Convergence of Iteration Systems",
  journal      = "Distributed Computing",
  year         = 1993,
  volume       = 7,
  number       = 1,
  pages        = "43--53",
  month        = nov,
  keywords     = "convergence, stabilization, iteration systems, dependency graph",
  abstract     = "An iteration system is a set of assignment statements whose
    computation proceeds in steps: at each step, an arbitrary subset of the
    statements is executed in parallel.  The set of statements thus executed
    may differ at each step; however, it is required that each statement is
    executed infinitely often along the computation.  The convergence of such
    systems (to a fixed point) is typically verified by showing that the value
    of a given variant function is decreased by each step that causes a state
    change.  Such a proof requires an exponential number of cases (in the
    number of assignment statements) to be considered.  In this paper, we
    present alternative methods for verifying the convergence of iteration
    systems.  In most of these methods, upto a linear number of cases need to
    be considered.",
  location     = "https://doi.org/10.1007/BF02278855"
}

@Article{ttipl,
  author       = "Herriot, Robert~G.",
  title        = "Towards the Ideal Programming Language",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design for Reliable Software)",
  year         = 1977,
  volume       = 12,
  number       = 3,
  pages        = "56--62",
  month        = mar,
  keywords     = "types, simula class, instances, pascal, adjectives,
    modifiers, procedures, extensible languages, plasma, smalltalk, prepositions,
    imperative operators, applicative operators, which operator, passive operator",
  abstract     = "A programming language with good features and notation can
    help the programmer represent his abstractions in the programming language,
    and can also help someone else understand the original abstraction.  There
    have been numerous proposals for better features.  In this paper we propose
    several new ideas to improve the notation.  First we suggest that class
    instances be named with a sequence of identifiers consisting of the class
    name preceded by modifiers.  Then we propose that prepositions be placed
    before procedure parameters to suggest their role.  Finally, we suggest
    that applicative and imperative operations can be separated semantically,
    and then recombined syntactically through the use of the which and passive
    operators.",
  location     = "https://doi.org/10.1145/390017.808311"
}

@Article{assofli,
  author       = "Douence, R{\' e}mi and Fradet, Pascal",
  title        = "{A} Systematic Study of Functional Language Implementations",
  journal      = toplas,
  year         = 1998,
  volume       = 20,
  number       = 2,
  pages        = "344--387",
  month        = mar,
  keywords     = "abstract machines, compilers, combinators, functional
    programming, program transformation, comparative implementations",
  abstract     = "We introduce a unified framework to describe, relate,
    compare, and classify functional language implementations.  The compilation
    process is expressed as a succession of program transformations in the
    common framework.  At each step, different transformations model
    fundamental choices.  A benefit of this approach is to structure and
    decompose the implementation process.  The correctness proofs can be
    tackled independently for each step and amount to proving program
    transformations in the functional world.  This approach also paves the way
    to formal comparisons by making it possible to estimate the complexity of
    individual transformations or compositions of them.  Our study aims at
    covering the whole known design space of sequential functional language
    implementations.  In particular, we consider call-by-value, call-by-name,
    call-by-need reduction strategies as well as environment- and graph-based
    implementations.  We describe for each compilation step the diverse
    alternatives as program transformations.  In some cases, we illustrate how
    to compare or relate compilation techniques, express global optimizations,
    or hybrid implementations.  We also provide a classification of well-known
    abstract machines.", 
  location     = "https://doi.org/10.1145/276393.276397"
}

@Article{dobps,
  author       = "Chin, Roger~S. and Chanson, Samuel~T.",
  title        = "Distributed Object-Based Programming Systems",
  journal      = surveys,
  year         = 1991,
  volume       = 23,
  number       = 1,
  pages        = "91--124",
  month        = mar,
  keywords     = "capabilities, distributed operating systems, error recovery,
    method invocation, nested transactions, object-based programming languages,
    object model, object reliability, processor allocation, resource management,
    synchronization, transactions",
  abstract     = "The development of distributed operating systems and
    object-based programming languages makes possible an environment in which
    programs consisting of a set of interacting modules, or objects, may
    execute concurrently on a collection of loosely coupled processors.  An
    object-based programming language encourages a methodology for designing
    and creating a program as a set of autonomous components, whereas a
    distributed operating system permits a collection of workstations or
    personal computers to be treated as a single entity.  The amalgamation of
    these two concepts has resulted in systems that shall be referred to as
    distributed, object-based programming systems.  This paper discusses issues
    in the design and implementation of such systems.  Following the
    presentation of fundamental concepts and various object models, issues in
    object management, object interaction management, and physical resource
    management are discussed.  Extensive examples are drawn from existing
    systems.", 
  location     = "https://doi.org/10.1145/103162.103165"
}

@Article{setas,
  author       = "Guttag, Jhon~V. and Horowitz, Ellis and Musser, David~R.",
  title        = "Some Extensions to Algebraic Specifications",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design for Reliable Software)",
  year         = 1977,
  volume       = 12,
  number       = 3,
  pages        = "62--67",
  month        = mar,
  keywords     = "abstract data type, data structures, programming languages,
    procedure specification, error specification, correctness, functional
    programming",
  abstract     = "Algebraic specifications of abstract data types are beginning
    to gain wide currency.  In this paper we discuss an extension to this
    specification technique which allows the specification of procedures which
    alter their parameters, and various ways of handling the specification of
    error conditions.",
  location     = "https://doi.org/10.1145/800022.808312"
}

@Article{rdtsaeoipov,
  author       = "Buckle, Normand",
  title        = "Restricted Data Types, Specification and Enforcement of Invariant Properties of Variables",
  journal      = sigplan # " (" # pot # "ACM Conference on Language Design for Reliable Software)",
  year         = 1977,
  volume       = 12,
  number       = 3,
  pages        = "68--76",
  month        = mar,
  keywords     = "data type, invariant property, programming language,
    readability, reliability, restricted type, runtime verification, type checking",
  abstract     = "When defining a data type, it is often useful to specify
    restrictions on the permitted values of that type.  Pascal's subrange type
    declaration, a special case of this kind of constraint definition, has
    already proved itself to be quite useful.  Restricted data types allow more
    complex constraints to be defined and checked; for example, a variable
    could be declared of type odd integer or the day field of a
    date type variable could be checked for consistency with the
    year and month fields.  A simple mechanism is proposed, allowing the
    formulation of such constraints and their association with data types; the
    behaviour of a restricted type variable is described.  The effects of the
    use of such a mechanism on program reliability, readability and efficiency
    are discussed.", 
  location     = "https://doi.org/10.1145/800022.808313"
}

@Article{olsicm,
  author       = "Anger, Frank~D.",
  title        = "On {L}amport's Interprocessor Communication Model",
  journal      = toplas,
  year         = 1989,
  volume       = 11,
  number       = 3,
  pages        = "404--417",
  month        = jul,
  keywords     = "nonatomic operations, abstractions, axiom schemes",
  abstract     = "Leslie Lamport presented a set of axioms in 1979 that capture
    the essential properties of the temporal relationships between complex and
    perhaps unspecified activities within any system, and proceeded to use this
    axiom system to prove the correctness of sophisticated algorithms for
    reliable communication and mutual exclusion in systems without shared
    memory.  As a step toward a more complete metatheory of Lamport's axiom
    system, this paper determines the extent to which that system differs from
    systems based on atomic or indivisible, actions.  Theorem 1 shows that only
    very weak conditions need be satisfied in addition to the given axioms to
    guarantee the existence of an atomic model while Proposition 1 gives
    sufficient conditions under which any such model must be a faithful
    representation.  Finally, Theorem 2 restates a result of Lamport showing
    exactly when a system can be thought of as made up of a set of atomic
    events that can be totally ordered temporally.  A new constructive proof is
    offered for this result.", 
  location     = "https://doi.org/10.1145/65979.65982"
}

@Article{iftsutsmaat,
  author       = "Schneider, Fred~B.",
  title        = "Implementing Fault-Tolerant Services Using the State Machine Approach: {A} Tutorial",
  journal      = surveys,
  year         = 1990,
  volume       = 22,
  number       = 4,
  pages        = "299--319",
  month        = dec,
  keywords     = "client-server, distributed services, state machines,
    fail-stop processors, byzantine failures", 
  abstract     = "The state machine approach is a general method for
    implementing fault-tolerant services in distributed systems.  This paper
    reviews the approach and describes protocols for two different failure
    models&mdash;Byzantine and fail stop.  Systems reconfiguration techniques
    for removing faulty components and integrating repaired components are also
    discussed.",
  location     = "https://doi.org/10.1145/98163.98167"
}

@Article{ascwfacadpl,
  author       = "Corrodi, Claudio and Heu{\ss}ner, Alexander and Poskitt, Christopher~M.",
  title        = "{A} Semantics Comparison Workbench for a Concurrent, Asynchronous, Distributed Programming Language",
  journal      = "Formal Aspects of Computing",
  year         = 2018,
  volume       = 30,
  number       = 1,
  pages        = "163--192",
  month        = jan,
  keywords     = "concurrent asynchronous programming, distributed programming
    with message passing, operational semantics, runtime semantics, graph
    transformation systems, verification/analysis parameterised by semantics,
    concurrency abstractions, object-oriented programming, software engineering,
    scoop, groove",
  abstract     = "A number of high-level languages and libraries have been
    proposed that offer novel and simple to use abstractions for concurrent,
    asynchronous, and distributed programming.  The execution models that
    realise them, however, often change over time--whether to improve
    performance, or to extend them to new language features--potentially
    affecting behavioural and safety properties of existing programs.  This is
    exemplified by Scoop, a message-passing approach to concurrent
    object-oriented programming that has seen multiple changes proposed and
    implemented, with demonstrable consequences for an idiomatic usage of its
    core abstraction.  We propose a semantics comparison workbench for Scoop
    with fully and semi-automatic tools for analysing and comparing the state
    spaces of programs with respect to different execution models or semantics.
    We demonstrate its use in checking the consistency of properties across
    semantics by applying it to a set of representative programs, and
    highlighting a deadlock-related discrepancy between the principal execution
    models of Scoop.  Furthermore, we demonstrate the extensibility of the
    workbench by generalising the formalisation of an execution model to
    support recently proposed extensions for distributed programming.  Our
    workbench is based on a modular and parameterisable graph transformation
    semantics implemented in the Groove tool.  We discuss how graph
    transformations are leveraged to atomically model intricate language
    abstractions, how the visual yet algebraic nature of the model can be used
    to ascertain soundness, and highlight how the approach could be applied to
    similar languages.", 
  location     = "https://doi.org/10.1007/s00165-017-0443-1"
}

@Article{aifssh,
  author       = "Serpette, Bernard~P. and Serrano, Manuel",
  title        = "An Interpreter for Server-Side {H}op",
  journal      = sigplan # " (" # pot # "Seventh Symposium on Dynamic Languages)",
  year         = 2012,
  volume       = 47,
  number       = 2,
  pages        = "1--12",
  month        = feb,
  keywords     = "functional languages, scheme, interpreter implementation,
    threaded code, optimizations",
  abstract     = "HOP is a Scheme-based multi-tier programming language for the
    Web. The client-side of a program is compiled to JavaScript, while the
    server-side is executed by a mix of natively compiled code and interpreted
    code.  At the time where HOP programs were basic scripts, the performance
    of the server-side interpreter was not a concern; an inefficient
    interpreter was acceptable.  As HOP expanded, HOP programs got larger and
    more complex.  A more efficient interpreter was necessary.  This new
    interpreter is described in this paper.  It is compact, its whole
    implementation counting no more than 2.5 KLOC.  It is more than twice
    faster than the old interpreter and consumes less than a third of its
    memory.  Although it cannot compete with static or JIT native compilers,
    our experimental results show that it is amongst the fastest interpreters
    for dynamic languages.",
  location     = "https://doi.org/10.1145/2168696.2047851"
}

@Article{hatjcfp,
  author       = "Homescu, Andrei and {\c S}uhan, Alex",
  title        = "HappyJIT:  A Tracing {JIT} Compiler for {PHP}",
  journal      = sigplan # " (" # pot # "Seventh Symposium on Dynamic Languages)",
  year         = 2012,
  volume       = 47,
  number       = 2,
  pages        = "25--36",
  month        = feb,
  keywords     = "php, jit compilation, interpretation, pypy, tracing,
    optimization, dynamic typing",
  abstract     = "Current websites are a combination of server-generated
    dynamic content with client-side interactive programs.  Dynamically - typed
    languages have gained a lot of ground in both of these domains.  The growth
    of Web 2.0 has introduced a myriad of websites which contain personalized
    content, which is specific to the user.  PHP or Python programs generate
    the actual HTML page after querying a database and processing the results,
    which are then presented by the browser.  It is becoming more and more
    vital to accelerate the execution of these programs, as this is a
    significant part of the total time needed to present the page to the user.
    This paper presents a novel interpreter for the PHP language written in
    RPython, which the PyPy translator then translates into C.  The translator
    integrates into the interpreter a tracing just-in-time compiler which
    optimizes the hottest loops in the interpreted programs.  We also describe
    a data model that supports all the data types in the PHP language, such as
    references and iterators.  We evaluate the performance of this interpreter,
    showing that speedups up to a factor of 8 are observed using this
    approach.", 
  location     = "https://doi.org/10.1145/2047849.2047854"
}

@Article{tgua,
  author       = "Brown, C.~Wayne",
  title        = "Teaching Graphics Using {A}da",
  journal      = "Ada Newsletter (" # pot # "2004 Annual ACM SIGAda International Conference on Ada)",
  year         = 2004,
  volume       = 24,
  number       = 4,
  pages        = "47--50",
  month        = dec,
  keywords     = "graphics, ada, ",
  abstract     = "This paper describes several Ada-language tools supporting a
    computer-graphics course.  These tools include an updated and improved
    OpenGL Ada specification file, a VRML-to-code conversion tool, and an
    Ada-to-C conversion tool.  The tool-development rational and some
    implementation issues are discussed.",
  location     = "https://doi.org/10.1145/1032297.1032306"
}

@Article{aoapffs,
  author       = "Friedman, Daniel~P. and Wise, David~S.",
  title        = "Aspects of Applicative Programming for File Systems",
  journal      = osr # " (" # pot # "ACM Conference on Language Design for Reliable Software)",
  year         = 1977,
  volume       = 11,
  number       = 2,
  pages        = "41--55",
  month        = apr,
  keywords     = "referential transparency, recursive programming, real time,
    shared file, functional combination, suspension, text editor, lazy
    evaluation",
  abstract     = "This paper develops the implications of recent results in
    semantics for applicative programming.  Applying suspended evaluation
    (call-by-need) to the arguments of file construction functions results in
    an implicit synchronization of computation and output.  The programmer need
    not participate in the determination of the pace and the extent of the
    evaluation of his program.  Problems concerning multiple input and multiple
    output files are considered: typical behavior is illustrated with an
    example of a rudimentary text editor written applicatively.  As shown in
    the trace of this program, the driver of the program is the sequential
    output device(s).  Implications of applicative languages for I/O bound
    operating systems are briefly considered.", 
  location     = "https://doi.org/10.1145/390018.808310"
}

@Article{ceaaofpl,
  author       = "Paul Hudak",
  title        = "Conception, Evolution, and Application of Functional Programming Languages",
  journal      = surveys,
  year         = 1989,
  volume       = 21,
  number       = 3,
  pages        = "359--411",
  month        = sep,
  keywords     = "data abstraction, higher-order functions, lazy evaluation,
    referential transparency, types, lambda calculus, language design, lisp,
    haskell, pattern matching, functional i-o", 
  abstract     = "The foundations of functional programming languages are
    examined from both historical and technical perspectives.  Their evolution
    is traced through several critical periods: early work on lambda calculus
    and combinatory calculus, Lisp, Iswim, FP, ML, and modern functional
    languages such as Miranda1 and Haskell.  The fundamental premises on which
    the functional programming methodology stands are critically analyzed with
    respect to philosophical, theoretical, and pragmatic concerns.  Particular
    attention is paid to the main features that characterize modern functional
    languages: higher-order functions, lazy evaluation, equations and pattern
    matching, strong static typing and type inference, and data abstraction.
    In addition, current research areas&mdash;such as parallelism,
    nondeterminism, input/output, and state-oriented computations&mdash;are
    examined with the goal of predicting the future development and application
    of functional languages.",
  location     = "https://doi.org/10.1145/72551.72554"
}

@Article{wsatframp,
  author       = "Maggiolo-Schettini, Andrea. and Napoli, Margherita and Tortora, Genoveffa",
  title        = "Web Structures:  {A} Tool for Representing and Manipulating Programs",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1621--1639",
  month        = nov,
  keywords     = "data flow analysis, high level program transformations,
    interpretive semantics, programming languages, replacement systems,
    category theory, web structures, macroderivations",
  abstract     = "The authors introduce web structures and their
    transformations and develop their theory in the framework of category
    theory.  Once a program has been represented as a web structure, software
    tools, such as a high-level data flow analyzer or other general program
    transformers, can be written as sets of web structure production rules.  An
    implementation of web structure transformations is in progress.  The
    mathematical theory of web structure transformations allows form proofs of
    properties both at the metatheoretical and theoretical levels.", 
  location     = "https://doi.org/10.1109/32.9050"
}

@Article{shsirl,
  author       = "Waldvogel, Marcel and Varghese, George and Turner, Jon and Plattner, Bernhard",
  title        = "Scalable High Speed {IP} Routing Lookups",
  journal      = ccr # " (" # pot # "ACM SIGCOMM '97 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication)",
  year         = 1997,
  volume       = 27,
  number       = 4,
  pages        = "25--36",
  month        = oct,
  keywords     = "binary search, hash tables, ip lookup, backtracking,
    precomputation, rope search",
  abstract     = "Internet address lookup is a challenging problem because of
    increasing routing table sizes, increased traffic, higher speed links, and
    the migration to 128 bit IPv6 addresses.  IP routing lookup requires
    computing the best matching prefix, for which standard solutions like
    hashing were believed to be inapplicable.  The best existing solution we
    know of, BSD radix tries, scales badly as IP moves to 128 bit addresses.
    Our paper describes a new algorithm for best matching prefix using binary
    search on hash tables organized by prefix lengths.  Our scheme scales very
    well as address and routing table sizes increase: independent of the table
    size, it requires a worst case time of log2(address bits) hash lookups.
    Thus only 5 hash lookups are needed for IPv4 and 7 for IPv6.  We also
    introduce Mutating Binary Search and other optimizations that, for a
    typical IPv4 backbone router with over 33,000 entries, considerably reduce
    the average number of hashes to less than 2, of which one hash can be
    simplified to an indexed array access.  We expect similar average case
    behavior for IPv6.", 
  location     = "https://doi.org/10.1145/263109.263136"
}

@Article{ptttm,
  author       = "John Vissides",
  title        = "Patterns: The Top Ten Misconceptions",
  journal      = "Object Magazine",
  year         = 1997,
  volume       = 7,
  number       = 1,
  pages        = "30--33",
  keywords     = "context",
  location     = "http://www.research.ibm.com/designpatterns/pubs/top10misc.html"
}

@Article{mipp,
  author       = "Charles Tilly",
  title        = "Mechanisms in Political Processes",
  journal      = "Annual Review of Political Science",
  year         = 2001,
  volume       = 4,
  pages        = "21--41",
  keywords     = "public politics, democratization, trust networks, inequality,
    regime environment, change mechanisms",
  abstract     = "Ostensibly theoretical disputes in political science often
    involve competing approaches to explanation, including skepticism, covering
    law arguments, reconstructions of propensities, system models, and
    explanations featuring causal mechanisms.  Mechanism- and process-based
    accounts, including cognitive, environmental, and relational effects,
    deserve more attention than they have received in recent political science.
    Analyses of democratization illustrate these points.",
  location     = "https://doi.org/10.1146/annurev.polisci.4.1.21"
}

@Article{icfaofopwtco,
  author       = "Debray, Saumya~K. and Proebsting, Todd~A.",
  title        = "Interprocedural Control Flow Analysis of First-Order Programs with Tail-Call Optimization",
  journal      = toplas,
  year         = 1997,
  volume       = 19,
  number       = 4,
  pages        = "568--585",
  month        = jul,
  keywords     = "control-flow analysis, interprocedural analysis, control-flow
    grammars, follow sets, lr(0) parsers, lr(1) parsers, ",
  abstract     = "Knowledge of low-level control flow is essential for many
    compiler optimizations.  In systems with tail-call optimization, the
    determination of interprocedural control flow is complicated by the fact
    that because of tail-call optimization, control flow at procedure returns
    is not readily evident from the call graph of the program.  This article
    shows how interprocedural control-flow analysis of first-order programs can
    be carried out using well-known concepts from parsing theory.  In
    particular, we show that context-insensitive ( or zeroth-order)
    control-flow analysis corresponds to the notion of FOLLOW sets in
    context-free grammars, while context-sensitive (or first-order)
    control-flow analysis corresponds to the notion of LR(1) items.  The
    control-flow information so obtained can be used to improve the precision
    of interprocedural dataflow analyses as well as to extend certain low-level
    code optimizations across procedure boundaries.", 
  location     = "https://doi.org/10.1145/262004.262006"
}

@Article{tladomsl,
  author       = "Ilkka Toumi",
  title        = "The Lives and Death of {M}oore's Law",
  journal      = "First Monday",
  year         = 2002,
  volume       = 7,
  number       = 11,
  month        = nov,
  keywords     = "transistor counts, hardware development",
  abstract     = "Mooreâ€™s Law has been an important benchmark for developments
    in microelectronics and information processing for over three decades.
    During this time, its applications and interpretations have proliferated
    and expanded, often far beyond the validity of the original assumptions
    made by Moore.  Technical considerations of optimal chip manufacturing
    costs have been expanded to processor performance, economics of computing,
    and social development.  It is therefore useful to review the various
    interpretations of Mooreâ€™s Law and empirical evidence that could support
    them.  Such an analysis reveals that semiconductor technology has evolved
    during the last four decades under very special economic conditions.  In
    particular, the rapid development of microelectronics implies that economic
    and social demand has played a limited role in this industry.  Contrary to
    popular claims, it appears that the common versions of Mooreâ€™s Law have not
    been valid during the last decades.  As semiconductors are becoming
    important in economy and society, Mooreâ€™s Law is now becoming an
    increasingly misleading predictor of future developments.", 
  location     = "http://firstmonday.org/ojs/index.php/fm/article/view/1000/921"
}

@Article{lslcw,
  author       = "Clark Williams",
  title        = "Linux Scheduler Latency",
  journal      = "EE Times",
  year         = 2002,
  month        = jun,
  keywords     = "latency, response time, interrupts, preemption",
  abstract     = "One of my jobs at Red Hat is to evaluate and recommend new
    techniques for embedded Linux solutions.  Scheduler latency is one of the
    biggest complaints that hard realtime champions have about Linux.  I
    decided to evaluate preemption and low-latency to see which one came out on
    top.",
  location     = "https://www.eetimes.com/document.asp?doc_id=1200916"
}

@Article{twtmsyppsdtmolb,
  author       = "Gregory~V. Wilson and Brent Gorda and Paul Lu",
  title        = "Twelve Ways to Make Sure Your Parallel Programming System Doesn't Make Others Look Bad",
  journal      = ieeec,
  year         = 1994,
  volume       = 27,
  number       = 10,
  pages        = 112,
  month        = oct,
  keywords     = "group operations, i-o, marshaling, timesharing, behavior, performance",
  abstract     = "Anyone who has done any parallel programming knows that it's
    more difficult than sequential programming.  To keep ourselves employed, we
    should make sure it stays that way.  Therefore, if you're adding to the
    hundreds of parallel programming systems in existence, please follow these
    rules so that your system won't make the rest of us look stupid.",
  location     = "TK 7885.A1 I15X"
}

@Article{affnps,
  author       = "H{\" u}ni, Hermann and Johnson, Ralph and Engel, Robert",
  title        = "{A} Framework for Network Protocol Software",
  journal      = sigplan # " (" # pot # "Tenth Annual Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA '95)",
  year         = 1995,
  volume       = 30,
  number       = 10,
  pages        = "358--369",
  month        = oct,
  keywords     = "mux, factories, architecture model, strategy pattern, visitor
    pattern, prototype pattern, atm signalling, evaluation",
  abstract     = "Writing software to control networks is important and
    difficult.  It must be efficient, reliable, and flexible.  Conduits+ is a
    framework for network software that has been used to implement the
    signalling system of a mullti-protocol ATM access switch.  An earlier
    version was used to implement TCP/IP.  It reduces the complexity of network
    software, makes it easier to extend or modify network protocols, and is
    sufficiently efficient.  Conduits+ shows the power of a componentized
    object-oriented framework and of common object-oriented design patterns.", 
  location     = "https://doi.org/10.1145/217839.217875"
}

@Article{sarosd,
  author       = "Ian~A. Mcleod",
  title        = "Storage and Retrieval of Structured Documents",
  journal      = "Journal of Information Processing and Management",
  year         = 1990,
  volume       = 26,
  number       = 2,
  pages        = "197--208",
  keywords     = "text retrieval, query language",
  abstract     = "There have been a number of important document related
    activities which suggest the need for a new model for text.  ISO standards
    for document description have been recently developed.  These standards
    view documents as hierarchical objects and it is likely that languages such
    as SGML will become widely used in the near future for document markup.  As
    structured documents become available, so there will be a need to evolve
    tools to take advantage of structural knowledge.  The goal of the work
    described here is to develop such tools.  A conceptual model for
    bibliographic data has been designed.  The model is known as Maestro
    (Management Environment for Structured Text Retrieval and Organization).
    It supports structured documents and provides a query language to retrieve
    and link information contained in these structures, in this paper, an
    overview of Maestro is presented together with an outline of the basic
    implementation strategy.", 
  location     = "https://doi.org/10.1016/0306-4573%2890%2990025-W"
}

@Article{pwthp,
  author       = "Andrew Davison",
  title        = "Programming With the {HTTP} Protocol",
  journal      = "Web Techniques",
  year         = 1996,
  volume       = 1,
  number       = 4,
  month        = jul,
  keywords     = "http, gets, web pages",
  location     = "http://www.cs.mu.oz.au/~ad"
}

@Article{sftffrl,
  author       = "Degermark, Mikael and Brodnik, Andrej and Carlsson, Svante and Pink, Stephen",
  title        = "Small Forwarding Tables for Fast Routing Lookups",
  journal      = ccr # " (" # pot # "ACM SIGCOMM Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication, SIGCOMM '97)",
  year         = 1997,
  volume       = 27,
  number       = 4,
  pages        = "3--14",
  month        = oct,
  keywords     = "routing tables, forwarding, performance",
  abstract     = "For some time, the networking community has assumed that it
    is impossible to do IP routing lookups in software fast enough to support
    gigabit speeds.  IP routing lookups must find the routing entry with the
    longest matching prefix, a task that has been thought to require hardware
    support at lookup frequencies of millions per second.We present a
    forwarding table data structure designed for quick routing lookups.
    Forwarding tables are small enough to fit in the cache of a conventional
    general purpose processor.  With the table in cache, a 200 MHz Pentium Pro
    or a 333 MHz Alpha 21164 can perform a few million lookups per second.
    This means that it is feasible to do a full routing lookup for each IP
    packet at gigabit speeds without special hardware.The forwarding tables are
    very small, a large routing table with 40,000 routing entries can be
    compacted to a forwarding table of 150-160 Kbytes.  A lookup typically
    requires less than 100 instructions on an Alpha, using eight memory
    references accessing a total of 14 bytes.",
  location     = "https://doi.org/10.1145/263105.263133"
}

@Article{ddcfhpc,
  author       = "Matheou, George and Evripidou, Paraskevas",
  title        = "Data-Driven Concurrency for High Performance Computing",
  journal      = "ACM Transactions on Architecture and Code Optimization",
  year         = 2017,
  volume       = 14,
  number       = 4,
  pages        = 53,
  month        = dec,
  keywords     = "data-driven multithreading, distributed execution, runtime
    system, high-performance computing, communication management, multi-core
    scheduling",
  abstract     = "In this work, we utilize dynamic dataflow/data-driven
    techniques to improve the performance of high performance computing (HPC)
    systems.  The proposed techniques are implemented and evaluated through an
    efficient, portable, and robust programming framework that enables
    data-driven concurrency on HPC systems.  The proposed framework is based on
    data-driven multithreading (DDM), a hybrid control-flow/dataflow model that
    schedules threads based on data availability on sequential processors.  The
    proposed framework was evaluated using several benchmarks, with different
    characteristics, on two different systems: a 4-node AMD system with a total
    of 128 cores and a 64-node Intel HPC system with a total of 768 cores.  The
    performance evaluation shows that the proposed framework scales well and
    tolerates scheduling overheads and memory latencies effectively.  We also
    compare our framework to MPI, DDM-VM, and OmpSs&commat;Cluster.  The
    comparison results show that the proposed framework obtains comparable or
    better performance.", 
  location     = "https://doi.org/10.1145/3162014"
}

@Article{tfrppt,
  author       = "Anderson, David~P.",
  title        = "Techniques for Reducing Pen Plotting Time",
  journal      = tog,
  year         = 1983,
  volume       = 2,
  number       = 3,
  pages        = "197--212",
  month        = jul,
  keywords     = "line drawing, plotting, minimization, data structure, quadtree",
  abstract     = "The amount of time used by a pen plotter in drawing a set of
    line segments depends on the order and directions in which the segments are
    drawn, and can generally be reduced by reordering and redirecting the
    segments.  This paper represents practical techniques for reducing plotting
    time.  A method is proposed in which a buffer of segments in maintained,
    and the criterion used in choosing a segment from the buffer to draw is
    that of closeness to the current pen position.  By storing the segment
    endpoints in a quadtree data structure, it is possible to find the closest
    endpoint in an amount of time which is essentially independent of the
    buffer size.  We give algorithms for inserting, deleting, and finding
    closest points in the quadtree.  The performance of the plotting time
    reduction program in a sample of real-world applications is given.  Test
    cases from data plotting, computer-aided design and VLSI design are used.", 
  location     = "https://doi.org/10.1145/357323.357327"
}

@Article{dotboacdn,
  author       = "Muayyad Al-Chalabi and William~J. Liss",
  title        = "Design of the {B}ank of {A}merica {C}alifornia Data Network",
  journal      = "AT\&T Technical Journal",
  year         = 1988,
  pages        = "87--106",
  month        = nov # "/" # dec,
  keywords     = "system engineering, datakit, network management, performance",
  abstract     = "This paper describes Bank of America's California data
    network, a corporate utility network that uses AT&T's Datakit
    virtual-circuit-switch technology to consolidate multiple networks into a
    single network.  The network is managed by AT&T's StarKeeper
    network-management system and Dataphone II level-IV system controller.  The
    network architecture consists of an access network that connects branches
    to hubs, and a backbone network that interconnects hubs and data centers.
    We address three fundamental areas: optimization of the network topology
    and node configuration, performance analysis, and network management.
    Network optimization deals with determining the optimal number of nodes,
    access facilities engineering, and backbone configuration and routine.
    Performance analysis shows the end-to-end delays for the applications.  In
    the network management area, we discuss administration, disaster recovery,
    network monitoring , and data collection." 
}

@Article{teonn40,
  author       = "Matt Anderson",
  title        = "The Evolution of {NTFS}: {NTFS} 4.0",
  journal      = "Ars Technica",
  keywords     = "file systems",
  abstract     = "Welcome to Part I of my series, the Evolution of NTFS. Part I
    deals with NTFS u through NTFS 1.1, the version of NTFS found in Windows NT
    4.0 (and commonly called NTFS 4.0).  The article will give background t the
    development o NTFS, and foreshadow some o the important changes found in
    the next generation of NTF found in Windows 2000.  Part II wil focus
    completely on NTFS 5.0 (yep, even Microsoft skipped a few numbers), and Par
    III will talk about ways you ca integrate NTFS into a multi-OS environment.
    If you're wanting to learn more about the version of NTFS found in Windows
    2000, start here.  99% o this data is related to NTFS 5.0, and won't be
    repeated in Part II.", 
  location     = "http://archive.arstechnica.com/paedia/n/ntfs.html"
}

@Article{teonn50,
  author       = "Matt Anderson",
  title        = "The Evolution of {NTFS}: {NTFS} 5.0",
  journal      = "Ars Technica",
  keywords     = "file system",
  abstract     = "What's in Part II? Part II is all about NTFS as it stands in
    Windows 2000.  I'm going to cover most of the more highly touted features
    of the semi-new filesystem, including Encrypting Filesystem (EFS),
    Distributed Link Tracking, Quotas, and more.  NTFS 5.0, as it's called in
    Windows 2000, is an important new step in the world of Win32 OSes, and even
    folks who don't use NTWin2K should be interested.  How is it important?
    Well, from an overview perspective, most of the new techs that I covered in
    Windows 2000: 5-n-5 Top Features require the added functionality laid down
    by the new NTFS release.  No matter what you're using now, if you're a
    Microsoft OS user, you'll be getting acquainted with a form of NTFS in the
    near future.", 
  location     = "http://archive.arstechnica.com/paedia/n/ntfs/ntfs5-1.html"
}

@Article{ctprimvms,
  author       = "Hartley, Stephen~J.",
  title        = "Compile-Time Program Restructuring in Multiprogrammed Virtual Memory Systems",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1640--1644",
  month        = nov,
  keywords     = "operating systems, program restructuring, paging behavior,
    performance",
  abstract     = "An evaluation is made of a way to reduce the cost of program
    restructuring by having a compiler determine the program's packing in
    virtual address space from an analysis of its source code.  Two features of
    this method are the duplication of code modules in virtual address space
    and the inline substitution of the code for a called procedure.  This
    compile-time restructuring algorithm is evaluated using the
    instruction-only address traces from a collection of programs.  In a
    simulation of a virtual memory system using disks as secondary storage
    devices, the method is not successful, since it leads to a higher optimum
    space-time execution cost than that of the unrestructured program.  The
    algorithm did reduce program space-time execution cost for some arbitrarily
    chosen memory allocations smaller than the optimum.  This could be useful
    in a multiuser, multiprogrammed environment.", 
  location     = "https://doi.org/10.1109/32.9051"
}

@Article{hidp,
  author       = "Hillier, Bill and Leaman, Adrian",
  title        = "How is Design Possible?",
  journal      = "Journal of Architectural and Planning Research",
  year         = 1974,
  volume       = 3,
  number       = 1,
  pages        = "4--11",
  month        = jan,
  keywords     = "genotypes, phenotypes, solution fields",
  abstract     = "This paper approaches the question 'how is design possible?'
    by suggesting that design is a relatively simple set of operations carried
    out on highly complex structures, which are themselves simplified by
    'theories' and modes of representation.  The analysis strongly suggests
    that if design method is to be improved then it is more important to study
    the environment itself than how designers design."
}

@Article{apsfhscobi,
  author       = "Zygmunt Haas",
  title        = "{A} Protocol Structure for High-Speed Communication Over Broadband {ISDN}",
  journal      = "IEEE Network Magazine",
  year         = 1991,
  volume       = 5,
  number       = 1,
  pages        = "64--70",
  month        = jan,
  keywords     = "protocol stacks, software architecture"
}

@Article{apstsfs,
  author       = "Wright, Andrew~K. and Cartwright, Robert",
  title        = "{A} Practical Soft Type System for {S}cheme",
  journal      = toplas,
  year         = 1997,
  volume       = 19,
  number       = 1,
  pages        = "87--152",
  month        = jan,
  keywords     = "run-time type checking, soft typing, type encodings,
    optimization, static types, type inference, presentation types, data
    definitions, first-class continuations, function types, polymorphism,
    generics", 
  abstract     = "A soft type system infers types for the procedures and data
    structures of dynamically typed programs.  Like conventional static types,
    soft types express program invariants and thereby provide valuable
    information for program optimization and debugging.  A soft type checker
    uses the types inferred by a soft type system to eliminate run-time checks
    that are provably unnecessary; any remaining run-time checks are flagged as
    potential program errors.  Soft Scheme is a practical soft type checker for
    R4RS Scheme.  Its underlying type system generalizes conventional
    Hindley-Milner type inference by incorporating recursive types and a
    limited form of union type.  Soft Scheme accommodates all of R4RS Scheme
    including uncurried procedures of fixed and variable arity, assignment, and
    continuations.", 
  location     = "https://doi.org/10.1145/239912.239917"
}

@Article{smaml,
  author       = "Raymund Sison and Masamichi Shimura",
  title        = "Student Modeling and Machine Learning",
  journal      = "International Journal of Artificial Intelligence in Education",
  year         = 1998,
  volume       = 9,
  number       = 1,
  keywords     = "student behavior, student modeling",
  abstract     = "After identifying essential student modeling issues and
    machine learning approaches, this paper examines how machine learning
    techniques have been used to automate the construction of student models as
    well as the background knowledge necessary for student modeling.  In the
    process, the paper sheds light on the difficulty, suitability and potential
    of using machine learning for student modeling processes, and, to a lesser
    extent, the potential of using student modeling techniques in machine
    learning.", 
  location     = "http://iaied.org/pub/1022/"
}

@Article{esetsisn,
  author       = "Marie Bod{\' e}n and Mikael Bod{\' e}n",
  title        = "Evolving Spelling Exercises to Suit Individual Student Needs",
  journal      = "Applied Soft Computing",
  year         = 2007,
  volume       = 7,
  number       = 1,
  month        = jan,
  keywords     = "computer-aided education, evolutionary computation, user
    modeling, ", 
  abstract     = "The principle of evolving educational content â€“ stepwise and
    stochastic refinement of educational problems on the basis of a student's
    previous success â€“ is extended and evaluated for the domain of spelling.
    Experimental results, generated by an implementation in a classroom
    setting, show that the principle of evolving educational content is not
    only sensitive to an individual student's ability but it also allows the
    student to take novel paths through an open-ended problem space.  Learning
    outcomes are confirmed both quantitatively and qualitatively, and indicate
    that the technique transfers to a pedagogically challenging domain.  We
    present how a problem space can be generated to effectively and
    automatically encompass a wider range of educational domains with little
    designer intervention.", 
  location     = "http://dx.doi.org/10.1016/j.asoc.2005.03.001"
}

@Article{iois,
  author       = "Gary~T. Leavens",
  title        = "Inheritance of interface specifications",
  journal      = sigplan # idl94,
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "129--138",
  month        = aug,
  keywords     = "modularity, information loss",
  abstract     = "Four alternatives for the semantics of inheritance of
    specifications are discussed.  The information loss and frame axiom
    problems for inherited specifications are also considered.",
  location     = "https://doi.org/10.1145/185084.185117"
}

@Article{uiitapisse,
  author       = "Hamilton, Graham and Radia, Sanjay",
  title        = "Using Interface Inheritance to Address Problems in System Software Evolution",
  journal      = sigplan # idl94,
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "119--128",
  month        = aug,
  keywords     = "interfaces, inheritance, versioning",
  abstract     = "Two specific problems faced in large distributed systems are
    (1) evolving and managing different versions of an interface while
    minimizing the impact on existing clients, and (2) supporting the addition
    of auxiliary interfaces that are orthogonal to the main interface of an
    abstraction.In the context of the Spring distributed system, we addressed
    both problems using an object-oriented interface definition language.
    Different versions of an interface are represented as different types with
    an inheritance relationship that minimizes the impact on existing clients
    and allows easy management of versions.We distinguish between fundamental
    and auxiliary properties each of which are defined as separate types.
    Rather than use simple root inheritance, we use a combination of root and
    leaf inheritance.  This provides flexibility in supporting auxiliary
    properties and allows us to add new auxiliary properties as the system
    evolves without forcing the system to be recompiled.The solutions have been
    tested and refined through their use in the Spring system.", 
  location     = "https://doi.org/10.1145/185084.185115"
}

@Article{pvil,
  author       = "Pippenger, Nicholas",
  title        = "Pure versus Impure {L}isp",
  journal      = toplas,
  year         = 1994,
  volume       = 19,
  number       = 2,
  pages        = "223--238",
  month        = mar,
  keywords     = "online computation, schematology, lisp machines, upper and
    lower bounds",
  abstract     = "The aspect of purity versus impurity that we address involves
    the absence versus presence of mutation: the use of primitives (RPLACA and
    RPLACD in Lisp, set-car! and set-cdr! in Scheme) that change the state of
    pairs without creating new pairs.  It is well known that cyclic list
    structures can be created by impure programs, but not by pure ones.  In
    this sense, impure Lisp is more powerful than pure Lisp.  If the inputs and
    outputs of programs are restricted to be sequences of atomic symbols,
    however, this difference in computability disappears.  We shall show that
    if the temporal sequence of input and output operations must be maintained
    (that is, if computations must be online), then a difference in complexity
    remains: for a pure program to do what an impure program does in n steps,
    O(n log n) steps are sufficient, and in some cases Â¿(n log n) steps are
    necessary.", 
  location     = "https://doi.org/10.1145/244795.244798"
}

@Article{anmfaaotw,
  author       = "Baker, James~E. and Cruz, Isabel~F. and Liotta, Giuseppe and Tamassia, Roberto",
  title        = "{A} New Model for Algorithm Animation Over the {WWW}",
  journal      = surveys,
  year         = 1995,
  volume       = 27,
  number       = 4,
  pages        = "568--572",
  month        = dec,
  keywords     = "algorithm animation, client-server architectures,
    event-driven architecture",
  location     = "https://doi.org/10.1145/234782.234792"
}

@Article{uams,
  author       = "Knight, Kevin",
  title        = "Unification: {A} Multidiscliplinary Survey",
  journal      = surveys,
  year         = 1989,
  volume       = 21,
  number       = 1,
  pages        = "93--124",
  month        = mar,
  keywords     = "artificial intelligence, computational complexity,
    equational theories, feature structures, generalization, higher-order logic,
    inheritance, lattices, logic programming, natural language processing, occur
    check, parallel algorithms, prolog, resolution, theorem proving, type
    inference, unification",
  abstract     = "The unification problem and several variants are presented.
    Various algorithms and data structures are discussed.  Research on
    unification arising in several areas of computer science is surveyed; these
    areas include theorem proving, logic programming, and natural language
    processing.  Sections of the paper include examples that highlight
    particular uses of unification and the special problems encountered.  Other
    topics covered are resolution, higher order logic, the occur check,
    infinite terms, feature structures, equational theories, inheritance,
    parallel algorithms, generalization, lattices, and other applications of
    unification.  The paper is intended for readers with a general computer
    science background&mdash;no specific knowledge of any of the above topics
    is assumed.", 
  location     = "https://doi.org/10.1145/62029.62030"
}

@Article{intbipl,
  author       = "Abbott, Mark~B. and Peterson, Larry~L.",
  title        = "Increasing Network Throughput by Integrating Protocol Layers",
  journal      = ton,
  year         = 1993,
  volume       = 1,
  number       = 5,
  pages        = "600-610",
  month        = oct,
  keywords     = "integrated layer processing, word filters, ordering
    constraints, modularity",
  abstract     = "Integrating protocol data manipulations is a strategy for
    increasing the throughput of network protocols.  The idea is to combine a
    series of protocol layers into a pipeline so as to access message data more
    efficiently.  This paper introduces a widely-applicable technique for
    integrating protocols.  This technique not only improves performance, but
    also preserves the modularity of protocol layers by automatically
    integrating independently expressed protocols.  The paper also describes a
    prototype integration tool, and studies the performance limits and
    scalability of protocol integration", 
  location     = "https://doi.org/10.1109/90.251918"
}

@Article{isaepifsois,
  author       = "Gregory~D. Abowd and Allan~J. Dix",
  title        = "Integrating Status and Event Phenomena in Formal Specifications of Interactive Systems",
  journal      = sen # " (" # pot # "Second ACM SIGSOFT Symposium on Foundations of Software Engineering, SIGSOFT '94)",
  year         = 1994,
  volume       = 19,
  number       = 5,
  pages        = "44--52",
  month        = dec,
  keywords     = "formal specifications, interactive system design, multi-user
    systems, mixed-control interaction",
  abstract     = "In this paper we investigate the appropriateness of formal
    specification languages for the description of user interface phenomena.
    Specifically, we are concerned with the distinction between continuously
    available information, which we call status, and atomic, non-persistent
    information, which we call events.  We propose a hybrid model and notation
    to address status and event phenomena symmetrically.  We demonstrate the
    effectiveness of this model for designing and understanding mixed control
    interaction, an especially important topic in the design of multi-user
    systems.", 
  location     = "https://doi.org/10.1145/193173.195293"
}

@Article{mtafgcicn,
  author       = "Hussein~M. Abdel-Wahab",
  title        = "Multiuser Tools Architecture for Group Collaboration in Computer Networks",
  journal      = "Computer Communications",
  year         = 1990,
  volume       = 13,
  number       = 3,
  pages        = "165--169",
  month        = apr,
  keywords     = "computer communications, distributed systems, collaborative
  work, x window system, unix operating system, internet protocol",
  abstract     = "With the widespread availability of data communications
    networks and powerful workstations, there is a strong and growing need to
    support collaboration among geographically distributed users.  This paper
    describes an architecture for constructing multiuser software tools for
    real-time collaboration among a group of remote users.  A prototype
    implementation of a multiuser tool, called CoDraw, based on this
    architecture is described.  CoDraw allows a group of remote users to
    collaborate in drawing figures and graphs.  It is built using the X window
    system and the internet communications in UNIX environment.", 
}

@Article{frog,
  author       = "Eytan Adar and Bernardo~A. Huberman",
  title        = "Free Riding on {G}nutella",
  journal      = fm,
  year         = 2000,
  volume       = 5,
  number       = 10,
  month        = oct,
  keywords     = "peer-to-peer networking, file sharing, tragedy of the commons",
  abstract     = "An extensive analysis of user traffic on Gnutella shows a
    significant amount of free riding in the system.  By sampling messages on
    the Gnutella network over a 24-hour period, we established that almost 70%
    of Gnutella users share no files, and nearly 50% of all responses are
    returned by the top 1% of sharing hosts.  Furthermore, we found out that
    free riding is distributed evenly between domains, so that no one group
    contributes significantly more than others, and that peers that volunteer
    to share files are not necessarily those who have desirable ones.  We argue
    that free riding leads to degradation of the system performance and adds
    vulnerability to the system.  If this trend continues copyright issues
    might become moot compared to the possible collapse of such systems.", 
  location     = "http://firstmonday.org/article/view/792/701"
}

@Article{tsippatsati,
  author       = "Henning Schulzrinne and Jonathan Rosenberg",
  title        = "The {S}ession {I}nitiation {P}rotocol: Providing Advanced Telephony Services Across the {I}nternet",
  journal      = bltj,
  year         = 2002,
  volume       = 3,
  number       = 4,
  pages        = "144--160",
  month        = oct,
  keywords     = "network servers, addressing, naming, mobility, protocol
    integration, modularity",
  abstract     = "During the past few years, Internet telephony has evolved
    from a toy for the technically savvy to a technology that, in the not too
    distant future, may replace the existing circuit-switched telephone
    network.  Supporting the widespread use of Internet telephony requires a
    host of standardized protocols to ensure quality of service (QoS),
    transport audio and video data, provide directory services, and enable
    signaling.  Signaling protocols are of particular interest because they are
    the basis for advanced services such as mobility, universal numbers,
    multiparty conferencing, voice mail, and automatic call distribution.  Two
    signaling protocols have emerged to fill this need: the ITU-T H.323 suite
    of protocols and session initiation protocol (SIP), developed by the
    Internet Engineering Task Force (IETF).  In this paper we examine how SIP
    is used in Internet telephony.  We present an overview of the protocol and
    its architecture, and describe how it can be used to provide a number of
    advanced services.  Our discussion of some of SIP's strengthsâ€”its
    simplicity, scalability, extensibility, and modularityâ€”also analyzes why
    these are critical components for an IP telephony signaling protocol.  SIP
    will prove to be a valuable tool, not just for end-to-end IP services, but
    also for controlling existing phone services." 
}

@Article{tsasfhpcs,
  author       = "Douglas~C. Schmidt and Tatsuya Suda",
  title        = "Transport System Architecture Services For High Performance Communications Systems",
  journal      = "IEEE Journal on Selected Areas in Communications",
  year         = 1993,
  volume       = 11,
  pages        = "489--506",
  month        = may,
  keywords     = "transport layer, protocol families, flow control",
  abstract     = "Providing end-to-end gigabit communication support for
    high-bandwidth multimedia applications requires transport systems that
    transfer data efficiently via network protocols such as TCP, TP4, XTP, and
    ST-II.  This paper describes and classiï¬es transport system services that
    integrate operating system resources such as CPU(s), virtual memory, and
    I/O devices together with network protocols to support distributed
    multimedia applications running on local and wide-area networks.  A taxonomy
    is presented that compares and evaluates four commercial and experimental
    transport systems in terms of their protocol processing support.  The
    systems covered in this paper include System V UNIX STREAMS, the BSD UNIX
    networking subsystem, the x-kernel, and the Choices Conduit system.  This
    paper is intended to navigate researchers and developers through the
    transport system design space by describing alternative approaches for key
    transport system services.", 
  location     = "http://doi.org/10.1109/49.221197"
}

@Article{eotaorabt,
  author       = "Howard Salwen and Richard Boule and J.~Noel Chiappa",
  title        = "Examination of the Applicability of Router and Bridging Techniques",
  journal      = ieeen,
  year         = 1988,
  volume       = 2,
  number       = 1,
  pages        = "77--80",
  month        = jan,
  keywords     = "bridges, routers, processing load, traffic, topology control
    network management, lan interconnection",
  abstract     = "Bridges are compared to routers from a number of
    perspectives. Routers are systems that interconnect networks based on
    information contained in layer 3, the networking layer, of the Open Systems
    Interconnection (OSI) model.  Bridges use layer 2 (data link layer)
    information to determine whether packets should be passed from one network
    to another.  This type of interconnection strategy use node address data
    only and thus is independent of the protocol used for OSI layer 3 and
    above.  Processing requirements of bridges and routers are compared,
    highlighting the more complex processing needs of the latter.  The greater
    functionality and flexibility of routing, which accompanies this increased
    complexity, is discussed.  In particular, the focus is on the ability of
    routers to interconnect different local area network techniques, deal with
    heavy traffic, and control topology", 
  location     = "https://doi.org/10.1109/65.3242"
}

@Article{wsnih11,
  author       = "Clinton Wong",
  title        = "What's New in {HTTP}/1.1",
  journal      = "World Wide Web Journal",
  year         = 1996,
  OPTvolume    = "",
  OPTnumber    = "",
  OPTpages     = "",
  OPTabstract  = "",
  OPTmonth     = "",
  OPTkeywords  = "",
  OPTlocation  = ""
}

@Article{oaics,
  author       = "Rob Kling",
  title        = "Organizational Analysis in Computer Science",
  journal      = "The Information Society",
  year         = 1993,
  volume       = 9,
  number       = 2,
  month        = mar # "-" # jun,
  keywords     = "usability, organizations, informatics, system design",
  abstract     = "Computer science in the United States is hard pressed to show
    broad utility to help justify billion dollar research programs and the
    value of educating well over 40,000 bachelor of science and master of
    science specialists annually in the United States.  The Computer Science
    and Telecommunications Board of the U.S.  National Research Council
    recently has issued a report, â€œComputing the Futureâ€ (Hartmanis & Lin
    1992), which sets a new agenda for computer science.  The report
    recommended that computer scientists broaden their conceptions of the
    discipline to include computing applications and domains to help understand
    them.  This article argues that many computer science graduates need some
    skills in analyzing human organizations to help develop appropriate systems
    requirements, because they are trying to develop highâ€performance computing
    applications that effectively support higher performance human
    organizations.  It is time for academic computer science to embrace
    organizational analysis (the field of Organizational Informatics) as a key
    area of research and instruction.", 
  location     = "https://doi.org/10.1080/01972243.1993.9960134"
}

@Article{astuip,
  author       = "Harald Wertz",
  title        = "{A} System to Understand Incorrect Programs",
  journal      = "Lisp Bulletin",
  year         = 1978,
  volume       = 1,
  number       = 2,
  pages        = "27--34",
  month        = jul,
  keywords     = "lisp, program understanding, rule-based reasoning",
  abstract     = "This paper presents a systems (PHENARETE) which understands
    and improves incompletely defined LISP programs, such as those written by
    students beginning to program in LISP.  This system takes, as input, the
    program without any additional information.  In order to understand the
    program, the system meta-evaluates it, using a library of pragmatic rules,
    describing the construction and correction of general program constructs,
    and a set of specialists, describing the syntax and semantics of the
    standard LISP functions.  The system can use its understanding of the
    program to detect errors in it, to debug them and, eventually, to justify
    its proposed modification.  This paper gives a brief survey of the working
    of the system, emphasizing on some commented examples.", 
  location     = "http://dx.doi.org/10.1145/1411798.1411808"
}

@Article{ansfedb,
  author       = "Attali, Isabelle and Caromel, Denis and Ehmety, Sidi Ould",
  title        = "A Natural Semantics for {E}iffel Dynamic Binding",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 6,
  pages        = "711--729",
  month        = nov,
  keywords     = "inheritance, big-step semantics, dynamic binding, ",
  abstract     = "This article formally defines Eiffel dynamic binding in
    presence of renaming and redefinition.  Message passing, inheritance, and
    polymorphism are expressed in an operational style using natural semantics.
    From the formal specification, we derive an algorithm to determine the
    appropriate version of a feature to apply to a given object.  This
    algorithm, based only on the class hierarchy and not using any intermediate
    structure, gives a practical approach to the understanding of inheritance,
    renaming, and redefinition in Eiffel.", 
  location     = "https://doi.org/10.1145/236114.236118"
}

@Article{aatspt,
  author       = "Carlos Urias Muniz",
  title        = "An Approach to Software Product Testing",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1589--1593",
  month        = nov,
  keywords     = "adaptive testing, black box, correctness measurement, defect
    detection, detect isolation, extensive testing random testing, self-checking,
    test case generator",
  abstract     = "An approach to software product testing is presented.  The
    approach uses the following techniques: automatic test case generation,
    self-checking test cases, black box test cases, random test cases, and a
    form of exhaustive testing, correctness measurements, and correction of
    defects in the test cases instead of in the product (direct circumvention).
    The techniques have been cost effective and applied to a very large
    products.", 
}

@Article{rtaap,
  author       = "Phil Agre",
  title        = "Responding to Arguments Against Privacy",
  journal      = "The Network Observer",
  year         = 1996,
  volume       = 3,
  number       = 7,
  pages        = "1--12",
  month        = jul,
  keywords     = "privacy",
  location     = "http://polaris.gseis.ucla.edu/pagre/tno.html"
}

@Article{pcrhvh,
  author       = "van Houten, Henk and Leibbrandt, Wouter",
  title        = "Phase Change Recording",
  journal      = cacm,
  year         = 2000,
  volume       = 43,
  number       = 11,
  pages        = "64--71",
  month        = nov,
  keywords     = "recordable media, lasers",
  abstract     = "Burning data into and off of the storage medium is such a
    reliable read/write method, the CD is now the world's most popular means of
    distributing and exchanging prerecorded digital content",
  location     = "https://doi.org/10.1145/353360.353366"
}

@Article{tdaioasas,
  author       = "Franklin, Matthew~K. and Reiter, Michael~K.",
  title        = "The Design and Implementation of a Secure Auction Service",
  journal      = tse,
  year         = 1996,
  volume       = 22,
  number       = 5,
  pages        = "302--312",
  month        = may,
  keywords     = "distributed systems, security, byzantine failures, electronic
    commerce, sealed-bit auctions, verifiable signature sharing",
  abstract     = "We present the design and implementation of a distributed
    service for performing sealed-bid auctions.  This service provides an
    interface by which clients, or bidders, can issue secret bids to the
    service for an advertised auction.  Once the bidding period has ended, the
    auction service opens the bids, determines the winning bid, and provides
    the winning bidder with a ticket for claiming the item bid upon.  Using
    novel cryptographic techniques, the service is constructed to provide
    strong protection for both the auction house and correct bidders, despite
    the malicious behavior of any number of bidders and even a constant
    fraction of the servers comprising the auction service.  Specifically, it
    is guaranteed that (i) bids of correct bidders are not revealed until after
    the bidding period has ended, (ii) the auction house collects payment for
    the winning bid, (iii) losing bidders forfeit no money, and (iv) only the
    winning bidder can collect the item bid upon.  We also discuss techniques
    to enable anonymous bidding.",
  location     = "https://doi.org/10.1109/32.502223"
}

@Article{popafutn,
  author       = "David~S. Linthicum",
  title        = "Perils of Porting Applications From " # unix # " to {NT}",
  journal      = "Uniforum",
  year         = 1996,
  month        = aug,
  keywords     = "porting, linux, nt, portability, ",
  location     = "http://www.uniforum.org/publications/ufm/aug96/unix-nt.html"
}

@Article{ipcastsh,
  author       = "Chris Lilley",
  title        = "Information Presentation: {{C}}ascading {{S}}tyle {{S}}heets",
  journal      = "WebSmith",
  year         = 1996,
  volume       = 1,
  number       = 3,
  month        = may # "-" # jun,
  keywords     = "css, html, styling",
  abstract     = "Looking for a simple, effective way to implement style
    changes in your web documents? Explore the possibilities of CCS1.", 
  location     = "http://www.ru.j-npcs.org/usoft/WWW/WebSmith/issues/i3/index.html"
}

@Article{wcssite,
  author       = "Liang, Ting-Peng and Lai, Hsiangchu and Chen, Nian-Shing and Wei, Hungshiung and Chen, Meng Chang",
  title        = "When Client\slash Server Isn't Enough",
  journal      = ieeec,
  year         = 1994,
  volume       = 27,
  number       = 5,
  pages        = "73--79",
  month        = may,
  keywords     = "groupware, task coordination, software architecture",
  abstract     = "Computing in a distributed environment for multitasked
    cooperative work is a promising area that presents many coordination
    issues.  Our prototype system implements a three-layer architecture to
    provide greater control and flexibility in the distributed multitasking
    environment.  The architecture includes a groupware server, application
    servers, and clients.  The architecture can be further refined to provide
    more flexible control of activities.  More applications, such as group
    calendaring and participative design can also be studied to find their
    idiosyncratic coordination needs and to elaborate the division of labor
    among different servers and clients.", 
  location     = "https://doi.org/10.1109/2.291288"
}

@Article{adlanppfcvadt,
  author       = "John~O. Limb and Lois~E. Flamm",
  title        = "{A} Distributed Local Area Network Packet Protocol for Combined Voice and Data Transmission",
  journal      = jsac,
  year         = 1983,
  volume       = 1,
  number       = 5,
  pages        = "926--934",
  month        = nov,
  keywords     = "local area networks, protocols, data communication,
    telecommunication traffic, facsimile, delay, algorithm design and analysis,
    distributed algorithms, circuit simulation, multiplexing",
  abstract     = "Local area networks designed to carry a variety of traffic
    such as data, voice, facsimile, and video should be able to implement low
    latency virtual circuits to meet the demands of periodic traffic.  We have
    designed a partially distributed algorithm to efficiently schedule voice
    traffic on a unidirectional bus system called Fasnet.  Virtual channels are
    allocated for the duration of a talk spurt and relinquished during the
    intervening silent intervals.  Conversations already in progress, but
    without an assigned circuit, take precedence over newly arriving calls.
    Unused voice capacity may be utilized by data stations when required.
    Simulations of the system indicate that performance is close to that
    obtained by an ideal TASI multiplexer.  While the algorithm is unfair, this
    is not a significant factor unless the network is loaded very heavily.
    Further, except for a sojourn time unused voice capacity is utilized by the
    data stations.", 
  location     = "https://doi.org/10.1109/JSAC.1983.1146006"
}

@Article{mspfbis,
  author       = "Thomas D.~C. Little and Arif Ghafoor",
  title        = "Multimedia Synchronization Protocols for Broadband Integrated Services",
  journal      = jsac,
  year         = 1991,
  volume       = 9,
  number       = 9,
  pages        = "1368--1382",
  month        = dec,
  keywords     = "protocols, intserv networks, streaming media, application specific processors, delay, multimedia systems, processor scheduling, data communication, broadband communication, telecommunication traffic",
  abstract     = "Protocols to provide synchronization of data elements with
    arbitrary temporal relationships of both stream and non-stream broadband
    traffic types are proposed.  It is specified that the provision of a
    synchronization function be performed within a packet switched network,
    and, accordingly, a two-level communication architecture is presented.  The
    lower level, called the network synchronization protocol (NSP), provides
    the ability to establish and maintain individual connections with specified
    synchronization characteristics.  The upper level, the application
    synchronization protocol (ASP), supports an integrated synchronization
    service for multimedia applications.  The ASP identifies the temporal
    relationships among an application's data objects and manages the
    synchronization of arriving data for playout.  The proposed NSP and ASP are
    mapped to the session and application layers of the
    open-systems-interconnection (OSI) reference model, respectively.", 
  location     = "https://doi.org/10.1109/49.108675"
}

@Article{wech,
  author       = "Rohit Khare",
  title        = "{W}* Effect Considered Harmful",
  journal      = "IEEE Internet Computing",
  year         = 1999,
  volume       = 3,
  number       = 4,
  pages        = "89--92",
  month        = jul # "-" # aug,
  keywords     = "wireless networking, WAP, Web standard, wireless Internet
    access, TCP/IP ", 
  abstract     = "Claiming that wireless is different WAP 1.1 rewrites almost
    every Web standard in the book.  The commercial demand for WAP has proved
    sufficient to implement most of its technologies, but it should be adopted
    very cautiously.  The author discusses the component technologies of WAP.", 
  location     = "https://doi.org/10.1109/4236.780965"
}

@Article{iaem,
  author       = "Kahrs, Stefan and Sannella, Donald and Tarlecki, Andrzej",
  title        = "Interfaces and {E}xtended {ML}",
  journal      = sigplan # idl94,
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "111--118",
  month        = aug,
  keywords     = "interfaces,  specifications, logics",
  abstract     = "This is a position paper giving our views on the uses and
    makeup of module interfaces.  The position espoused is inspired by our work
    on the Extended ML (EML) formal software development framework and by ideas
    in the algebraic foundations of specification and formal development.  The
    present state of interfaces in EML is outlined and set in the context of
    plans for a more general EML-like framework with axioms in interfaces taken
    from an arbitrary logical system formulated as an institution.  Some more
    speculative plans are sketched concerning the simultaneous use of multiple
    institutions in specification and development.", 
  location     = "https://doi.org/10.1145/185084.185113"
}

@Article{cssanp,
  author       = "Sidhu, Deepinder~P. and Aristizabal, Juan",
  title        = "Constructing Submodule Specifications and Network Protocols",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1565--1577",
  month        = nov,
  keywords     = "automation, formal modeling, protocol development tools,
    protocol entities, protocol properties, protocol service, protocol
    verification, state transition",
  abstract     = "Applications of an automated tool for module specification
    (ATMS) that finds the specification for a submodule of a system are
    presented.  Given the specification of a system, together with the
    specification for n-1 submodules, the ATMS constructs the specification for
    the nth addition submodule such that the interaction among the n submodules
    is equivalent to the specification of the system.  The implementation of
    the technique is based on an approach proposed by P.  Merlin and G.B.
    Bochmann (1983).  The specification of a system and its submodules consists
    of all possible execution sequences of their individual operations.  The
    ATMS uses finite-state machine concepts to represent the specifications and
    interactions of the system and its submodules.  The specification found by
    the ATMS for a missing module of a system is the most general one, if one
    exists.  Application of the ATMS in the area of communication protocols is
    discussed.  A manual process to find the specification for a missing module
    using the Merlin-Bochmann technique is time-consuming and prone to errors.
    The automated tool presented proves a reliable method for constructing such
    a module.", 
  location     = "https://doi.org/10.1109/32.9045"
}

@Article{shoti,
  author       = "Bruce Sterling",
  title        = "Short History of the {I}nternet",
  journal      = "The Magazine of Fantasy and Science Fiction",
  year         = 1993,
  month        = feb,
  keywords     = "internet, arpanet",
  location     = "https://www.internetsociety.org/internet/history-internet/short-history-of-the-internet/"
}

@Article{asdmaiatpacsd,
  author       = "Norio Shiratori and Kaoru Takahashi and Shoichi Noguchi",
  title        = "{A} Software Design Method and Its Application to Protocol and Communication Software Development",
  journal      = cnis,
  year         = 1988,
  volume       = 15,
  number       = 4,
  pages        = "245--267",
  keywords     = "software design method, protocols, communication software,
    protocol verification, protocol implementation, specification language,
    programming language, computer networks, support system for protocol development",
  abstract     = "This paper proposes an approach, called the Harmonic Design
    Method, to achieve an approximately ideal language that simultaneously
    serves the purposes or requirements of software specification,
    verification, implementation and so on.  This approach is based on two
    important concepts-partitioning and unification.  In the Harmonic Design
    Method, the collection of the problem-oriented languages and the
    transformation algorithms between the languages, provided through the
    process of the partitioning and unification, is regarded as the
    approximation to the target ideal language.  As an application of the
    Harmonic Design Method, the design of a software support system for making
    the development of protocols and communication software easy is given.  In
    this design, we provide three problem-oriented languages, viz., the
    protocol specification language NESDEL, the communication software oriented
    programming language IDL and the language EXPA which has both a framework
    for expressing protocols and an algorithm for verifying protocols, and
    three transformation algorithms between them, i.e., NESDEL-to-EXPA,
    EXPA-to-NESDEL and NESDEL-to-IDL.  The details of these languages and
    transformation algorithms are also given.  Finally, we introduce some
    software tools used for supporting these languages and transformation
    algorithms.", 
  location     = "https://doi.org/10.1016/0169-7552%2888%2990062-1"
}

@Article{ampocfans,
  author       = "Fekete, Alan and Lynch, Nancy and Shira, L.",
  title        = "{A} Modular Proof of Correctness for a Network Synchronizer",
  journal      = pot # "Amsterdam Workshop on Distributed Algorithms",
  year         = 1987,
  pages        = "219--256",
  keywords     = "networks, synchronization (electronics), input output models,
    computer communications, algorithms, allocations, automation, clustering,
    distribution, graphs, modular construction, nodes, reasoning, resource
    management, synchronism",
  abstract     = "In this paper we offer a formal, rigorous proof of the
    correctness of Awerbuch's algorithm for network synchronization.  We
    specify both the algorithm and the correctness condition using the I/O
    automation model, which has previously been used to describe and verify
    algorithms for concurrency control and resource allocation.  We show that
    the model is also a powerful tool for reasoning about distributed graph
    algorithms.  Our proof of correctness follows closely the intuitive
    arguments made by the design techniques as stepwise refinement and
    modularity.  In particular, since the algorithm uses simpler algorithms for
    synchronization within and between 'clusters' of nodes, our proof can
    import as lemmas the correctness of these simpler algorithms.  Keywords:
    Verification, Modularity, Network protocols, and Synchronization.", 
  location     = "http://www.dtic.mil/dtic/tr/fulltext/u2/a192726.pdf"
}

@Article{nsfm,
  author       = "Domenico Ferrari ane Anindo Banerjea and Hui Zhang",
  title        = "Network Support for Multimedia",
  journal      = cnis,
  year         = 1994,
  volume       = 26,
  pages        = "1267--1280",
  keywords     = "channel setup, protocol suites",
  abstract     = "Multimedia communication can be supported in an
    integrated-services network in the general framework of realtime
    communication.  The Tenet Group has devised an approach that provides some
    initial solutions to the realtime communication problem.  This paper
    attempts to identify the principles behind these solutions.  We also
    describe a suite of protocols, and their implementations in several
    environments, that embody these principles, and work in progress that will
    lead towards more complete solutions.", 
}

@Article{drcrf,
  author       = "Rob Falla",
  title        = "Dynamically Replaced Content",
  journal      = "Webreview.Com",
  year         = 1998,
  month        = "11 " # dec,
  keywords     = "web development",
  abstract     = "Today we will look at several ways to give your Web page the
    editable feel.  These techniques allow users to replace parts of a Web page
    with their own information.  The functionality is almost the same as using
    the form input controls text and textarea but with a noticeable improvement
    to the appearance.  We will examine four alternative implementations of the
    Replaced Content technique in this article.  The first two are browser
    dependent implementations that highlight the use of this technique in a
    controlled environment like an Intranet.  The other two demonstrate the
    ease with which this technique works cross-browser.  The fourth differs
    from the others by the way it accepts data.", 
  location     = "https://people.apache.org/~jim/NewArchitect/webrevu/1998/12_11/developers/12_11_98_1.html"
}

@Article{rasiimc,
  author       = "Rajagopalan, Bala",
  title        = "Reliability and Scaling Issues in Multicast Communication",
  journal      = ccr # " (Conference Proceedings On Communications Architectures \& Protocols, SIGCOMM '92)",
  year         = 1992,
  volume       = 22,
  number       = 4,
  pages        = "188--198",
  month        = oct,
  keywords     = "multicast group association protocol, reliable multicasting,
    gateway-host protocols, group addressing",
  abstract     = "The efficiency with which multicast communication can take
    place is largely determined by the network level support available for such
    communication.  Two factors contribute to the complexity of supporting
    current multicast applications: the lack of reliable multicast transport
    mechanisms at the network level and the lack of network support for large
    scale multicast communication.  In this paper, we examine the issues
    pertinent to eliminating these shortcomings.  We first show that internet
    multicasting algorithms based on reverse path forwarding are inherently
    unreliable and present a source-tree-based reliable multicasting scheme.
    The new scheme makes use of simple inter-gateway protocols and works on top
    of previously developed distance vector and link state internet routing
    schemes.  Next, to support large scale applications, we present a scheme
    for partial multicasting and introduce a new network level operation,
    called gather.  The partial multicasting mechanism allows messages to be
    delivered to subsets of multicast destinations, while the gather operation
    aids gateways in selectively suppressing redundant messages, thus reducing
    the message complexity.  Using simulations, we investigate the efficacy of
    our schemes in supporting a sample application based on multicast
    communication.", 
  location     = "https://doi.org/10.1145/144179.144275"
}

@Article{twsppuscbtfossd,
  author       = "Chris Rasch",
  title        = "The {W}all {S}treet Performer Protocol:  Using Software Completion Bonds to Fund Open Source Software Development",
  journal      = "First Monday",
  year         = 2001,
  volume       = 6,
  number       = 6,
  month        = "4 " # jun,
  keywords     = "social policy, open source marketplaces, software completion
    bond markets, funding",
  abstract     = "In their article â€œThe street performer protocol and digital
    copyrightsâ€ (Kelsey and Schneier, 1999) suggest that copyright will become
    increasingly difficult to enforce.  They propose a general mechanism for
    funding digital public works, the â€œstreet performer protocolâ€ in which
    authors produce their work only after they receive enough contributions to
    make it worth their while.  In this article, I sketch out a proposal for
    the creation of a software completion bond market.  I think such a market
    would be a practical implementation of the â€œstreet performer protocolâ€ for
    the funding of open source software.  I first describe how such a bond
    market might work, and why I think the open source community needs a bond
    market.  Then I examine the underlying economics of open source software.
    Finally, I review some of the existing and potential alternatives to a
    software completion bond market [1].",
  location     = "http://firstmonday.org/ojs/index.php/fm/article/view/865/774"
}

@Article{jitcc,
  author       = "Peter Chalk",
  title        = "Java in the Computing Curricula",
  journal      = sigplan,
  year         = 1999,
  volume       = 34,
  number       = 12,
  pages        = "9--11",
  month        = dec,
  keywords     = "java, object-oriented programming, pedagogy",
  location     = "https://doi.org/10.1145/344283.344284"
}

@Article{sahpia,
  author       = "David~R. Cheriton",
  title        = "Sirpent:  {A} High-Performance Internetworking Approach",
  journal      = ccr # " (Conference Proceedings On Communications Architectures \& Protocols, SIGCOMM '89)",
  year         = 1989,
  volume       = 19,
  number       = 4,
  pages        = "158--169",
  month        = sep,
  keywords     = "routing, high-performance, resource management, scalability,
    source routing, transport layer, packet lifetimesl",
  abstract     = "A clear target for computer communication technology is to
    support a high-performance global internetwork.  Current internetworking
    approaches use either concatenated virtual circuits, as in X.75, or a
    &ldquo;universal&rdquo; internetwork datagram, as in the DoD Internet IP
    protocol and the ISO connectionless network protocol (CLNP).  Both
    approaches have significant disadvantages.  This paper describes
    Sirpent&trade; (Source Internetwork Routing Protocol with Extended Network
    Transfer)1, a new approach to an internetwork architecture that makes
    source routing the basis for interconnection, rather than an option as in
    IP.  Its benefits include simple switching with low per-packet processing
    and delay, support for accounting and congestion control, and scalability
    to a global internetwork.  It also supports flexible, user-controlled
    routing such as required for security, policy-based routing and realtime
    applications.  We also propose a specific internetwork protocol, called
    VIPER&trade;2, as a realization of the Sirpent approach.", 
  location     = "https://doi.org/10.1145/75246.75263"
}

@Article{gepcfaas,
  author       = "Dabbous, Walid and O'Malley, Sean and Castelluccia, Claude",
  title        = "Generating Efficient Protocol Code from an Abstract Specification",
  journal      = ccr # " (Conference Proceedings On Communications Architectures \& Protocols, SIGCOMM '96)",
  year         = 1996,
  volume       = 26,
  number       = 4,
  pages        = "60--72",
  month        = oct,
  keywords     = "esterel, code generation, input scheduling, sharing, performance",
  abstract     = "A protocol compiler takes as input an abstract specification
    of a protocol and generates an implementation of that protocol.  Protocol
    compilers usually produce inefficient code both in terms of code speed and
    code size.  In this paper, we show that the combination of two techniques
    makes it possible to build protocol compilers that generate efficient code.
    These techniques are i) the use of a compiler that generates from the
    specification a unique tree-shaped automaton (rather than multiple
    independent automata), and ii) the use of optimization techniques applied
    at the automaton level, i.e.  on the branches of the trees.We have
    developed a protocol compiler that uses both these techniques.  The
    compiler takes as input a protocol specification written in the synchronous
    language Esterel.  The specification is compiled into a unique automaton by
    the Esterel front end compiler.  The automaton is then optimized and
    converted into C code by our protocol optimizer called HIPPCO.  HIPPCO
    improves code performance and reduces code size by simultaneously
    optimizing the performance of the common path and optimizing the size of
    the uncommon path.  We evaluate the gain expected with our approach on a
    real-life example, namely a working subset of the TCP protocol generated
    from an Esterel specification.  We compare the protocol code generated with
    our approach to that derived from the standard BSD TCP implementation.  The
    results are very encouraging.  HIPPCO-generated code executes up to 25 %
    fewer instructions than the BSD code for input packet processing while
    maintaining comparable code size.", 
  location     = "https://doi.org/10.1145/248156.248163"
}

@Article{ggoweb,
  author       = "Karl Beiser",
  title        = "Getting Grabby: Offline {{W}}eb Browsing",
  journal      = "Online",
  year         = 1997,
  volume       = 21,
  number       = 2,
  pages        = "20--27",
  month        = mar # "/" # apr,
  keywords     = "web, bandwidth, webwhacker"
}

@Article{ctate,
  author       = "Palsberg, Jens and Smith, Scott",
  title        = "Constrained Types and Their Expressiveness",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 5,
  pages        = "519--527",
  month        = sep,
  keywords     = "constraints, constrained types",
  abstract     = "A constrained type consists of both a standard type and a
    constraint set.  Such types enable efficient type inference for
    object-oriented languages with polymorphism and subtyping, as demonstrated
    by Eifrig, Smith, and Trifonov.  Until now, it has been unclear how
    expressive constrained types are.  In this article we study constrained
    types without universal quantification.  We prove that they accept the same
    programs as the type system of Amadio and Cardelli with subtyping and
    recursive types.  This result gives a precise connection between
    constrained types and the standard notion of types.",
  location     = "https://doi.org/10.1145/232706.232715"
}

@Article{sdm,
  author       = "Peckham, Joan and Maryanski, Fred",
  title        = "Semantic Data Models",
  journal      = surveys,
  year         = 1988,
  volume       = 20,
  number       = 3,
  pages        = "153--189",
  month        = sep,
  keywords     = "conceptual data models, database systems, data models,logical
  database design, next generation data models, comparative analysis",
  abstract     = "Semantic data models have emerged from a requirement for more
    expressive conceptual data models.  Current generation data models lack
    direct support for relationships, data abstraction, inheritance,
    constraints, unstructured objects, and the dynamic properties of an
    application.  Although the need for data models with richer semantics is
    widely recognized, no single approach has won general acceptance.  This
    paper describes the generic properties of semantic data models and presents
    a representative selection of models that have been proposed since the
    mid-1970s.  In addition to explaining the features of the individual
    models, guidelines are offered for the comparison of models.  The paper
    concludes with a discussion of future directions in the area of conceptual
    data modeling.", 
  location     = "https://doi.org/10.1145/62061.62062"
}

@Article{tsosr,
  author       = "Frank Pajares",
  title        = "The Structure of Scientific Revolutions",
  journal      = "Philosopher's Web Magazine",
  keywords     = "normal science, paradigms, anomaly, scientific theories, crisis",
  abstract     = "A synopsis from the original",
  location     = "https://www.uky.edu/~eushe2/Pajares/kuhnsyn.html"
}

@Article{macsiichtatfoal,
  author       = "Amy~C. Page",
  title        = "Microsoft: {A} Case Study in International Competitiveness, Hight Technology, and the Future of Antitrust Law",
  journal      = "Federal Communications Law Journal",
  year         = 1994,
  volume       = 47,
  number       = 1,
  pages        = "artical 9",
  keywords     = "antitrust, microsoft, monopolization, globalization, policy",
  location     = "http://www.repository.law.indiana.edu/fclj/vol47/iss1/9"
}

@Article{ctailfli,
  author       = "Radia Perlman and Arthur Harvey and George Varghese",
  title        = "Choosing the Appropriate {ISO} layer for {LAN} Interconnection",
  journal      = ieeen,
  year         = 1988,
  volume       = 2,
  number       = 1,
  pages        = "81--86",
  month        = jan,
  keywords     = "bridges, routers, addressing, bandwidth, control",
  abstract     = "The authors discuss the technical ramifications involved in
    the choice between interconnecting local area networks with a layer 3 (ISO
    network layer) versus layer 2 (ISO data link layer) approach, that is,
    routers versus bridges.  They consider the distinction between two layers
    and define routers and bridges.  They then argue the case for each.  They
    conclude that neither approach is better, in the sense that each has its
    appropriate problem space, and suggest a mixture of relays.", 
  location     = "https://doi.org/10.1109/65.3243"
}

@article{ecfoam,
  author       = "Chrysanthis, Panos~K. and Raghuram, S. and Ramamritham, Krithi",
  title        = "Extracting Concurrency From Objects: {A} Methodology",
  journal      = "ACM SIGMOD Record (" # pot # " 1991 ACM SIGMOD International Conference on Management of Data, SIGMOD '91)",
  year         = 1991,
  pages        = "108--117",
  volume       = 20,
  number       = 2,
  month        = jun,
  keywords     = "concurrency control, semantics, object graphs",
  abstract     = "Whereas a number of semantics-based concurrency control
    schemes for object-oriented systems have been proposed in the literature,
    each scheme has approached the issue from fairly narrow considerations.  In
    this paper, we have made an effort to discover, from first principles, the
    nature of concurrency semantics inherent in objects.  Towards this end, we
    identify the dimensions along which object and operation semantics can be
    modeled.  These dimensions are then used to classify and unify existing
    semantic-based concurrency control schemes.  To formalize this
    classification, we propose a graph representation for objects that can be
    derived from the abstract specification of an object, Based on this
    representation, which helps identify the semantic information inherent in
    an object, we propose a methodology that shows how various semantic notions
    applicable to concurrency control can be effectively combined to improve
    concurrency.  In this process, we identify and exploit a new source of
    semantic information, namely, the ordering among component objects, to
    further enhance concurrency.  Lastly, we present a scheme, based on this
    methodology, for deriving compatibility tables for operations on objects.", 
  location     = "https://doi.org/10.1145/119995.115803"
}

@Article{iigttotwoc,
  author       = "Molinero-Fern{\' a}ndez, Pablo and McKeown, Nick and Zhang, Hui",
  title        = "Is {IP} Going to Take Over the World of Communication?",
  journal      = ccr,
  year         = 2003,
  volume       = 33,
  number       = 1,
  pages        = "113--118",
  month        = jan,
  keywords     = "ip, packet switching, circuit swithing",
  abstract     = "While it is technically pleasing to believe that IP will
    dominate all forms of communication, our delight in its elegance is making
    us overlook its shortcomings.  IP is an excellent means to exchange data,
    which explains its success.  It remains ill suited as a means to provide
    many other types of service; and is too crude to form the transport
    infrastructure in its own right.  To allow the continued success of IP, we
    must be open-minded to it living alongside, and co-operating with other
    techniques (such as circuit switching) and protocols that are optimized to
    different needs.  In this position paper, we question some of the folklore
    surrounding IP and packet switching.  We conclude that while
    packet-switched IP will continue to dominate best-effort data services at
    the edge of the network, the core of the network will use optical circuit
    switching as a platform for multiple services.",
  location     = "http://yuba.stanford.edu/~nickm/papers/sigcomm_2002_position.pdf", 
  location     = "https://doi.org/10.1145/774763.774781"
}

@Article{tsktsosr,
  author       = "Daniel~P. Moloney",
  title        = "Thomas {S}. {K}uhn, {\it {T}he {S}tructure of {S}cientific {R}evolutions}",
  journal      = "First Things",
  year         = 2000,
  number       = 101,
  pages        = "53--55",
  month        = mar,
  keywords     = "kuhn",
  location     = "https://www.firstthings.com/article/2000/03/the-structure-of-scientific-revolutions"
}

@Article{cpyipysi,
  author       = "David Mertz",
  title        = "Charming {P}ython: Inside {P}ython's Implementations",
  journal      = "IBM developerWorks",
  year         = 2000,
  volume       = 19,
  number       = 48,
  month        = "13 " # nov,
  keywords     = "stackless python, scripting languages, language implementation",
  abstract     = "What most programmers probably think of when they talk about
    Python is the specific implementation sometimes called CPython (because it
    is implemented in C).  However, Python as a language specification has been
    implemented several times in parallel with the evolution of Guido van
    Rossum's reference implementation.  This article consists of annotated
    interviews with the creators of two of the non-standard Pythons --
    Stackless and Vyper.", 
  location     = "https://www.linuxtoday.com/infrastructure/2000111301306NWCYSW"
}

@Article{rfccatal,
  author       = "Narian~H. Gehani and William~D. Roome",
  title        = "Rendezvous Facilities: {C}oncurrent {C} and the {A}da Language",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1546--1553",
  month        = nov,
  keywords     = "parallel programming, Concurrent C, Ada, concurrent
    programming, rendezvous, synchronization, expressiveness, priority,
    language constructs, process management", 
  abstract     = "The concurrent programming facilities in both Concurrent C
    and the Ada language are based on the rendezvous concept.  Although these
    facilities are similar, there are substantial differences.  Facilities in
    Concurrent C were designed keeping in perspective the concurrent
    programming facilities in the Ada language and their limitations.
    Concurrent C facilities have also been modified as a result of experience
    with its initial implementations.  The authors compare the concurrent
    programming facilities in Concurrent C and Ada and show that it is easier
    to write a variety of concurrent programs in Concurrent C than in Ada.", 
  location     = "https://doi.org/10.1109/32.9043"
}

@Article{rocbmd,
  author       = "Candea, George and Brown, Aaron~B. and Fox, Armando and Patterson, David",
  title        = "Recovery-Oriented Computing:  Building Multitier Dependability",
  journal      = ieeec,
  year         = 2004,
  volume       = 37,
  number       = 11,
  pages        = "60--67",
  month        = nov,
  keywords     = "microbooting, undo/redo systems, fast recovery, system
    dependability, system recovery", 
  abstract     = "The Recovery-Oriented Computing project studied techniques to
    help systems quickly recover from inevitable failures.  ROC research
    focuses mainly on Internet services because they can growto immense
    proportions, are subject to perpetual evolution, have varying workloads,
    and are expected to run 24/7.The project has implemented two building
    blocks for recovery: microreboot and system-level undo.  These researchers
    believe that most of what we have learned from Internet services can also
    be appliedto desktops, smaller network services, and other computing
    environments.", 
  location     = "https://doi.org/10.1109/MC.2004.219"
}

@Article{cwprctattotups,
  author       = "Craig Calhoun",
  title        = "Community without Propinquity Revisited: Communications Technology and the Transformation of the Urban Public Sphere",
  journal      = "Sociological Inquiry",
  year         = 1998,
  volume       = 68,
  number       = 3,
  pages        = "373--397",
  month        = jul,
  keywords     = "urban phenomenon, interpersonal community, urban public
  sphere",
  abstract     = "Recent discussions of the Internet have touted â€œvirtual
    communityâ€ and a capacity to enhance citizen power in democracies.  The
    present essay (a) calls for a more rigorous understanding of community; (b)
    suggests that relationships forged with the aid of electronic technology
    may do more to foster â€œcategorical identitiesâ€ than they do dense,
    multiplex, and systematic networks of relationships; and (c) argues that an
    emphasis on community needs to be complemented by more direct attention to
    the social bases of discursive publics that engage people across lines of
    basic difference in collective identities.  Previous protest movements have
    shown that communications media have an ambiguous mix of effects.  They do
    facilitate popular mobilization, but they also make it easy for relatively
    ephemeral protest activity to outstrip organizational roots.  They also
    encourage governments to avoid concentrating their power in specific
    spatial locations and thus make revolution in some ways more difficult.", 
  location     = "https://doi.org/10.1111/j.1475-682X.1998.tb00474.x"
}

@Article{dcdal,
  author       = "Lelewer, Debra~A. and Hirschberg, Daniel~S.",
  title        = "Data Compression",
  journal      = surveys,
  year         = 1987,
  volume       = 19,
  number       = 3,
  pages        = "261--296",
  month        = sep,
  keywords     = "adaptive coding, adaptive huffman coding, coding, coding
    theory, file compression, huffman codes, minimum-redundancy codes, optimal
    codes, prefix codes, text compression",
  abstract     = "This paper surveys a variety of data compression methods
    spanning almost 40 years of research, from the work of Shannon, Fano, and
    Huffman in the late 1940s to a technique developed in 1986.  The aim of
    data compression is to reduce redundancy in stored or communicated data,
    thus increasing effective data density.  Data compression has important
    application in the areas of file storage and distributed systems.  Concepts
    from information theory as they relate to the goals and evaluation of data
    compression methods are discussed briefly.  A framework for evaluation and
    comparison of methods is constructed and applied to the algorithms
    presented.  Comparisons of both theoretical and empirical natures are
    reported, and possibilities for future research are suggested.", 
  location     = "https://doi.org/10.1145/45072.45074"
}

@Article{cagjtb,
  author       = "Boyland, John Tang",
  title        = "Conditional Attribute Grammars",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 1,
  pages        = "73--108",
  month        = jan,
  keywords     = "attribute grammars, conditionals, demand evaluation,
    functional dependencies, language processor generators, non-strict
    evaluation, static analysis",
  abstract     = "Attribute grammars are a useful formalism for the
    specification of computations on structured terms.  The classical
    definition of attribute grammars, however, has no way of treating
    conditionals nonstrictly.  Consequently, the natural way of expressing many
    otherwise well-behaved computations involves a circularity.  This article
    presents conditional attribute grammars, and extension of attribute
    grammars that enables more precise analysis of conditionals.  In
    conditional attribute grammars, attribute equations may have guards.
    Equations are active only when their guards are satisfied.  The standard
    attribute grammar evaluation classes are definable for conditional
    attribute grammars, and the corresponding evaluation techniques can be
    easily adapted.  However, determining membership in standard evaluation
    classes such as 1-SWEEP, OAG, and SNC is NP-hard.", 
  location     = "https://doi.org/10.1145/225540.225544"
}

@Article{sfithu,
  author       = "Hudson, Scott~E. and King, Roger",
  title        = "Semantic Feedback in the {H}iggens {UIMS}",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1188--1206",
  month        = aug,
  keywords     = "computer graphics, incremental attribute evaluation, semantic
    feedback, user interface management, user reversal and recovery",
  abstract     = "Almost all applications using interactive graphics contain
    important structures and concepts which are deeper than the geometres used
    to display them to the user.  One of the major tasks of the system
    implementer is to cause the user interface to reflect this deeper structure
    accurately so that it may be directly manipulated by the user.  The authors
    describe a tool, the Higgens user interface management system (UIMS), which
    can automate much of this task for a wide class of systems using
    interactive graphics.  It is able to generate graphical user interfaces
    automatically from a high-level interface specification.  These
    specifications are primarily nonprocedural in nature.  They describe how
    graphical images can be automatically derived and updated based on
    applications entities, and how graphical inputs can be translated back into
    terms which are appropriate to the application.", 
  location     = "https://doi.org/10.1109/32.7628"
}

@Article{sfodpcsafd,
  author       = "Ute Bormann and Carsten Bormann",
  title        = "Standards for Open Document Processing:  Current State and Future Developments",
  journal      = cnis,
  year         = 1991,
  volume       = 21,
  number       = 3,
  pages        = "149--163",
  month        = may,
  keywords     = "open document processing, sgml, oda",
  abstract     = "SGML (ISO 8879) and ODA (ISO 8613) are the two predominant
    international standards in the realm of open document processing, gaining
    more and more importance for the interchange of documents in both the
    publishing environment and the office environment.  To ensure early
    availability the functionality currently provided by these standards has
    been restricted with respect to some future requirements.  The pertinent
    international standardization committees are currently working on the
    required future extensions to these standards.",
  location     = "http://dx.doi.org/10.1016/0169-7552%2891%2990035-B"
}

@Article{tamfm,
  author       = "Chambers, Craig and Leavens, Gary~T.",
  title        = "Typechecking and Modules for Multimethods",
  journal      = toplas,
  year         = 1995,
  volume       = 17,
  number       = 6,
  pages        = "805--843",
  month        = nov,
  keywords     = "object-oriented languages, Cecil, modules, packages, type
    systems, type checking algorithms, subtyping, signatures, inheritance", 
  abstract     = "Two major obstacles that hinder the wider acceptance of
    multimethods are (1) concerns over the lack of encapsulation and modularity
    and (2) the absence of static typechecking in existing multimethod-based
    languages.  This article addresses both of these problems.  We present a
    polynomial-time, static typechecking algorithm that checks the conformance,
    completeness, and consistency of a group of method implementations with
    respect to declared message signatures.  This algorithm improves on
    previous algorithms by handling separate type and inheritance hierarchies,
    abstract classes, and graph-based method lookup semantics.  We also present
    a module system that enables independently developed code to be fully
    encapsulated and statically typechecked on a per-module basis.  To
    guarantee that potential conflicts between independently developed modules
    have been resolved, a simple well-formedness condition on the modules
    comprising a program is checked at link-time.  The typechecking algorithm
    and module system are applicable to a range of multimethod-based languages,
    but the article uses the Cecil language as a concrete example of how they
    can be applied.", 
  location     = "https://doi.org/10.1145/218570.218571"
}

@Article{micamif,
  author       = "Soma Chadhuri",
  title        = "More {\it Choices\/} Allow More {\it Faults\/}",
  subtitle     = "Set Consensus Problems in Totally Asynchronous Systems",
  journal      = "Information and Computation",
  year         = 2001,
  volume       = 105,
  number       = 1,
  pages        = "132--158",
  month        = mar,
  keywords     = "consensus, impossibility results, fault-tolerance,
    asynchronous distributed systems, set consensus",
  abstract     = "We define the k-SET CONSENSUS PROBLEM as an extension of the
    CONSENSUS problem, where each processor decides on a single value such that
    the set of decided values in any run is of size at most k.  We require the
    agreement condition that all values decided upon are initial values of some
    processor.  We show that the problem has a simple (kâˆ’1) -resilient protocol
    in a totally asynchronous system.  In an attempt to come up with a matching
    lower bound on the number of failures, we study the uncertainty condition,
    which requires that there must be some initial configuration from which all
    possible input values can be decided.  We prove using a combinatorial
    argument that any k-resilient protocol for the k-set agreement problem
    would satisfy the uncertainty condition, while this is not true for any
    (kâˆ’1)-resilient protocol.  This result seems to strengthen the conjecture
    that there is no k-resilient protocol for this problem.  We prove this
    result for a restricted class of protocols.  Our motivation for studying
    this problem is to test whether the number of choices allowed to the
    processors is related to the number of faults.  We hope that this will
    provide intuition towards achieving better bounds for more practical
    problems that arise in distributed computing, e.g., the renaming problem.
    The larger goal is to characterize the boundary between possibility and
    impossibility in asynchronous systems given multiple faults", 
  location     = "http://dx.doi.org/10.1006/inco.1993.1043"
}

@Article{aaogmids,
  author       = "Kemper, Alfons and Wallrath, Mechtild",
  title        = "An Analysis of Geometric Modeling in Database Systems",
  journal      = surveys,
  year         = 1987,
  volume       = 19,
  number       = 1,
  pages        = "47--91",
  month        = mar,
  keywords     = "engineering database systems, geometric modeling,
    object-oriented database systems, cad-cam database systems, constructive
    solid geometry, boundary representation, database access languages, object
    representations, relational modeling",
  abstract     = "The data-modeling and computational requirements for
    integrated computer aided manufacturing (CAM) databases are analyzed, and
    the most common representation schemes for modeling solid geometric objects
    in a computer are described.  The primitive instancing model, the boundary
    representation, and the constructive solid geometry model are presented
    from the viewpoint of database representation.  Depending on the
    representation scheme, one can apply geometric transformations to the
    stored geometric objects.  The standard transformations, scaling,
    translation, and rotation, are outlined with respect to the data structure
    aspects.  Some of the more recent developments in the area of engineering
    databases with regard to supporting these representation schemes are then
    explored, and a classification scheme for technical database management
    systems is presented that distinguishes the systems according to their
    level of object orientation: structural or behavioral object orientation.
    First, several systems that are extensions to the relational model are
    surveyed, then the functional data model DAPLEX, the nonnormalized
    relational model NF2, and the database system R2D2 that provides abstract
    data types in the NF2 model are described.", 
  location     = "https://doi.org/10.1145/28865.28866"
}

@Article{asagqffcm,
  author       = "Golestani, S.~Jamaloddin",
  title        = "{A} Stop-And-Go Queueing Framework for Congestion Management",
  journal      = ccr # " (" # pot # "ACM SIGCOMM '97 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication)",
  year         = 1990,
  volume       = 20,
  number       = 4,
  pages        = "8--18",
  month        = sep,
  keywords     = "framing strategies, packet admission policies, frame size,
    queueing delay, bandwidth allocation, congestion strategies",
  abstract     = "A framework for congestion management in integrated services
    packet networks based on a particular service discipline, called
    stop-and-go queueing, is proposed.  In this framework, loss-free and
    bounded-delay transmission is provided to the class of traffic with
    stringent delay and loss requirements, e.g., real-time traffic, while the
    bursty traffic without such requirements is treated on a different basis to
    achieve high transmission efficiency.  Loss-free and bounded-delay
    transmission is accomplished by means of an admission policy which ensures
    smoothness of the traffic at the network edge, and the stop-and-go queueing
    which maintains the traffic smoothness throughout the network.  Both the
    admission policy and the stop-and-go queueing are based on a time framing
    concept, addressed in a previous paper.  This concept is further developed
    here to incorporate several frame sizes into the strategy, thereby
    providing the necessary flexibility in accommodating throughput and
    end-to-end delay requirements of different connections on an as-needed
    basis.", 
  location     = "https://doi.org/10.1145/99508.99523"
}

@Article{fosem,
  author       = "Robert~L. Glass",
  title        = "Facts of Software Engineering Management",
  journal      = "InformIT",
  year         = 2002,
  month        = "22 " # nov,
  keywords     = "management, programmer quality, programmer productivity, work
    environment, exaggeration, learning, tooling, estimation, timing",
  abstract     = "Robert L.  Glass explains why a software manager can't forget
    about the most important facts â€”like people are important, technical hype
    does more harm that good, and complexity is, well, complex.", 
  location     = "http://www.informit.com/articles/index.aspx?st=66385"
}

@Article{kvtlmp,
  author       = "Aviel~D. Rubin",
  title        = "Kerberos Versus the {L}eighton-{M}icali Protocol",
  journal      = ddj,
  year         = 2000,
  volume       = 25,
  number       = 11,
  pages        = "21--26",
  month        = nov,
  keywords     = "kerberos, cryptography",
  location     = "http://www.drdobbs.com/kerberos-versus-the-leighton-micali-pr/184404307"
}

@Article{ccittips,
  author       = "Craig~H. Rowland",
  title        = "Covert Channels in the {TCP}/{IP} Protocol Suite",
  journal      = "First Monday",
  year         = 1997,
  volume       = 2,
  number       = 5,
  month        = jan,
  keywords     = "tcp/ip headers, sequence numbers, tcp acknowledgments, protection",
  abstract     = "The TCP/IP protocol suite has a number of weaknesses that
    allow an attacker to leverage techniques in the form of covert channels to
    surreptitiously pass data in otherwise benign packets.  This paper attempts
    to illustrate these weaknesses in both theoretical and practical
    examples.", 
  location     = "http://dx.doi.org/10.5210/fm.v2i5.528",
  location     = "http://firstmonday.org/ojs/index.php/fm/article/view/528/449"
}

@Article{hodo,
  author       = "Cejtin, Henry and Jagannathan, Suresh and Kelsey, Richard",
  title        = "Higher-Order Distributed Objects",
  journal      = toplas,
  year         = 1995,
  volume       = 17,
  number       = 5,
  pages        = "704--739",
  month        = sep,
  keywords     = "concurrency, continuations, higher-order languages, message
    passing, garbage collection, proxies, interpretation",
  abstract     = "We describe a distributed implementation of Scheme that
    permits efficient transmission of higher-order objects such as closures and
    continuations.  The integration of distributed communication facilities
    within a higher-order programming language engenders a number of new
    abstractions and paradigms for distributed computing.  Among these are
    user-specified load-balancing and migration policies for threads,
    incrementally linked distributed computations, and parameterized
    client-server applications.  To our knowledge, this is the first
    distributed dialect of Scheme (or a related language) that addresses
    lightweight communication abstractions for higher-order objects.", 
  location     = "https://doi.org/10.1145/213978.213986",
  location     = "https://www.cs.purdue.edu/homes/suresh/papers/toplas95.ps.gz"
}

@Article{tpemho,
  author       = "Olson, Margrethe~H. and Bly, Sara~A.",
  title        = "The {P}ortland Experience",
  subtitle     = "A Report on a Distributed Research Group",
  journal      = "International Journal of Man-Machine Studies",
  year         = 1991,
  volume       = 34,
  number       = 2,
  pages        = "211--228",
  month        = feb,
  keywords     = "distributed laboratory, social research, management control",
  abstract     = "From 1985 for three years, the System Concepts Laboratory
    (SCL) of the Xerox Palo Alto Research Center had employees in both Palo
    Alto, California, and Portland, Oregon.  The Portland remote site was
    intended to be a forcing function for the lab to focus on issues of
    interpersonal computing in a geographically distributed organization.
    Interpersonal computing supports people communicating and working together
    through computers; it includes tools and support interaction separated by
    time and/or space as well as face-to-face interaction and meetings.  A
    consultant to the laboratory took on the role of outside observer to
    provide insight into questions about the process of working in a
    distributed organization and about tools for supporting collaboration in a
    distributed organization.  The primary collaborative world of the lab
    itself was design.  The major tool that developed to support the cross-site
    environment was Media Space, a network of video, audio and computing
    technologies.  With the Media Space, SCL members were able to make
    significant progress in supporting their distributed design process.  The
    SCL experience adds to the existing knowledge of collaboration by focusing
    on intellectual effort where the primary resource is information.  The
    activities of the lab depended on reciprocal interdependence of group
    members for information.  Their work required them to be in touch with one
    another to share and coordinate information, yet lab members were often not
    together physically or temporally.  The SCL work forced the boundaries of
    social place to extend beyond the boundaries of physical place.", 
  location     = "https://doi.org/10.1016/0020-7373%2891%2990042-6"
}

@Article{tdotvos,
  author       = "Barbara~H. Liskov",
  title        = "The Design of the {V}enus Operating System",
  journal      = cacm,
  year         = 1972,
  volume       = 15,
  number       = 3,
  pages        = "144--149",
  month        = mar,
  keywords     = "operating systems, system design, levels of abstraction,
    machine architecture, microprogramming, signals, semaphores,
    multiprogramming, virtual machines, processes, process communication,
    virtual devices, data sharing, resource management, deadlock,
    segmentation",
  abstract     = "The Venus Operating System is an experimental
    multiprogramming system which supports five or six concurrent users on a
    small computer.  The system was produced to test the effect of machine
    architecture on complexity of software.  The system is defined by a
    combination of microprograms and software.  The microprogram defines a
    machine with some unusual architectural features; the software exploits
    these features to define the operating system as simply as possible.  In
    this paper the development of the system is described, with particular
    emphasis on the principles which guided the design.", 
  location     = "https://doi.org/10.1145/361268.361272"
}

@Article{aaospimmswfssd,
  author       = "Steven~J. Hartley",
  title        = "An Analysis of Some Problems in Managing Virtual Memory Systems with Fast Secondary Storage Devices",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1176--1187",
  month        = aug,
  keywords     = "storage allocation, virtual memory, secondary storage, cyclic
    locality interval, least-cost pathway, memory management, loop structure,
    space-time execution cost", 
  abstract     = "Some of the problems that are expected to be encountered in
    managing virtual memory systems using the newer-technology secondary
    storage devices are address.  The difficulties that two proposed policies
    have in choosing the most economical program localities of reference to
    assign to primary memory are analyzed.  K.  Koh's (1981) criterion for
    examining the cyclic locality interval (CLI) hierarchy of a program and
    choosing the least-cost pathway is examined.  Koh's criterion is designed
    for the case of a CLI containing a single inner CLI.  The decision to
    descend the hierarchy is based on the cycle time of the outer CLI.  If the
    outer CLI has two or more inner CLIs, it is possible for Koh's criterion to
    indicate that it is more economical to descend to one of the inner CLIs
    without that actually being the case.  Choosing which CLI to descend to
    requires knowledge of its duration, and this is not generally available to
    the memory management system.  An attempt to use Koh's criterion with the
    loop structure of a program in order to reduce space-time execution cost
    was not successful.", 
  location     = "https://doi.org/10.1109/32.7627"
}

@Article{gseiahe,
  author       = "Alain Karsenty and Christophe Tronche and Michel Beaudouin-Lafon",
  title        = "{GroupDesign}:  Shared Editing in a Heterogeneous Environment",
  journal      = cs,
  year         = 1993,
  volume       = 6,
  number       = 2,
  pages        = "167--195",
  month        = "Spring",
  keywords     = "shared editors, synchronous groupware, cscw, user interfaces,
    purely replicated architecture, distributed systems, interactive systems
    engineering",
  abstract     = "This article describes GroupDesign, a multi-user drawing tool
    that runs in a heterogeneous environment (a network of Apple Macintosh
    computers and Unix workstations).  From the perspective of the users, we
    present a number of functionalities that we have developed for supporting
    the collaborative aspect of work and the new user interfaces issues raised
    by the shared editing of a document: Graphic & Audio Echo, Localization,
    Identification, Age, History, Teleconference and Private Editing.  From the
    perspective of the designers, we introduce the notion of purely replicated
    architecture and we describe the tools we have developed to implement this
    architecture in a heterogeneous environment.  We also demonstrate the
    possibility of creating a multi-user application from a single-user one and
    address the issues in developing synchronous heterogeneous groupware.",
  location     = "https://pdfs.semanticscholar.org/2be1/dcc7105e1c6f8b171e2263367dcf2560baca.pdf"
}

@Article{srtaiaispnaam,
  author       = "Clark, David~D. and Shenker, Scott and Zhang, Lixia",
  title        = "Supporting Real-Time Applications in an Integrated Services Packet Network: Architecture and Mechanism",
  journal      = ccr # " (" # pot # "ACM SIGCOMM '92 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication)",
  year         = 1992,
  volume       = 22,
  number       = 4,
  pages        = "14--26",
  month        = oct,
  keywords     = "real-time, applications, delay, qos, traffic guarantees,
    scheduling, service interfaces, admission control",
  abstract     = "This paper considers the support of real-time applications in
    an Integrated Services Packet Network (ISPN).  We first review the
    characteristics of real-time applications.  We observe that, contrary to
    the popular view that real-time applications necessarily require a fixed
    delay bound, some real-time applications are more flexible and can adapt to
    current network conditions.  We then propose an ISPN architecture that
    supports two distinct kinds of real-time service: guaranteed service, which
    is the traditional form of real-time service discussed in most of the
    literature and involves pre-computed worst-case delay bounds, and predicted
    service which uses the measure performance of the network in computing
    delay bounds.  We then propose a packet scheduling mechanism that can
    support both of these real-time services as well as accommodate datagram
    traffic.  We also discuss two other aspects of an overall ISPN
    architecture: the service interface and the admission control criteria.", 
  location     = "https://doi.org/10.1145/144179.144199", 
  location     = "https://groups.csail.mit.edu/ana/Publications/PubPDFs/Supporting%20Real-Time%20Applications%20in%20an%20Integrated%20Services%20Packet%20Network.pdf"
}

@Article{palparmsfdp,
  author       = "Kessels, Joep L.~W.",
  title        = "{PHILAN}:  {A} {LAN} Providing a Reliable Message Service for Distributed Processing",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 10,
  pages        = "1424--1431",
  month        = oct,
  keywords     = "circuit-switched traffic, fiber-optic ring, flow and error
    control, local area network, reliable message service",
  abstract     = "A local area network (LAN) design based on a ring topology is
    presented which can support both packet-switched and circuit-switched
    traffic.  The packet-switching service is reliable in that the LAN
    controllers deal with all protocol problems, i.e., medium arbitrations as
    well as flow and error control.  The service can meet real-time
    constraints, since the performance is stable under high load conditions and
    the arbitration delays are bounded.  Moreover, the processing speed of the
    LAN controller is independent of the transmission speed, and the speed
    requirements are such that they can be met by a microprocessor (no need for
    dedicated hardware to process the information on the fly).  Before the
    design of PHILAN is presented, an analysis is given of the protocol
    problems that have to be dealt with when establishing a reliable
    packet-switching service on a LAN.", 
  location     = "https://doi.org/10.1109/32.6187"
}

@Article{iitdoatfsmge,
  author       = "Michael Knister and Atul Prakash",
  title        = "Issues in the Design of a Toolkit for Supporting Multiple Group Editors",
  journal      = cs,
  year         = 1993,
  volume       = 6,
  number       = 2,
  pages        = "135--166",
  month        = "Spring",
  keywords     = "cscw, sharing toolkit, isis, group editing, retrofitting",
  abstract     = "A great interest has developed in recent years in building
    tools that allow people to collaborate on work without the need for
    physical proximity.  One such class of tools, group editors, allows
    collaborators to view and edit a shared document simultaneously from their
    workstations.  Building group editors, however, requires solving
    non-trivial problems such as providing adequate response time for edit
    operations and yet ensuring consistency with concurrent updates, and
    providing adequate per-user undo facilities.  We have implemented a
    toolkit, called DistEdit, for building new interactive group editors and
    for converting existing single-user editors into group editors with minimal
    changes to their code.  The toolkit allows different users to use their
    favorite editors (e.g., Xedit, Gnu Emacs) to edit a shared file and observe
    each others' changes as they occur.  The toolkit provides fine-grain
    concurrency control, fault-tolerance, synchronization of views, and support
    for per-user undo.  V/e describe the detailed design and implementation of
    the DistEdit toolkit and report our experiences in converting several
    editors, including Gnu Emacs and Xedit, to group editors using the
    toolkit.",
  location     = "https://www.usenix.org/publications/compsystems/1993/spr_knister.pdf"
}

@Article{sfrig,
  author       = "Ramamoorthy, C.~V. and Garg, Vijay and Prakash, Atul",
  title        = "Support for Reusability in {G}enesis",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1145--1154",
  month        = aug,
  keywords     = "abstraction, programming environment, reusability,
    traceability, attributes, entities, relations, query languages",
  abstract     = "Genesis is a software-engineering-based programming
    environment geared to support big software projects.  The authors first
    discuss a reusability-driven development methodology that advocates
    software development based on reusability considerations.  Then, they
    discuss the tools and techniques provided in Genesis to support this
    methodology.  Techniques are suggested for improving the retrievability,
    composability, and understandability of software resources.  Retrievability
    is improved by use of ESL (entity specification language) for tying
    resources through attributes and relations.  Composability is improved
    through a mechanism called functional composition that provides
    considerably more generality than Unix pipes for composing programs.
    Understandability is improved by the use of program abstractors.", 
  location     = "https://doi.org/10.1109/32.7625"
}

@Article{tcmfat,
  author       = "Sol M. Shatz",
  title        = "Towards Complexity Metrics for {A}da Tasking",
  journal      = tse,
  year         = 1988,
  OPTvolume    = 14,
  number       = 8,
  pages        = "1122--1127",
  month        = aug,
  keywords     = "distributed computing, software maintenance, software
    measurement, software testing, complexity theory, petri nets, programming,
    software design, guidelines, software metrics",
  abstract     = "Using Ada as a representative distributed programming
    language, the author discusses some ideas on complexity metrics that focus
    on Ada tasking and rendezvous.  Concurrently active rendezvous are claimed
    to be an important aspect of communication complexity.  A Petri net graph
    model of Ada rendezvous is used to introduce a rendezvous graph, an
    abstraction that can be useful in viewing and computing effective
    communication complexity.", 
  location     = "https://doi.org/10.1109/32.7623"
}

@Article{spijat,
  author       = "Qusay~H. Mahmoud",
  title        = "Sockets Programming in {J}ava:  {A} Tutorial",
  journal      = "JavaWorld",
  year         = 1996,
  month        = "11 " # dec,
  keywords     = "java, sockets, programming",
  abstract     = "This classic JavaWorld tutorial presents an introduction to
    sockets programming over TCP/IP networks and demonstrates how to write
    client/server applications in Java.", 
  location     = "https://www.javaworld.com/article/2077322/core-java/core-java-sockets-programming-in-java-a-tutorial.html"
}

@Article{autfdsca,
  author       = "Dorab Patel and Scott~D. Kalter",
  title        = "{A} " # unix # " Toolkit for Distributed Synchronous Collaborative Applications",
  journal      = cs,
  year         = 1993,
  volume       = 6,
  number       = 2,
  pages        = "105--134",
  month        = "Spring",
  keywords     = "groupware, distributed applications, rendezvous, resource
    discovery, session management, asynchronous i-o",
  abstract     = "There are many low-level problems, such as resource discovery
    and rendezvous, faced by developers of distributed synchronous
    collaborative applications.  This paper systematically explores these
    problems and discusses their solutions under Unix.  These solutions are
    collected into a toolkit that provides a high-level abstract interface to
    developers for a variety of different application classes.  The toolkit
    supports rendezvous via a file, rather than via a user or application.
    This lets clients join a session without additional user specification.  A
    toolkit evaluation, and comparison with alternatives, indicates the class
    of applications most suited to this approach.  Experience using the toolkit
    with various applications demonstrates the usefulness of the provided
    primitives for rapidly developing collaborative applications.", 
  location     = "http://www.usenix.org/publications/compsystems/1993/spr_patel.pdf"
}

@Article{bagtap,
  author       = "Proebsting, Todd~A.",
  title        = "{BURS} Automata Generation",
  journal      = toplas,
  year         = 1995,
  volume       = 17,
  number       = 3,
  pages        = "461--486",
  month        = may,
  keywords     = "code generation, code-generator generator, dynamic
    programming, tree pattern matching, redundancy elimination, table-driven
    processing", 
  abstract     = "A simple and efficient algorithm for generating bottom-up
    rewrite system (BURS) tables is described.  A small code-generator
    generator implementation produces BURS tables efficiently, even for complex
    instruction set descriptions.  The algorithm does not require novel data
    structures or complicated algorithmic techniques.  Previously published
    methods for on-the-fly elimination of states are generalized and simplified
    to create a new method, triangle trimming, that is employed in the
    algorithm.  A prototype implementation, burg, generates BURS tables very
    efficiently.", 
  location     = "https://doi.org/10.1145/203095.203098"
}

@Article{hbft,
  author       = "Bressoud, Thomas~C. and Schneider, Fred~B.",
  title        = "Hyperviser-based Fault-tolerance",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "1-11",
  month        = dec,
  keywords     = "hypervisors, fault tolerance, mirroring, replication protocols",
  abstract     = "Protocols to implement a fault-tolerant computing system are
    described. These protocols augment the hypervisor of a virtual-machine
    manager and coordinate a primary virtual machine with its backup.  No
    modifications to the hardware, operating system, or application programs
    are required.  A prototype system was constructed for HP's PA-RISC
    instruction-set architecture.  Even though the prototype was not carefully
    tuned, it ran programs about a factor of 2 slower than a bare machine
    would.", 
  location     = "https://doi.org/10.1145/224057.224058"
}

@Article{taoedc,
  author       = "John Vincent Astanasoff",
  title        = "The Advent of Electronic Digital Computing",
  journal      = "Annals of the History of Computing",
  year         = 1984,
  volume       = 6,
  number       = 3,
  pages        = "229--282",
  month        = jul # "/" # sep,
  keywords     = "binary representation, digital computing, regenerating
    storage, patent cases",
  location     = "http://findingaids.lib.iastate.edu/spcl/arch/rgrp/13-20-51.html"
}

@Article{hfcfsmm,
  author       = "Chapin, John and Rosenblum, Mendel and Devine, Scott and Lahiri, Tirthankar and Teodosiu, Dan and Gupta, Anoop",
  title        = "Hive:  Fault Containment for Shared-Memory Multiprocessors",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "12-25",
  month        = dec,
  keywords     = "fault detection, shared storage, rpc, global resource
    allocation, fail-stop processors, wild writes, hardware-software codesign,
    hardware simulation",
  abstract     = "In this paper we describe Hive, an operating system designed
    for large-scale shared-memory multiprocessors.  Hive is fundamentally
    different from previous monolithic and microkernel Reliability and
    scalability are major concerns when designing operating systems for
    large-scale shared-memory multiprocessors.  SMP OS implementations: it is
    structured as an internal distributed system of independent kernels
    calledcells.  This multicellular In this paper we describe Hive, an
    operating system with a novel kernel architecture has two main advantages:
    kernel architecture that addresses these issues.  Hive is structured as an
    internal distributed system of independent kernels called â€¢ Reliability: In
    SMP OS implementations, any significant cells.  This improves reliability
    because a hardware or software hardware or software fault causes the entire
    system to crash.  fault damages only one cell rather than the whole system,
    and For large-scale machines this can result in an unacceptably low
    improves scalability because few kernel resources are shared by mean time
    to failure.  In Hive, only the cell where the fault processes running on
    different cells.  The Hive prototype is a occurred crashes, so only the
    processes using the resources of complete implementation of UNIX SVR4 and
    is targeted to run on that cell are affected.  This is especially beneï¬cial
    for compute the Stanford FLASH multiprocessor.  server workloads where
    there are multiple independent This paper focuses on Hiveâ€™s solution to the
    following key processes, the predominant situation today.  In addition,
    challenges: (1) fault containment, i.e.  conï¬ning the effects of scheduled
    hardware maintenance and kernel software upgrades hardware or software
    faults to the cell where they occur, and (2) can proceed transparently to
    applications, one cell at a time.  memory sharing among cells, which is
    required to achieve â€¢ Scalability: SMP OS implementations are difï¬cult to
    scale to application performance competitive with other multiprocessor
    large machines because all processors directly share all kernel operating
    systems.  Fault containment in a shared-memory resources.  Improving
    parallelism in a â€œshared-everythingâ€ multiprocessor requires defending each
    cell against erroneous architecture is an iterative trial-and-error process
    of identifying writes caused by faults in other cells.  Hive prevents such
    damage and ï¬xing bottlenecks.  In contrast, Hive offers a systematic by
    using the FLASHï¬rewall, a write permission bit-vector approach to
    scalability.  Few kernel resources are shared by associated with each page
    of memory, and by discarding potentially corrupt pages when a fault is
    detected.  Memory sharing processes running on different cells, so
    parallelism can be improved by increasing the number of cells.  is provided
    through a uniï¬ed ï¬le and virtual memory page cache across the cells, and
    through a uniï¬ed free page frame pool.  However, the multicellular
    architecture of Hive also creates new implementation challenges.  These
    include: We report early experience with the system, including the â€¢ Fault
    containment: The effects of faults must be conï¬ned to the results of fault
    injection and performance experiments using cell in which they occur .
    This is dif ï¬cult since a shared-memory SimOS, an accurate simulator of
    FLASH.  The effects of faults multiprocessor allows a faulty cell to
    issuewild writes which were contained to the cell in which they occurred in
    all 49 tests can corrupt the memory of other cells.  where we injected
    fail-stop hardware faults, and in all 20 tests where we injected kernel
    data corruption.  The Hive prototype executes test workloads on a
    four-processor four-cell system with â€¢ Resource sharing: Processors,
    memory, and other system between 0% and 11% slowdown as compared to SGI
    IRIX 5.2 (the resources must be shared ï¬‚exibly across cell boundaries, to
    version of UNIX on which it is based).  preserve the execution efï¬ciency
    that justiï¬es investing in a shared-memory multiprocessor.", 
  location     = "https://doi.org/10.1145/224056.224059",
  location     = "https://doi.org/10.1145/224056.224059"
}

@Article{asfgloe,
  author       = "Tenma, Takao and Tsubotani, Hideaki and Tanaka, Minoru and Ichikawa, Tadao",
  title        = "{A} System for Generating Language-Oriented Editors",
  journal      = tse,
  year         = "1988",
  volume       = 14,
  number       = 8,
  pages        = "1098--1109",
  month        = aug,
  keywords     = "generation systems, intermediate representation, language
    description, language-oriented editor, object-oriented systems",
  abstract     = "The authors seek to establish a simple and flexible framework
    for internal representation of language-dependent information, and the
    behavior of language-oriented tools for user's operations.  They present a
    system for generating language-oriented editors based on object-oriented
    concepts.  Features of the target language are represented as classes and
    their relations.  A program is represented as an abstract syntax tree.
    Each node in the tree belongs to a node class.  For generating more
    advanced editors, probes, internal-classes, and gates are incorporated into
    the system.  The system generates a flexible and easily extendable
    language-oriented editor from a target language description in a highly
    modularized fashion by using the description language which the system
    provides.", 
  location     = "https://doi.org/10.1109/32.7620"
}

@Article{lvmdrc,
  author       = "Cheriton, David~R. and Duda, Kenneth~J.",
  title        = "Logged Virtual Memory",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "26--38",
  month        = dec,
  keywords     = "logging, checkpointing, transaction processing, hardware
    assists, virtual storage",
  abstract     = "Logged virtual memory (LVM) provides a log of writes to one
    or more specified regions of the virtual address space.  Logging is useful
    for applications that require rollback and/ or persistence such as parallel
    simulations and memory-mapped object-oriented databases.  It can also be
    used for output, debuggingand distributed consistency maintenance.  This
    paper describes logged virtual memory as an extension of the standard
    virtual memory system software and hardware, our prototype implementation,
    and some performance measurements from this prototype.  Based on these
    measurements and the experience with our prototype, we argue that logged
    virtual memory canbe supported with modest extensions to standard virtual
    memory systems, provides significant benefit to applications and servers,
    and is faster than other log-generation techniques.", 
  location     = "https://doi.org/10.1145/224057.224060"
}

@Article{unaulnifpadc,
  author       = "von Eicken, Thorsten and Basu, Anindya and Buch, Vineet and Vogels, Werner",
  title        = "{U-Net}:  {A} User-Level Network Interface for Parallel and Distributed Computing",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "40--53",
  month        = dec,
  keywords     = "user-space protocol implementations, multiplexing network
    interface, application-level framing, ",
  abstract     = "The U-Net communication architecture provides processes with
    a virtual view of a network interface to enable user-level access to
    high-speed communication devices.  The architecture, implemented on
    standard workstations using off-the-shelf ATM communication hardware,
    removes the kernel from the communication path, while still providing full
    protection.  The model presented by U-Net allows for the construction of
    protocols at user level whose performance is only limited by the
    capabilities of network.  The architecture is extremely ï¬‚exible in the
    sense that traditional protocols like TCP and UDP, as well as novel
    abstractions like Active Messages can be implemented efï¬ciently.  A U-Net
    prototype on an 8-node ATM cluster of standard workstations offers 65
    microseconds round-trip latency and 15 Mbytes/sec bandwidth.  It achieves
    TCP performance at maximum network bandwidth and demonstrates performance
    equivalent to Meiko CS-2 and TMC CM-5 supercomputers on a set of Split-C
    benchmarks.", 
  location     = "https://doi.org/10.1145/224056.224061",
  location     = "https://www.cs.cornell.edu/tve/u-net/papers/sosp.pdf"
}

@Article{ahasis,
  author       = "Nelson, Michael~N. and Linton, Mark and Owicki, Susan",
  title        = "{A} Highly Available, Scalable {ITV} System",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "54--67",
  month        = dec,
  keywords     = "distributed objects, replication",
  abstract     = "As part of Time Warner's interactive TV trial in Orlando,
    Florida, we have implemented mechanisms for the construction of highly
    available and scalable system services and applications.  Our mechanisms
    rely on an underlying distributed objects architecture, similar to
    Spring[1].  We have extended a standard name service interface to provide
    selectors for choosing among service replicas and auditing to allow the
    automatic detection and removal of unresponsive objects from the name
    space.  In addition, our system supports resource recovery, by letting
    servers detect client failures, and automated restart of failed services.
    Our experience has been that these mechanisms greatly simplify the
    development of services that are both highly available and scalable.  The
    system was built in less than 15 months, is currently in a small number of
    homes, and will support the trial's 4,000 users later this year.", 
  location     = "https://doi.org/10.1145/224056.224062"
}

@Article{oanctmahc,
  author       = "Steensgaard, Bjarne and Jul, Eric",
  title        = "Object and Native Code Thread Mobility Among Heterogeneous Computers",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "68--77",
  month        = dec,
  keywords     = "intermediate data representation, synchronization points, emerald",
  abstract     = "We present a technique for moving objects and threads among
    heterogeneous computers at the native code level.  To enable mobility of
    threads running native code, we convert thread states among
    machine-dependent and machine-independent formats.  We introduce the
    concept of bus stops, which are machine-independent representations of
    program points as represented by program counter Sun3 SPARC values.  The
    concept of bus stops can be used also for other purposes, workstation
    workstation e.g., to aid inspecting and debugging optimized code, garbage
    collection etc.  We also discuss techniques for thread mobility among
    Ethernet processors executing differently optimized codes.  We demonstrate
    the viability of our ideas by providing a prototype implementation of
    object and thread mobility among heterogeneous computers.  The prototype
    uses the Emerald distributed programming language without modiï¬cation; we
    have merely extended the Emerald runtime system and the code generator of
    the Emerald compiler.  Our extensions allow object and thread mobility
    among VAX, Sun-3, HP9000/300, and Sun SPARC workstations.  The excellent
    intra-node performance of the original homogeneous Emerald is retained:
    migrated threads run at native code speed before and after migration; the
    same speed as on homogeneous Emerald and close to C code performance.  Our
    implementation of mobility has not been optimized: thread mobility and
    trans-architecture invocations take about 60% longer than in the
    homogeneous implementation.  We are able to move both objects and native
    code threads in our We believe this is the first implementation of full
    object and prototype implementation.  thread mobility among heterogeneous
    computers with threads executing native code.",
  location     = "https://doi.org/10.1145/224056.224063"
}

@Article{ipac,
  author       = "Patterson, R.~Hugo and Gibson, Garth~A. and Ginting, Eka and Stodolsky, Daniel and Zelenka, Jim",
  title        = "Informed Prefetching and Caching",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "79--95",
  month        = dec,
  keywords     = "hints, behavior-directed management, estimation, cost-benefit
    analysis, file buffer management",
  abstract     = "In this paper, we present aggressive, proactive mechanisms
    that tailor file system resource management to the needs of I/O-intensive
    applications.  In particular, we show how to use application-disclosed
    access patterns (hints) to expose and exploit I/O parallelism, and to
    dynamically allocate file buffers among three competing demands: prefetching
    hinted blocks, caching hinted blocks for reuse, and caching recently used
    data for unhinted accesses.  Our approach estimates the impact of
    alternative buffer allocations on application execution time and applies
    cost-benefit analysis to allocate buffers where they will have the greatest
    impact.  We have implemented informed prefetching and caching in Digitalâ€™s
    OSF/1 operating system and measured its performance on a 150 MHz Alpha
    equipped with 15 disks running a range of applications.  Informed
    prefetching reduces the execution time of text search, scientific
    visualization, relational database queries, speech recognition, and object
    linking by 20-83%.  Informed caching reduces the execution time of
    computational physics by up to 42% and contributes to the performance
    improvement of the object linker and the database.  Moreover, applied to
    multiprogrammed, I/O-intensive workloads, informed prefetching and caching
    increase overall throughput.", 
  location     = "https://doi.org/10.1145/224056.224064",
  location     = "http://www.pdl.cmu.edu/PDL-FTP/TIP/SOSP15.pdf"
}

@Article{thahss,
  author       = "Wilkes, John and Golding, Richard and Staelin, Carl and Sullivan, Tim",
  title        = "The {HP} {AutoRAID} Hierarchical Storage System",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "96--108",
  month        = dec,
  keywords     = "raid, disk performance, adaptive systems, storage management,
    simulation, logged disk i-o",
  abstract     = "Configuring redundant disk arrays is a black art.  To
    configure an array properly, a system administrator must understand the
    details of both the array and the workload it will support.  Incorrect
    understanding of either, or changes in the workload over time, can lead to
    poor performance.  We present a solution to this problem: a two-level
    storage hierarchy implemented inside a single disk-array controller.  In
    the upper level of this hierarchy, two copies of active data are stored to
    provide full redundancy and excellent performance.  In the lower level,
    RAID 5 parity protection is used to provide excellent storage cost for
    inactive data, at somewhat lower performance.  The technology we describe
    in this article, know as HP AutoRAID, automatically and transparently
    manages migration of data blocks between these two levels as access
    patterns change.  The result is a fully redundant storage system that is
    extremely easy to use, is suitable for a wide variety of workloads, is
    largely insensitive to dynamic workload changes, and performs much better
    than disk arrays with comparable numbers of spindles and much larger
    amounts of front-end RAM cache.  Because the implementation of the HP
    AutoRAID technology is almost entirely in software, the additional hardware
    cost for these benefits is very small.  We describe the HP AutoRAID
    technology in detail, provide performance data for an embodiment of it in a
    storage array, and summarize the results of simulation studies used to
    choose algorithms implemented in the array.", 
  location     = "https://doi.org/10.1145/225535.225539"
}

@Article{snfs,
  author       = "Anderson, Thomas~E. and Dahlin, Michael~D. and Neefe, Jeanna~M. and Patterson, David~A. and Roselli, Drew~S. and Wang, Randolph~Y.",
  title        = "Serverless Network File Systems",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "109--126",
  keywords     = "raid, distributed file servers, journaling file systems,
    zebra, cache consistency, metadata, striping, caching, journal cleaning",
  abstract     = "In this paper, we propose a new paradigm for network file
    system design, serverless network file systems.  While traditional network
    file systems rely on a central server machine, a serverless system utilizes
    workstations cooperating as peers to provide all file system services.  Any
    machine in the system can store, cache, or control any block of data.  Our
    approach uses this location independence, in combination with fast local
    area networks, to provide better performance and scalability than
    traditional file systems.  Further, because any machine in the system can
    assume the responsibilities of a failed component, our serverless design
    also provides high availability via redundant data storage.  To demonstrate
    our approach, we have implemented a prototype serverless network file
    system called xFS.  Preliminary performance measurements suggest that our
    architecture achieves its goal of scalability.  For instance, in a 32-node
    xFS system with 32 active clients, each client receives nearly as much read
    or write throughput as it would see if it were the only active client.", 
  location     = "https://homes.cs.washington.edu/~tom/pubs/xfs.html",
  location     = "https://doi.org/10.1145/224056.224066"
}

@Article{poccisf,
  author       = "John~S. Heidemann and Gerald~J. Popek",
  title        = "Performance of Cache Coherence in Stackable Filing",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "127--142",
  keywords     = "stackable file systems, cache coherence, caching, cache management",
  abstract     = "Stackable design of filing systems constructs sophisticated
    services from multiple, independently developed layers.  This approach has
    been advocated to address development problems from code re-use, to
    extensibility, to version management.  Individual layers of such a system
    often need to cache data to improve performance orprovide desired
    functionality.  Whenaccessto different layers isallowed, cache
    incoherencies can occur.  Without a cache coherence solution, layer
    designers must either restrict layer access and flexibility or compromise
    the layered structure to avoid potential data corruption.  Thevalue of
    modular designs such as stacking can be questioned without a suitable
    solution to this problem.  This paper presents a general cache coherence
    architecture for stackable tiling, including a standard approach to data
    identifications a key component tolayered coherence protocols.  We also
    present a detailed performance analysis of one implementation of stack
    cache-coherence, which suggests that very low overheads can be achieved in
    practice.",
  location     = "http://www.isi.edu/%7ejohnh/PAPERS/Heidemann95c.html"
}

@Article{ewcfmfa,
  author       = "Mummert, Lily~B. and Ebling, Maria~R. and Satyanarayanan, M.",
  title        = "Exploiting Weak Connectivity for Mobile File Access",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "143--155",
  keywords     = "caching, adaptive systems, intermittent file systems,
    disconnected operation",
  abstract     = "Weak connectivity, in the form of intermittent,
    low-bandwidth, or expensive networks is a fact of life in mobile computing.
    In this paper, we describe how the Coda File System has evolved to exploit
    such networks.  The underlying theme of this evolution has been the
    systematic introduction of adaptivity to eliminate hidden assumptions about
    strong connectivity.  Many aspects of the system, including communication,
    cache validation, update propagation and cache miss handling have been
    modified.  As a result, Coda is able to provide good performance even when
    network bandwidth varies over four orders of magnitude -- from modem speeds
    to LAN speeds.", 
  location     = "https://doi.org/10.1145/224056.224068",
  location     = "https://www.cs.cmu.edu/~satya/docdir/mummert-sosp15-coda-1995.pdf"
}

@Article{ratfmia,
  author       = "Anthony~D. Joseph and Alan~F. deLespinasse and Joshua~A. Tauber and David~K. Gifford and M.~Frans Kaashoek",
  title        = "Rover:  {A} Toolkit for Mobile Information Access",
  journal      = sosp95,
  year         = 1995,
  volume       = 29,
  number       = 5,
  pages        = "156--171",
  keywords     = "client-server architecture, disconnected operation, caching,
    logging, application consistency management, low bandwidth communication",
  abstract     = "The Rover toolkit combines relocatable dynamic objects and
    queued remote procedure calls to provide unique services for roving mobile
    applications.  A relocatable dynamic object is an object with a
    well-defined interface that can be dynamically loaded into a client
    computer from a server computer (or vice versa) to reduce client-server
    communication requirements.  Queued remote procedure call is a
    communication system that permits applications to continue to make
    non-blocking remote procedure call requests even when a host is
    disconnected, with requests and responses being exchanged upon network
    reconnection.  The challenges of mobile environments include intermittent
    connectivity, limited bandwidth, and channel-use optimization.
    Experimental results from a Rover-based mail reader, calendar program, and
    two non-blocking versions of World-Wide Web browsers show that Rover's
    services are a good match to these challenges.  The Rover toolkit also
    offers advantages for workstation applications by providing a uniform
    distributed object architecture for code shipping, object caching, and
    asynchronous object invocation.", 
  location     = "https://people.cs.umass.edu/~mcorner/courses/691M/papers/joseph.pdf"
}

@InProceedings{amitbpl,
  author       = "Kristensen, Bent Bruun and Madsen, Ole Lehrmann and M{\o}ller-Pedersen, Birger and Nygaard, Kristen",
   title        = "Abstraction Mechanisms in the {B}eta Programming Language",
  booktitle     = pot # "10th Annual " # popl,
  year         = 1983,
  editor       = "Alan Demers and Tim Teitelbaum",
  pages        = "285--298",
  address      = "Austin, Texas",
  month        = "24--26 " # jan,
  keywords     = "language design, object-oriented language, hierarchies,
    subclassing",
  abstract     = "The BETA programming language is developed as part of the
    BETA project.  The purpose of this project is to develop concepts,
    constructs and tools in the field of programming and programming
    languages. BETA has been developed from 1975 on.", 
  location     = "https://doi.org/10.1145/567067.567094"
}

@InProceedings{mdb,
  author       = "Bergel, Alexandre and Ducasse, Stephane and Putney, Colin and Wuyts, Roel",
  title        = "Meta-Driven Browsers",
  booktitle    = "Advances in Smalltalk",
  year         = 2006,
  editor       = "Wolfgang De~Meuter",
  pages        = "134--156",
  publisher    = "Springer",
  address      = "Prague, Czechoslovakia",
  series       = lncs,
  volume       = 4406,
  month        = "4--8 " # sep,
  keywords     = "tools, metamodeling,Â ui, Browsers, squeak, smalltalk, domain
    models",
  abstract     = "Smalltalk is not only an object-oriented programming
    language; it is also known for its extensive integrated development
    environment supporting interactive and dynamic programming.  While the
    default tools are adequate for browsing the code and developing
    applications, it is often cumbersome to extend the environment to support
    new language constructs or to build additional tools supporting new ways of
    navigating and presenting source code.  In this paper, we present the
    OmniBrowser, a browser framework that supports the definition of browsers
    based on an explicit metamodel.  With OmniBrowser a domain model is
    described in a graph and the navigation in this graph is specified in its
    associated metagraph.  We present how new browsers are built from
    predefined parts and how new tools are easily described.  The browser
    framework is implemented in the Squeak Smalltalk environment.  This paper
    shows several concrete instantiations of the framework: a remake of the
    ubiquitous Smalltalk System Browser, and a coverage browser.", 
  location     = "https://doi.org/10.1007/978-3-540-71836-9_7"
}

@InProceedings{acooet,
  author       = "Small, Christopher and Seltzer, Margo",
  title        = "{A} Comparison of {OS} Extension Technologies",
  booktitle    = pot # "1996 USENIX Annual Technical Conference",
  year         = 1996,
  pages        = "41--54",
  address      = sdca,
  month        = "22--26 " # jan,
  keywords     = "operating systems, device drivers, kernel modifications,
    user-space code, up-calls, kernel modules, os security",
  abstract     = "The current trend in operating systems research is to allow
    applications to dynamically extend the kernel to improve application
    performance or extend functionality, but the most effective approach to
    extensibility remains unclear.  Some systems use safe languages to permit
    code to be downloaded directly into the kernel; other systems provide
    in-kernel interpreters to execute extension code; still others use software
    techniques to ensure the safety of kernel extensions.  The key
    characteristics that distinguish these systems are the philosophy behind
    extensibility and the technology used to implement extensibility.  This
    paper presents a taxonomy of the types of extensions that might be
    desirable in an extensible operating system, evaluates the performance cost
    of various extension technologies currently being employed, and compares
    the cost of adding a kernel extension to the benefit of having the
    extension in the kernel.  Our results show that compiled technologies (e.g.
    Modula-3 and software fault isolation) are good candidates for implementing
    general-purpose kernel extensions, but that the overhead of interpreted
    languages is sufficiently high that they are inappropriate for this use.", 
  location     = "https://www.eecs.harvard.edu/margo/papers/usenix96-os/paper.ps"
}

@InProceedings{tmsdsmfs4,
  author       = "Ronald~G. Minnich and David~J. Farber",
  title        = "The {M}ether System:  Distributed Shared Memory for {SunOS} 4.0",
  booktitle    = pot # "Summer 1989 USENIX Conference",
  year         = 1989,
  pages        = "51--60",
  address      = bama,
  month        = "12--16 " # jun,
  keywords     = "operating systems, kernel drivers, distributed shared memory,
    user-space servers, system calls",
  abstract     = "Mether is a Distributed Shared memory (DSM) that runs on Sun
    workstations under the SunOS 4.0 operating system.  User programs access
    the Mether address space in a way indistinguishable from other memory.
    Mether was inspired by the MemNet DSM, but unlike MemNet Mether consists of
    sotfware communicating over a conventional Ethernet.  hTe kernel part of
    Mether actually does no data transmission over the network.  Data
    transmission is accomplished by a user-level server.  hTe kernel driver has
    no preference for a server, and indeed does not know that servers exist.
    The kernel driver has been made very safe, and in fact panic is not in its
    dictionary.",  
  location     = "https://repository.upenn.edu/cis_reports/332/"
}

@InProceedings{eaoftmmm,
  author       = "James~Q. Arnold",
  title        = "{ELF}:  An Object File to Mitigate Mischievous Misoneism",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "1--10",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "linkers, object-file formats, text processing, change management",
  abstract     = "An object file is much like a shipping box: People typically
     ignore the container and focus on the contents.  Despite its
     unobtrusiveness, a system's object file directly affects services such as
     program execution and development, and a deficient file format restricts
     the services a system can deliver.  Moreover, some issues surface only as
     the computing environment changes.  For example, an object file with mixed
     or ambiguous byte order complicates file sharing across a heterogeneous
     network, without causing problems for a homogeneous environment.  ELF
     (Executable and Linking Format) is the object file for System V Release 4.
     Unlike previous object files, ELF includes an access library that provides
     key services such as host/target translation and version control.  In
     combination, the new object file format and the access library eliminate
     many problems and support new services.  Besides the technical aspects of
     object file design, this paper addresses the practical problem of changing
     object file formats.  Object files contain the binary representations for
     programs, in which people may have substantial investments of time or
     money.  Introducing ELF was made more challenging by the need to preserve
     investments and to limit the turmoil for people who write programs, for
     people who port System V to other architectures, and for people who use
     applications." 
}

@InProceedings{aprtsfthdpl,
  author       = "David~F. Bacon and Andy Lowry",
  title        = "A Portable Run-Time System for the {H}ermes Distributed Programming Language",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "39--49",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "interpreters, distributed systems, distributed programming
    language, language design, inter-process communication, data structures, ",
  abstract     = "We present our implementation of a portable run-time system
    for Hermes, a very high level language containing integrated constructs
    similar to those provided at the system and library level in systems like
    Mach and SQL.  The Hermes features we will focus upon in this paper are
    lightweight concurrent processes, the use of ports for typed communication
    between processes, a typed object store and its implementation via the Unix
    filesystem, and relational data structures for high-level associative
    queries.",
  location     = "http://researcher.ibm.com/files/us-bacon/Bacon90Portable.pdf"
}

@InProceedings{lddeim,
  author       = "Goel, Shantanu and Duchamp, Dan",
  title        = "Linux Device Driver Emulation in {M}ach",
  booktitle    = pot # "1996 USENIX Annual Technical Conference",
  year         = 1996,
  pages        = "65--74",
  address      = sdca,
  month        = "22--26 " # jan,
  keywords     = "device drivers, linux, mach, emulation",
  abstract     = "We describe the design and performance of code added to the
    Mach microkernel (Mach 4.0, version UK02p21) that permits one to build a
    Mach kernel that includes unmodified Linux device drivers.  We have written
    emulation code to support all Linux 1.3.35 network and SCSI drivers for the
    ISA and PCI I/O buses.  Emulation increases latency, but very little.  The
    degree depends on both device and operation, and varies from 2 microseconds
    for receiving small (60 byte) network packets up to 197 microseconds for
    writing 16KB to an ISA SCSI device.",
  location     = "https://www.usenix.org/publications/library/proceedings/sd96/full_papers/goel.ps"
}

@InProceedings{ssootoclou,
  author       = "Vaziri, Mandana and Jackson, Daniel",
  title        = "Some Shortcomings of {OCL}, the Object Constrain Language of {UML}",
  booktitle    = pot # "Technology of Object-Oriented Languages and Systems (TOOLS '00)",
  year         = 2000,
  pages        = "555--572",
  address      = "Santa Barbara, " # CA,
  month        = "30 July-3 August",
  keywords     = "ocl, alloy, uml metamodel",
  abstract     = "We illustrate some shortcomings of the Object Constraint
    Language of UML, and ways in which it may be improved, by comparing it to
    Alloy, a simile object modeling language.  We use the core package of the
    UML metamodel as a basis for the comparison.",
  location     = "http://dx.doi.org/10.1109/TOOLS.2000.10063"
}

@InProceedings{apbarwfaacs,
  author       = "P. Tonella and R. Fiutem and G. Antoniol and E. Merlo",
  title        = "Augmenting Pattern-Based Architectural Recovery with Flow Analysis:  a Case Study",
  booktitle    = pot # "3rd Working Conference on Reverse Engineering (WCRE '96)",
  year         = 1996,
  pages        = "198--208",
  month        = "8--10 " # nov,
  keywords     = "patterns, architectural analysis, architectural recognizers",
  abstract     = "Understanding the overall organization of a software system,
    i.e. its software architecture, is often required during software
    maintenance: tools can help maintainers in managing the evolution of legacy
    systems, by showing them architectural information.  In this paper, the
    analysis of a medium-sized application using a pattern based architectural
    recovery environment is presented.  The results obtained give useful
    information about the system architecture but also show some limitations of
    a purely pattern based approach.  To overcome such limitations,
    architectural analysis algorithms have been augmented with information
    about control and data flow and the case study application has been
    re-analyzed.  Complementing pattern matching with flow information has
    allowed to detect architectural constructs also when they are spread over
    different procedures in source code and to extract useful additional
    information through the use of constant propagation and slicing.", 
  location     = "0-8186-7674-4"
}

@InProceedings{ucailsr,
  author       = "T.~A. Wiggerts",
  title        = "Using Clustering Algorithms in Legacy Systems Remodularization",
  booktitle    = pot # "4th Working Conference on Reverse Engineering (WCRE '97)",
  year         = 1997,
  pages        = "33--43",
  month        = "8--10 " # nov,
  keywords     = "clustering, similarity, optimization, hierarchical
    algorithms, rmodularization",
  abstract     = "Incited by the observation that cluster analysis and the 
    remodularization of software systems solve similar problems, we have done
    research in both these areas in order to provide theoretical background for
    the application of cluster analysis in systems remodularization.  In this
    article we present an overview of cluster analysis and of systems
    remodularization.  It appears that system remodularization techniques often
    either reinvent clustering techniques or could be augmented by them.  We
    also give directions for further research.",
  location     = "0-8186-7674-4"
}

@InProceedings{anefsmnaac,
  author       = "Robert Lake and Laura Pate",
  title        = "{A} Network Environment for Studying Multimedia Network Architecture and Control",
  booktitle    = "IEEE Global Telecommunications Conference and Exhibition",
  year         = 1989,
  pages        = "1232--1236",
  address      = "Dallas, Texas",
  month        = "27--30 " # nov,
  keywords     = "multimedia applications, multimedia services, multimedia
    mail, multimedia databases",
  abstract     = "Bellcore's Integrated Media Architecture Laboratory (IMAL)
    studies architecture, control and network design issues of network-based
    multimedia services.  This paper will present an overview of a set of
    likely multimedia services that use audio, video, graphics, text, and other
    sorts of data; describe the laboratory environment we use to support these
    services; and provide a high-level description of how we have implemented
    these services as networked modules."
}

@InProceedings{wberafcwasacasotip,
  author       = "Lakshman, T.~V. and Suter, B. and Madhow, U.",
  title        = "Window-Based Error Recovery and Flow Control with a Slow Acknowledgement Channel: {A} Study of {TCP}/{IP} Performance",
  booktitle    = pot # "Sixteenth Annual Joint Conference of the IEEE Computer and Communications Societies (INFOCOM '97)",
  year         = 1997,
  pages        = "1199--1210",
  month        = "9--11 " # apr,
  keywords     = "path models, random loss, multiple collections, buffer sharing",
  abstract     = "With the envisaged growth in Internet access services over
    networks with asymmetric links such as Asymmetric Digital Subscriber Line
    (ADSL) and Hybrid Fiber Coax (HFC), it becomes crucial to evaluate the
    performance of window-based protocols over systems in which the reverse
    link is considerably slower than the forward link.  Even if the actual
    bandwidth asymmetry is moderate, high effective asymmetries can result
    because of bidirectional traffic.  Our objective is to determine, whether
    TCP/IP performs reasonably in a setting in which the reverse link is the
    primary bottleneck.Our main results are: (1) For both the prevalent Tahoe
    version with Fast Retransmit and the Reno version of TCP, we determine the
    throughput as a function of buffering, round-trip times and (normalized)
    asymmetry.  (2) Asymmetry increases TCP's already high sensitivity to
    random packet losses.  (3) Congestion in the reverse path adds considerably
    to TCP's unfairness when multiple connections share the reverse link.",
  location     = "0-8186-7780-5"
}

@InProceedings{tcpivc,
  author       = "Alain~J. Martin",
  title        = "Translating Concurrent Programs Into {VLSI} Chips",
  booktitle    = "Parallel Architectures and Languages Europe (PARLE '92)",
  year         = 1992,
  editor       = "Etiemble, D. and Syre, J.~C.",
  pages        = "515--532",
  volume       = 605,
  series       = lncs,
  publisher    = "Springer",
  address      = "Paris, France",
  month        = "15--18 " # jun,
  keywords     = "production rule, clock signal, clock period, program
    transformation, vlsi designÂ ",
  abstract     = "This paper reviews the results of almost a decade of research
    in the synthesis of asynchronous VLSI circuits from concurrent programs.
    In view of these results, it is argued that a method based on program
    transformations can produce circuits that are both correct by construction
    and efficient.  The design of the first asynchronous microprocessor is used
    as an example.", 
  location     = "http://dx.doi.org/10.1007/3-540-55599-4_108"
}

@InProceedings{uedmtilsre,
  author       = "Jean-Marc Debaud",
  title        = "Using Executable Domain Models to Implement Legacy Software Re-engineering",
  booktitle    = pot # "OOPSLA'95 Workshop on Legacy Systems and Object Technology",
  year         = 1995,
  address      = atx,
  month        = "16 " # oct,
  keywords     = "domain modeling, reverse engineering",
  abstract     = "In this position paper, we advocate a domain-centric approach
    to the evolution of legacy systems.  The migration of legacy systems is a
    difficult endeavor because traditional methods have two principal
    deficiencies.  First, they fail to capture the context of a system, i.e.,
    its domain.  Second, the legacy systemâ€™s comprehension results are not
    directly usable for the system evolution.  We propose the construction of
    executable domain models to alleviate both problems.  The construction of
    an executable domain model entails a process of domain analysis that leads
    to a domain model, as well as the transition of the former to an executable
    state.  The domain model provides domain expectations that drive legacy
    system understanding.  The executable domain model provides a medium in
    which the result of the legacy system comprehension can be recorded.  In
    fact, the executable domain model is instantiated using the system
    requirements derived during program comprehension.  The artifact thus
    created takes the role of the re-engineered program.  Our work uses the
    technique of object-oriented frameworks (OOF) as the executable domain
    model representation.", 
  location     = "ftp://ftp.cc.gatech.edu/pub/groups/reverse/repository/legacy-RE.ps"
}

@InProceedings{cpatav,
  author       = "Michael Deck",
  title        = "Cleanroom Practice: {A} Theme and Variations",
  booktitle    = pot # "9th International Software Quality Week",
  year         = 1996,
  keywords     = "software development, testing, specifications"
}

@InProceedings{annatsutbs,
  author       = "N.~Z. Hakim and H.~E. Meadows",
  title        = "{A} Neural Network Approach to Set Up the {B}enes Switch",
  booktitle    = "Ninth Annual Joint Conference of the IEEE Computer and Communication Societies (INFOCOM '90)",
  year         = 1990,
  month        = "3--7 " # jul,
  keywords     = "neural networks",
  abstract     = "A novel technique for setting up the Benes switch that has
    essentially optimal time complexity when implemented on a neural network is
    presented.  This approach consists of defining distances between input or
    output ports and expressing the Banyan network's ability to realize a given
    permutation in terms of a distance matrix.  This description allows a
    neural network implementation of the setup algorithm.  It is shown that the
    neural network converges to a solution that will allow the switch to
    self-route the information according to the desired permutation.  The time
    complexity of this operation is closer to optimal and the hardware simpler
    to implement than with previously presented algorithms", 
  location     = "http://dx.doi.org/10.1109/INFCOM.1990.91274"
}

@InProceedings{anafdms,
  author       = "Joel~F. Adam and Henry~H. Houh and Michael Ismert and David~L. Tennenhouse",
  title        = "{A} Network ARchitecture for Distributed Multimedia Systems",
  booktitle    = pot # "International Conference on Multimedia Computing and Systems",
  year         = 1994,
  pages        = "76--85",
  keywords     = "ATM, distributed systems, multimedia hardware, multimedia
    systems, network architecture",
  abstract     = "This paper presents a novel network architecture for
    distributed multimedia systems.  The VuNet is a gigabit-per-second
    desk/local-area ATM network which interconnects general-purpose
    workstations, networkbased multimedia devices and bridges to other
    networks.  During the course of an application, media streams are exchanged
    between the workstations and devices in a seamless manner.  This
    architecture has several advantages over traditional workstation-centric
    systems including the ability to share multimedia devices and to reduce the
    burden of multimedia tasks on the workstation.  This paper describes the
    VuNet philosophy, the VuNet hardware, and presents the results of
    experiments in which high bit-rate video streams are transported across the
    system.", 
  location     = "https://pdfs.semanticscholar.org/854f/b70434b1ed2dcd67bf8e98d17cb3460fe049.pdf"
}

@InProceedings{tloacaaotar,
  author       = "Nikos~A. Salingaros",
  title        = "The Life of a Carpet an Application of the {A}lexander Rules",
  booktitle    = "Oriental Carpet and Textile Studies V",
  year         = 1999,
  editor       = "M. {Eiland, Jr.} and R. Pinner",
  pages        = "189--196",
  keywords     = "design, carpeting, randomness",
  abstract     = "The greatest carpets project a very powerful presence.  We
    analyze various design factors that contribute to this effect.
    Differentiating space on the smallest perceivable scale creates life in a
    carpet.  This is activated through the process of coupling mutually
    contrasting elements, both in terms of color and geometry.  A carpet's
    large-scale coherence depends on arranging the small-scale elements
    symmetrically, and defining complex elements that could themselves be
    decomposed into smaller elements.  The same rules apply to all types of
    carpets, regardless of provenance or age.", 
  location     = "http://zeta.math.utsa.edu/~yxk833/life.carpet.html"
}

@InProceedings{sdjcw,
  author       = "Jean-Claude Wippler",
  title        = "Scripted Documents",
  booktitle    = pot # "Seventh USENIX Tcl/Tk Conference",
  year         = 2000,
  organization = "Usenix",
  address      = ate,
  month        = "14--18 " # feb,
  keywords     = "packaging, scripting, extensions",
  abstract     = "Software used to be written as source code, which was then
    compiled and linked into a single machine-specific application program.
    With scripting languages, editable scripts are now executable without
    intermediate steps, but the dependency on lots of script files complicates
    robust deployment.  A range of wrapping schemes are in use today to package
    scripts and extensions into a single file.  The Scripted Document approach
    presented here goes further by offering a database-centric solution for
    packaging, installation, configuration, upgrades, as well as all
    application-specific data.  An implementation for Tcl is described â€” using
    MetaKit as embedded database â€” with a summary of the experiences gathered
    so far.", 
  location     = "https://www.usenix.org/legacy/publications/library/proceedings/tcl2k/wippler.html"
}

@InProceedings{anfsohraamofaif,
  author       = "Oleg Kiselyov",
  title        = "{A} Network File System Over {HTTP}: Remote Access and Modification of Files and {\it Files}",
  booktitle    = pot # "Annual USENIX Conference",
  year         = 1999,
  pages        = "31--17",
  address      = "Monterey, " # CA,
  month        = "6--11 " # jun,
  keywords     = "system call replacement, client-server architecture, security",
  abstract     = "The goal of the present HTTPFS project is to enable access to
    remote files, directories, and other containers through an HTTP pipe.
    HTTPFS system permits retrieval, creation and modification of these
    resources as if they were regular files and directories on a local
    filesystem.  The remote host can be any UNIX or Win9x/WinNT box that is
    capable of running a Perl CGI script and accessible either directly or via
    a web proxy or a gateway.  HTTPFS runs entirely in user space.  The current
    implementation fully supports reading as well as creating, writing,
    appending, and truncating of files on a remote HTTP host.  HTTPFS provides
    an isolation level for concurrent file access stronger than the one
    mandated by POSIX file system semantics, closer to that of AFS.  Both a
    programmatic interface with familiar open(), read(), write(), close(), etc.
    calls, and an interactive interface, via the popular Midnight Commander
    file browser, are provided." 
}

@InProceedings{itpodauan,
  author       = "Ulana Legedza and David~J. Wetherall and John Guttag",
  title        = "Improving the Performance of Distributed Applications Using Active Networks",
  booktitle    = "IEEE INFOCOM '98",
  year         = 1998,
  pages        = "590--599",
  month        = apr,
  keywords     = "active networking, network architectures, capsules,
    multicast, auctions, network caching, routers",
  abstract     = "An active network permits applications to inject customized
    programs into network nodes.  This permits faster protocol innovation by
    making it easier to deploy new network protocols, even over the wide area.
    In this paper, we argue that the ability to introduce active protocols
    offers important opportunities for end-to-end performance improvements of
    distributed applications.  We begin by describing several active protocols
    that provide novel network services and discussing the impact of the
    services on end-to-end application performance.  We then discuss two active
    protocols that implement a previously studied service, reliable multicast.
    One protocol is optimized to support batch applications and the other
    interactive applications.  Finally, we analyze the performance of these
    protocols relative to a baseline non-active protocol.  The results clearly
    demonstrate that the introduction of active protocols tuned to the needs of
    specific applications can lead to significant performance improvements.", 
  location     = "http://www.sds.lcs.mit.edu/publications/infocom98lwg.html"
}

@InProceedings{prndsbans,
  author       = "Thomas~A. Limoncelli and Tom Reingold and Ralph Loura",
  title        = "Providing Reliable {NT} Desktop Services By Avoiding {NT} Server",
  booktitle    = pot # "Large Installation System Administration of Windows NT Conference, LISA-NT",
  year         = 1998,
  pages        = "75--89",
  address      = sewa,
  month        = "5--8 " # aug,
  keywords     = "open systems, simplicity, calendar management",
  abstract     = "We have developed a reliable, stable NT Desktop environment
    for our customers.  The services we provide include: Standard desktop
    applications (word processing, spreadsheet, etc.), access to UNIX compute
    servers, file storage and backups, e-mail, printing, calendar, netnews,
    web, and Internet access.  We founded our architecture by selecting open,
    standard protocols rather than specific applications.  This decoupled our
    client application selection process from our server platform selection
    process.  We could then choose the server based on our needs for
    reliability, scalability, and manageability and let customers independently
    choose their clients based on their needs of platform (NT or UNIX),
    features, and preferences.  We can now choose between competing server
    products rather than be locked into the (potentially difficult to manage)
    server required for a particular client application.  This created a ``no
    compromises'' environment on the desktop as well as in our server room.
    Our customers are happy because the ``tail'' doesn't ``wag the dog''.  Our
    ability to manage this infrastructure is superior because the dog doesn't
    wag the tail either.  The resulting system gives us a strong base to build
    new services.", 
  location     = "https://www.usenix.org/legacyurl/papers-large-installation-sys-admin-windows-nt-6"
}

@InProceedings{wcsit,
  author       = "Don Libes",
  title        = "Writing {CGI} Scripts in {T}cl",
  booktitle    = pot # "4th Conference on USENIX Tcl/Tk Workshop",
  year         = 1996,
  pages        = "21--34",
  address      = "Monterey, " # CA,
  month        = "10--13 " # jul,
  keywords     = "tcl, cgi, scripting",
  abstract     = "CGI scripts enable dynamic generation of HTML pages.  This
    paper describes how to write CGI scripts using Tcl.  Many people use Tcl
    for this purpose already but in an ad hoc way and without realizing many of
    the more nonobvious benefits.  This paper reviews these benefits and
    provides a framework and examples.  Canonical solutions to HTML quoting
    problems are presented.  This paper also discusses using Tcl for the
    generation of different formats from the same document.  As an example, FAQ
    generation in both text and HTML are described.", 
  location     = "https://www.researchgate.net/publication/243609777_Writing_CGI_scripts_in_Tcl"
}

@InProceedings{ambpafrtp,
  author       = "Kevin~B. Kenny and Kwei-Jay Lin",
  title        = "{A} Measurement-Based Performance Analyzer For Real-Time Programs",
  booktitle    = pot # "Tenth Annual International Phoenix Conference on Computers and Communications",
  year         = 1991,
  pages        = "93--99",
  address      = "Scottsdale, " # az,
  month        = "27--30 " # mar,
  keywords     = "measurement-based performance analyzer, real-time programs,
    program measurements, performance behavior, parametric model, unbounded
    loops, recursive control, statistical confidence", 
  abstract     = "The authors present a system that uses program measurements
    as an aid in analyzing the performance behavior of real-time programs.  The
    authors propose a system that can measure the time required for a task
    under various conditions, and integrate these measured times into a
    parametric model supplied by the programmer.  The measurement must require
    only insignificant time compared to the task being performed.  Some
    capabilities of such a system include: analysis of program structures that
    are impossible for other systems, such as unbounded loops and recursive
    control structures; providing accurate timing information even on hardware
    whose timing behavior is difficult to model and analyze; and providing
    confidence in the timing model by validating it statistically for goodness
    of fit.  The system allows for dependency of the execution time on the
    input data.  It allows the programmer to build a model of a task's timing
    behavior that incorporates world knowledge, and gives a measure of
    statistical confidence that the model accurately represents the program's
    actual behavior.", 
  location     = "https://doi.org/10.1109/PCCC.1991.113797"
}

@InProceedings{samfatposa,
  author       = "Kazman, Rick and Bass, Len and Webb, Mike and Abowd, Gregory",
  title        = "{SAAM}:  {A} Method for Analyzing the Properties of Software Architectures",
  booktitle    = pot # "16th International Conference on Software Engineering (ICSE '94)",
  year         = 1994,
  pages        = "81--90",
  address      = "Sorrento, Italy",
  month        = "16--21 " # may,
  keywords     = "software architecture analysis, SAAM, organization life
    cycle, software quality, software maintainability, software modularity,
    software reusability, Software Architecture Analysis Method, user
    interface, modifiability quality, software portability", 
  abstract     = "While software architecture has become an increasingly
    important research topic in recent years, insufficient attention has been
    paid to methods for evaluation of these architectures.  Evaluating
    architectures is difficult for two main reasons.  First, there is no common
    language used to describe different architectures.  Second, there is no
    clear way of understanding an architecture with respect to an
    organization's life cycle concerns -software quality concerns such as
    maintainability portability, modularity, reusability, and so forth.  We
    address these shortcomings by describing three perspectives by which we can
    understand the description of a software architecture and then proposing a
    five-step method for analyzing software architectures called SAAM (Software
    Architecture Analysis Method).  We illustrate the method by analyzing three
    separate user interface architectures with respect to the quality of
    modifiability.", 
  location     = "https://doi.org/10.1109/ICSE.1994.296768"
}

@InProceedings{htictb,
  author       = "Vinton Cerf",
  title        = "How the Internet Came to Be",
  booktitle    = "The Online User's Encyclopedia",
  year         = 1993,
  editor       = "Bernard Adoba",
  publisher    = "Addison-Wesley",
  keywords     = "arpanet, internet",
  location     = "http://www.netvalley.com/archives/mirrors/cerf-how-inet.html"
}

@InProceedings{sotfnb,
  author       = "Nicholson Baker",
  title        = "Survival of the Fittest",
  booktitle    = "The Best American Essays",
  year         = 1994,
  editor       = "Tracy Kidder",
  pages        = "1--15",
  publisher    = "Houghton Mifflin",
  address      = boma,
  keywords     = "american essays, 20th century",
  location     = "PS 688.B48"
}

@InProceedings{tiheta,
  author       = "Erik~D. Demaine",
  title        = "Tetris is Hard, Even to Approximate",
  booktitle    = pot # "9th Ann. Int. Conf. Computing and Combinatorics (COCOON'03)",
  year         = 2003,
  editor       = "T. Warnow and B. Zhu",
  pages        = "351--363",
  publisher    = sv,
  volume       = "2697",
  series       = lncs,		  
  month        = jul,
  keywords     = "tetris, reductions, completeness, soundness,
    inapproximability, variants",
  abstract     = "In the popular computer game of Tetris, the player is given a
    sequence of tetromino pieces and must pack them into a rectangular
    gameboard initially occupied by a given configuration of filled squares;
    any completely filled row of the gameboard is cleared and all filled
    squares above it drop by one row.  We prove that in the offline version of
    Tetris, it is NP-complete to maximize the number of cleared rows, maximize
    the number of tetrises (quadruples of rows simultaneously filled and
    cleared), minimize the maximum height of an occupied square, or maximize
    the number of pieces placed before the game ends.  We furthermore show the
    extreme inapproximability of the first and last of these objectives to
    within a factor of p^(1-epsilon)Îµ, when given a sequence of p pieces, and
    the inapproximability of the third objective to within a factor of 2 -
    epsilonÎµ, for any epsilonÎµ> 0.  Our results hold under several variations
    on the rules of Tetris, including different models of rotation, limitations
    on player agility, and restricted piece sets.", 
  location     = "https://www.ocf.berkeley.edu/~wwu/readordie/tetris-npc.pdf"
}

@InProceedings{alc,
  author       = "Luca Cardelli",
  title        = "Amber",
  booktitle    = "Combinators and Functional Programming Languages",
  year         = 1986,
  editor       = "Guy Cousineau and Pierre-Louis Curien and Bernard Robinet",
  pages        = "21--70",
  publisher    = sv,
  volume       = 242,
  series       = lncs,
  keywords     = "amber, syntax, semantics",
  location     = "http://lucacardelli.name/Papers/Amber.pdf"
}

@InProceedings{mcarwatpc,
  author       = "Kenneth~L. Calvert",
  title        = "Module Composition and Refinement with Applications to Protocol Conversion",
  booktitle    = pot # "IFIP TC6/WG6.1. Twelfth International Symposium on Protocol Specification, Testing and Verification",
  year         = 1992,
  editor       = "R.~J. {Linn, Jr.} and M.~{\" U}. Uyar",
  pages        = "383--397",
  address      = "Lake Buena Vista, Florida",
  month        = "22--25 " # jun,
  keywords     = "",
  abstract     = "In Lam and Shankar's theory of specifications based on state
    transition systems, modules correspond to programs or implementations;
    interfaces are abstract specifications defining the services that modules
    provide to each other.  A module that correctly implements the service
    defined by a given interface is said to offer the interface.  This paper
    defines two refinement relations on module specifications.  The first is a
    sufficient condition for safety and progress properties of one module to
    hold in the other; it is a slight generalization of Lam and Shankar's
    well-formed refinement.  The second relation implies that if one module
    offers an interface, the other does so as well.  A composition operation,
    permitting compatible module specifications to be combined without
    explicitly specifying an interface between them, is also defined.", 
  location     = "https://doi.org/10.1016/B978-0-444-89874-6.50030-1"
}

@InProceedings{tcpdaia,
  author       = "Yih-Farn Chen",
  title        = "The {C} Program Database and Its Applications",
  booktitle    = pot # "Summer 1989 USENIX Conference",
  year         = 1989,
  pages        = "157--171",
  address      = bama,
  month        = "12--16 " # jun,
  keywords     = "program analysis, cia, relational analysis, program graphs,
    dead-code elimination, subsystem extraction, refactoring",
  abstract     = "The C program database is a collection of files that stores
    the structure information about software objects in C programs.  These
    files can be processed by relational database tools to locate object
    declarations and analyze their relations hips.  This paper describes how
    various tools use the C program Database to provide graphic views of
    program structures, extract self-contained subsystems, eliminate dead code,
    and automate software restructuring tasks.  Program databases have been
    built for several widely used tools and systems.  The analysis results of
    these databases are compared."
}

@InProceedings{iotfrfs,
  author       = "Richard Guy and John~S. Heidemann and Wai Mak and Thomas~W. {Page, Jr.} and Gerald~J. Popek and Dieter Rothmeier",
  title        = "Implementation of the {F}icus Replicated File System",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "63--71",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "distributed file systems, network partitioning, vnodes,
    layered architecture, layer interfaces, nfs, replication, conflict resolution",
  abstract     = {As we approach nation-wide integration of computer systems,
    it is clear that file replication will play a key role, both to improve
    data availability in the face of failures, and to improve performance by
    locating data near where it will be used.  We expect that future file
    systems will have an extensible, modular structure in which features such
    as replication can be slipped in as a transparent layer in a stackable
    layered architecture.  We introduce the Ficus replicated file system for
    NFS and show how it is layered on top of existing file systems.  The Ficus
    file system differs from previous file replication services in that it
    permits update during network partition if any copy of a file is
    accessible.  File and directory updates are automatically propagated to
    accessible replicas.  Conflicting updates to directories are detected and
    automatically repaired; conflicting updates to ordinary files are detected
    and reported to the owner.  The frequency of communications outages
    rendering inaccessible some replicas in a large scale network and the
    relative rarity of conflicting updates make this optimistic scheme
    attractive.  Stackable layers facilitate the addition of new features to an
    existing file system without reimplementing existing functions.  This is
    done in a manner analogous to object-oriented programming with inheritance.
    By structuring the file system as a stack of modules, each with the same
    interface, modules which augment existing services can be added
    transparently.  This paper describes the implementation of the Ficus file
    system using the layered architecture.}, 
  location     = "https://www.isi.edu/~johnh/PAPERS/Guy90b.pdf"
}

@InProceedings{iisld,
  author       = "Marc Sabatella",
  title        = "Issues in Shared Libraries Design",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "11-23",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "program organization, sharability, library binding time,
    importability, symbol binding time, binding granularity, version control,
    program size, execution sped, flexibility, transparency, reliability,
    security", 
  abstract     = {On traditional Unix systems, executable programs may be
    shared on disk and in memory, but library code may not be shared between
    programs.  Several Unix platforms now support shared library facilities.
    While the existing implementations share some common aspects, there are
    several important concerns that have been addressed differently.  These
    include program organization, sharability, library binding time,
    importability, symbol binding time, binding granularity, and version
    control.  I explore these issues and their impacts on program size,
    execution sped, flexibility, transparency, reliability, and security.  The
    programs are interrelated, and often there are trade-offs against linker
    and loader complexity as well.  I then give an overview of the HP-US shared
    libraries design, emphasizing how we resolved the concerns discussed in
    this paper.}  
}

@InProceedings{tsbtaai,
  author       = "Mark~D. Campbell and Tracy~R. Edmonds",
  title        = "{TOWER} {STREAMS}-Based {TTY}:  Architecture and Implementation",
  booktitle    = pot # "Summer 1989 USENIX Conference",
  year         = 1989,
  pages        = "15--27",
  address      = bama,
  month        = "12--16 " # jun,
  keywords     = "ttys, ",
  abstract     = "This paper discusses architectural and implementation issues
    of STREAMS-based TTY with respect to the members of the TOWER family.
    Issues examined include general architectural concerns, implementation
    decisions, performance, and efficiency with respect to unintelligent,
    semi-intelligent, intelligent, and multi-noded intelligent TTY subsystems.
    Three classes of STREAMS-based TTY architectures, local, remote and hybrid
    STREAMS-based techniques, are examined and critiqued with respect to the
    four types of TTY subsystems present on TOWER systems today.  The TOWER
    STREAMS-based TTY subsystem (hereafter referred to as TSTTY) is presented
    in light of these models.  Performance and system efficiency data of the
    Clist- and STREAMS-based TTY subsystems are given for the semi-intelligent
    and intelligent TTY subsystems.  The myth of increased character-level
    response time associated with STREAMS-based TTY is disproven with results
    showing that the tsTTY scheme actually results in the decrease of
    character-level response time." 
}

@InProceedings{atopm,
  author       = "Geetha Ramalingam and Thomas William Reps",
  title        = "{A} Theory of Program Modifications",
  booktitle    = "Proceedings of the International Joint Conference on Theory and Practice of Software Development (TAPSOFT '91)",
  series       = lncs,
  volume       = 494,
  year         = 1991,
  pages        = "137--152",
  publisher    = "Springer",
  address      = "Brighton, UK",
  month        = "8--12 " # apr,
  keywords     = "functional modification, functional-modification algebras,
    brouwerian algebra",
  abstract     = "The need to integrate several versions of a program into a
    common one arises frequently, but it is a tedious and time consuming task
    to merge programs by hand.  The program-integration algorithm proposed by
    Horwitz, Prins, and Reps provides a way to create a semantics-based tool
    for integrating a base program with two or more variants.  The integration
    algorithm is based on the assumption that any change in the behaviour,
    rather than the text, of a program variant is significant and must be
    preserved in the merged program.  An integration system based on this
    algorithm will determine whether the variants incorporate interfering
    changes, and, if they do not, create an integrated program that includes
    all changes as well as all features of the base program that are preserved
    in all variants.  This paper studies the algebraic properties of the
    program-integration operation, such as whether there is a law of
    associativity.  (For example, in this context associativity means: â€œIf
    three variants of a given base are to be integrated by a pair of
    two-variant integrations, the same result is produced no matter which two
    variants are integrated first.â€) Whereas an earlier work that studied the
    algebraic properties of program integration formalized the
    Horwitz-Prins-Reps integration algorithm as an operation in a Brouwerian
    algebra, this paper introduces a new algebraic structure in which
    integration can be formalized, called fmalgebra.  In fm-algebra, the notion
    of integration derives from the concepts of a program modification and an
    operation for combining modifications.  (Thus, while earlier work concerned
    an algebra of programs, this paper concerns an algebra of program
    modifications.) The potential benefits of an algebraic theory of
    integration, such as the one developed in this paper, are actually
    three-fold: (1) It allows one to understand the fundamental algebraic
    properties of integrationâ€”laws that express the â€œessence of integration.â€
    Such laws allow one to reason formally about the integration operation.
    (2) It provides knowledge that is useful for designing alternative
    integration algorithms whose power and scope are beyond the capabilities of
    current algorithms.  (3) Because such a theory formalizes certain
    operations that are more primitive than the integration operation, an
    implementation of these primitive operations can form the basis for a more
    powerful program-manipulation system than one based on just the integration
    operation.", 
  location     = "http://dx.doi.org/10.1007/3540539816_65", 
  location     = "https://link.springer.com/content/pdf/10.1007%2F3540539816_65.pdf"
}

@InProceedings{dafdfs,
  author       = "Alex Siegel and Kenneth Birman and Keith Marzullo",
  title        = "Deceit:  {A} Flexible Distributed File System",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "51--61",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "flexible distributed file system, fault-tolerance,
    availability, file replication, concurrent reads, update propagation
    strategies, automatic disk load balancing, multiple versions, Sun Network
    File Server, protocol compatibility, NFS client software, Deceit, NFS
    servers", 
  abstract     = "Deceit, a distributed file system that provides flexibility
    in the fault-tolerance and availability of files, is described.  Deceit
    provides many capabilities to the user: file replication with concurrent
    reads and writes, a range of update propagation strategies, automatic disk
    load balancing and the ability to have multiple versions of a file.  Deceit
    provides Sun Network File Server (NFS) protocol compatibility; no change in
    NFS client software is necessary in order to use Deceit.  The purpose of
    Deceit is to replace large collections of NFS servers.  NFS suffers from
    several problems in an environment where most clients mount most servers.
    First, if any one server crashes, clients will block or fail when they try
    to access that server, and, as the number of servers increases, this
    problem becomes more likely.  Second, servers have a (roughly) fixed
    capacity, yet it is difficult to move files from one NFS server to another
    without disrupting clients.  Third, replicating a file to increase its
    availability must be managed by the user.  Deceit addresses these three
    problems.", 
  location     = "https://doi.org/10.1109/MRD.1990.138237"
}

@InProceedings{beouutvk,
  author       = "Cheriton, David~R. and Whitehead, Gregory~R. and Sznyter, Edward~W.",
  title        = "Binary Emulation of" # unix #  " Using the {V} Kernel",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "73--85",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "binary emulation, unix, v, kernel support",
  abstract     = "Binary emulation support is essential in future operating
    systems to support the enormous body of existing application software.
    Future systems should be able to emulate existing systems, such as Unix,
    with comparable performance to native execution.  This paper describes the
    binary emulation of Unix under V, focusing on the kernel and process-level
    emulation mechanisms.  Binary emulation support requires minimal mechanism
    in the kernel and makes good use of V's server facilities.  Binary
    emulation performance is comparable to that of the native Unix system.  For
    most Unix applications, incompatibilities with the native Unix system
    appear comparable to these between different versions and releases of the
    Unix system itself."
}

@InProceedings{uaaap,
  author       = "David Golub and Randall Dean and Alessandro Forin and Richard Rashid",
  title        = unix # " as an Application Program",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "87--95",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "mach, memory management, signal management, ipc, performance",
  abstract     = "Since March of 1989 we have had running at CMU a computing
    environment in which the functions of a traditional Unix system are cleanly
    divided into two parts: facilities which manage the hardware resources of a
    computer system (such as CPU, I/O and memory) and support for higher-level
    resource abstractions used in the building of application programs, e.g.
    files and sockets.  This paper describes the implementation of Unix as a
    multithreaded application program running on the Mach kernel.  The
    rationale, design, implementation history and performance of the system is
    presented.", 
  location     = "http://flint.cs.yale.edu/cs422/doc/mach-app.ps"
}

@InProceedings{etvi,
  author       = "David S.~H. Rosenthal",
  title        = "Evolving the {V}node Interface",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "107--117",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "software evolution, file systems",
  abstract     = "The vnode interface has succeeded in supporting a wide range
    of file system implementations over its 6-year history.  During that time
    it has also had to accommodate evolution in file system semantics, and in
    the relationship between the file system and the virtual memory system.
    The effects of this evolution have been less than elegant, and pressures
    for further evolution are mounting.  The evolution of the interface is
    reviewed in order to identify the problems it has caused, and a more robust
    revision of the interface design proposed.  This design also permits new
    file systems to be implemented in terms of pre-existing file system
    implementations; it is more like the Streams interface in this respect.
    The current state of a prototype implementation is described and its
    performance characterized.", 
  location     = "https://pdfs.semanticscholar.org/d166/0be2246bbbb28706a802f804999fa936ae77.pdf"
}

@InProceedings{tceotjvm,
  author       = "Michel Schinz and Martin Odersky",
  title        = "Tail-Call Elimination on the {J}ava {V}irtual {M}achine",
  booktitle    = pot # "ACM SIGPLAN Workshop on Multi-Language Infrastructure and Interoperability (BABEL '01)",
  year         = 2001,
  volume       = 59,
  number       = 1,
  series       = "Electronic Notes in Theoretical Computer Science",
  publisher    = "Elsevier",
  pages        = "155-168",
  address      = "Firenze, Italy",
  month        = "8 " # sep,
  keywords     = "jvm, tail-call elimination, trampolines, continuations,
    compilation, stack unwinding, program optimization",
  abstract     = "A problem that often has to be solved by compilers for
    functional languages targeting the Java Virtual Machine is the elimination
    of tail calls.  This paper explains how we solved it in our Funnel compiler
    and presents some experimental results about the impact our technique has
    on both performance and size of the compiled programs.", 
  location     = "http://lampwww.epfl.ch/~odersky/papers/babel01.html",
  location     = "http://www.elsevier.nl/locate/entcs/volume59.html"
}

@InProceedings{aiortts,
  author       = "Mark Heuser",
  title        = "An Implementation of Real-Time Thread Synchronization",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "97--105",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "priority inversion, real-time scheduling, busy waiting",
  abstract     = "High-priority threads need fast and predictable service in
    real-time applications.  When threads interact by serializing their access
    to shared data, it is possible for one or more low-priority threads to
    indefinitely postpone the execution of a high-priority thread.  This
    situation, known as unbounded priority inversion, poses a serious threat to
    the application's ability to meet its deadlines.  The delay experienced by
    high-priority threads in the presence of contention must be bounded, and
    synchronization overhead in the absence of contention should be low.  This
    paper describes a collection of low-level synchronization tools --- CPU
    rescheduling control, busy-weight mutual exclusion, and client-server
    coordination --- designed to meet these needs in a unix operating system.
    Together they can be used to implement basic priority inheritance, the
    simplest of the techniques for controlling priority inversion.  The effects
    of priority inheritance and unbounded priority inversion are demonstrated
    with some measurements." 
}

@InProceedings{atiafroa,
  author       = "Bruce Thompson and Daryl Stolte and David Ellis",
  title        = "{A} Transparent Integration Approach for Rewritable Optical Autochangers",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "119--126",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "direct access secondary storage, transparent integration, swapping",
  abstract     = "Insufficient disk space has been a problem with computer
    systems since their introduction.  The high cost of online peripherals and
    limited floor space constrains the amount of disk storage a system user can
    afford.  Optical storage, in conjunction with autochangers promises to
    relive the online data crunch by providing storage at a cost competitive
    with tapes but with access speeds approaching disks.  Because these direct
    access secondary storage (dass tm) devices have unique attributes, a new
    method of peripheral integration is required.  This paper describes an
    integration technique for re-writable optical storage and autochangers for
    the uni operating system that is transparent to users and applications.
    All the standard unix methods of accessing and managing files work on the
    autochanger as they do with disks.  No new commands or utilities are
    needed." 
}

@InProceedings{andfdstrmm,
  author       = "Douglas Comer and James Griffioen",
  title        = "{A} New Design for Distributed Systems:  The Remote Memory Model",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "119--126",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "remote paging, special-purpose protocols, client-server computing",
  abstract     = "This paper describes a new model for constructing distributed
    systems called the Remote Memory Model.  The remote memory model consists
    of several client machines, one or more dedicated machines called remote
    memory servers, and a communication channel interconnecting them.  In the
    remote memory model, client machines share the memory resources located on
    the remote memory server.  Client machines that exhaust their local memory
    move portions of their address space to the remote memory server and
    retrieve pieces as needed.  Because the remote memory server uses a
    machine-independent protocol to communicate with client machines, the
    remote memory server can support multiple heterogeneous client machines
    simultaneously.  This paper describes the remote memory model and discusses
    the advantages and issues of systems that use this model.  It examines the
    design of a highly efficient, reliable, machine-independent protocol used
    by the remote memory server to communicate with the client machines.  It
    also outlines the algorithms and data structures employed by the remote
    memory server to efficiently locate the data stored on the server.
    Finally, it presents measurements of a prototype implementation that
    clearly demonstrate the viability and competitive performance of the remote
    memory model.", 
  location     = "https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1829&context=cstech"
}

@InProceedings{apmbf,
  author       = "Marshall~K. McKusick and Michael~J. Karels and Keith Bostic",
  title        = "{A} Pageable Memory Based Filesystem",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "137--143",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "file systems, memory-resident file systems, io performance",
  abstract     = "This paper describes the motivations for memory-based
    filesystems.  It compares techniques used to implement them and describes
    the drawbacks of using dedicated memory to support such filesystems.  To
    avoid the drawbacks of using dedicated memory, it discusses building a
    simple memory-based filesystem in pageable memory.  It details the
    performance characteristics of this filesystem and concludes with areas for
    future work.", 
  location     = "https://people.debian.org/~adamm/doc/papers/memfs.ps.gz"
}

@InProceedings{opsgns,
  author       = "George~N. Rouskas and Lisong Xu",
  title        = "Optical Packet Switching",
  booktitle    = "Emerging Optical Network Technologies",
  year         = 2005,
  OPTeditor    = "Sivalingam, K.~M. and Subramaniam, S.",
  publisher    = "Springer",
  address      = boma,
  keywords     = "optical packet switching, wavelength division multiplexing
    (WDM), switch architectures, contention resolution techniques", 
  abstract     = "The concept of optical packet switching (OPS) is emerging as
    an alternative to coarser-grained switching in the optical domain.  Despite
    the significant technological challenges it faces, OPS holds the promise of
    a highly reconfigurable, bandwidth-efficient, and ï¬‚exible optical layer.
    In this chapter we study some of the architectural and design issues for
    OPS networks, we examine a number of enabling technologies, and we discuss
    some of the ongoing research and experimental efforts.",  
  location     = "https://www.csc2.ncsu.edu/faculty/rouskas/Publications/Books/Kluwer-Rouskas-2004.pdf",  
  location     = "https://doi.org/10.1007/0-387-22584-6_5"
}

@InProceedings{aulmtr13r2,
  author       = "Danny Cohen and Andreas Kemkes",
  title        = "Applying User-Level Measurements to {RTI} 1.3 Release 2",
  booktitle    = pot # "Simulation Interoperability Workshop",
  year         = 1998,
  month        = "Fall",
  keywords     = "hla, rtl, ddm, routing space, use case, federate performance,
    performance measurement"
}

@InProceedings{afttfsbdmo,
  author       = "Masataka Ohta and Hiroshi Tezuka",
  title        = "{A} Fast {\tt /tmp} File System By Delay Mount Option",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "145--150",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "file systems, system calls, disk buffering, cache semantics,
    i-o performance",
  abstract     = "To improve the speed of a /tmp file system, a new mount
    option delay is introduced.  A usual UNIX kernel has three types of write
    operations: sync write, async write and delayed write.  For important data
    such as directory structure, slow but sure sync write is used to maintain
    file system integrity even through system crash.  For less important data,
    fast delayed write is used to gain efficiency.  As delayed write only
    writes to memory called a buffer cache, which is later copied to the disk,
    it is much faster than other types of write operations.  The delay option
    enforces all write operations on the file system performed with the delayed
    write.  For the /tmp file system, where files are removed shortly after
    creation, integrity is not so much necessary.  So, by specifying the delay
    option, a fast /tmp file system is obtained.  The delay option is
    implemented with modification of less than 50 lines in UNIX kernel and less
    than 10 lines in /etc/mount command.  Compared to memory disk
    implementation of a fast /tmp file system, delay approach is faster.
    Moreover, with the delay option, /tmp file system may be retained after
    power failure.  The size of the file system is not limited by the size of
    memory and can be as large a an ordinary file system.  Combined with
    dynamic buffer caching, delay option can utilize all free memory to
    accelerate file operations on /tmp.  The delay option is also useful for
    the fast installation of a totally new file system." 
}

@InProceedings{dfsao,
  author       = "Michael~L. Kazar and Bruce~W. Leverett and Owen~T. Anderson and Vasilis Apostolides and Beth~A. Bottos and Sailesh Chutani and Craig~F. Everhart and W.~Anthony Mason and Shu-Tsui Tu and Edward~R. Zayas",
  title        = "{DEcorum} File System Architectural Overview",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "151--163",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "distributed file systems, rpc, volumes, aggregates, acls,
    client-server architecture, caching",
  abstract     = "We describe the DEcorum file system, a distributed file
    system designed for high performance, low network load, easy operation and
    administration, and interoperability with other file systems.  The DEcorum
    file system has three components: the DEcorum protocol exporter (or file
    server); the Episode physical file system; and the DEcorum client (or cache
    manager).  Episode is a module that implements the Vnode/VFS interface,
    using transaction logging to allow fast recovery from crashes.  To be
    exact, it implements a VFS+ interface: extensions to the standard Vnode and
    VFS interfaces, and two new modules, aggregates and volumes, which give
    flexibility beyond what is provided by Unix partitions to support
    administration and operation of networks of thousands of workstations.  The
    DEcorum protocol exporter provides remote access to the Episode physical
    file system via remote procedure calls (RPCs).  It can export access to
    other physical file systems, such as the Berkeley fast file system, using
    extensions of the physical file systems to support the VFS+ interface.  The
    DEcorum client exports a Vnode interface, but obtains its data by making
    RPCs to a DEcorum protocol exporter.  It caches data from the file server.
    To synchronize accesses to files, preserving single-system UNIX semantics,
    it relies on typed tokens obtained with the data: guarantees provided by
    the server that various operations can be performed remotely.  Tokens can
    be revoked by the file server using separate RPCs.  A locking hierarchy is
    used to avoid deadlock between clients accessing files and servers revoking
    tokens on the same files; we explain the hierarchy and informally sketch a
    proof of its correctness."
}

@InProceedings{tcscs,
  author       = "Daniel Farmer and Eugene~H. Spafford",
  title        = "The {{\sc Cops}} Security Checker System",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "151--163",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "security, system administration",
  abstract     = "In the past several years, there have been a large number of
    published works that have graphically described a wide variety of security
    problems particular to Unix.  Without fail, the same problems have been
    discussed over and over again, describing the problems with SUID (set user
    ID) programs, improper file permissions, and bad passwords (to name a few).
    There are two common characteristics to each of these problems: first, they
    are usually simple to correct, if found; second, they are fairly easy to
    detect.  Since almost all Unix systems have fairly equivalent problems, it
    seems appropriate to create a tool to detect potential security problems as
    an aid to system administrators.  This paper describes one such tool: Cops.
    Cops (Computerized Oracle and Password System) is a freely-available,
    reconfigurable set of programs and shell scripts that enable system
    administrators to check for possible security holes in their systems.  This
    paper briefly describes the system.  Included are the underlying design
    goals, the functions provided by the tool, possible extensions, and some
    experiences gained from its use.  We also include information on how to
    obtain a copy of the initial Cops release.", 
  location     = "https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1844&context=cstech"
}

@InProceedings{peapdotin,
  author       = "Andrew Odlyzko",
  title        = "Privacy, Economics, and Price Discrimination of the {I}nternet",
  booktitle    = pot # "5th International Conference on Electronic Commerce",
  year         = 2003,
  pages        = "355--366",
  address      = ppa,
  month        = "30 " # sep # "- 3 " # oct,
  keywords     = "price discrimination, versioning, behavioral economics",
  abstract     = "The rapid erosion of privacy poses numerous puzzles.  Why is
    it occurring, and why do people care about it? This paper proposes an
    explanation for many of these puzzles in terms of the increasing importance
    of price discrimination.  Privacy appears to be declining largely in order
    to facilitate difierential pricing, which ofiers greater social and
    economic gains than auctions or shopping agents.  The thesis of this paper
    is that what really motivates commercial organizations (even though they
    often do not realize it clearly themselves) is the growing incentive to
    price discriminate, coupled with the increasing ability to price
    discriminate.  It is the same incentive that has led to the airline yield
    management system, with a complex and constantly changing array of prices.
    It is also the same incentive that led railroads to invent a variety of
    price and quality difierentiation schemes in the 19th century.  Privacy
    intrusions serve to provide the information that allows sellers to
    determine buyers' willingness to pay.  They also allow monitoring of usage,
    to ensure that arbitrage is not used to bypass discriminatory
    pricing.Economically, price discrimination is usually regarded as
    desirable, since it often increases the efficiency of the economy.  That is
    why it is frequently promoted by governments, either through explicit
    mandates or through indirect means.  On the other hand, price
    discrimination often arouses strong opposition from the public.There is no
    easy resolution to the conflict between sellers; incentives to price
    discriminate and buyers' resistance to such measures.  The continuing
    tension between these two factors will have important consequences for the
    nature of the economy.  It will also determine which technologies will be
    adopted widely.  Governments will likely play an increasing role in
    controlling pricing, although their roles will continue to be ambiguous.
    Sellers are likely to rely to an even greater extent on techniques such as
    bundling that will allow them to extract more consumer surplus and also to
    conceal the extent of price discrimination.  Micropayments and auctions are
    likely to play a smaller role than is often expected.  In general, because
    of strong conflicting pressures, privacy is likely to prove an intractable
    problem that will be prominent on the the public agenda for the foreseeable
    future.", 
  location     = "http://dx.doi.org/10.1007/1-4020-8090-5_15", 
  location     = "http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf"
}

@InProceedings{csfaplftfatd,
  author       = "Norman~L. Kerth",
  title        = "Caterpillar's Fate: {A} Pattern Language for Transformation from Analysis to Design",
  booktitle    = "Pattern Languages of Program Design",
  year         = 1995,
  editor       = "James Coplien and Douglas Schmidt",
  publisher    = "Addison-Wesley",
  keywords     = "work practices, collaboration, concurrency",
  abstract     = "Caterpillar's Fate is a pattern language used to support the
    transformation from fine analysis documents to an initial software design.
    Just as the concept metamorphosis is used to explain the magical emergence
    of butterflies; Caterpillar's Fate explores the magic of constructing a
    system of objects from an object-free analysis.",
  location     = "http://c2.com/ppr/catsfate.html"
}

@InProceedings{teot,
  author       = "William Cattey",
  title        = "The Evolution of {\it turnin\/}",
  subtitle     = "A Classroom-Oriented File Exchange Service",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "137--143",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "scripting, program evolution, system management",
  abstract     = "From the beginning, MIT Professors wanted to use the Project
    Athena campus wide computer network to collect assignments.  The turnin
    program started off as a shell script that sent files to a central
    timesharing host for perusal by a grader.  When timesharing hosts were
    replaced by a network of workstations, turnin became a network service
    layered on NFS.  At that time, programs were added to help graders sort
    through the files.  Student retrieval of prepared handouts and the exchange
    of papers in real-time were added.  Today, turnin is a stand alone network
    service with cooperating servers and a replicated database.  It has been
    integrated with a WYSIWYG editor for composition of complex documents, and
    their annotation by peers and teachers.  The teacher side of the interface
    is evolving into a point and click gradebook interface.  This paper
    describes the evolution of turnin from its original shell script form to
    its current integrated editing/formatting/annotating system.", 
  location     = "http://web.mit.edu/wdc/www/ezhist.html"
}

@InProceedings{ectufoi,
  author       = "Don Libes",
  title        = "{\tt expect}: Curing Those Uncontrollable Fits of Interaction",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "137--143",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "expect, interaction, programmed dialogue, shell tcl, unix,
    uucp, tty i-o",
  abstract     = "UNIX programs used to be designed so that they could be
    connected with pipes created by a shell.  This paradigm is insufficient
    when dealing with many modern programs that demand to be used
    interactively.  Expect is a program designed to control interactive
    programs.  Expect reads a script that resembles the dialogue itself but
    which may include multiple paths through it.", 
  location     = "https://www.nist.gov/publications/expect-curing-those-uncontrollable-fits-interaction"
}

@InProceedings{eotuccilahp,
  author       = "Paul Chan and Manoj and Vasta Santhanam",
  title        = "Evolution of the {U}-code Compiler Intermediate Language at {H}ewlett-{P}ackard",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "137--143",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "intermediate representation, language evolution, compilation,
    stack machines, u-code, p-code, pascal",
  abstract     = "U-code is a simple stack-based compiler intermediate language
    developed several years ago for use in portable Pascal and FORTRAN
    compilers.  Several companies including Hewlett-Packard have used U-code to
    implement production compilers.  Through the years, the original U-code
    definition has been extended at Hewlett-Packard to support new languages
    and compiler functionality.  Recently, Hewlett-Packard proposed a variant
    of U-code for use as an Architecture-Neutral Distribution Format (ANDF) in
    response to Open Software Foundation's Request for Technology.  This paper
    provides a retrospective look at the evolution of U-code at Hewlett-Packard
    and discusses its suitability as an ANDF." 
}

@InProceedings{teotd,
  author       = "Mark~A. Linton",
  title        = "The Evolution of {{\tt dbx}}",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "211--220",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "source-level debugging, modular structure, breakpoints,
    tracing, symbol tables",
  abstract     = "Dbx is the standard source-level debugger on most Unix
    workstations. Over the past six years Dbx has grown from a debugger for
    interpreted Pascal programs to a debugger for compiled C, C++, FORTRAN,
    Pascal, and Modula-2 programs.  Dbx also has been retargetted to a variety
    of architectures, including VAX, Motorola 68000, MIPS, IBM RT-PC, IBM 370,
    Sun SPARC, and Intel 80386.  This paper describes the evolution of Dbx and
    examines how the organization of Dbx has enhanced its portability and
    extensibility.  The structure of Dbx is based on a set of abstractions that
    deï¬ne what a debugger must do, not on a decomposition by language or
    machine.  These abstractions provide greater ï¬‚exibility in handling the
    unexpected problems associated with retargetting a program.",
  location     = "ftp://gatekeeper.dec.com/pub/X11/interviews/papers/dbx.ps.Z"
}

@InProceedings{tdoasig,
  author       = "Bill Cheswick",
  title        = "The Design of a Secure {I}nternet Gateway",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "233--237",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "security, gateways, system administration, dmz, intranet",
  abstract     = "The Internet supports a vast and growing community of
    computers users around the world.  Unfortunately, this network can provide
    anonymous access to this community by the unscrupulous, careless, or
    dangerous.  On any given Internet there is a certain percentage of
    poorly-maintained systems.  AT&T has a large internal Internet that we wish
    to protect from outside attacks, while providing useful services between
    the two.  This paper describes our Internet gateway.  It is an
    application-level gateway that passes mail and many of the common Internet
    services between our internal machines and the Internet.  This is
    accomplished without IP connectivity using a pair of machines: a trusted
    internal machine and an untrusted external gateway.  These are connected by
    a private link.  The internal machine provides a few carefully-guarded
    services to the external gateway.  This configuration helps protect the
    internal internet even if the external machine is fully compromised.", 
  location     = "http://www.cheswick.com/ches/papers/gateway.pdf"
}

@InProceedings{dagipd,
  author       = "Ronald~A. Olsson and Richard~H. Crawford and W.~Wilson Ho",
  title        = "Dalek: {A} {GNU}, Improved Programmable Debugger",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "221--231",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "debugging, gdb, events"
}

@InProceedings{puovfc,
  author       = "Mike O'Dell",
  title        = "Putting " # unix # " on Very Fast Computers",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "239--246",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "system design, hardware-software codesign, GaAs circuitry,
    system calls, signals, interface semantics",
  abstract     = "A computer with a 250 MHz clock and built from leading-edge
    technology works in fundamentally different ways compared with a one-chip
    CMOS VLSI processor clocking in at less than 50 MHz.  The interactions
    between a UNIX implementation and its supporting hardware have always been
    quite subtle and remain a considerable headache for those charged with
    porting the system.  But in addition to the imprecisions of fuzzy
    functional definitions for some key system facilities, the laws of physics
    conspire to make the marriage of very fast computers and modern UNIX
    systems an even more interesting challenge than it would normally be.  This
    paper discusses some of the matchmaking necessary to achieve a matrimonious
    accommodation." 
}

@InProceedings{tbpvsbirt,
  author       = "Roy~D. Trammell",
  title        = "The Big Picture:  Visualizing System Behavior in Real Time",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "257--266",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "system performance, visualization, performance analysis",
  abstract     = "In developing unix systems and applications it is frequently
    useful to observe system behavior and resource consumption.  Several tools
    exist which provide information of this kind.  KATO was developed to
    address the need for a performance analysis tool which had broader
    coverage, did not perturb the target system, and displayed data graphically
    in real time.  KATO solicits telemetry from a remote target and runs as an
    x client, presenting information through five basic display types.  A
    flight recorder allows the storage and playback of telemetry via a VCR-like
    control panel.  Some novel aspects of this tool are the variety and
    immediacy of data, techniques of visual presentation, selection of per
    process information, and the ability to remotely modify system tunable
    parameters." 
}

@InProceedings{watosgfafah,
  author       = "John~K. Ousterhout",
  title        = "Why Arenâ€™t Operating Systems Getting Faster As Fast as Hardware?",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "247--256",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "system performance, bandwidth mismatches",
  abstract     = "This paper evaluates several hardware platforms and operating
    systems using a set of benchmarks that stress kernel entry/exit, file
    systems, and other things related to operating systems.  The overall
    conclusion is that operating system performance is not improving at the
    same rate as the base speed of the underlying hardware.  The most obvious
    ways to remedy this situation are to improve memory bandwidth and reduce
    operating systemsâ€™ tendency to wait for disk operations to complete.", 
  location     = "https://web.stanford.edu/~ouster/cgi-bin/papers/osfaster.pdf"
}

@InProceedings{ponfspc,
  author       = "Bruce~E. Keith",
  title        = "Perspectives on {NFS} File Server Performance Characterization",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "267--277",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "nfs, performance measurement, simulated loads, live loads,
    analysis comparisons",
  abstract     = {Two major approaches to Network File System (NFS) file server
    performance characterization exists today.  One approach, denoted the
    synthetic-workload, single-client (SWS) approach, uses an NFS workload
    abstraction in terms of an NFS operation request mix and an NFS operation
    request rate as input to a load generator utility running on a single, or
    small number of NFS clients.  Another approach, used within Digital
    Equipment Corporation and denoted the actual-workload, multiple-client
    (AWM) approach, is to execute an actual workload on multiple NFS clients.
    In both approaches, various performance parameters are monitored while an
    NFS load is applied to the server.  This paper discusses the results of an
    initial evaluation of the SWS approach's ability to generate server and
    network loads and associated client response that are equivalent to those
    generated by the AWM approach.  The paper further discusses the fundamental
    reason for investigating file server performance: helping a computing
    facility answer the question How will our application (workload) perform
    using this file server?} 
}

@InProceedings{pmoamsk,
  author       = "John~H. Hartman and John~K. Ousterhout",
  title        = "Performance Measurements of a Multiprocessor {S}prite Kernel",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "279--287",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "multiprocessing, locking, kernel throughput, multithreaded
    computation, bottlenecks, monitors, kernel programming, mutual exclusion,
    virtual memory, scheduling, sprite",
  abstract     = "This report presents performance measurements made of the
    Sprite operating system running on a multiprocessor.  A variety of microand
    macro-benchmarks were run while varying the number of processors in the
    system, and both the elapsed time and the contention for kernel locks were
    recorded.  A number of interesting conclusions are drawn from the results.
    First, the macro-benchmarks show acceptable performance on systems of up to
    five processors.  Total system throughput increases almost linearly with
    the system size.  Projections of the lock contention measurements show that
    the maximum performance will be reached with about seven processors in the
    system.  Second, it is often difficult to predict the effect of a benchmark
    on particular kernel locks.  It was anticipated that different benchmarks
    would saturate different kernel monitor locks.  After running the
    benchmarks it was found that a single master lock was the biggest kernel
    bottleneck, and that one of the micro-benchmarks had saturated a different
    lock than the one at which it was targeted.  The kernel locking structure
    has become so complex as the system has evolved that it is hard to
    determine cause and effect relationships.  Third, although the kernel
    contains many locks, only a few of them are performance bottlenecks.
    Performance measurements such as those presented here allow the relevant
    parts of the kernel to be redesigned to eliminate the bottlenecks.  Such a
    redesign is needed to allow the system to scale gracefully beyond about
    seven processors.", 
  location     = "https://pdfs.semanticscholar.org/d62c/c6245f2136b944d016a9eac1d42c37e1babc.pdf"
}

@InProceedings{mbwisp,
  author       = "Paul Haahr",
  title        = "Montage:  Breaking Windows into Small Pieces",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "289--297",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "window managers, scheme, csp",
  abstract     = {Window systems are hard to program because the involve
    connecting an asynchronous world, where a mouse may move or a key may be
    pressed a any moment, to programs which execute synchronously.  This
    requirement has led to the use of the 9inverted program structure style of
    programming, which adds complexity to the underlying code.  The Montage
    window system eliminates this complexity by providing a programming model
    that uses sequential fragments of code connected by synchronous I/O.  The
    system has its clients are written in an extension to the Scheme
    programming language which supports concurrency.  In the same way as useful
    routines can be built up from simple programs by composing Unix pipelines,
    sophisticated applications can be created in Montage by connecting simple
    lightweight processes.  In addition, the programs may be trivially (and
    transparently) modified by adding processes that filter input to or output
    from applications.  This use of concurrency and compatibility is isomorphic
    to object-oriented programming.  Things that would be objects in other
    window systems, such as window decoration (borders, title bars, etc.) or
    menus are processes, but, in practice, Montage processes are easier to
    write than objects in other window systems.}
}

@InProceedings{saxwms,
  author       = "Thomas~E. LaStrange",
  title        = "{swm}: An {X} Window Manager Shell",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "299--306",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "configuration, virtual desktops, session management,
    object-oriented structuring",
  abstract     = "swm is a policy-free, user conï¬gurable window manager client
    for the X Window System.  Besides providing basic window manager
    functionality, swm introduces new features not found in existing window
    managers.  First and foremost, swm has no default look-and-feel.  Like the
    X Window system itself, swm does not dictate policy (look-and-feel);
    rather, it provides the mechanism for implementing window management
    policy.  Users are not required to learn a new programming language to
    modify its behavior; instead, simple objects with associated actions
    determine swmâ€™s operation.  Its major advantage over other window managers
    is a feature called the Virtual Desktop.  The Virtual Desktop effectively
    makes the X root window larger than the physical limits of the display and
    can be panned in a number of ways,including scroll bars, a panner object,
    or window manager commands.  Besides window management, swm also provides
    primitive session management.  It can save a userâ€™s current window layout
    and restart those clients when X is restarted.  swm can restart clients
    regardless of what toolkit they were built on or what remote host (if any)
    they were running on.  All relevant client information is restored,
    including window position and size, icon position, and the state of the
    client.", 
  location     = "http://www.lastrange.com/work/swm.pdf"
}

@InProceedings{ahluitftxwsact,
  author       = "Pedneault, Michel",
  title        = "{A} High-Level User Interface Toolkit for the {X} {WINDOW} {SYSTEM} and Character Terminals",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "307--313",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "user interface toolkits, interface polymorphism,
    character-based interfaces, graphical interfaces, curses",
  abstract     = "NTUI is a high-level user interface toolkit that allows
    single-stream development of unix applications intended for both the X
    window System and character terminals.  The graphical and the
    character-based versions of an application share the same source code.  The
    sharing is not limited to code written in a high-level programming language
    such as C.  It also includes defaults specified in X resource files, and
    objects, such as forms and menus, built with a user interface definition
    language that provides a non-programmatic way of specifying the
    presentation aspects of a user interface.  An important characteristic of
    this toolkit is that the character-based version does not impose
    constraints on the appearance of the graphical version.  Similarly, the
    usability of the character-based version is not compromised by the richer
    interactive environment in which the graphical version is used.  This is
    achieved by a careful encapsulation of appearance and behavior semantics at
    the toolkit level.  Both versions of NTUI are based on the X Toolkit.  The
    X Window System version follows a client-server model.  In the
    character-based version, windows and events are local to the application; a
    library provides windowing system and even-handling services that the X
    Toolkit normally obtains from an X Server.  The sharing of a single
    terminal among several NTUI and other character-based applications is
    achieved by a single screen manager which provides serial access to
    applications running in parallel." 
}

@InProceedings{tlsm,
  author       = "Mendel Rosenblum and John~K. Ousterhout",
  title        = "The {LFS} Storage Manager",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "315--324",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "log-structured file systems, cpu-storage speed mismatch,
    immutable data structures, disk performance, storage management, primary
    store caches, free-space management, checkpointing",
  abstract     = "Advances in computer system technology in the areas of CPUs,
    disk subsystems, and volatile RAM memory are combining to create
    performance problems existing file systems are ill-equipped to solve.  This
    paper identifies the problems of using the existing UNIX file systems on
    1990's technology and presents an alternative file system design that can
    use disks an order-of-magnitude more efficiently for typical UNIX
    workloads.  The design, named LFS for log-structured file system, treats
    the disk as a segmented append-only log.  This allows LFS to write many
    small changes to disk in a single large I/O while still maintaining the
    fast file reads of existing file systems.  In addition, the log-structured
    approach allows near instantaneous file system crash recovery without
    coupling CPU and disk performance with synchronous disk writes.  This paper
    describes and justifies the major data structures and algorithms of the LFS
    design.  We compare an implementation of LFS in the Sprite distributed
    operating system to SunOS's file system running on the same hardware.  For
    tests that create, destroy, or modify files at a high rate, LFS can achieve
    an order-of-magnitude speedup over SunOS.  In spite of its obvious
    write-optimization, LFS's read performance matches or exceeds the SunOS
    file system under most common UNIX workloads.", 
  location     = "https://users.soe.ucsc.edu/~sbrandt/290S/lfs.ps"
}

@InProceedings{eulfcmotsvi,
  author       = "David~C. Steere and James~J. Kistler and M.~Satyanarayanan",
  title        = "Efficient User-Level File Cache Management on the {S}un {V}node Interface",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "325--332",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "performance, user-level file systems, caching, ipc, coda, venus",
  abstract     = "In developing a distributed file system, there are several
    good reasons for implementing the client file cache manager as a user-level
    process.  These include ease of implementation, increased portability, and
    minimal impact on kernel size.  For reasons of compatibility it is also
    desirable to use a standard file intercept mechanism on the client.  The
    Sun VFS/Vnode file system interface is such a standard.  However, this
    interface is designed for kernel-based file systems, and a user-level cache
    manager that used the Vnode mechanism would pay a large performance penalty
    due to the high number of kernel to cache manager context switches per file
    system call.  This paper describes our solution to the problem for the Coda
    file system.  By using a relatively small amount of kernel code to cache
    critical information, we are able to retain the much larger and more
    complex components of the Coda cache manager in a user level process.  The
    measurements of Coda presented here confirm the performance benefits of
    this strategy, and indicate the relative merits of caching different kinds
    of information in the kernel.", 
  location     = "https://www.cs.cmu.edu/~satya/docdir/steere-usenix-vfs-1990.pdf"
}

@InProceedings{affsd,
  author       = "David Hendricks",
  title        = "{A} Filesystem for Software Development",
  booktitle    = usenixs90,
  year         = 1990,
  pages        = "333--340",
  address      = "Anaheim, " # CA,
  month        = "11--15 " # jun,
  keywords     = "user-space file systems, union file systems, file systems,
    vnodes, version control",
  abstract     = "Successful software development often requires the
    duplication of source hierarchies, either to make snapshots of releases or
    to allow multiple developers to work in parallel on common sets of sources.
    Copying files is expensive in terms of space, time, and the administrative
    burden of keeping all the copies up-to-date.  The Translucent File Service
    (TFS) is a special-purpose filesystem transparent to user programs, that
    removes the need to copy files.  The TFS is a Sun Operating System (SunOS)
    filesystem with copy-on-write semantics.  The TFS allows users both to
    share a file hierarchy and to have a private hierarchy into which files
    from the shared hierarchy are copied as they are modified.  Consequently,
    users are isolated from each other's changes, as files in the shared
    hierarchy are guaranteed not to change.  Files are only copied when they
    are modified, conserving disk space.  The TFS was built to support Sun's
    version configuration and management tool, the Network Software Environment
    (NSE).  The TFS is a mature filesystem that has been made a standard part
    of SunOS version 4.1.  This paper describes the semantics that the TFS
    provides, and presents several applications of the TFS.  The implementation
    of the TFS is described, along with possibilities for future development." 
}

@InProceedings{fsfialfs,
  author       = "Udi Manber",
  title        = "Finding Similar Files in a Large File System",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "1--10",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "fingerprinting, approximate fingerprinting",
  abstract     = "We present a tool, called sif, for finding all similar files
    in a large file system.  Files are considered similar if they have
    significant number of common pieces, even if they are very different
    otherwise.  For example, one file may be contained, possibly with some
    changes, in another file, or a file may be a reorganization of another
    file.  The running time for finding all groups of similar files, even for
    as little as 25% similarity, is on the order of 500MB to 1GB an hour.  The
    amount of similarity and several other customized parameters can be
    determined by the user at a post-processing stage, which is very fast.  Sif
    can also be used to very quickly identify all similar files to a query file
    using a preprocessed index.  Application of sif can be found in file
    management, information collecting (to remove duplicates), program reuse,
    file synchronization, data compression, and maybe even plagiarism
    detection.", 
  location     = "https://www.usenix.org/publications/library/proceedings/sf94/full_papers/manber.finding"
}

@InProceedings{tmetfhas,
  author       = "Herbert Hecht and Myron Hecht and Dolores Wallace ",
  title        = "Toward More Effective Testing for High-Assurance Systems",
  booktitle    = pot # "1997 High-Assurance Engineering Workshop",
  year         = 1997,
  pages        = "176--181",
  address      = wdc,
  month        = "11--12 " # aug,
  keywords     = "system testing, software testing, failure analysis, nist,
    costs, hardware, guidelines, application software, fault tolerance,
    software reliability", 
  abstract     = "The objective of the paper is to reduce the cost of testing
    software in high assurance systems.  It is at present a very expensive
    activity and one for which there are no generally accepted guidelines.  A
    part of the problem is that failure mechanisms for software are not as
    readily understood as those for hardware, and that the experience of any
    one project does not provide enough data to improve the understanding.  A
    more comprehensive attack on the high cost of software test requires
    pooling of fault and failure data from many projects, and an initiative by
    NIST that can furnish the basis for the data collection and analysis is
    described.", 
  location     = "https://doi.org/10.1109/HASE.1997.648060"
}

@InProceedings{em30tamtm,
  author       = "Ford, Bryan and Lepreau, Jay",
  title        = "Evolving {M}ach 3.0 to a Migrating Thread Model",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "97--114",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "mach, threads, thread migration, active objects, operating
    systems, protection boundaries, upcalls",
  abstract     = "We have modified Mach 3.0 to treat cross-domain remote
    procedure call (RPC) as a single entity, instead of a sequence of message
    passing operations.  With RPC thus elevated, we improved the transfer of
    control during RPC by changing the thread model.  Like most operating
    systems, Mach views threads as statically associated with a single task,
    with two threads involved in an RPC.  An alternate model is that of
    migrating threads, in which, during RPC, a single thread abstraction moves
    between tasks with the logical flow of control, and server code is
    passively executed.  We have compatibly replaced Mach's static threads with
    migrating threads, in an attempt to isolate this aspect of operating system
    design and implementation.  The key element of our design is a decoupling
    of the thread abstraction into the execution context and the schedulable
    thread of control, consisting of a chain of contexts.  A key element of our
    implementation is that threads are now based in the kernel, and temporarily
    make excursions into tasks via upcalls.  The new system provides more
    precisely defined semantics for thread manipulation and additional control
    operations, allows scheduling and accounting attributes to follow threads,
    simplifies kernel code, and improves RPC performance.  We have retained the
    old thread and IPC interfaces for backwards compatibility, with no changes
    required to existing client programs and only a minimal change to servers,
    as demonstrated by a functional Unix single server and clients.  The
    logical complexity along the critical RPC path has been reduced by a factor
    of nine.  Local RPC, doing normal marshaling, has sped up by factors of
    1.7-3.4.  We conclude that a migrating-thread model is superior to a static
    model, that kernel-visible RPC is a prerequisite for this improvement, and
    that it is feasible to improve existing operating systems in this manner.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/presentation/evolving-mach-30-migrating-thread-mo"
}

@InProceedings{ccalfdp,
  author       = "Auerbach, Joshua~S. and Goldberg, Arthur~P. and Goldszmidt, Germ{\' a}n S. and Gopal, Ajei~S. and Kennedy, Mark~T. and Rao, Josyula~R. and Russell, James~R.",
  title        = "Concert/{C}:  {A} Language for Distributed Programming",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "79--96",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "distributed programming, rpc, language translation, language
    extension, transparency",
  abstract     = "Concert/C is a new language for distributed C programming
    that extends ANSI C to support distribution and process dynamics.
    Concert/C provides the ability to create and terminate processes, connect
    them together, and communicate among them.  It supports transparent remote
    function calls (RPC) and asynchronous messages.  Interprocess
    communications interfaces are typed in Concert/C, and type correctness is
    checked at compile time wherever possible, otherwise at runtime.  All C
    data types, including complex data structures containing pointers and
    aliases, can be transmitted in RPCs.  Concert/C programs run on a
    heterogeneous set of machine architectures and operating systems and
    communicate over multiple RPC and messaging protocols.  The current
    Concert/C implementation runs on AIX 3.2, SunOS 4.1, Solaris 2.2 and OS/2
    2.1, and communicates over Sun RPC, OSF/DCE and UDP multicast.  Several
    groups inside and outside IBM are actively using Concert/C, and it is
    available via anonymous ftp from software.watson.ibm.com:/pub/concert.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/concertc-language-distributed-programming"
}

@InProceedings{tirdbds,
  author       = "Golding, Richard~A. and Long, Darrell D.~E. and Wilkes, John",
  title        = "The {\it refdbms\/} distributed bibliographic database system",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "79--96",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "bibliographic databases, distributed databases, replicated
    databases, weak consistency protocol, refer, bibtex",
  abstract     = "Refdbms is a database system for sharing bibliographic
    references among many users at sites on a wide-area network such as the
    Internet.  This paper describes our experiences in building and using
    refdbms for the last two years.  It summarizes the collection of facilities
    that refdbms provides, and gives detailed information on how well refdbms
    functions as a collaborative, wide-area, distributed information system.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/refdbms-distributed-bibliographic-database-system"
}

@InProceedings{dftfmun,
  author       = "Lidl, Kurt and Osborne, Josh and Malcolm, Joseph",
  title        = "Drinking from the Firehose:  Multicast {USENET} News",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "33--45",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "multicast transport, mbone, netnews, nntp",
  abstract     = "News transport and spooling systems of the last several years
    have concentrated on decreasing the resource load on news servers.  One
    beneficial side effect has been the average decrease in time that a news
    system spends on a given article.  This paper describes a novel USENET news
    transport protocol, which we call Muse.  The two major motivations behind
    Muse are to reduce the average propagation delays of articles on USENET and
    to further reduce the resource load on a centralized news server.  Muse
    runs on top of the experimental Internet multicast backbone, commonly
    referred to as the Mbone.  Major design and implementation issues are
    discussed.  Security concerns of multicast news are discussed and our
    solution is examined.  The problems of scaling news distribution to
    thousands of hosts are also addressed.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/presentation/drinking-firehose-multicast-usenet-n"
}

@InProceedings{gattstefs,
  author       = "Udi Manber and Sun Wu",
  title        = "{GLIMPSE}:  {A} Tool to Search Through Entire File Systems",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "23--32",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "search, indexing, approximate matching, big data",
  abstract     = "GLIMPSE, which stands for GLobal IMPlicit SEarch, provides
    indexing and query schemes for file systems.  The novelty of glimpse is
    that it uses a very small index - in most cases 2-4% of the size of the
    text - and still allows very flexible full-text retrieval including Boolean
    queries, approximate matching (i.e., allowing misspelling), and even
    searching for regular expressions.  In a sense, glimpse extends agrep to
    entire file systems, while preserving most of its functionality and
    simplicity.  Query times are typically slower than with inverted indexes,
    but they are still fast enough for many applications.  For example, it took
    5 seconds of CPU time to find all 19 occurrences of Usenix AND Winter in a
    file system containing 69MB of text spanning 4300 files.  Glimpse is
    particularly designed for personal information, such as one's own file
    system.  The main characteristic of personal information is that it is
    non-uniform and includes many types of documents.  An information retrieval
    system for personal information should support many types of queries,
    flexible interaction, low overhead, and customization, All these are
    important features of glimpse.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/glimpse-tool-search-through-entire-file-systems"
}

@InProceedings{caffdql,
  author       = "Glenn Fowler",
  title        = "{cql} --- {A} Flat File Database Query Language",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "11--21",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "queries, unix tools, file processing, record processing",
  abstract     = "cql is a UNIX system tool that applies C style query
    expressions to flat file databases.  In some respects it is yet another
    addition to the toolbox of programmable file filters: grep [Hume88], sh
    [Bour78][BK89], awk [AKW88], and perl [Wall].  However, by restricting its
    problem domain, cql takes advantage of optimizations not available to these
    more general purpose tools.  This paper describes the cql data description
    and query language, query optimizations, and provides comparisons with
    other tools.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/presentation/cql-flat-file-database-query-languag"
}

@InProceedings{tdsmoswaos,
  author       = "Keleher, Pete and Cox, Alan~L. and Dwarkadas, Sandhya and Zwaenepoel, Willy",
  title        = "{TreadMarks}:  Distributed Shared Memory on Standard Wrokstations and Operating Systems",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "115--132",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "release consistency, lazy release consistency, communication
    overhead, distributed programming, workstation lans, performance,
    distributed shared memory",
  abstract     = "TreadMarks is a distributed shared memory (DSM) system for
    standard Unix systems such as SunOS and Ultrix.  This paper presents a
    performance evaluation of TreadMarks running on Ultrix using
    DECstation-5000/240's that are connected by a 100-Mbps switch-based ATM LAN
    and a 10-Mbps Ethernet.  Our objective is to determine the efficiency of a
    user-level DSM implementation on commercially available workstations and
    operating systems.  We achieved good speedups on the 8-processor ATM
    network for Jacobi (7.4), TSP (7.2), Quicksort (6.3), and ILINK (5.7).  For
    a slightly modified version of Water from the SPLASH benchmark suite, we
    achieved only moderate speedups (4.0) due to the high communication and
    synchronization rate.  Speedups decline on the 10-Mbps Ethernet (5.5 for
    Jacobi, 6.5 for TSP, 4.2 for Quicksort, 5.1 for ILINK, and 2.1 for Water),
    reflecting the bandwidth limitations of the Ethernet.  These results
    support the contention that, with suitable networking technology, DSM is a
    viable technique for parallel computation on clusters of workstations.  To
    achieve these speedups, TreadMarks goes to great lengths to reduce the
    amount of communication performed to maintain memory consistency.  It uses
    a lazy implementation of release consistency, and it allows multiple
    concurrent writers to modify a page, reducing the impact of false sharing.
    Great care was taken to minimize communication overhead.  In particular, on
    the ATM network, we used a standard low-level protocol, AAL3/4, bypassing
    the TCP/IP protocol stack.  Unix communication overhead, however, remains
    the main obstacle in the way of better performance for programs like Water.
    Compared to the Unix communication overhead, memory management cost (both
    kernel and user level) is small and wire time is negligible.", 
  location     = ""
}

@InProceedings{earftioaasf,
  author       = "Black, Richard and Crosby, Simon",
  title        = "Experience and Results from the Implementation of an {ATM} Socket Family",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "143--152",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "atm, kernel-user space split, tunneling, kernel development, sockets",
  abstract     = "This paper describes the implementation of an ATM protocol
    stack as a protocol family within a 4.3 BSD derived Unix.  A novel approach
    to the implementation of the management and control functions for the ATM
    protocol stack has been adopted.  The data path is implemented within the
    kernel but all control and management functions are implemented by a user
    space daemon.  An encapsulation of IP on the ATM protocol is provided by
    means of a logical IP interface.  The mapping of IP addresses to ATM
    addresses is performed by the user space daemon.", 
  location     = "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/usenix1994.pdf"
}

@InProceedings{wsfrtmc,
  author       = "Hagsand, Olof and Sj{\" o}din, Peter",
  title        = "Working Support for Real-time Multimedia Communication",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "143--152",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "atm, real-time scheduling, multi-media networking, kernel, os
    facilities",
  abstract     = "We show how multimedia applications with real-time
    requirements can be supported in a distributed system.  A UNIX system has
    been modified to give soft real-time support.  The modifications include
    deadline-based scheduling, preemption points and prioritized interrupt
    processing.  In addition, a system call interface for real-time application
    programming has been designed.  We justify the modifications by experiments
    with a simple distributed multimedia delivery system.  The experiments are
    made on an ATM network, where resources are reserved by means of the ST-2
    internetworking protocol.", 
  location     = "http://eprints.sics.se/3372/01/WS-RT.ps"
}

@InProceedings{fdaaumfnia,
  author       = "Summit, Steve",
  title        = "Filesystem Daemons as a Unifying Mechanism for Network Information Access",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "63--77",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "system-call interception, user-space file systems,
    unified information access",
  abstract     = "As the Net burgeons, new tools and protocols are being
    introduced to permit some orderly use to be made of the wealth of
    information available.  These new protocols, however, often presuppose the
    use of new, nonstandard, highly interactive user interfaces.  This paper
    presents a mechanism for unifying access to diverse network services
    through filesystem daemons, which allow network information services to be
    treated as if they were conventional files and directories, residing in the
    local namespace, and accessed transparently with standard tools.  Besides
    normal filesystem operations (open, read, write, etc.), the daemons may
    introduce extended operations, which provide generic access to such
    features as network database lookup operations.", 
  location     = "https://www.usenix.org/publications/library/proceedings/sf94/full_papers/summit.a"
}

@InProceedings{epdfmealm,
  author       = "Yuhara, Masanobu and Bershad, Brian~N. and Maeda, Chris and Moss, J. Eliot~B.",
  title        = "Efficient Packet Demultiplexing for Multiple Endpoints and Large Messages",
  booktitle    = usenixw94,
  year         = 1994,
  pages        = "153--165",
  address      = sfca,
  month        = "17--21 " # jan,
  keywords     = "packet filters, mach, code fusion, fragmentation, dispatch",
  abstract     = "This paper describes a new packet filter mechanism that
    efficiently dispatches incoming network packets to one of multiple
    endpoints, for example address spaces.  Earlier packet filter systems
    iteratively applied each installed filter against every incoming packet,
    resulting in high processing overhead whenever multiple filters existed.
    Our new packet filter provides an associative match function that enables
    similar but not identical filters to be combined together into a single
    filter.  The filter mechanism, which we call the Mach Packet Filter (MPF),
    has been implemented for the Mach 3.0 operating system and is being used to
    support endpoint-based protocol processing, whereby each address space
    implements its own suite of network protocols.  With large numbers of
    registered endpoints, MPF outperforms the earlier BSD Packet Filter (BPF)
    by over a factor of four.  MPF also allows a filter program to dispatch
    fragmented packets, which was quite difficult with previous filter
    mechanisms.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/efficient-packet-demultiplexing-multiple"
}

@InProceedings{laotoaan,
  author       = "Wolman, Alec and Voelker, Geoff and Thekkath, Chandramohan~A.",
  title        = "Latency Analysis of {TCP} on an {ATM} Network",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "167--179",
  month        = "17--21 " # jan,
  keywords     = "checksumming, delay, atm, tcp, header prediction, data
    copying, protocol performance",
  abstract     = "In this paper we characterize the latency of the BSD 4.4
    alpha implementation of TCP on an ATM network.  Latency reduction is a
    difficult task, and careful analysis is the first step towards reduction.
    We investigate the impact of both the network controller and the protocol
    implementation on latency.  We find that a low latency network controller
    has a significant impact on the overall latency of TCP.  We also
    characterize the impact on latency of some widely discussed improvements to
    TCP, such as header prediction and the combination of the checksum
    calculation with data copying.", 
  location     = "ftp://ftp.cs.washington.edu/tr/1993/03/UW-CSE-93-03-03.PS.Z"
}

@InProceedings{iukpupbo,
  author       = "Speer, Steven~E. and Kumar, Rajiv and Partridge, Craig",
  title        = "Improving " # unix # " Kernel Performance using Profile Based Optimization",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "181--188",
  month        = "17--21 " # jan,
  keywords     = "performance measurements, directed code optimization,
    profile-based optimizations, risc processors",
  abstract     = "Several studies have shown that operating system performance
    has lagged behind improvements in application performance.  In this paper
    we show how operating systems can be improved to make better use of RISC
    architectures, particularly in some of the networking code, using a
    compiling technique known as Profile Based Optimization (PBO).  PBO uses
    profiles from the execution of a program to determine how to best organize
    the binary code to reduce the number of dynamically taken branches and
    reduce instruction cache misses.  In the case of an operating system, PBO
    can use profiles produced by instrumented kernels to optimize a kernel
    image to reflect patterns of use on a particular system.  Tests applying
    PBO to an HP-UX kernel running on an HP9000/720 show that certain parts of
    the system code (most notably the networking code) achieve substantial
    performance improvements of up to 35% on micro benchmarks.  Overall system
    performance typically improves by about 5%.", 
  location     = "https://www.usenix.org/publications/library/proceedings/sf94/full_papers/partridge.ps"
}

@InProceedings{mboaxws,
  author       = "Chen, J.~Bradley",
  title        = "Memory Behavior of an {X11} Window System",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "189--200",
  month        = "17--21 " # jan,
  keywords     = "context switching, caches, look-aside buffers, client-server
    architecture",
  abstract     = "We used memory reference traces from a DEC Ultrix system
    running the X11 window system from MIT Project Athena and several freely
    available X11 applications to measure different aspects of memory system
    behavior and performance.  Our measurements show that memory behavior for
    X11 workloads differs in several important ways from workloads more
    traditionally used in cache performance studies.  User instruction cache
    behavior is a major component in overall memory system delays, with
    significant competition within and between address spaces.  User TLB miss
    rates are up to a factor of two higher than other ill-behaved integer
    workloads.  Write-buffer stalls, data cache behavior, and uncached memory
    reads can be problematic for microbenchmarks, but they are not an issue for
    the realistic applications we tested.", 
  location     = "https://www.cs.cmu.edu/afs/cs/project/mach/public/www/doc/abstracts/X11_mem_behavior.html"
}

@InProceedings{aunsfssue,
  author       = "Nelson, Michael~N. and Radia, Sanjay~R.",
  title        = "{A} Uniform Name Service for {S}pring's " # unix # " Environment",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "201--209",
  month        = "17--21 " # jan,
  keywords     = "name spaces, object-oriented systems, plan 9",
  abstract     = "The Spring operating system provides a uniform name service
    that can be used to associate any name with any object independent of the
    type of object, and allows arbitrary name spaces to be created and used as
    first-class objects.  We have used this name service to unify the many
    UNIX&#174; name spaces.  Objects that on UNIX systems are typically stored
    in separate name spaces are all accessible via a single uniform name
    service in Spring.  In addition, it is easy to add new Spring objects that
    are not currently available in UNIX systems without modifying the
    underlying name service.", 
  location     = "https://www.usenix.org/publications/library/proceedings/sf94/full_papers/nelson.pdf"
}

@InProceedings{fsdfanfsa,
  author       = "Hitz, Dave and Lau, James and Malcolm, Michael",
  title        = "File System Design for an {NFS} File Server Appliance",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "235--246",
  month        = "17--21 " # jan,
  keywords     = "file systems, nvram, nfs servers",
  abstract     = "Network Appliance Corporation recently began shipping a new
    kind of network server called an NFS file server appliance, which is a
    dedicated server whose sole function is to provide NFS file service.  The
    file system requirements for an NFS appliance are different from those for
    a general-purpose UNIX system, both because an NFS appliance must be
    optimized for network file access and because an appliance must be easy to
    use.  This paper describes WAFL (Write Anywhere File Layout), which is a
    file system designed specifically to work in an NFS appliance.  The primary
    focus is on the algorithms and data structures that WAFL uses to implement
    Snapshotst, which are read-only clones of the active file system.  WAFL
    uses a copy-on-write technique to minimize the disk space that Snapshots
    consume.  This paper also describes how WAFL uses Snapshots to eliminate
    the need for file system consistency checking after an unclean shutdown.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/file-system-design-nfs-file-server-appliance"
}

@InProceedings{aadbfal,
  author       = "Phil Winterbottom",
  title        = "Acid: {A} Debugger Built From {A} Language",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "211--222",
  month        = "17--21 " # jan,
  keywords     = "alef, interpreter, debugging, extension mechanisms, name spaces",
  abstract     = "Acid is an unusual sourceÂ­level symbolic debugger for Plan 9.
    It is implemented as a language interpreter with specialized primitives
    that provide debugger support.  Programs written in the language manipulate
    one or more target processes; variables in the language represent the
    symbols, state, and resources of those processes.  This structure allows
    complex interaction between the debugger and the target program and
    provides a convenient method of parameterizing differences between machine
    architectures.  Although some effort is required to learn the debugging
    language, the richness and flexibility of the debugging environment
    encourages new ways of reasoning about the way programs run and the
    conditions under which they fail.", 
  location     = "http://doc.cat-v.org/plan_9/4th_edition/papers/acidpaper"
}

@InProceedings{itwpoans,
  author       = "Chet Juszczak",
  title        = "Improving the Write Performance of an {NFS} Server",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "247--259",
  month        = "17--21 " # jan,
  keywords     = "io performance, clustered writes, asynchrony, nfs semantics",
  abstract     = "The Network File System (NFS) utilizes a stateless protocol
    between clients and servers; the major advantage of this statelessness is
    that NFS crash recovery is very easy.  However, the protocol requires that
    data modification operations such as write be fully committed to stable
    storage before replying to the client.  The cost of this is significant in
    terms of response latency and server CPU and I/O loading.  This paper
    describes a write gathering technique that exploits the fact that there are
    often several write requests for the same file presented to the server at
    about the same time.  With this technique the data portions of these writes
    are combined and a single metadata update is done that applies to them all.
    No replies are sent to the client until after this metadata update has been
    fully committed, thus the NFS crash recovery design is not violated.  This
    technique can be used in most NFS server implementations and requires no
    client modifications.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/improving-write-performance-nfs-server"
}

@InProceedings{nqnsccfn,
  author       = "Rick Macklem",
  title        = "Not Quite {NFS}, Soft Cache Consistency for {NFS}",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "261--278",
  month        = "17--21 " # jan,
  keywords     = "nfs, stateless protocols, caching, leases",
  abstract     = "There are some constraints inherent in the NFS protocol that
    result in performance limitations for high performance workstation
    environments.  This paper discusses an NFS-like protocol named Not Quite
    NFS (NQNFS), designed to address some of these limitations.  This protocol
    provides full cache consistency during normal operation, while permitting
    more effective client-side caching in an effort to improve performance.
    There are also a variety of minor protocol changes, in order to resolve
    various NFS issues.  The emphasis is on observed performance of a
    preliminary implementation of the protocol, in order to show how well this
    design works and to suggest possible areas for further improvement.",  
  location     = "https://www.usenix.org/publications/library/proceedings/sf94/full_papers/macklem.ps"
}

@InProceedings{ttphd,
  author       = "Douglis, Fred and Krishnan, P. and Marsh, Brian",
  title        = "Thwarting the Power-Hungry Disk",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "292--306",
  month        = "17--21 " # jan,
  keywords     = "simulation, disk-drive management, spin control algorithms",
  abstract     = "Minimizing power consumption is important for mobile
    computers, and disks consume a significant portion of system-wide power.
    There is a large difference in power consumption between a disk that is
    spinning and one that is not, so systems try to keep the disk spinning only
    when it must.  The system must trade off between the power that can be
    saved by spinning the disk down quickly after each access and the impact on
    response time from spinning it up again too often.  We use trace-driven
    simulation to examine these trade-offs, and compare a number of different
    algorithms for controlling disk spin-down.  We simulate disk accesses from
    a mobile computer (a Macintosh Powerbook Duo 230) and also from a desktop
    workstation (a Hewlett-Packard 9000/845 personal workstation running
    HP-UX), running on two disks used on mobile computers, the Hewlett-Packard
    Kittyhawk C3014A and the Quantum GoDrive 120.  We show that the perfect
    off-line algorithm--one that consumes minimum power without increasing
    response time relative to a disk that never spins down--can reduce disk
    power consumption by 35--50%, compared to the fixed threshold suggested by
    manufacturers.  An on-line algorithm with a threshold of 10 seconds,
    running on the Powerbook trace and GoDrive disk, reduces energy consumption
    by about 40% compared to the 5-minute threshold recommended by
    manufacturers of comparable disks; however, over a 4-hour trace period it
    results in 140 additional delays due to disk spin-ups.",
  location     = "https://www.usenix.org/publications/library/proceedings/sf94/full_papers/marsh.ps"
}

@InProceedings{aqaoddpmipc,
  author       = "Li, Kester and Kumpf, Roger and Horton, Paul and Anderson, Thomas",
  title        = "{A} Quantitative Analysis of Disk Drive Power Management in Portable Computers",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "279--291",
  month        = "17--21 " # jan,
  keywords     = "power management, disk management, caching, trace-driven
    simulations, spindown, user latency",
  abstract     = "With the advent and subsequent popularity of portable
    computers, power management of system components has become an important
    issue.  Current portable computers implement a number of power reduction
    techniques to achieve a longer battery life.  Included among these is
    spinning down a disk during long periods of inactivity.  In this paper, we
    perform a quantitative analysis of the potential costs and benefits of
    spinning down the disk drive as a power reduction technique.  Our
    conclusion is that almost all the energy consumed by a disk drive can be
    eliminated with little loss in performance.  Although on current hardware,
    reliability can be impacted by our policies, the next generation of disk
    drives will use technology (such as dynamic head loading) which is
    virtually unaffected by repeated spinups.  We found that the optimal
    spindown delay time, the amount of time the disk idles before it is spun
    down, is 2 seconds.  This differs significantly from the 3-5 minutes in
    current practice by industry.  We will show in this paper the effect of
    varying the spindown delay on power consumption; one conclusion is that a
    3-5 minute delay results in only half of the potential benefit of spinning
    down a disk.", 
  location     = "http://nma.berkeley.edu/ark:/28722/bk0005n3672"
}

@InProceedings{pieriepos,
  author       = "Daniel~T. Schuh and Michael~J. Carey and David~J. DeWitt",
  title        = "Persistence in {E} Revisited --- Implementation Experiences",
  booktitle    = pot # "1990 International Workshop on Persistent Object Systems",
  year         = 1990,
  pages        = "345--359",
  publisher    = "Morgan Kaufmann",
  address      = "Martha's Vineyard, Massachusetts",
  month        = "23--27 " # sep,
  keywords     = "pointer swizzling, virtual machines, data persistence,
    programming language, run-time support",
  abstract     = "This paper discusses the design and implementation of the E
    Persistent Virtual Machine (EPVM), an interpreter that provides support for
    persistent data access in the current version of the E programming
    language.  Included are descriptions of both the EPVM interface and the
    major implementation tactics employed within EPVM.  A novel pointer
    swizzling scheme that has been investigated in the context of E and EPVM is
    also described.  Finally, a performance analysis of the key EPVM primitives
    is presented." 
}

@InProceedings{aupaeoawadfs,
  author       = "Spasojevic, Mirjana and Satyanarayanan, M.",
  title        = "{A} Usage Profile and Evaluation of a Wide-Area Distributed File System",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "307--323",
  month        = "17--21 " # jan,
  keywords     = "distributed file system, andrew file system, collaborative
    work, evaluation, wide-area scalability",
  abstract     = "The evolution of the Andrew File System (AFS) into a
    wide-area distributed file system has encouraged collaboration and
    information dissemination on a much broader scale than ever before.  In
    this paper, we examine AFS as a provider of wide-area file services to over
    80 organizations around the world.  We discuss usage characteristics of AFS
    derived from empirical measurements of the system, and from user responses
    to a questionnaire.  Our observations indicate that AFS provides robust and
    efficient data access in its current configuration, thus confirming its
    viability as a design point for wide-area distributed file systems.",
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/usage-profile-and-evaluation-wide-area"
}

@InProceedings{aootnos,
  author       = "Major, Drew and Minshall, Greg and Powell, Kyle",
  title        = "An Overview of the {NetWare} Operating System",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "355--372",
  month        = "17--21 " # jan,
  keywords     = "operating systems, inter-process communication, rpc,
    mirroring protocol, fault tolerance",
  abstract     = "The NetWare operating system is designed specifically to
    provide service to clients over a computer network.  This design has
    resulted in a system that differs in several respects from more
    general-purpose operating systems.  In addition to highlighting the design
    decisions that have led to these differences, this paper provides an
    overview of the NetWare operating system, with a detailed description of
    its kernel and its software-based approach to fault tolerance.", 
  location     = "https://www.usenix.net/publications/library/proceedings/sf94/full_papers/minshall.pdf"
}

@InProceedings{wutuw,
  author       = "Spinellis, Diomidis",
  title        = "Wux:  " # unix # " Tools under {W}indows",
  booktitle    = usenixw94,
  year         = 1994,
  address      = sfca,
  pages        = "325--336",
  month        = "17--21 " # jan,
  keywords     = "libraries, emulation, software portability, operating systems",
  abstract     = "Wux is a port of Unix tools to the Microsoft Windows
    environment.  It is based on a library providing a Unix-compatible set of
    system calls on top of Windows.  Unix-derived tools run in parallel,
    communicating using the Unix pipe abstraction.  All processes are run
    within an application template that gives them basic Windows compatibility
    such as input and output windows and an icon.  The performance of the
    system is comparable to that of Unix ports to the PC architecture.", 
  location     = "https://www.usenix.org/conference/usenix-winter-1994-technical-conference/wux-unix-tools-under-windows"
}

@TechReport{dacsbssbsalbl,
  author       = "P.~Emerald Chung and Yennun Huang and Shalini Yajnik and
    Deron Liang and Joanne~C. Shih and Chung-Yih Wang and Yi-Min Wang",
  title        = "{DCOM} and {CORBA} Side by Side, Step by Step, and Layer by Layer",
  institution  = "Bell Laboratories, Lucent Technologies",
  address      = "Murray Hill, New Jersey",
  keywords     = "corba, dom, distributed computing, architectures",
  abstract     = "DCOM (Distributed Component Object Model) and CORBA (Common
    Object Request Broker Architecture) are two popular distributed object
    models.  In this paper, we make architectural comparison of DCOM and CORBA
    at three different layers: basic programming architecture, remoting
    architecture, and the wire protocol architecture.  A step-by-step
    description of remote object activation and method invocation is provided
    to demonstrate the similarities and differences of the two frameworks.  A
    primary goal is for people who are already familiar with one model to
    quickly understand the basic architecture of the other.",
  location     = "http://research.microsoft.com/~ymwangspapers/HTML/DCOMnCORBA/S.html"
}

@TechReport{crfrtcs,
  author       = "D. Ferrari",
  title        = "Client Requirements for Real-Time Communication Services",
  institution  = "Internet Engineering Task Force, Network Working Group",
  year         = 1990,
  type         = "Request for Comments",
  number       = 1193,
  address      = bca,
  month        = nov,
  keywords     = "client requests, performance, delay, reliability,
    translation",
  abstract     = "A real-time communication service provides its clients with
    the ability to specify their performance requirements and to obtain
    guarantees about the satisfaction of those requirements.  In this paper, we
    propose a set of performance specifications that seem appropriate for such
    services; they include various types of delay bounds, throughput bounds,
    and reliability bounds.  We also describe other requirements and desirable
    properties from a client's viewpoint, and the ways in which each
    requirement is to be translated to make it suitable for lower levels in the
    protocol hierarchy.  Finally, we present some examples of requirements
    specification, and discuss some of the possible objections to our
    approach.", 
  location     = "https://tools.ietf.org/html/rfc1193"
}

@TechReport{agaftalbp,
  author       = "Edward~J. Anderson and Michael~C. Ferris",
  title        = "{A} Genetic Algorithm for the Assembly Line Balancing Problem",
  institution  = "Optimization Group, UW-Madison Computer Sciences, " # uwisc,
  year         = 1990,
  number       = 926,
  address      = madw,
  keywords     = "genetic algorithms, parallel computing",
  abstract     = "",
  location     = "ftp://ftp.cs.wisc.edu/tech-reports/reports/1990/tr926"
}

@TechReport{msltfoesatlosr,
  author       = "Robert~M. Brady and Ross~J. Anderson and Robin~C. Ball",
  title        = "Murphy's Law, the Fitness of Evolving Species, and the Limits of Software Reliability",
  institution  = "Computing Laboratory, Cambridge University",
  year         = 1998,
  type         = "UCAM-CL-TR",
  number       = 471,
  address      = cen,
  month        = sep,
  keywords     = "software reliability, evolving species, reliability growth
    model, software development, poisson distribution, experimental
    measurement, mass market computing, biological evolution, spiral model,
    statistical thermodynamics, software errors, software assurance,
    evolutionary development model observed reliability growth, one-off
    software development",
  abstract     = "We tackle two problems of interest to the software assurance
    community. Firstly, existing models of software development (such as the
    waterfall and spiral models) are oriented towards one-off software
    development projects, while the growth of mass market computing has led to
    a world in which most software consists of packages which follow an
    evolutionary development model.  Thisleads us to ask whether anything
    interesting and useful may be said about evolutionary development.  We
    answer in the afï¬rmative.  Secondly, existing reliability growth models
    emphasise the Poisson distribution of individual software bugs, while the
    empirically observed reliability growth for large systems is asymptotically
    slower than this.  We provide a rigorous explanation of this phenomenon.
    Our reliability growth model is inspired by statistical thermodynamics, but
    also applies to biological evolution.  It is in close agreement with
    experimental measurements of the ï¬tness of an evolving species and the
    reliability of commercial software products.  However, it shows that there
    are signiï¬cant differences between the evolution of software and the
    evolution of species.  In particular, we establish maximisation properties
    corresponding to Murphyâ€™s law which work to the advantage of a biological
    species, but to the detriment of software reliability.", 
  location     = "https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-471.pdf"
}

@TechReport{aniotil,
  author       = "Todd~A. Proebsting and Gregg~M. Townsend",
  title        = "{A} New Implementation of the {I}con Language",
  institution  = csd # uaz,
  year         = 1999,
  number       = "TR 99-13",
  address      = taz,
  abstract     = "We describe Jcon, a new, Java-based implementation of the
    Icon programming language.  The implementation includes a compiler and
    runtime system.  The runtime system is novel in its concise and efficient
    object-oriented implementation of a dynamically typed language, as well as
    its simple mechanism for realizing Icon generators.",
  month        = "4 " # oct,
  keywords     = "icon, java, object-oriented programming, generators, language
    implementation, backtracking, intermediate representations",
  location     = "https://www.microsoft.com/en-us/research/publication/a-new-implementation-of-the-icon-language/"
}

@TechReport{iaf7tcftutsststg,
  author       = "Aaron Sawdey and Matthew O'Keefe and Terrance Parr",
  title        = "Implementing a {F}ortran 77 to {CM} {F}ortran Translator Using the {SORCERER} Source-To-Source Translator Generator",
  institution  = "University of Minnesota",
  year         = 1993,
  type         = "AHPCRC Preprint",
  number       = "93-102",
  month        = oct,
  address      = "",
  keywords     = "language translation, tree transformations, intermediate
    representations, high-performance computing",
  abstract     = "",
  location     = ""
}

@TechReport{ltchamfsp,
  author       = "Lawrence Bernstein and David Klappholz",
  title        = "Live-Through Case Histories as Motivation for Software Process",
  institution  = "New Jersey Center for Software Engineering",
  keywords     = "capstone courses, requirements analysis, case histories,
    project management",
  location     = "http://www.njcse.org/Documents/version40.pdf"
}

@TechReport{sscsh,
  author       = "Cay~S. Horstmann",
  title        = "Safe {STL}",
  abstract     = "STL, the Standard Template Library designed by Alexander
    Stepanov and Meng Lee, is slated to become a part of the ANSI/ISO C++
    Standard.  Reaction to STL has been mixed.  Some programmers applaud its
    elegance and power, others find flaws with the interface, naming
    conventions, multithread support or safety.  While STL may not be the
    perfect container class library, it is here to stay.  I designed this small
    but useful enhancement to make STL safer to use.  Safe STL catches many
    typical STL programming errors at runtime (and a few at compile time).",
  keywords     = "stl, c++, programming errors, iterators",
  location     = "http://horstmann.com/safestl.html"
}

@TechReport{fasfathop,
  author       = "Craig~A. Damon and Ralph Melton and Robert~J. Allen and Elizabeth Bigelow and James~M. Ivers and David Garlan",
  title        = "Formalizing a Specification for Analysis:  The {HLA} Ownership Properties",
  institution  = scs # cmu,
  year         = 1999,
  number       = "CMU-CS-99-126",
  address      = ppa,
  month        = apr,
  keywords     = "Formal specification, model checking, Z specification language, distributed simulation",
  abstract     = "Interfaces are commonly specified using informal or
    semi-formal techniques, relying primarily on natural language descriptions.
    Such specifications, however, can easily overlook significant details and
    are not amenable to analysis by automated tools.  This paper looks at
    formalizing one portion of a substantial specification, the ownership
    management chapter of the DoD HLA framework, and at the subsequent analysis
    using the tool Ladybug.", 
  location     = "http://www.cs.cmu.edu/afs/cs/project/nitpick/www/ownership.html"
}

@TechReport{csejf,
  author       = "John Foreman",
  title        = "Cleanroom Software Engineering",
  institution  = sei,
  year         = 2005,
  type         = "Software Technology Roadmap",
  address      = ppa,
  keywords     = "maturity, complementary technologies",
  abstract     = "Cleanroom software engineering is a theory-based
    team-oriented process for development and certification of high-reliability
    software systems under statistical quality control.  A principal objective
    of the Cleanroom process is development of software that exhibits zero
    failures in use.  The Cleanroom name is borrowed from hardware Cleanrooms,
    with their emphasis on rigorous engineering discipline and focus on defect
    prevention rather than defect removal.  Cleanroom combines mathematically
    based methods of software specification, design, and correctness
    verification with statistical, usage-based testing to certify software
    fitness for use.  Cleanroom projects have reported substantial gains in
    quality and productivity.Â  This report defines the Cleanroom Software
    Engineering Reference Model, or CRM.  The CRM is expressed in terms of a
    set of 14 Cleanroom processes and 20 work products.  It is intended as a
    guide for Cleanroom project management and performance, process assessment
    and improvement, and technology transfer and adoption.", 
  location     = "http://www.sei.cmu.edu/library/abstracts/reports/96tr022.cfm"
}

@TechReport{watps,
  author       = "Lee Haugen",
  title        = "Writing a Teaching Philosophy Statement",
  institution  = "Center for Teaching Excellence, Iowa State University",
  year         = 1998,
  address      = "Ames, Iowa",
  month        = mar,
  keywords     = "teaching, objectives, tactics, commitment, justification",
  location     = "https://www.learner.org/workshops/hswriting/support/writingTeachPhilosophy.pdf"
}

@TechReport{paplfan,
  author       = "Michael Hicks and Pankaj Kakkar and Jonathan~T. Moore and Carl~A. Gunter and and Scott Nettles",
  title        = "{PLAN}: {A} Programming Language for Active Networks",
  institution  = "Department of Computer and Information Science, University of Pennsylvania",
  year         = 1997,
  address      = phpe,
  month        = "7 " # nov,
  keywords     = "active networking, code injection, protection",
  abstract     = "PLAN (Programming Language for Active Networks) is a new
    language for programs that are carried in the packets of a programmable
    network.  PLAN programs replace the packet headers (which can be viewed as
    `dumb' programs) used in current networks.  As a header replacement, PLAN
    programs must be lightweight and of limited functionality.  These
    limitations are mitigated by allowing PLAN code to call service routines
    written in other, more powerful languages.  These service routines may also
    be loaded into the routers dynamically.  This two-level architecture, in
    which PLAN serves as a scripting or `glue' language for more general
    services, is the primary contribution of the paper.  PLAN is a strict
    functional language providing a limited set of primitives and datatypes.
    PLAN defines primitives for remotely executing PLAN programs on other
    nodes, and these primitives are used to provide basic data transport in the
    network.  Because remote execution makes debugging difficult, PLAN provides
    strong static guarantees to the programmer, such as type safety.  A more
    novel property aimed at protecting network availability is a guarantee that
    plan programs use a bounded amount of space and time on active routers and
    bandwidth in the network." 
}

@TechReport{mslac,
  author       = "Martin~E. Hellman",
  title        = "Moore's Law and Communications",
  institution  = "Department of Electrical Engineering, Stanford University",
  year         = 2003,
  address      = paca,
  month        = "11 " # jun,
  keywords     = "communication, moore's law",
  location     = "https://ee.stanford.edu/~hellman/opinion/moore.html"
}

@TechReport{5dtatp,
  author       = "Michael Henderson",
  title        = "56kbps Data Transmission Across the {PSTN}",
  institution  = "Network Access Division, Conexant Systems, Inc.",
  year         = 1998,
  address      = "St. Louis, Missouri",
  month        = "14 " # oct,
  keywords     = "modems",
  location     = "http://www.michael-henderson.us/Papers/56Kbps.pdf"
}

@TechReport{wiwikwlh,
  author       = "Stephen Diehl",
  title        = "What {I} Wish {I} Know When Learning Haskell",
  year         = 2012,
  month        = "10 " # sep,
  keywords     = "haskell, cabal, ghci, monads, applicative functors, arrows,
    gadts, lambda calculus, hoas, core, typeclasses, monad transformers, quickcheck",
  location     = "http://dev.stephendiehl.com/hask/"
}

@TechReport{adbiissa,
  author       = "Abowd, Gregory~D. and Pitkow, James Edward and Kazman, Rick",
  title        = "Analyzing Differences Between {I}nternet Information System Software Architectures",
  institution  = "GVU, College of Computing, Georgia Institute of Technology",
  year         = 1995,
  number       = "GIT-GVU-95-34",
  address      = atga,
  keywords     = "internet information systems, software architecture,
    scenario-based analysis, www, wais, harvest",
  abstract     = "While the growth and variety of Internet information systems
    has been dramatic over the past five years, the methodical consideration of
    the differences between systems has not been emphasized.  We present a
    particular scenario-based method for analyzing different systems in this
    domain based on their software architecture.  We demonstrate this method,
    the Software Architecture Analysis Method (SAAM), by applying it to three
    well-known Internet information systems-WWW, WAIS and Harvest.", 
  location     = "https://smartech.gatech.edu/bitstream/handle/1853/3578/95-34.pdf?sequence=1&isAllowed=y"
}

@TechReport{rwwwhwr,
  author       = "Arjen~K. Lenstra and James~P. Hughes and Maxime Augler and
    Joppe~W. Bos and Thorsten Kleinjung and Christophe Wachter",
  title        = "Ron was Wrong, {W}hit was Right",
  institution  = "EPFL IC LACL",
  year         = 2012,
  address      = "Lausanne, Switzerland",
  keywords     = "sanity check, rsa, 99.8% security, elgamal, dsa, ecdsa,
    (batch) factoring, discrete logarithm, euclidean algorithm, seeding random
    number generators, k9", 
  abstract     = "We performed a sanity check of public keys collected on the
    web.  Our main goal was to test the validity of the assumption that
    different random choices are made each time keys are generated.  We found
    that the vast majority of public keys work as intended.  A more
    disconcerting finding is that two out of every one thousand RSA moduli that
    we collected offer no security.  Our conclusion is that the validity of the
    assumption is questionable and that generating keys in the real world for
    â€œmultiple-secretsâ€ cryptosystems such as RSA is significantly riskier than
    for â€œsingle-secretâ€ ones such as ElGamal or (EC)DSA which are based on
    Diffie-Hellman.", 
  location     = "http://eprint.iacr.org/2012/064.pdf"
}

@TechReport{cssl1,
  author       = "H\r{a}kon Lium Lie and Bert Bos",
  title        = "{C}ascading {S}tyle {S}heets, level 1",
  institution  = "W3C",
  year         = 1999,
  number       = "REC-CSS1-19990111",
  month        = "11 " # jan,
  keywords     = "html, style sheets, css",
  abstract     = "This document specifies level 1 of the Cascading Style Sheet
    mechanism (CSS1).  CSS1 is a simple style sheet mechanism that allows
    authors and readers to attach style (e.g.  fonts, colors and spacing) to
    HTML documents.  The CSS1 language is human readable and writable, and
    expresses style in common desktop publishing terminology.  One of the
    fundamental features of CSS is that style sheets cascade; authors can
    attach a preferred style sheet, while the reader may have a personal style
    sheet to adjust for human or technological handicaps.  The rules for
    resolving conflicts between different style sheets are defined in this
    specification.  This Recommendation results from W3C activities in the area
    of Style Sheets.  For background information on style sheets, see [1].", 
  location     = "https://www.w3.org/TR/CSS1"
}

@TechReport{trotmatfoete,
  author       = "Kempf, James and Austein, Rob",
  title        = "The Rise of the Middle and the Future of End to End",
  institution  = "IETF",
  year         = 2003,
  type         = "RFC",
  number       = "3724",
  month        = jan,
  keywords     = "internet architecture, system development, security, iana",
  abstract     = "The end-to-end principle is the core architectural guideline
    of the Internet.  In this document, we briefly examine the development of
    the end-to-end principle as it has been applied to the Internet
    architecture over the years.  We discuss current trends in the evolution of
    the Internet architecture in relation to the end-to-end principle, and try
    to draw some conclusion about the evolution of the end-to-end principle,
    and thus for the Internet architecture which it supports, in light of these
    current trends.", 
  location     = "https://tools.ietf.org/html/rfc3724"
}

@TechReport{anmd,
  author       = "R. Clayton",
  title        = "{A} New {MICE} Database",
  institution  = bcr,
  year         = 1987,
  number       = "IM-000-21460-87-02",
  address      = "Morristown, N.J.",
  month        = "14 " # aug,
  keywords     = "mice, intelligent services, databases, telephony",
  abstract     = "The Modular, Integrated Communications Environment (MICE) is
    an intelligent-network services testbed which uses a single database to
    store operational data.  In addition to being a performance bottle-neck,
    the database makes it difficult to implement and experiment with services.
    This paper describes the current MICE database arrangement and the problems
    it causes, and proposes a solution based on multiple databases.  The paper
    then describes the changes made to MICE so it can use multiple databases,
    and describes how the changes were implemented."
}

@TechReport{napar,
  author       = "David~D. Clark",
  title        = "Name, Addresses, Ports, and Routes",
  institution  = ietf,
  year         = 1982,
  number       = "RFC 814",
  month        = jul,
  keywords     = "names, addresses, service identifiers",
  abstract     = "This RFC gives suggestions and guidance for the design of the
    tables and algorithms necessary to keep track of these various sorts of
    identifiers inside a host implementation of TCP/IP.", 
  location     = "https://tools.ietf.org/html/rfc814"
}

@TechReport{aa43ict,
  author       = "Samuel~J. Leffler and Robert~S. Fabry and William~N. Joy and
    Phil Lapsley and Steve Miller and Chris Torek",
  title        = "An Advanced 4.{3BSD} Interprocess Communication Tutorial",
  institution  = "Computer Systems Research Group, Department of Electrical
    Engineering and Computer Science, University of California, Berkeley",
  year         = 1986,
  address      = beca,
  keywords     = "unix, interprocess communication, sockets",
  abstract     = "This document provides an introduction to the interprocess
    communication facilities included in the 4.3BSD release of the Unix system.
    It discusses the overall model for interprocess communication and
    introduces the interprocess communication primitives which have been added
    to the system.  The majority of the document considers the use of these
    primitives in developing applications.  The reader is expected to be
    familiar with the C programming language as all examples are written in
    C."
}

@TechReport{cmopc,
  author       = "Tim Tiemens",
  title        = "Cognitive Models of Program Comprehension",
  institution  = "Software Engineering Research Center",
  year         = 1989,
  address      = atga,
  month        = "8 " # dec,
  keywords     = "brooks, comprehension, soloway, representation, programmers
    apprentice, plan recognition",
  abstract     = "This paper describes some cognitive models in program
    comprehension.  Th goal is to use this knowledge about cognitive models to
    produce a tool (the Cognitive Support Tool, CST) which can reduce the
    amount of effort needed to understand program.  The models discussed here
    were derived from both a human perspective and from a source code
    perspective.  After reviewing these models, a synthesis sectio uggests some
    implications of the information presented.  Finally, a section describing a
    sample interactive sessions with CST is presented.", 
  location     = "http://www.cc.gatech.edu/reverse/repository/cogmodels.ps"
}

@TechReport{igmpv2,
  author       = "W. Fenner",
  title        = "Internet Group Management Protocol, Version 2",
  institution  = ietf,
  year         = 1997,
  type         = "RFC",
  number       = 2236,
  month        = nov,
  keywords     = "multicast, group management",
  abstract     = "This memo documents IGMPv2, used by IP hosts to report their
    multicast group memberships to routers.  It updates STD 5, RFC 1112.
    IGMPv2 allows group membership termination to be quickly reported to the
    routing protocol, which is important for high-bandwidth multicast groups
    and/or subnets with highly volatile group membership.  This document is a
    product of the Inter-Domain Multicast Routing working group within the
    Internet Engineering Task Force.  Comments are solicited and should be
    addressed to the working group's mailing list at idmr@cs.ucl.ac.uk and/or
    the author(s).", 
  location     = "https://datatracker.ietf.org/doc/rfc2236/"
}

@TechReport{fhidpl,
  author       = "Richard~D. Schlichting and Titus D.~M. Purdin",
  title        = "Failure Handling in Distributed Programming Languages",
  institution  = dcs # uaz,
  year         = 1985,
  number       = "TR 85-14",
  address      = taz,
  month        = "2 " # aug,
  keywords     = "fail-stop processors, failure handling, sr, distributed
    programming languages, events",
  abstract     = "",
  location     = ""
}

@TechReport{istls,
  author       = "Stuart Cheshire",
  title        = "It's the Latency, Stupid",
  year         = 1996,
  month        = may,
  keywords     = "bandwidth, latency, consumer devices, compression",
  abstract     = "Years ago David Cheriton at Stanford taught me something that
    seemed very obvious at the time -- that if you have a network link with low
    bandwidth then it's an easy matter of putting several in parallel to make a
    combined link with higher bandwidth, but if you have a network link with
    bad latency then no amount of money can turn any number of them into a link
    with good latency.  It's now many years later, and this obvious fact seems
    lost on the most companies making networking hardware and software for the
    home.  I think it's time it was explained again in writing.", 
  location     = "http://www.stuartcheshire.org/rants/Latency.html"
}

@TechReport{smasaldrsfmm,
  author       = "Shun Yan Cheung",
  title        = "Subgraph Multicasting: {A} Scalable and Low-Delay Routing Scheme for Multipoint Messages",
  institution  = "Department of Mathematics and Computer Science, Emory University",
  address      = atga,
  keywords     = "subgraph multicasting, looping, delay, atm, ",
  abstract     = "We present a new multicast routine technique that is scalable
    and can have low message delays.  The subgraph multicasting method uses a
    subgraph spanning all multicast destinations and forwards messages over the
    links in the subgraph.  the method is scalable because the network
    maintains only one subgraph per multicast group and lower message delay is
    possible due to the fact that the subgraph has alternate shorter paths to
    deliver messages from a source to a destination.  However, cycles may form
    in the subgraph which an cause messages to loop indefinitely.  We present
    an efficient technique for detecting and removing unnecessary messages, and
    who how minimum delay multicast subgraphs can be constructed.  We also
    present an implementation of the subgraph multicasting technique in
    Asynchronous Transfer Mode (ATM) networks.  The performance of minimum
    delay subgraph multicasting is studied in ten random networks and compared
    with the core based tree (CBT) multicasting method." 
}

@TechReport{jrt,
  author       = "Kenneth Baclawski",
  title        = "Java {RMI} Tutorial",
  institution  = "College of Computer Science, Northeastern University",
  year         = 2004,
  address      = boma,
  keywords     = "java, rmi, tutorial"
}

@TechReport{nvb,
  author       = "Fran{\c c}ios M{\' e}nard and David Isenberg",
  title        = "Netheads Versus {B}ellheads",
  institution  = "T.~M. Denton Consultants",
  address      = "Ottawa, Canada",
  keywords     = "internets, pstn",
  location     = "http://www.cs.columbia.edu/~hgs/papers/others/1999/Dent9905_Netheads.pdf"
}

@TechReport{clswas,
  author       = "Douglas~W. Clark",
  title        = "Copying List Structures Without Auxilliary Storage",
  institution  = dcs # cmu,
  year         = 1975,
  address      = ppa,
  month        = oct,
  keywords     = "list structures, copying, algorithms",
  abstract     = "An algorithm is presented for copying an arbitrary list
  structure into a block of contiguous storage locations without destroying the
  original list.  Apart form a fixed number of program variables, no auxiliary
  storage, such as a stack, is used.  The algorithm needs no mark bits and
  operates in linear time.  It is shown to be significantly faster than the
  best previous algorithm for the same problem.", 
  location     = "https://doi.org/10.21236"
}

@TechReport{cgagmm,
  author       = "Amit Gupta and Mark Moran",
  title        = "Channel Groups",
  institution  = "Tenet Group, University of California",
  year         = 1993,
  number       = "TR-93-015",
  address      = bca,
  month        = mar,
  keywords     = "resource sharing, multicast, teleconferences",
  abstract     = "A single distributed application typically requires setting
    up a number of real-time connections, or channels.  Current schemes usually
    assume different channels are independent, when in reality, important
    relationships often exist between them.  We introduce a new abstraction
    called channel groups that lets network clients describe these
    relationships explicitly to the network service provider.  For example, by
    describing sharing relationships between channels, the network client
    enables the network to share resource allocations among related
    channelsâ€”lowering the cost and improving the scalability of communication.
    In addition, specification of other relationships, such as inter-stream
    synchronization, disjoint-path routing, relative dropping priorities, and
    simultaneous establishment provide a richer, more efficient service.
    Channel groups provide a unifying abstraction and an easily-extensible
    interface for specifying these and other relationships.  This report
    presents a general description of the channel group abstraction and
    demonstrates its usefulness in describing several types of inter-stream
    relationships.", 
  location     = "https://www.icsi.berkeley.edu/ftp/global/pub/techreports/1993/tr-93-015.pdf"
}

@TechReport{hggnfg,
  author       = "Neal Gunther",
  title        = "Hypernets --- Good ({G})news for {G}nutella",
  year         = 2002,
  month        = "15 " # feb,
  keywords     = "hypernet topologies, tree topologies, performance metrics,
    relative bandwidth",
  abstract     = "Criticism of Gnutella network scalability has rested on the
    bandwidth attributes of the original interconnection topology: a Cayley
    tree.  Trees, in general, are known to have lower aggregate bandwidth than
    higher dimensional topologies e.g., hypercubes, meshes and tori.  Gnutella
    was intended to support thousands to millions of peers.  Studies of
    interconnection topologies in the literature, however, have focused on
    hardware implementations which are limited by cost to a few thousand nodes.
    Since the Gnutella network is virtual, hyper-topologies are relatively
    unfettered by such constraints.  We present performance models for several
    plausible hyper-topologies and compare their query throughput up to
    millions of peers.  The virtual hypercube and the virtual hypertorus are
    shown to offer near linear scalability subject to the number of peer TCP/
    IP connections that can be simultaneously kept open.", 
  location     = "http://www.perfdynamics.com/Papers/Gnews.html"
}

@TechReport{dpsg1sd,
  author       = "K.~L. Calvert and M. Marsh",
  title        = "{DATAKIT} Packet Switch --- Generic 1 System Description",
  institution  = "Bell Laboratories",
  year         = 1983,
  type         = "Memorandum for File",
  number       = "95454-1",
  address      = "Homdel, N.J.",
  month        = "14 " # jul,
  keywords     = "networking"
}

@TechReport{afmss,
  author       = "Kenneth~L. Calvert",
  title        = "{A} Flexible Message Service Specification",
  institution  = coc # git,
  address      = atga,
  abstract     = "This paper explores the use of a single, parameterized
    specification to define services with a range of different degrees of
    reliability.  An example service specification is presented, which closely
    resembles the popular sockets interface to networking services.  The
    specification embodies a model that is quite general, and handles unicast
    and multicast communication in the same framework.  The specification
    itself has a modular structure so that, by instantiating certain predicates
    differently, different service characteristics are obtained.  The limits of
    this approach, in particular the difficulty of separating safety and
    progress specifications, are discussed.", 
  keywords     = "service specification, modularity, state transition specifications"
}

@TechReport{afetepf,
  author       = "Kenneth~L. Calvert",
  title        = "{A} Flexible End-to-End Protocol Framework",
  institution  = coc # git,
  address      = atga,
  keywords     = "end-to-end protocol services, tau, infrastructure processing"
}

@TechReport{soaps11,
  author       = "Don Box and David Ehnebuske and Gopal Kakivaya and Andrew Layman and Noah Mendelsohn and Henrik Frystyk Nielsen and Satish Thatte and Dave Winer",
  title        = "Simple {O}bject {A}ccess {P}rotocol ({SOAP}) 1.1",
  institution  = "W3C",
  year         = 2000,
  type         = "note",
  number       = "SOAP-20000508",
  month        = "8 " # may,
  keywords     = "messaging, activation, rpc",
  abstract     = "SOAP is a lightweight protocol for exchange of information in
    a decentralized, distributed environment.  It is an XML based protocol that
    consists of three parts: an envelope that defines a framework for
    describing what is in a message and how to process it, a set of encoding
    rules for expressing instances of application-defined datatypes, and a
    convention for representing remote procedure calls and responses.  SOAP can
    potentially be used in combination with a variety of other protocols;
    however, the only bindings defined in this document describe how to use
    SOAP in combination with HTTP and HTTP Extension Framework.",
  location     = "http://www.w3.org/TR/2000/NOTE-SOAP-20000508"
}

@TechReport{dcfwcgc,
  author       = "Richard~A. Golding, Darrell D.~E. Long",
  title        = "Design Choices for Weak-Consistency Group Communication",
  institution  = "Concurrent Systems Laboratory, " # cis # ", " # ucal,
  year         = 1992,
  number       = "UCSC-TR-92-45",
  address      = scca,
  month        = "12 " # oct,
  keywords     = "group membership, weak consistency replication, mobile
    computing systems, bibliographic databases, reliability measurements",
  abstract     = "Many wide-area distributed applications can be implemented
    using distributed group communication, a mechanism for coordinating the
    activities of related processes running at different sites.  We have
    developed a modular architecture for group communication systems that can
    be used to build a system tailored to application requirements.  We focus
    on *weak consistency* mechanisms for group communication, since these allow
    highly efficient operation on wide-area internetworks.  We examine several
    design choices that can be made in building a weakly-consistent group
    communication mechanism, and discuss the decisions we made in building two
    very different wide-area applications.  The architecture accommodates both
    systems well, and allows several application-specific decisions that
    increase efficiency and flexibility.", 
  location     = "https://www.soe.ucsc.edu/research/technical-reports/UCSC-CRL-92-45"
}

@TechReport{tpowcrp,
  author       = "Richard~A. Golding, Darrell D.~E. Long",
  title        = "The Performance of Weak-Consistency Replication Protocols",
  institution  = "Concurrent Systems Laboratory, " # cis # ", " # ucal,
  year         = 1992,
  number       = "UCSC-CRL-92-30",
  address      = scca,
  month        = "6 " # jul,
  keywords     = "internet, time-stamped anti-entropy, fault tolerance,
    consistency, delay, propagation delay",
  abstract     = "Weak-consistency replication protocols can be used to build
    wide-area services that are scalable, fault- tolerant, and useful for
    mobile computer systems.  We have developed the *timestamped anti-entropy*
    protocol, which provides reliable eventual delivery with a variety of
    message orderings.  Pairs of replicas periodically exchange update
    messages; in this way updates eventually propagate to all replicas.  In
    this paper we present a detailed analysis of the fault tolerance and the
    consistency provided by this protocol.  The protocol is extremely robust in
    the face of site and network failure, and it scales well to large numbers
    of replicas.", 
  location     = "https://www.soe.ucsc.edu/research/technical-reports/UCSC-CRL-92-30"
}

@TechReport{aaioom,
  author       = "Linda~H. Rosenberg",
  title        = "Applying and Interpreting Object-Oriented Metrics",
  institution  = "Software Assurance Technology Center, NASA",
  month        = apr,
  year         = 1998,
  keywords     = "object-oriented metrics, software management, software
    assurance", 
  abstract     = "Object-oriented design and development is becoming very
    popular in today's software development environment.  Object oriented
    development requires not only a different approach to design and
    implementation, it requires a different approach to software metrics.
    Since object oriented technology uses objects and not algorithms as its
    fundamental building blocks, the approach to software metrics for object
    oriented programs must be different from the standard metrics set.  Some
    metrics, such as lines of code and cyclomatic complexity, have become
    accepted as standard for traditional functional/ procedural programs, but
    for object-oriented, there are many proposed object oriented metrics in the
    literature.  The question is, Which object oriented metrics should a
    project use, and can any of the traditional metrics be adapted to the
    object oriented environment? In this paper, the Software Assurance
    Technology Center (SATC) at NASA Goddard Space Flight Center discusses its
    approach to choosing metrics for a project by first identifying the
    attributes associated with object oriented development.  Within this
    framework, nine metrics for object oriented are selected.  These metrics
    include three traditional metrics adapted for an object oriented
    environment, and six new metrics to evaluate the principle object oriented
    structures and concepts.  The metrics are first defined, then using a very
    simplistic object oriented example, the metrics are applied.
    Interpretation guidelines are then discussed and data from NASA projects
    are used to demonstrate the application of the metrics.  In the experience
    of the SATC, projects choose the data they collect by default - if the tool
    they are using compiles it, the project collects it.  The purpose of this
    paper is to help project managers choose a comprehensive set of metrics,
    not by default, but by using a set of metrics based on attributes and
    features of object oriented technology.  Applying and Interpreting Object
    Oriented Metrics", 
  location     = "http://www.literateprogramming.com/ooapply.pdf"
}

@TechReport{sprfsma,
  author       = "Spencer Rugaber and Victoria~G. Tisdale",
  title        = "Software Psychology Requirements for Software Maintenance Activities",
  institution  = "Software Engineering Research Center, Georgia Institute of Technology",
  year         = 1992,
  address      = atga,
  month        = "17 " # nov,
  keywords     = "programming, program comprehension, debugging, composition,
    modification, problem solving"
}

@TechReport{egcfrhvdd,
  author       = "Jeremy R. Cooperstock and Steve Kotsopoulos",
  title        = "Exploring Group Communication for Reliable High Volume Data Distribution",
  institution  = "Department of Electrical and Computer Engineering, University of Toronto",
  address      = toon,
  keywords     = "multicast, broadcast, data distribution, performance, protocols",
  abstract     = "The design and implementation of a protocol to provide
    reliable and efficient distribution of large quantities of data to many
    hosts on a local area network or internetwork is described.  By exploiting
    the one-to-many transmission capabilities of multicast and broadcast, it is
    possible to transmit data to multiple hosts simultaneously, using less
    bandwidth and thus obtaining greater efficiently than repeated
    multicasting.  Although performance measurements indicate the superiority
    of multicast, we dynamically select from available transmission modes so as
    to maximize efficiency and throughput while providing reliable delivery of
    data to all hosts.  Our results demonstrate that file-distribution program
    based on this protocol can benefit from a linear speed-up over TCP-based
    programs such as rdist." 
}

@TechReport{wswpgtdotn,
  author       = "C. Cook",
  title        = "What Should We Plan Given the Dilemma of the Network?",
  institution  = IETF,
  year         = 1993,
  type         = "RFC",
  number       = 1527,
  month        = sep,
  keywords     = "regulation, technology transfer, network policy, network
    access, nren",
  abstract     = "Early last year, as the concluding effort of an 18 month
    appointment at the US Congress Office of Technology Assessment (OTA), I
    drafted a potential policy framework for Congressional action on the
    National Research and Education Network (NREN).  The Internet community
    needs to be asking what the most important policy issues facing the network
    are.  And given agreement on any particular set of policy issues, the next
    thing we should be asking is, what would be some of the political choices
    that would follow for Congress to make? It is unfortunate that this was
    never officially done for or by the Congress by OTA.  What we have as a
    result is network policy making being carried out now by the Science
    Subcommittee on the House side in consultation with a relatively small
    group of interested parties.  The debate seems to be more focused on
    preserving turf than on any sweeping understanding of what the legislation
    is doing.  That is unfortunate.  In the hope that it may contain some
    useful ideas, I offer a shortened version of the suggested policy draft as
    information for the Internet community.", 
  location     = "https://dx.doi.org/10.17487/RFC1527",
  location     = "https://tools.ietf.org/html/rfc1527"
}

@TechReport{apapss,
  author       = "Ramsey~W. Haddad and Donald~E. Knuth",
  title        = "{A} Programming and Problem-Solving Seminar",
  institution  = csd # "Stanford University",
  year         = 1985,
  number       = "STAN-CS-85-1055",
  address      = paca,
  keywords     = "monotonic squares, code breaking, hardware fault detection,
    distributed stability, art",
  abstract     = "This report contains edited transcripts of the discussions
    held in Stanfordâ€™s course CS204, Problem Seminar, during winter quarter
    1985.  Since the topics span a large range of ideas in computer science,
    and since most of the important research paradigms and programming
    paradigms were touched on during the discussions, these notes may be of
    interest to graduate students of computer science at other universities, as
    well as to their professors and to professional people in the real
    world. The present report is the sixth in a series of such transcripts,
    continuing the tradition established in STAN-CS-77-606 (Michael J. Clancy,
    1977), STAN-CS-79-707 (Chris Van Wyk, 1979), STAN-CS-U-863 (Allan A. Miller,
    1981), STAN-CS-83-989 (Joseph S. Weening, 1983), STAN-CS-83-990 (John
    D. Hobby, 1983).", 
  location     = "https://www-cs-faculty.stanford.edu/~knuth/papers/cs1055.pdf"
}

@Manual{atajsm,
  title        = "{ANT} Tutorial",
  author       = "Ashley J.~S. Mills",
  organization = "The University of Birmingham",
  year         = 2002,
  keywords     = "build management, xml, java",
  location     = "http://supportweb.cs.bham.ac.uk/docs/tutorials/docsystem/build/tutorials/ant/ant.html"
}

@Manual{fugsk,
  title        = "Freemind User Guide",
  author       = "Shailaja Kumar",
  address      = "Toronto, ON, Canada",
  edition      = "0.8.0",
  keywords     = "mind mapping",
  location     = "http://freemind.sourceforge.net/FreeMind%20User%20Guide%20by%20Shailaja%20Kumar%20%28manual%29.pdf"
}

@Manual{gmbl,
  title        = "Git Magic",
  author       = "Ben Lynn",
  year         = 2007,
  month        = aug,
  keywords     = "git, history, workflow, cloning",
  location     = "http://www-cs-students.stanford.edu/~blynn/gitmagic/"
}

@Manual{gftbu,
  title        = "Git from the Bottom Up",
  author       = "John Wiegley",
  year         = 2009,
  month        = "2 " # dec,
  keywords     = "git, repository, blogs, index, stashing, reflog",
  location     = "https://jwiegley.github.io/git-from-the-bottom-up/"
}

@Manual{nabi,
  title        = "NetLogo: {A} Basic Introduction",
  author       = "Alan~G. Isaac",
  organization = "American University",
  year         = 2012,
  keywords     = "netlogo, programming",
  location     = "https://docplayer.net/36247919-Netlogo-a-basic-introduction.html"
}

@Manual{npai,
  title        = "NetLogo Programming: An Introduction",
  author       = "Alan~G. Isaac",
  organization = "American University",
  year         = 2012,
  keywords     = "netlogo, programming, program structure",
  location     = "https://subversion.american.edu/aisaac/notes/netlogo-intro.xhtml"
}

@Manual{ctarm,
  title        = "{\tt cgi.tcl} - {A} Reference Manual",
  author       = "Don Libes",
  keywords     = "www, cgi, tcl, scripting",
  location     = "ftp://ftp.ntua.gr/mirror/expect/cgi.tcl/ref.html"
}

@Manual{ptpwm,
  title        = "{PLWM} --- The Pointless Window Manager",
  author       = "Peter Liljenberg",
  year         = 2002,
  keywords     = "window manager, python",
  location     = "http://plwm.sourceforge.net/"
}

@Manual{drdscs,
  title        = "{DVD}-{ROM} Drive {SCSI} Command Set",
  organization = "Pioneer",
  edition      = "TB--0597",
  keywords     = "scsi, dvd",
  location     = "https://slidex.tips/download/technical-bulletin-no-tb-0597-dvd-rom-drive-scsi-command-set"
}

@Manual{ckum,
  title        = "CarbonKernel User Manual",
  edition      = "1.3",
  year         = 2001,
  month        = jul,
  keywords     = "real-time operating system simulator",
  location     = "https://sourceforge.net/projects/carbonkernel/"
}

@Manual{cblosxom,
  title        = "Configure Blosxom",
  keywords     = "blogging",
  location     = "http://blosxom.sourceforge.net/documentation/users/onfigure/"
}

@Manual{latgpp,
  title        = "\LaTeX\ and the {G}nuplot Plotting Program",
  author       = "David Kotz",
  edition      = "4.0",
  year         = 2004,
  month        = mar,
  keywords     = "gnuplot, latex",
  location     = "http://www.gnuplot.info/files/tutorial.pdf"
}

@Manual{gtwck,
  title        = "Gnuplot",
  author       = "Thomas Williams and Colin Kelley",
  edition      = "4.0",
  year         = 2004,
  month        = "13 " # mar,
  keywords     = "gnuplot",
  location     = "http://www.gnuplot.info/"
}

@Manual{g40abmat,
  title        = "Gnuplot 4.0 --- {A} Brief Manual and Tutorial",
  organization = "Department of Civil and Environmental Engineering, Edmund T. Pratt School of Engineering, Duke University",
  address      = "Durham, N.C.",
  edition      = "",
  year         = 2005,
  month        = "13 " # apr,
  keywords     = "gnuplot",
  location     = "http://vlsicad.eecs.umich.edu/BK/Slots/cache/www.duke.edu/~hpgavin/gnuplot.html"
}

@Manual{mgsr,
  title        = "mpatrol",
  author       = "Graeme~S. Roy",
  edition      = "2.13 for {\tt mpatrol} version 1.4.8",
  year         = 2002,
  month        = "8 " # jan,
  keywords     = "memory management, debugging, gnu",
  location     = "http://mpatrol.sourceforge.net/"
}

@Manual{btmr,
  title        = "beepcore-tcl",
  author       = "Marshal Rose",
  organization = "Dover Beach Consulting, Inc.",
  year         = 2002,
  month        = jan,
  keywords     = "beep, tcl",
  location     = "http://beepcore-tcl.sourceforge.net/"
}

@Manual{rlas,
  title        = "{RTP} Library {API} Specification",
  organization = "Lucent Technologies",
  year         = 1998,
  month        = jun,
  keywords     = "rtp, api, spec",
  location     = "http://www.cs.columbia.edu/irt/software/rtplib/rtplib-1.0a1/rtp_api.html"
}

@Manual{rpcpg,
  title        = "Remote Procedure Call Programming Guide",
  organization = "FreeBSD",
  keywords     = "rpc, coding",
  location     = "https://docs.freebsd.org/44doc/psd/23.rpc/paper.pdf"
}

@Manual{rpcgenpg,
  title        = "{\tt rpcgen} Programming Guide",
  organization = "FreeBSD",
  keywords     = "rpcgen, coding",
  location     = "https://docs.freebsd.org/44doc/psd/22.rpcgen/paper.pdf"
}

@Manual{aoora,
  title        = "An Overview of {RMI} Applications",
  organization = "Oracle",
  keywords     = "rmi, java",
  location     = "https://docs.oracle.com/javase/tutorial/rmi/overview.html"
}

@Manual{mmosm,
  title        = "Moscow {ML} Owner's Manual",
  author       = "Sergei Romanenko and Peter Sestoft and Claudio Russo",
  year         = 1998,
  month        = "1 " # jul,
  keywords     = "ml, programming, polymorphism",
  location     = "http://mosml.org/manual.pdf"
}

@Unpublished{ivbf,
  author       = "Bob Frankston",
  title        = "Implementing {VisiCalc}",
  keywords     = "visicalc, software development, apple ][, ",
  year         = 2003,
  month        = apr,
  location     = "http://rmf.vc/ImplementingVisiCalcV1"
}

@Misc{ifsi,
  author       = "Linas Vepstas",
  title        = "Is Free Software Inevitable?",
  year         = 2001,
  month        = feb # "-" # jul,
  keywords     = "free trade, free software, altruistic behavior, corporations,
    indirect investment, monopoly",
  location     = "https://www.linas.org/theory/freetrade.html"
}

@Misc{casp,
  author       = "Christian Tismer",
  title        = "Continuations and Stackless Python",
  howpublished = "web",
  keywords     = "continuations, generators, python",
  location     = "http://www.stackless.com/spcpaper.htm"
}

@Misc{coip,
  author       = "Jason Tackaberry",
  title        = "{CORBA} Objects in {P}ython",
  howpublished = "web",
  year         = 2000,
  month        = apr,
  keywords     = "distributed objects, corba, gnome, orb, idl",
  location     = "https://projects-old.gnome.org/ORBit2/orbit-python.pdf"
}

@Misc{abdsgts11,
  author       = "Dave Winer",
  title        = "{A} Busy Developer's Guide to {SOAP} 1.1",
  howpublished = "WWW",
  year         = 2001,
  month        = "2 " # apr,
  keywords     = "soap, xml",
  location     = "scripting.com/davenet/2001/04/04/aBusyDevelopersGuideToSoap.html"
}

@Misc{hmre,
  author       = "James Marshall",
  title        = "{HTTP} Made Really Easy",
  howpublished = "WWW",
  year         = 1997,
  month        = aug,
  keywords     = "transactions, head, post, proxies, 1.1, clients, services",
  location     = "https://www.jmarshall.com/easy/http/"
}

@Misc{aamtkspsitsosr,
  title        = "Analysis as Model: {T}homas {K}uhn's Paradigm Shift in the Structure of Scientific Revolutions",
  howpublished = "WWW",
  keywords     = "kuhn, philosophy of science",
  location     = "http://webpages.shepherd.edu/maustin/kuhn/kuhnpaper.htm"
}

@Misc{mnhiw,
  title        = "Mojo Nation --- How It Works",
  howpublished = "WWW",
  keywords     = "peer-to-peer networks, reputation systems, payment systems",
  location     = "http://archive.li/YxpAA"
}

@Misc{siema,
  author       = "Mitch Altman",
  title        = "Soldering is Easy",
  howpublished = "WWW",
  keywords     = "soldering",
  location     = "https://mightyohm.com/files/soldercomic/FullSolderComic_EN.pdf"
}

@Misc{suassfur,
  author       = "Ladd Angelius",
  title        = "Set Up a Simple Syndication Feed Using {RSS}",
  howpublished = "WWW",
  keywords     = "rss, distribution, xml",
  location     = "http://www.devx.com/xml/Article/10790"
}

@Misc{rjldb,
  author       = "Dmitry Baranovskiy",
  title        = "Raphael JavaScript Library",
  howpublished = "Web site",
  keywords     = "graphics",
  location     = "http://dmitrybaranovskiy.github.io/raphael/"
}

@Misc{flapjaxtutorial,
  title        = "Flapjax Tutorial",
  howpublished = "Web site",
  year         = 2014,
  keywords     = "javascript, web programming, reactive programming",
  location     = "http://www.flapjax-lang.org/tutorial/"
}

@Misc{piccolo,
  title        = "Piccolo",
  howpublished = "Web site",
  keywords     = "graphics, zooming interface",
  location     = "http://piccolo2d.org/index.html"
}

@Misc{vvym,
  author       = "Uwe Dreschsel",
  title        = "{VYM} --- View Your Mind",
  howpublished = "Web site",
  year         = 2012,
  month        = "13 " # jun,
  keywords     = "mind mapping",
  location     = "https://sourceforge.net/p/vym/wiki/"
}

@Misc{mgiw,
  author       = "Oliver Steele",
  title        = "My {G}it Workflow",
  howpublished = "Web",
  year         = 2008,
  month        = may,
  keywords     = "git, index, workflow",
  location     = "https://blog.osteele.com/2008/05/my-git-workflow/"
}

@Misc{cpos,
  author       = "Oliver Steele",
  title        = "Commit Policies",
  howpublished = "Web",
  year         = 2008,
  month        = may,
  keywords     = "git, committing",
  location     = "https://blog.osteele.com/2008/05/commit-policies/"
}

@Misc{maplusrs,
  author       = "Derek Sivers",
  title        = "Memorizing a Programming Language Using Spaced Repetition Software",
  howpublished = "Web",
  year         = 2013,
  month        = "6 " # jan,
  keywords     = "spaced repetition, learning, remembering",
  location     = "https://sivers.org/srs"
}

@Misc{jmjk,
  author       = "Jack Kinsella",
  title        = "Janki Method",
  howpublished = "Web",
  year         = 2011,
  month        = "5 " # dec,
  keywords     = "learning, memorization",
  location     = "https://www.jackkinsella.ie/articles/janki-method"
}

@Misc{gtawr2bsas,
  author       = "Steven Ness",
  title        = "Git Tips and Workflows, Round 2: Basics, Stashes and Submodules",
  howpublished = "Web",
  year         = 2013,
  month        = "15 " # jan,
  keywords     = "git, workflow, projects, ",
  location     = "http://sness.blogspot.com/2013/01/git-tips-and-workflows-round-2-basics.html"
}

@Misc{hiugi,
  author       = "Glenn Stovall",
  title        = "How {I} Use {G}it",
  howpublished = "Web",
  year         = 2013,
  month        = "15 " # mar,
  keywords     = "git, repository, bitbucket, shipping"
}

@Misc{bacwswh,
  title        = "Building a Concurrent {W}eb Scraper With {H}askell",
  howpublished = "Web",
  year         = 2012,
  month        = "16 " # apr,
  keywords     = "haskell, web scraping, concurrency",
  location     = "http://adit.io/posts/2012-03-10-building_a_concurrent_web_scraper_with_haskell.html"
}

@Misc{gtctawftt,
  title        = "Git: Twelve Curated Tips and Workflows from the Trenches",
  howpublished = "Web",
  year         = 2012,
  month        = "5 " # dec,
  keywords     = "git, diff, proxies",
  location     = "http://durdn.com/blog/2012/12/05/git-12-curated-git-tips-and-workflows/"
}

@Misc{mgh,
  author       = "Mark Dominus",
  OPTtitle     = "My {G}it Habits",
  howpublished = "Web",
  year         = 2012,
  month        = "15 " # mar,
  keywords     = "git, branches",
  location     = "https://blog.plover.com/prog/git-habits.html"
}

@Misc{ddocawc,
  author       = "Douglas~C. Schmidt",
  title        = "Developing Distributed Object Computing Applications With {CORBA}",
  howpublished = "Web",
  keywords     = "distributed software",
  location     = "https://www.cse.wustl.edu/~schmidt/PDF/corba4.pdf"
}

@Misc{aitqcaqc,
  author       = "Rob Pike",
  title        = "An Introduction to Quantum Computation and Quantum Computing",
  howpublished = "Invited {\sc Usenix} talk",
  year         = 2000,
  month        = "23 " # jun,
  keywords     = "quantum computing, quantum communication",
  location     = "https://www.usenix.org/events/usenix2000/invitedtalks/pike_html/"
}

@Misc{acccpcatfn,
  author       = "R.~J. Keevers",
  title        = "Area Codes, Country Codes, Penal Codes and Toll Free Numbers",
  howpublished = "PDF",
  keywords     = "number plans, standardization"
}

@Misc{fsngrp,
  author       = "Ian Clarke",
  title        = "Freenet's Next Generation Routing Protocol",
  howpublished = "Web",
  year         = 2003,
  month        = "20 " # jul,
  keywords     = "routing, peer-to-peer networking",
  location     = "http://freenetproject.org/index.php?page=ngrouting"
}

@Misc{osgeraecic,
  author       = "Benjamin Sims",
  title        = "On Shifting Ground:  Earthquake Retrofit and Engineering Culture in {C}alifornia",
  keywords     = "construction risk, caltrans, civil engineers, design
    formalism, practices",
  location     = "http://polaris.gseis.ucla.edu/pagre/rre.html"
}

@Misc{aism,
  author       = "David Poole and Alan Mackworth",
  title        = "Artificial Intelligence Solutions Manual",
  year         = 2009,
  month        = "9 " # nov,
  keywords     = "all the answers"
}

@Misc{lsemd,
  author       = "Mike Dahlin",
  title        = "{LESS} Software Engineering",
  year         = 2000,
  month        = "15 " # may,
  keywords     = "coding standards"
}

@Misc{byobcp,
  author       = "David Palmer",
  title        = "Building Your Own Basic {CGI} Program",
  howpublished = "Web page",
  keywords     = "cgi, scripting",
  location     = "http://perl.find-info.ru/perl/007/index.htm"
}

@Misc{stotuciaiciahe,
  author       = "Craig Calhoun",
  title        = "Structural Transformation of the University:  Contradictory Ideals and Institutional Compromises in {A}merican Higher Education",
  howpublished = "Presentation, Thesis 11 Center for Critical Theory, La Trobe
    University", 
  year         = "2002",
  month        = "17" # jul
}

@Misc{dpiawstpso,
  author       = "Joacrim Schrod",
  title        = "Documenting Programs in a {WEB} style:  The {\tt progltx} style option",
  year         = 1991,
  month        = "25 " # aug,
  keywords     = "documentation, web, literate programming, latex, style file"
}

@Misc{itiftldn,
  author       = "Andrew~M. Odlyzko",
  title        = "Internet {TV}: Implications for the Long Distance Network",
  year         = 2003,
  keywords     = "long distance network, internet tv, internet backbone, new
    technology, new mode , traditional broadcast tv, main reason, vinyl record,
    broadcast tv signal, traditional tv, improved variant, consumer market,
    natural inertia, cell phone , old medium, last mile, little impact", 
  abstract     = "The migration of traditional TV to the Internet is likely to
    have little impact on the long distance network.  The main reason is that
    consumers still take on the order of a decade to embrace new technologies
    (such as cell phones) or even improved variants of old media (as with CDs
    replacing vinyl records).  Hence we should not expect traditional broadcast
    TV to change substantially or to migrate to new modes of distribution any
    time soon.  Yet within much less than a decade, progress in photonics will
    produce an increase in the capacity of Internet backbones far beyond that
    required to carry all the broadcast TV signals.  There will continue to be
    bottlenecks in the â€last mileâ€ that will limit the migration of TV to the
    Internet (and this will reinforce the natural inertia of the consumer
    market).  However, the backbones are unlikely to be an impediment.  The
    Internet is likely to have a much larger impact on TV than TV will have on
    Internet backbones.  There is vastly more storage than transmission
    capacity, and this is likely to continue.  Together with the requirements
    of mobility, and the need to satisfy human desires for convenience and
    instant gratiï¬cation, this is likely to induce a migration towards a
    store-and-replay model, away from the current real-time streaming model of
    the broadcast world.  Further, HDTV may ï¬nally get a chance to come into
    widespread use.  The ï¬‚exibility of the Internet is its biggest advantage,
    and will allow for continued experimentation with novel services.", 
  location     = "http://www.dtc.umn.edu/~odlyzko/doc/tv.internet.pdf"
}

@Misc{algtdp,
  author       = "Joshua Kerievsky",
  title        = "A Learning Guide to Design Patterns",
  howpublished = "web page",
  year         = 2000,
  month        = feb,
  keywords     = "study groups, software patterns",
  abstract     = "Every now and then I ask people if they are familiar with the
    book, Design Patterns: Elements of Reusable Object-Oriented Software.  On
    such occassions, I'm often surprised to hear someone respond, Yes, I've
    read it. Having spent close to three years running a study group devoted to
    understanding the subtleties, combinations and variations of the patterns
    in this book and others, I am often compelled to ask these individuals if
    they actually believe that the book can be read rather than studied? This
    learning guide has been written for those who want to learn and use design
    patterns, rather than just read about them.", 
  location     = "https://www.industriallogic.com/papers/learning.html"
}

@Misc{wabmfof,
  author       = "John Lindal",
  OPTtitle     = "Why a Bazaar may Fizzle or Fail",
  year         = 1990,
  keywords     = "cathedral, bazaar"
}

@Misc{aatcs,
  author       = "Charles Staats III",
  title        = "An Asymptote Tutorial",
  year         = 2014,
  month        = "17 " # may,
  keywords     = "asymptote",
  location     = "https://math.uchicago.edu/~cstaats/Charles_Staats_III/Notes_and_papers_files/asymptote_tutorial.pdf"
}

@MastersThesis{cchioawan,
  author       = "Nitin~K. Ganatra",
  title        = "Census: Collecting Host Information on a Wide Area Network",
  school       = "Computer and Information Science, University of California, Santa Cruz",
  year         = 1992,
  address      = scca,
  month        = jun,
  keywords     = "internet, internet hosts, dns",
  abstract     = "The exponential growth of the Internet presents new problems
    in recording global network information.  The Domain Name System provided a
    way to cope with the enormous growth rates by distributing network
    information among all domains.  This distribution accomplished its goal of
    eliminating the need for a central database, but at the same time
    eliminated the source of centralized network information.  Such information
    is useful in applications dealing with resource discovery on the Internet
    and in studies of the network topography.  Census is a program to traverse
    the Internet domain tree and collect information by recursively querying
    name servers for host information and other sub-domains.  During the
    development of the Census program (about 6 months), the host population of
    the Internet has grown in size by 30 percent, and has showed no sign of
    abating.", 
  location     = "https://www.researchgate.net/publication/2651480_Census_Collecting_Host_Information_on_a_Wide_Area_Network"
}
