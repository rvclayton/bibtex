.so bibtex.header
		  
@string{ir95  = " (ACM SIGPLAN Workshop on Intermediate Representations, IR '95)"}
@string{idl94 = " (" # pot # "Workshop on Interface Definition Languages, IDL '94)"}
@string{rs77  = " (" # pot # "ACM Conference on Language Design For Reliable Software)"}		  
		  
@Book{atamfm,
  author       = "Maureen~F. McHugh",
  title        = "After the Apocalypse",
  publisher    = "Small Beer Press",
  year         = 2011,
  address      = "Easthampton, MA",
  keywords     = "collapse, survival",
  location     = "PS 3563.C3687 A69"
}

@Book{scnn,
  author       = "Carl~N. Nightengale",
  title        = "Segregation",
  publisher    = ucp,
  year         = 2012,
  address      = chil,
  keywords     = "segregation, racial politics, city planning, colonialism",
  location     = "HD 7288.75.N54"
}

@Book{lfsdk,
  author       = "Dori Katz",
  title        = "Looking For Strangers",
  publisher    = ucp,
  year         = 2013,
  address      = chil,
  keywords     = "rememberance, holocast, world war ii, resistance",
  location     = "D 804.48.K314"
}

@Book{caimrg,
  author       = "Michael~R. Garey and David~S. Johnson",
  title        = "Computers and Intractability",
  publisher    = "W.~H. Freeman",
  year         = 1979,
  address      = nyny,
  keywords     = "computers, complexity, intractability, np-completeness,
    np-hardness, complexity proofs",
  location     = "QA 76.6 G35"
}

@Book{dja,
  author       = "John Altman",
  title        = "Deception",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2003,
  address      = nyny,
  keywords     = "mcguffins, children at play",
  location     = "PS 3601.L85 D43"
}

@Book{otbhlc,
  author       = "Hillary~L. Chute",
  title        = "Outside the Box",
  publisher    = ucp,
  year         = 2014,		  
  address      = chil,
  keywords     = "scott mccloud, charles burns, aline kominsky-crumb, daniel
    clowes, phoebe gloeckner, joe sacco, alison bechdel, francoise mouly, lynda
    barry, adrian tomine, art spiegelman, chris ware, comix, art",
  location     = "NC 1305 C48"
}

@Book{dezs,
  author       = "Zo{\" e} Sharp",
  title        = "Die Easy",
  publisher    = "Pegasus Crime",
  year         = 2013,
  address      = nyny,
  keywords     = "murrdaar, the long cold hand of revenge",
  location     = ""
}

@Book{tdjtk,
  author       = "James~T. Kloppenberg",
  title        = "Towards Democracy",
  publisher    = oup,
  year         = 2016,
  address      = nyny,
  keywords     = "democracy, enlightenment, america, french revolution,
    england, reformation",
  location     = "JC 421 K526"
}

@Book{tfob,
  author       = "Tzvetan Todorov",
  title        = "The Fear of Barbarians",
  publisher    = ucp,
  year         = 2010,
  address      = chil,
  keywords     = "civilization, islam, politics, europe, democracy, religion,
    manichaeism, world politics",
  location     = "CB 251.T5913"
}

@Book{ahateotw,
  author       = "Erin Claiborne",
  title        = "{A} Hero at the End of the World",
  publisher    = "Big Bang Press",
  year         = 2014,
  address      = "Brooklyn, N.Y.",
  keywords     = "magic, london",
  location     = "isbn-13 9780990484400"
}

@Book{tieb,
  author       = "Elif Batuman",
  title        = "The Idiot",
  publisher    = "Penguin",
  year         = 2017,
  address      = nyny,
  keywords     = "education, love, language, philosophy",
  location     = "PS 3602.A9237 I45"
}

@Book{ttjg,
  author       = "James Gleick",
  title        = "Time Travel",
  publisher    = "Pantheon",
  year         = 2016,
  address      = nyny,
  keywords     = "time travel, literature, the artistic imagination, space and
    time, time", 
  location     = "QC 173.59.S65 G54"
}

@Book{litb,
  author       = "George Saunders",
  title        = "Lincoln in the Bardo",
  publisher    = "Random House",
  year         = 2017,
  address      = nyny,
  keywords     = "the dead and how they got there, unfinished business",
  location     = "PS 3569.A7897"
}

@Book{litsus,
  author       = "Sarah Vowell",
  title        = "Lafayette in the Somewhat United States",
  publisher    = "Riverhead Books",
  year         = 2015,
  address      = nyny,
  keywords     = "revolutionary war, diplomacy, france, lafayette, washington",
  location     = "E 207.L2 V69"
}

@Book{8zal,
  author       = "Alan~R. Miller",
  title        = "8080/{Z80} Assembly Language",
  publisher    = "John Wiley \& Sons",
  year         = 1981,
  address      = nyny,
  keywords     = "number bases, logical operations, stacks, i/o, macros, system
     monitor, zilog z-80 processors, intel 8080 processors, number-base
     conversion, paper tape, magnetic tape, cp/m",
  location     = "QA 76.8.I28 M53"
}

@Book{clr2017,
  author       = "Lucinda Rosenfeld",
  title        = "Class",
  publisher    = "Little, Brown",
  year         = 2017,
  address      = nyny,
  month        = "January",
  keywords     = "schooling, social class, income stratification, family",
  location     = "813.54"
}

@Book{fuddb,
  author       = "Danielle DiMartino Booth",
  title        = "Fed Up",
  publisher    = "Portfolio",
  year         = 2017,
  address      = nyny,
  keywords     = "economics, federal reserve banks, alan greenspan, ben
    bernake, janet yellin, banks, banking, monetary policy, richard fisher,
    dallas fed",
  location     = "HG 2563.B586"
}

@Book{tifjk,
  author       = "Jason Kekulak",
  title        = "The Impossible Fortress",
  publisher    = "Simon \& Schuster",
  year         = 2017,
  address      = nyny,
  keywords     = "game programming, computer games, bad decision making, geeks,
    1980s, boys and girls together, C-64", 
  location     = "PS 3618.E57275 I47"
}

@Book{tbtb,
  author       = "John McWhorter",
  title        = "Talking Back Talking Black",
  publisher    = "Bellevue Literary Press",
  year         = 2017,
  address      = nyny,
  keywords     = "aave, dialect",
  location     = "978 1 942658 20 7"
}

@Book{ttplss,
  author       = "Steven Slade",
  title        = "The T Programming Language",
  publisher    = ph,
  year         = 1987,
  address      = ecnj,
  keywords     = "lisp, symbolic problems"
}

@Book{ahwiab,
  author       = "David Grossman",
  title        = "{A} Horse Walks into a Bar",
  publisher    = "Knopf",
  year         = 2017,
  address      = nyny,
  keywords     = "rememberance, stand-up comedy",
  location     = "PJ 5054.G728 S8813"
}

@Book{htbas,
  author       = "Massimo Pigliucci",
  title        = "How to Be a Stoic",
  publisher    = "Basic Books",
  year         = 2017,
  address      = nyny,
  keywords     = "stoicism, philosophy",
  location     = "B 528.P53"
}

@Book{rar11,
  author       = "Gabriel Kolko",
  title        = "Railroads and Regulation 1877--1916",
  publisher    = "W.~W. Norton \& Co.",
  year         = 1970,
  address      = nyny,
  keywords     = "railroads, regulation, federalism, economic theory",
  location     = "KF 2289.K6"
}

@Book{mwwhm,
  author       = "Haruki Murakami",
  title        = "Men Without Woman",
  publisher    = "Knopf",
  year         = 2017,
  address      = nyny,
  keywords     = "friendship, men and women, story tellin'",
  location     = "PL 856.U673 A2"
}

@Book{crm,
  author       = "Barbara Liskov and Russell Atkinson and Toby Bloom and Eliot
  Moss and J.~Craig Shaffert and Robert Scheifler and Alan Snyder",
  title        = "{CLU} Reference Manual",
  publisher    = "Springer",
  year         = 1981,
  volume       = 114,
  series       = lncs,
  address      = bege,
  keywords     = "programming languages, modules, data types, objects",
  location     = "QA 76.73.C25 C58"
}

@Book{grs2017,
  author       = "R{\" u}diger Safranski",
  title        = "Goethe",
  publisher    = "Liveright",
  year         = 2017,
  address      = nyny,
  keywords     = "goethe, german history, art, literature",
  location     = "PT 2051.S2413"
}

@Book{fhamec,
  author       = "Alan Moore and Eddie Campbell",
  title        = "From Hell",
  publisher    = "Top Shelf Productions",
  year         = 2006,
  address      = "Marietta, Georgia",
  keywords     = "crime, victorian london",
  location     = "PN 6728.F76 M66"
}

@Book{lscdf,
  author       = "Daniel Farber",
  title        = "Lincoln's Constitution",
  publisher    = ucp,
  year         = 2003,
  address      = chil,
  keywords     = "lincoln, the us constitution, the civil war, session, law",
  location     = "E 457.2 F216"
}

@Book{acitaoe11,
  author       = "Robert Green McCloskey",
  title        = "American Conservatism In the Age of Enterprise 1865--1910",
  publisher    = "Harper Torchbooks",
  year         = 1964,
  address      = nyny,
  keywords     = "economics, william graham sumner, stephen j. field, andrew
    carnegie, democracy, politics", 
  location     = "JA 84.U5 M35"
}

@Book{mmc2016,
  author       = "Michael Chabon",
  title        = "Moonglow",
  publisher    = "Harper",
  year         = 2016,
  address      = nyny,
  keywords     = "space flight, history, biography",
  location     = "PS 3553.H15 M66"
}

@Book{bamu,
  author       = "Howard~S. Baker",
  title        = "Becoming a Marihauna User",
  publisher    = ucp,
  year         = 2015,
  address      = chil,
  keywords     = "drug use, marijuana, drug psychology, drug sociology",
  location     = "HV 5822.M3 B395"
}

@Book{tsowps,
  author       = "Pamela Sargent",
  title        = "The Shore of Women",
  publisher    = "Crown",
  year         = 1986,
  address      = nyny,
  keywords     = "recovery, religion, boys and girls together",
  location     = "PS 3569.A6887 S47"
}

@Book{jatsr,
  author       = "Helena Kelly",
  title        = "Jane Austen, the Secret Radical",
  publisher    = "Knopf",
  year         = 2017,
  address      = nyny,
  keywords     = "austen, 18th/19th century life, literature, slavery,
    enclosure, entailment, primogeniture",
  location     = "PR 4038.P6 K38"
}

@Book{tfitaoos,
  author       = "Ross Thomas",
  title        = "The Fools in Town are on Our Side",
  publisher    = "Morrow",
  year         = 1971,
  address      = nyny,
  keywords     = "skullduggery, elections, texas, corruption, teamwork",
  location     = "PS 3570.H58"
}

@Book{tbgb,
  author       = "Oliver Bleeck",
  title        = "The Brass Go-Between",
  publisher    = "Harper \& Row",
  year         = 1983,
  address      = nyny,
  keywords     = "trades, dirty dealing",
  location     = "PS 3570.H58 B7"
}

@Book{tlhck,
  author       = "Herbert~C. Kraft",
  title        = "The Lenape",
  publisher    = "New Jersey Historical Society",
  year         = 1988,
  address      = "Newark, N.J.",
  keywords     = "lenape, exploration",
  location     = "F 131.N62"
}

@Book{tfwtbl,
  author       = "Jarett Kobek",
  title        = "The Future Won't Be Long",
  publisher    = "Viking",
  year         = 2017,
  address      = nyny,
  keywords     = "the big city, drug abuse, the 80s, the 90s, artists",
  location     = "PS 3611.O3 F88"
}

@Book{tpooi,
  author       = "Simon Reid-Henry",
  title        = "The Political Origins of Inequality",
  publisher    = ucp,
  year         = 2015,
  address      = chil,
  keywords     = "inequality, development politics, poverty, wealth",
  location     = "HM 821.R45"
}

@Book{mbfef,
  author       = "Elena Ferrante",
  title        = "My Brillant Friend",
  publisher    = "Europa",
  year         = 2012,
  address      = nyny,
  keywords     = "naples",
  location     = "PQ 4866.E6345 A8113"
}

@Book{jyc,
  author       = "Yahtzee Croshaw",
  title        = "Jam",
  publisher    = "Dark Horse Books",
  year         = 2012,
  address      = "Milwaukie, Oregon",
  keywords     = "the apocalypse, skullduggery",
  location     = "PR 9619.4.C735 J36"
}

@Book{qtm,
  author       = "Stephen Jay Gould",
  title        = "Questioning the Millennium",
  publisher    = "Harmony Books",
  year         = 1997,
  address      = nyny,
  keywords     = "leap years, calendar, millennium",
  location     = "CB 161.G67"
}

@Book{cays,
  author       = "Ross Thomas",
  title        = "Cast a Yellow Shadow",
  publisher    = "William Morrow \& Co.",
  year         = 1967,
  address      = nyny,
  keywords     = "assassination, skullduggery, race relations",
  location     = "PS 3570.H58"
}

@Book{mldfm,
  author       = "Douglas~F. MacKenzie",
  title        = "Mango Lassie",
  publisher    = "Loch Lomond Books",
  year         = 2011,
  address      = "Washington, D.~C.",
  keywords     = "the 60s, georgetown, drugs, rampant sexism",
  location     = "978 0 615 52266 1"
}

@Book{rgkm,
  author       = "Kate Moore",
  title        = "Radium Girls",
  publisher    = "Sourcebooks",
  year         = 2017,
  address      = "Naperville, IL",
  keywords     = "watch dial painters, industrial injuries, radium poisoning",
  location     = "HD 6067.2.U6 M66"
}

@Book{lfsad,
  author       = "Antonio Damasio",
  title        = "Looking for Spinoza",
  publisher    = "Harcourt",
  year         = 2003,
  address      = "Orlando, Florida",
  keywords     = "spinoza, emotions, feelings, mind-body, neurophyschology",
  location     = "QP 401.D203"
}

@Book{fvs,
  author       = "C.~H.~O'D. Alexander",
  title        = "Fischer v. Spassky",
  publisher    = "Vintage",
  year         = 1972,
  address      = nyny,
  keywords     = "chess, bobby fischer, boris spassky, world championship",
  location     = "GV 1455.A47"
}

@Book{jcp,
  author       = "Cherie Priest",
  title        = "Jacaranda",
  publisher    = "Subterranean Press",
  year         = 2015,
  address      = "Burton, MI",
  keywords     = "eeeevil, guilt, broken promises",
  location     = "978 1 59606 685 4"
}

@Book{wwrbp,
  author       = "Richard~B. Primack",
  title        = "Walden Warming",
  publisher    = ucp,
  year         = 2014,
  address      = chil,
  keywords     = "global warming, walden pond, climate change, thoreau,
    ecology, record keeping",
  location     = "QH 105.M4 P75"
}

@Book{tfsssjg,
  author       = "Stephen Jay Gould",
  title        = "The Flamingo's Smile",
  publisher    = "W.~W. Norton",
  year         = 1987,
  address      = nyny,
  keywords     = "evolution, scientific practice, taxonomies, trends",
  location     = "QH 81 G673"
}

@Book{vfms,
  author       = "Michael Swanwick",
  title        = "Vacuum Flowers",
  publisher    = "Arbor House",
  year         = 1987,
  address      = nyny,
  keywords     = "personality, individuality, collectivism",
  location     = "PS 3569.W28 V3"
}

@Book{wsw,
  author       = "Kate Auspitz",
  title        = "Wallis's War",
  publisher    = ucp,
  year         = 2015,
  address      = chil,
  keywords     = "love, wwii, duchess of windsor, espionage",
  location     = "PS 3601.U853 W35"
}

@Book{4321,
  author       = "Paul Auster",
  title        = "4 3 2 1",
  publisher    = "Henry Holt",
  year         = 2017,
  address      = nyny,
  keywords     = "alternate time lines, coming of age",
  location     = "PS 3551.U77 A615"
}

@Book{ggdc,
  author       = "Giovanni {Della Casa}",
  title        = "Galateo",
  publisher    = ucp,
  year         = 2013,
  address      = chil,
  keywords     = "etiquette, medieval life",
  location     = "BJ 1921.D4413"
}

@InProceedings{rdlrr,
  author       = "Reia, Rafael and Menezes Leit{\~ a}o, Ant{\' o}nio",
  title        = "Refactoring Dynamic Languages",
  booktitle    = pot # "9th European Lisp Symposium",
  year         = 2016,
  address      = "Krak{\' o}w, Poland",
  month        = "9--10 " # may,
  keywords     = "ides, refactoring tools, novice programming, scheme, racket",
  abstract     = "Typically, beginner programmers do not master the style rules
    of the programming language they are using and, frequently, do not have yet
    the logical agility to avoid writing redundant code.  As a result, although
    their programs might be correct, they can also be improved and it is
    important for the programmer to learn about the improvements that, without
    changing the meaning of the program, simplify it or transform it to follow
    the style rules of the language.  These kinds of transformations are the
    realm of refactoring tools.  However, these tools are typically associated
    with sophisticated integrated development environments (IDEs) that are
    excessively complex for beginners.  In this paper, we present a refactoring
    tool designed for beginner programmers, which we made available in
    DrRacket, a simple and pedagogical IDE.  Our tool provides several
    refactoring operations for the typical mistakes made by beginners and is
    intended to be used as part of their learning process.", 
  location     = "978-2-9557474-0-7", 
  location     = "https://www.youtube.com/watch?v=Sx-6WpiobIU"
}

@InProceedings{dacfqc,
  author       = "Dongol, Brijesh and Hierons, Robert~M.",
  title        = "Decidability and Complexity for Quiescent Consistency",
  booktitle    = pot # "31st Annual ACM/IEEE Symposium on Logic in Computer Science (LICS '16)",
  year         = 2016,
  pages        = "116--125",
  address      = nyny,
  month        = "5--8 " # jul,
  keywords     = "quiescent consistency, concurrent objects, decidability,
    finite automata, traces, correctness, membership",
  abstract     = "Quiescent consistency is a notion of correctness for a 
    concurrent object that gives meaning to the object's behaviours in
    quiescent states, i.e., states in which none of the object's operations are
    being executed.  The condition enables greater flexibility in object design
    by allowing more behaviours to be admitted, which in turn allows the
    algorithms implementing quiescent consistent objects to be more efficient
    (when executed in a multithreaded environment).  Quiescent consistency of
    an implementation object is defined in terms of a corresponding abstract
    specification.  This gives rise to two important verification questions:
    membership (checking whether a behaviour of the implementation is allowed
    by the specification) and correctness (checking whether all behaviours of
    the implementation are allowed by the specification).  In this paper, we
    consider the membership and correctness conditions for quiescent
    consistency, as well as a restricted form that assumes an upper limit on
    the number of events between two quiescent states.  We show that the
    membership problem for unrestricted quiescent consistency is NP-complete
    and that the correctness problem is decidable, coNEXPTIME-hard, and in
    EXPSPACE.  For the restricted form, we show that membership is in PTIME,
    while correctness is PSPACE-complete.", 
  location     = "https://doi.org/10.1145/2933575.2933576"
}

		  
@InProceedings{svaet,
  author       = "Javier Castillo and Pablo Heurta and Jos{\' e} Ignacio Mart{\' \i}nez",
  title        = "An Open-Source Tool for {SystemC} to {Verilog} Automatic Translation",
  booktitle    = "",
  year         = 2007,
  OPTeditor    = "",
  pages        = "347--354",
  keywords     = "",
  abstract     = "As the complexity of electronic systems increases, new ways
    for describing these systems are proposed.  One actual trend involves the
    use of system level languages that allows the description of the whole
    system in a higher abstraction level.  This type of methodology helps a
    designer to obtain an appropriate Hw-Sw partition, where the Sw is compiled
    to the target platform and the Hw is refined to bring it down to a lower
    level of abstraction in order to be synthesized.  This last step usually
    requires the use of a translation tool that from a description of the
    system in a system level modeling language, converts it to an equivalent
    one in a standard Hardware Description Language, usually Verilog or VHDL.
    This works presents a tool that from a SystemC RTL description generates
    its equivalent Verilog code ready to be synthesized by any standard Verilog
    Synthesis Tool.", 
  OPTlocation  = ""
}

@InProceedings{imsdimaictdtlsanlpc2,
  author       = "Lillian Lee",
  title        = "``{I}'m sorry Dave, {I}'m afraid {I} can't do that'' : Linguistics, Statistics, and Natural Language Processing Circa 2001",
  booktitle    = "Computer Science: Reflections on the Field",
  year         = 2004,
  pages        = "111-118",
  publisher    = "National Academies Press",
  address      = wadc,
  keywords     = "ambiguity, language analysis, empiricism",
  abstract     = {A brief, general-audience overview of the history of natural
    language processing, focusing on data-driven approaches.  Topics include
    Ambiguity and language analysis, Firth things first, A 'C' change, and The
    empiricists strike back.},
  location     = "http://www.cs.cornell.edu/home/llee/papers/cstb.pdf"
}

@InProceedings{aoic,
  author       = "Atkinson, Russell~R. and Liskov, Barbara~H. and Scheifler, Robert~W.",
  title        = "Aspects of Implementing {CLU}",
  booktitle    = pot # "1978 Annual Conference",
  year         = 1978,
  pages        = "123--129",
  address      = "Washington, D.~C.",
  month        = "4--6 " # dec,
  keywords     = "exception handling, parametric polymorphism, iterators,
    language implementation",
  abstract     = "Linguistic mechanisms used in CLU to support 1) structured
    exception handling, 2) iteration over abstract objects, and 3)
    parameterized abstractions are briefly reviewed, and methods of realizing
    these mechanisms are described.  The mechanisms discussed support features
    that are likely to be included in other programming languages, and the
    implementation methods should be applicable to a wide range of languages.",
  location     = "https://doi.org/10.1145/800127.804079"
}

@InProceedings{daare,
  author       = "Jean-Marc DeBaud and Bijith Moopen and Spencer Rugaber",
  title        = "Domain Analysis and Reverse Engineering",
  booktitle    = pot # "International Conference on Software Maintenance (ICSM '94)",
  year         = 1994,
  editor       = "Hausi~A. M{\" u}ller and Mari Georges",
  pages        = "326--335",
  month        = oct,
  keywords     = "domain engineering, reverse engineering, report writing,
    domain models, object-oriented frameworks",
  abstract     = "Current reverse engineering technology is typically based on
    program analysis methods such as parsing and data flow analysis.  As such,
    it is limited in what it can accomplish.  Knowledge of the application
    domain containing a program can help overcome this limit and aid the
    comprehension process.  The paper discusses the relationship of application
    domain analysis and reverse engineering.  Two case studies are presented.
    The first describes how domain knowledge, expressed as an object-oriented
    framework, can aid the reverse engineering process for a well-understood
    domain.  The second studies how reverse engineering can be used to build a
    domain model.  Issues raised by the confluence of domain analysis and
    reverse engineering are discussed, and implications on future work in the
    area are suggested" 
}

@Article{erisrp,
  author       = "McKenzie, Bruce~J. and Yeatman, Corey and de Vere, Lorraine",
  title        = "Error Repair in Shift-Reduce Parsers",
  journal      = toplas,
  year         = 1995,
  volume       = 17,
  number       = 4,
  pages        = "672--689",
  month        = jul,
  keywords     = "algorithms, languages, theory, bison, error recovery, least
    cost error recovery, shift-reduce parsers, yacc",
  abstract     = "Local error repair of strings during CFG parsing requires the
    insertion and deletion of symbols in the region of a syntax error to
    produce a string that is error free.  Rather than precalculating tables at
    parser generation time to assist in finding such repairs, this article
    shows how such repairs can be found during shift-reduce parsing by using
    the parsing tables themselves.  This results in a substantial space saving
    over methods that require precalculated tables.  Furthermore, the article
    shows how the method can be integrated with lookahead to avoid finding
    repairs that immediately result in further syntax errors.  The article
    presents the results of experiments on a version of the LALR(1)-based
    parser generator Bison to which the algorithm was added.", 
  location     = "https://doi.org/10.1145/210184.210193"
}

@Article{dmaahv,
  author       = "Veen, Arthur~H.",
  title        = "Dataflow Machine Architecture",
  journal      = surveys,
  year         = 1986,
  OPTvolume    = 18,
  number       = 4,
  pages        = "365--396",
  month        = dec,
  keywords     = "data-driven architectures, dataflow machines, data structure
    storage, parallel execution, dataflow graphs, iterative and recursive
    constructs, packet communication, code copying, tagged tokens, matching", 
  abstract     = "Dataflow machines are programmable computers of which the
    hardware is optimized for fine-grain data-driven parallel computation.  The
    principles and complications of data-driven execution are explained, as
    well as the advantages and costs of fine-grain parallelism.  A general
    model for a dataflow machine is presented and the major design options are
    discussed.  Most dataflow machines described in the literature are surveyed
    on the basis of this model and its associated technology.  For
    general-purpose computing the most promising dataflow machines are those
    that employ packet-switching communication and support general recursion.
    Such a recursion mechanism requires an extremely fast mechanism to map a
    sparsely occupied virtual space to a physical space of realistic size.  No
    solution has yet proved fully satisfactory.  A working prototype of one
    processing element is described in detail.  On the basis of experience with
    this prototype, some of the objections raised against the dataflow approach
    are discussed.  It appears that the overhead due to fine-grain parallelism
    can be made acceptable by sophisticated compiling and employing special
    hardware for the storage of data structures.  Many computing-intensive
    programs show sufficient parallelism.  In fact, a major problem is to
    restrain parallelism when machine resources tend to get overloaded.
    Another issue that requires further investigation is the distribution of
    computation and data structures over the processing elements.", 
  location     = "https://doi.org/10.1145/27633.28055"
}

@Article{aafmusde,
  author       = "Ben-Shaul, Israel~Z. and Kaiser, Gail~E. and Heineman, George~T.",
  title        = "An Architecture for Multi-User Software Development Environments",
  journal      = cs,
  year         = 1993,
  volume       = 6,
  number       = 2,
  pages        = "65--113",
  month        = "Spring",
  keywords     = "synchronization, task management, data management,
    client-server architecture, transaction and lock management, marvel,
    process modeling, visualization, software development environment",
  abstract     = "We present an architecture for multi-user software
    development environments, covering general, process-centered and rule-based
    MUSDEs.  Our architecture is founded on componentization, with particular
    concern for the capability to replace the synchronization component--to
    allow experimentation with novel concurrency control mechanisms--with
    minimal effects on other components while still supporting integration.
    The architecture has been implemented for the MARVEL SDE, and we report our
    experience replacing and tailoring several parts of the synchronization
    component as part of Marvel", 
  location     = "https://www.usenix.org/publications/compsystems/1993/spr_benshaul.pdf"
}

@Article{asossmatcn,
  author       = "Ramamurthy, Bina and Melton, Austin",
  title        = "{A} Synthesis of Software Science Measures and the Cyclomatic Number",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1116--1121",
  month        = aug,
  keywords     = "control flow, cyclomatic number, software complexity,
    software complexity measure,   software complexity metric, software
    science, structured programs",
  abstract     = "A solution is obtained to the problem of defining a software
    measure or a family of measures which simultaneously detect those aspects
    of software complexity that are detected by the software science measures
    and the cyclomatic number.  The authors present a family of measures,
    called weighted measures that is built on the software science measures by
    adding weights to certain operators and operands; the size of the weights
    is determined by a theorem which relates nesting levels and the cyclomatic
    number.  Thus, by construction the weighted measures synthesize the
    software science measures and the cyclomatic number.  Further, by applying
    the weighted measures, the software science measures, and the cyclomatic
    number to sample programs, it is shown that the weighted measures also
    synthesize in practice the software science measures and the cyclomatic
    number.", 
  location     = "https://doi.org/10.1109/32.7622"
}

@Article{apatss,
  author       = "Freitag, Burkhard and Margaria, Tiziana and Steffen, Bernhard",
  title        = "{A} Pragmatic Approach to Software Synthesis",
  journal      = sigplan # idl94,
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "22--34",
  month        = aug,
  keywords     = "interface definition languages, interface constraints,
    modules, parameter configuration",
  abstract     = "We present a practice oriented tool for software synthesis
    that supports the interface-correct configuration of complex systems from a
    library of reusable software components.  Besides simply checking the
    interface-correctness of a link by means of type constraints, the tool is
    also designed to propose software components for solving a (loosely)
    specified problem within a certain context.  In particular, it identifies
    possible interfacing modules that in case of an interface-conflict may
    serve for the right conversion, transformation or parameter configuration.
    We illustrate our tool, which is based on the deductive database system
    LOLA, in three application specific settings.", 
  location     = "https://doi.org/10.1145/185084.185102"
}

@Article{biatmt,
  author       = "Kiselyov, Oleg and Shan, Chung-chieh and Friedman, Daniel~P. and Sabry, Amr",
  title        = "Backtracking, Interleaving, and Terminating Monad Tansformers",
  journal      = sigplan # " (" # pot # "Tenth ACM SIGPLAN International Conference on Functional Programming, ICFP '05)",
  year         = 2005,
  volume       = 40,
  number       = 9,
  pages        = "192--203",
  month        = sep,
  keywords     = "continuations, control delimiters, haskell, logic
    programming, prolog, streams, control strucures, backtracking computations,
    cuts, monads",
  abstract     = "We design and implement a library for adding backtracking
    computations to any Haskell monad.  Inspired by logic programming, our
    library provides, in addition to the operations required by the MonadPlus
    interface, constructs for fair disjunctions, fair conjunctions,
    conditionals, pruning, and an expressive top-level interface.  Implementing
    these additional constructs is easy in models of backtracking based on
    streams, but not known to be possible in continuation-based models.  We
    show that all these additional constructs can be generically and
    monadically realized using a single primitive msplit.  We present two
    implementations of the library: one using success and failure
    continuations; and the other using control operators for manipulating
    delimited continuations.", 
  location     = "https://doi.org/10.1145/1086365.1086390"
}

@Article{tapidpl,
  author       = "Atkinson, Malcolm~P. and Buneman, O.~Peter",
  title        = "Types and Persistance in Database Programming Languages",
  journal      = surveys,
  year         = 1987,
  volume       = 19,
  number       = 2,
  pages        = "105--170",
  month        = jun,
  keywords     = "conceptual languages, databases, data models, data types,
    embedded languages, integrated languages, object-oriented programming,
    persistence, persistent languages, polymorphism, programming languages,
    type inheritance",
  abstract     = "Traditionally, the interface between a programming language
    and a database has either been through a set of relatively low-level
    subroutine calls, or it has required some form of embedding of one language
    in another.  Recently, the necessity of integrating database and
    programming language techniques has received some long-overdue recognition.
    In response, a number of attempts have been made to construct programming
    languages with completely integrated database management systems.  These
    languages, which we term database programming languages, are the subject of
    this review.  The design of these languages is still in its infancy, and
    the purpose of writing this review is to identify the areas in which
    further research is required.  In particular, we focus on the problems of
    providing a uniform type system and mechanisms for data to persist.  Of
    particular importance in solving these problems are issues of polymorphism,
    type inheritance, object identity, and the choice of structures to
    represent sets of similar values.  Our conclusion is that there are areas
    of programming language research&mdash;modules, polymorphism, persistence,
    and inheritance&mdash;that must be developed and applied to achieve the
    goal of a useful and consistent database programming language.  Other
    research areas of equal importance, such as implementation, transaction
    handling, and concurrency, are not examined here in any detail.", 
  location     = "https://doi.org/10.1145/62070.45066"
}

@Article{acilfpbs,
  author       = "Russell, James~R. and Strom, Robert~E. and Yellin, Daniel~M.",
  title        = "{A} Checkable Interface Language for Pointer-Based Structures",
  journal      = sigplan # idl94,
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "59--73",
  month        = aug,
  keywords     = "constraints, interface specifications, dataflow analysis,
    lattices, idls",
  abstract     = "We present a technique for analysing structural constraints
    on data aggregates in high-level languages.  Our technique includes a
    formal constraint language and a dataflow algorithm for automatically
    checking equality constraints.  The constraint language is used to augment
    the type information on program interfaces.  For example, one can specify
    that a procedure must return aggregates A and B where each element in
    aggregate A points to some element in aggregate B, and that parameter C
    will have the properties of a rooted tree both on input and output.  Our
    dataflow algorithm tracks the constraints which must apply at each
    statement in order for the procedure to satisfy its interface, and detects
    invalid programs which fail to satisfy the constraints on their interfaces.
    We apply our technique to several examples.Our work is motivated by the
    requirements for expressive interface definition languages for distributed
    systems, and by the desire to mechanically check program modules against
    their interfaces.  Our analysis techniques also yield information which may
    enable compilers and stub generators to produce better implementations.", 
  location     = "https://doi.org/10.1145/185084.185105"
}

@Article{ptvaar,
  author       = "Waters, Richard~C.",
  title        = "Program Translation via Abstraction and Reimplementation",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1207--1228",
  month        = aug,
  keywords     = "artificial intelligence, compilation, program analysis,
    programmer's apprentice, program translation, program plans, abstraction",
  abstract     = "An abstraction-and-reimplementation paradigm is presented in
    which the source program is first analyzed in order to obtain a
    programming-language-independent abstract understanding of the computation
    performed by the program as a whole.  The program is then reimplemented in
    the target language based on this understanding.  The key to this approach
    is the abstract understanding obtained.  It allows the translator to
    benefit from an appreciation of the global features of the source program
    without being distracted by what are considered irrelevant details.
    Knowledge-based translation via abstraction and reimplementation is
    described as one of the goals of the Programmer's Apprentice project.  A
    translator which translates Cobol programs into Hibol (a very-high-level
    business data processing language) has been constructed.  A computer which
    generates extremely efficient PDP-11 object code for Pascal programs has
    been designed.", 
  location     = "https://doi.org/10.1109/32.7629"
}

@Article{ptovar,
  author       = "Smith, Geoffrey and Volpano, Denniso",
  title        = "Polymorphic Typing of Variables and References",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 3,
  pages        = "254--267",
  month        = may,
  keywords     = "languages, theory, verification, assignment, references,
    variables, type systems, weakly-typed variables",
  abstract     = "In this article we consider the polymorphic type checking of
    an imperative language.  Our language contains variables, first-class
    references (pointers), and first-class functions.  Variables, as in
    traditional imperative languages, are implicitly dereferenced, and their
    addresses (L-values) are not first-class values.  Variables are easier to
    type check than references and, in many cases, lead to more general
    polymorphic types.  We present a polymorphic type system for our language
    and prove that it is sound.  Programs that use variables sometimes require
    weak types, as in Tofte's type system for Standard ML, but such weak types
    arise far less frequently with variables than with references", 
  location     = "https://doi.org/10.1145/229542.229544",
  location     = "https://users.cs.fiu.edu/~smithg/papers/toplas96.pdf"
}

@Article{ttaoop,
  author       = "Scott Danforth and Chris Tomlinson",
  title        = "Type Theories and Object-Oriented Programming",
  journal      = surveys,
  year         = 1988,
  volume       = 20,
  number       = 1,
  edition      = "29--72",
  month        = mar,
  keywords     = "languages, theory, data abstraction, inheritance,
    object-oriented programming, polymorphism, type checking, type
    interference, abstract data types, subtyping", 
  abstract     = "Object-oriented programming is becoming a popular approach to
    the construction of complex software systems.  Benefits of object
    orientation include support for modular design, code sharing, and
    extensibility.  In order to make the most of these advantages, a type
    theory for objects and their interactions should be developed to aid
    checking and controlled derivation of programs and to support early binding
    of code bodies for efficiency.  As a step in this direction, this paper
    surveys a number of existing type theories and examines the manner and
    extent to which these theories are able to represent the ideas found in
    object-oriented programming.  Of primary interest are the models provided
    by type theories for abstract data types and inheritance, and the major
    portion of this paper is devoted to these topics.  Code fragments
    illustrative of the various approaches are provided and discussed.  The
    introduction provides an overview of object-oriented programming and types
    in programming languages; the summary provides a comparative evaluation of
    the reviewed typing systems, along with suggestions for future work.", 
  location     = "https://doi.org/10.1145/62058.62060"
}

@Article{asmftsacu,
  author       = "Scott, Michael~L. and Finkel, Raphael~A.",
  title        = "{A} Simple Mechanism for Type Security Across Compilation Units",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1238--1239",
  month        = aug,
  keywords     = "type checking, link-time checking, hash codes",
  abstract     = "A simple technique is described that detects structural-type
    clashes across compilation units with an arbitrarily high degree of
    confidence.  The type of each external object is described in canonical
    form.  A hash function compresses the description into a short code.  If
    the code is embedded in a symbol-table name, then consistency can be
    checked by an ordinary linker.  For distributed programs, run-time checking
    of message types can be performed with very little overhead.",
  location     = "https://doi.org/10.1109/32.7631"
}

@Article{didfds,
  author       = "Bochmann, Gregor",
  title        = "Delay-Independent Design for Distributed Systems",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 8,
  pages        = "1229--1237",
  month        = aug,
  keywords     = "distributed systems, regularity, distributed synchronization,
    module interconnections",
  abstract     = "Methods of limiting the impact of communication delays on the
    logical behavior of distributed systems are considered.  It is assumed that
    a distributed system is described in terms of a number of interconnected
    modules, and each module is described in terms of its possible states and
    the possible state transitions.  Transitions may be initiated spontaneously
    by a module and may give rise to output messages, which will be received,
    after some possible delay, by another module as an input.  Otherwise,
    transitions may be initiated by received input.  If the system has the
    property called regularity, its behavior is logically independent of the
    communication delays.  A simple condition for regularity is given.  This
    condition is the basis for the implementation of counter-based
    synchronization conditions in a distributed environment.  Weaker forms of
    regularity, which make abstraction of internal operations invisible from
    the point of view of an outside observer, are also considered.  The
    application of these concepts to the design of module interfaces involving
    'collisions' and to communication including timeouts is discussed in some
    detail with examples.", 
  location     = "https://doi.org/10.1109/32.7630"
}

@Article{tcbliittofp,
  author       = "Sands, David",
  title        = "Total Correctness by Local Improvement in the Transformation of Functional Programs",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 2,
  pages        = "175--234",
  month        = mar,
  keywords     = "correctness, improvement, operational equivalence, program
    transformation, fold-unfold",
  abstract     = "The goal of program transformation is to improve efficiency
    while preserving meaning.  One of the best-known transformation techniques
    is Burstall and Darlington's unfold-fold method.  Unfortunately the
    unfold-fold method itself guarantees neither improvement in efficiency nor
    total correctness.  The correctness problem for unfold-fold is an instance
    of a strictly more general problem: transformation by locally
    equivalence-preserving steps does not necessarily preserve (global)
    equivalence.  This article presents a condition for the total correctness
    of transformations on recursive programs, which, for the first time, deals
    with higher-order functional languages (both strict and nonstrict)
    including lazy data structures.  The main technical result is an
    improvement theorem which says that if the local transformation steps are
    guided by certain optimization concerns (a fairly natural condition for a
    transformation), then correctness of the transformation follows.  The
    improvement theorem makes essential use of a formalized improvement theory;
    as a rather pleasing corollary it also guarantees that the transformed
    program is a formal improvement over the original.  The theorem has
    immediate practical consequences: it is a powerful tool for proving the
    correctness of existing transformation methods for higher-order functional
    programs, without having to ignore crucial factors such as memoization or
    folding, and it yields a simple syntactic method for guiding and
    constraining the unfold-fold method in the general case so that total
    correctness (and improvement) is always guaranteed.", 
  location     = "https://doi.org/10.1145/227699.227716"
}

@Article{bsidadp,
  author       = "C{\' e}dric Bouhours and Herv{\' e} Leblanc and Christian Percebois",
  title        = "Bad Smells in Design and Design Patterns",
  journal      = jot,
  year         = 2009,
  volume       = 8,
  number       = 3,
  pages        = "43--63",
  month        = may # "-" # jun,
  keywords     = "spoiled patterns, design patterns, design reviews",
  abstract     = {To give a consistent and more valuable property on models,
    model-driven processes should be able to reuse the expert knowledge
    generally expressed in terms of patterns.  We focus our work on the design
    stage and on the systematically use of design patterns.  Choose a good
    design pattern and ensure the correct integration of the chosen pattern are
    non trivial for a designer who wants to use them.  To help designers, we
    propose design inspection in order to detect “bad smells in design” and
    models reworking through use of design patterns.  The automatic detection
    and the explanation of the misconceptions are performed thanks to spoiled
    patterns.  A “spoiled pattern” is a pattern which allows to instantiate
    inadequate solutions for a given problem: requirements are respected, but
    architecture is improvable.}, 
  location     = "http://www.jot.fm/issues/issue_2009_05/column5.pdf"
}

@Article{ddidd,
  author       = "Edgar Knapp",
  title        = "Deadlock Detection in Distributed Databases",
  journal      = surveys,
  year         = 1987,
  volume       = 19,
  number       = 4,
  pages        = "303--328",
  month        = dec,
  keywords     = "deadlock detection, deadlock models, distributed deadlocks,
    diffusing computations, global-state detection, edge-chasing algorithms,
    path-pushing algorithms, wait-for graphs",
  abstract     = "The problem of deadlock detection in distributed systems has
    undergone extensive study.  An important application relates to distributed
    database systems.  A uniform model in which published algorithms can be
    cast is given, and the fundamental principles on which distributed deadlock
    detection schemes are based are presented.  These principles represent
    mechanisms for developing distributed algorithms in general and deadlock
    detection schemes in particular.  In addition, a hierarchy of deadlock
    models is presented; each model is characterized by the restrictions that
    are imposed upon the form resource requests can assume.  The hierarchy
    includes the well-known models of resource and communication deadlock.
    Algorithms are classified according to both the underlying principles and
    the generality of resource requests they permit.  A number of algorithms
    are discussed in detail, and their complexity in terms of the number of
    messages employed is compared.  The point is made that correctness proofs
    for such algorithms using operational arguments are cumbersome and error
    prone and, therefore, that only completely formal proofs are sufficient for
    demonstrating correctness.", 
  location     = "https://doi.org/10.1145/45075.46163"
}

@Article{idlcrt,
  author       = "Gay, David~E.",
  title        = "Interface Definition Language Conversions: Recursive Types",
  journal      = sigplan # idl94,
  year         = 1994,
  volume       = 29,
  number       = 8,
  pages        = "101--110",
  month        = aug,
  keywords     = "interface conversions, distributed computation, type models,
    type recursion, pointers",
  abstract     = "A large heterogeneous network contains many applications
    developed in different environments, each with its own incompatible
    interface definition language.  One way of dealing with this diversity is
    to define a conversion from the interfaces of one system into another, thus
    giving access from the second system to the first.  This presents a number
    of difficulties, amongst which is the different representation of recursive
    types in different languages.  This paper gives two algorithms for
    converting the representation of such recursive types between different
    styles of interface definition languages.", 
  location     = "https://doi.org/10.1145/185084.185112"
}

@Article{osam,
  author       = "Abadi, Mart{\' \i}n and Cardelli, Luca",
  title        = "On Subtyping and Matching",
  journal      = toplas,
  year         = 1996,
  volume       = 18,
  number       = 4,
  pages        = "401--423",
  month        = jul,
  keywords     = "f-bounded subtyping, subtyping, self, matching, type
    operators, type theory, object types, inheritance, binary methods,
    protocols, recursive object types, higher-order subtyping",
  abstract     = "A relation between recursive object types, called matching,
    has been proposed as a generalization of subtyping.  Unlike subtyping,
    matching does not support subsumption, but it does support inheritance of
    binary methods.  We argue that matching is a good idea, but that it should
    not be regarded as a form of F-bounded subtyping (as was originally
    intended).  We show that a new interpretation of matching as higher-order
    subtyping has better properties.  Matching turns out to be a third-order
    construction, possibly the only one to have been proposed for general use
    in programming.", 
  location     = "https://doi.org/10.1145/233561.233563"
}

@Article{cbsfcwagdm,
  author       = "Kraemer, Kenneth~L. and King, John Leslie",
  title        = "Computer-Based Systems for Cooperative Work and Group Decision Making",
  journal      = surveys,
  year         = 1988,
  volume       = 20,
  number       = 2,
  pages        = "115--146",
  month        = jun,
  keywords     = "cooperative work, group decision making, system evaluation,
    decision making",
  abstract     = "Application of computer and communications technology to
    cooperative work and group decision making has grown out of three
    traditions: computer-based communications, computer:based information
    service provision, and computer-based decision support.  This paper reviews
    the group decision support systems (GDSSs) that have been configured to
    meet the needs of groups at work, and evaluates the experience to date with
    such systems.  Progress with GDSSs has proved to be slower than originally
    anticipated because of shortcomings with available technology, poor
    integration of the various components of the computing package, and
    incomplete understanding of the nature of group decision making.
    Nevertheless, the field shows considerable promise with respect to the
    creation of tools to aid in group decision making and the development of
    sophisticated means of studying the dynamics of decision making in
    groups.", 
  location     = "https://doi.org/10.1145/46157.46158"
}

@Article{oteeoapa,
  author       = "Choi, Jong-Deok and Cytron, R. and Ferrante, J.",
  title        = "On the Efficient Engineering of Ambitious Program Analysis",
  journal      = tse,
  year         = 1994,
  volume       = 20,
  number       = 2,
  pages        = "105--114",
  month        = feb,
  keywords     = "data-flow graphs, data-flow chains, data-flow analysis,
    reaching definitions, static single assignment, compact representation,
    demand-driven computation",
  abstract     = "Recent advances in languages, software design methodologies,
    and architecture have prompted the development of improved compile-time
    methods for analyzing the effects of procedure calls, pointer references,
    and array accesses.  Such sophistication, however, generally implies that
    compilers and programming environments will experience a corresponding
    increase in the volume of analysis information, which may be difficult to
    use efficiently.  In this paper, we consider the practical accommodation of
    such information.  Our results show how to engineer a compiler such that
    its optimization phase takes time proportional to the benefit, rather than
    the size, of such information.", 
  location     = "https://doi.org/10.1109/32.265631"
}

@Article{doatfsapcp,
  author       = "De Francesco, Nicoletta and Vaglini, Gigliola",
  title        = "Description of a Tool for Specifying and Prototyping Concurrent Programs",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1554--1564",
  month        = nov,
  keywords     = "automatic programming, events, historical references,
    programming environment, rapid prototyping, specification language
  environment, specification of concurrent programs",
  abstract     = "",
  location     = ""
}

@Article{hrocosr,
  author       = "Hanan Samet",
  title        = "Hierarchical Representations of Collections of Small Rectangles",
  journal      = surveys,
  year         = 1988,
  volume       = 20,
  number       = 4,
  pages        = "271--309",
  month        = dec,
  keywords     = "cartography, geographic information systems, interval trees,
    hierarchical data structures, multidimensional data structures, plane-sweep
    methods, priority search trees, quadtrees, R-trees, rectangle intersection
    problem, rectangles, representative points, segment trees, vlsi design rule
    checking",
  abstract     = "A tutorial survey is presented of hierarchical data
    structures for representing collections of small rectangles.  Rectangles
    are often used as an approximation of shapes for which they serve as the
    minimum rectilinear enclosing object.  They arise in applications in
    cartography as well as very large-scale integration (VLSI) design rule
    checking.  The different data structures are discussed in terms of how they
    support the execution of queries involving proximity relations.  The focus
    is on intersection and subset queries.  Several types of representations
    are described.  Some are designed for use with the plane-sweep paradigm,
    which works well for static collections of rectangles.  Others are oriented
    toward dynamic collections.  In this case, one representation reduces each
    rectangle to a point in a higher multidimensional space and treats the
    problem as one involving point data.  The other representation is area
    based&mdash;that is, it depends on the physical extent of each rectangle.",
  location     = "http://dl.acm.org/citation.cfm?id=50021"
}

@Article{spbrtewpcs,
  author       = "Ceri, Stefano and Crespi-Reghizzi, Stefano and Di~Maio, Aandrea and Lavazza, Luigi~A.",
  title        = "Software Prototyping by Relational Techniques:  Experiences with Program Construction Systems",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1597--1609",
  month        = nov,
  keywords     = "ada, program construction environments, rapid prototyping,
  relational programming, target computer description",
  abstract     = "A method for designing and prototyping program construction
    systems using relational databases is presented.  Relations are the only
    data structures used inside the systems and for interfaces; programs
    extensively use relational languages, in particular relational algebra.
    Two large projects are described.  The Ada Relational Translator (ART) is
    an experimental compiler-interpreter for Ada in which all subsystems,
    including the parser, semantic analyzer, interpreter, kernel, and debugger,
    use relations as their only data structure; the relational approach has
    been pushed to the utmost to achieve fast prototyping in a student
    environment.  Multi-Micro Line (MML) is a tool set for constructing
    programs for multimicroprocessors' targets, in which relations are used for
    allocation and configuration control.  Both experiences validate the
    approach for managing teamwork in evolving projects, identify areas where
    this approach is appropriate, and raise critical issues.", 
  location     = "https://doi.org/10.1109/32.9048"
}

@Article{galfsaiovp,
  author       = "Ambler, Allen~L. and Good, Donald~I. and Browne, James~C. and Burger, Wilhelm~F. and Cohen, Richard~M. and Hoch, Charles~G. and Wells, Robert~E.",
  title        = "{GYPSY}: {A} Language for Specification and Implementation of Verifiable Programs",
  journal      = sigplan # rs77,
  year         = 1977,
  month        = mar,
  volume       = 12,
  number       = 3,
  pages        = "1--10",
  keywords     = "verification, pascal, language design, incremental
    development, specification",
  abstract     = "An introduction to the Gypsy programming and specification
    language is given.  Gypsy is a high-level programming language with
    facilities for general programming and also for systems programming that is
    oriented toward communications processing.  This includes facilities for
    concurrent processes and process synchronization.  Gypsy also contains
    facilities for detecting and processing errors that are due to the actual
    running of the program in an imperfect environment.  The specification
    facilities give a precise way of expressing the desired properties of the
    Gypsy programs.  All of the features of Gypsy are fully verifiable, either
    by formal proof or by validation at run time.  An overview of the language
    design and a detailed example program are given.", 
  location     = "https://doi.org/10.1145/390017.808306"
}

@Article{aocdics,
  author       = "Colbourn, Charles~J. and van Oorschot, Paul~C.",
  title        = "Applications of Combinatorial Designs in Computer Science",
  journal      = surveys,
  year         = 1989,
  volume       = 21,
  number       = 2,
  pages        = "223--250",
  month        = jun,
  keywords     = "algorithms, design, security, theory, authentication,
    combinatorial design, distributed consensus, file organization,
    intercommunication networks memory access, parallel algorithms, parallel
    sorting", 
  abstract     = "The theory of combinatorial designs has been used in widely
    different areas of computation concerned with the design and analysis of
    both algorithms and hardware.  Combinatorial designs capture a subtle
    balancing property that is inherent in many difficult problems and hence
    can provide a sophisticated tool for addressing these problems.  The role
    of combinatorial designs in solving many problems that are basic to the
    field of computing is explored in this paper.  Case studies of many
    applications of designs to computation are given; these constitute a first
    survey, which provides a representative sample of uses of designs.  More
    importantly, they suggest paradigms in which designs can be used profitably
    in algorithm design and analysis.", 
  location     = "https://doi.org/10.1145/66443.66446"
}

@Article{otuorefst,
  author       = "Clarke, Charles~L.~A. and Cormack, Gordon~V.",
  title        = "On the Use of Regular Expressions for Searching Text",
  journal      = toplas,
  year         = 1997,
  volume       = 19,
  number       = 3,
  pages        = "413--426",
  month        = may,
  keywords     = "specialized application languages, regular expressions,
    regular languages, sgml",
  abstract     = {The use of regular expressions for text search is widely
    known and well understood.  It is then surprising that the standard
    techniques and tools prove to be of limited use for searching structured
    text formatted with SGML or similar markup languages.  Our experience with
    structured text search has caused us to reexamine the current practice.
    The generally accepted rule of "leftmost longest match" is an unfortunate
    choice and is at the root of the difficulties.  We instead propose a rule
    which is semantically cleaner.  This rule is generally applicable to a
    variety of text search applications, including source code analysis, and
    has interesting properties in its own right.  We have written a publicly
    available search tool implementing the theory in the article, which has
    proved valuable in a variety of circumstances.},
  location     = "https://doi.org/10.1145/256167.256174"
}

@Article{dcpcem,
  author       = "McDowell, Charles~E. and Helmbold, David~P.",
  title        = "Debugging Concurrent Programs",
  journal      = surveys,
  year         = 1989,
  volume       = 21,
  number       = 4,
  pages        = "593--622",
  month        = dec,
  keywords     = "distributed computing, event history, nondeterminism,
    parallel processing, probe effect, program replay, program visualization,
    static analysis",
  abstract     = "The main problems associated with debugging concurrent
    programs are increased complexity, the probe effect, nonrepeatability, and
    the lack of a synchronized global clock.  The probe effect refers to the
    fact that any attempt to observe the behavior of a distributed system may
    change the behavior of that system.  For some parallel programs, different
    executions with the same data will result in different results even without
    any attempt to observe the behavior.  Even when the behavior can be
    observed, in many systems the lack of a synchronized global clock makes the
    results of the observation difficult to interpret.  This paper discusses
    these and other problems related to debugging concurrent programs and
    presents a survey of current techniques used in debugging concurrent
    programs.  Systems using three general techniques are described:
    traditional or breakpoint style debuggers, event monitoring systems, and
    static analysis systems.  In addition, techniques for limiting, organizing,
    and displaying a large amount of data produced by the debugging systems are
    discussed.", 
  location     = "https://doi.org/10.1145/76894.76897"
}

@Article{eiaoortcipa,
  author       = "Fischer, Charles~N. and LeBlanc, Richard~J.",
  title        = "Efficient Implementation and Optimization of Run-Time Checking in {{P}}ascal",
  journal      = sigplan # rs77,
  year         = 1977,
  month        = mar,
  volume       = 12,
  number       = 3,
  pages        = "19--24",
  keywords     = "pascal, run-time check generation, run-time check
    optimization, discriminated type unions, pointers, heap management,
    by-reference parameters, programming language design",
  abstract     = "Complete run-time checking of programs is an essential tool
    for the development of reliable software.  A number of features of the
    programming language PASCAL (arrays, subranges, pointers, record variants
    (discriminated type unions), formal procedures, etc.) can require some
    checking at run-time as well as during compilation.  The problem of
    efficiently implementing such checking is considered.  Language
    modifications to simplify such checking are suggested.  The possibility of
    optimizing such checking is discussed.", 
  location     = "https://doi.org/10.1145/390018.808308"
}

@Article{notdoe,
  author       = "Popek, Gerald~J. and Horning, J.~J. and Lampson, Butler~W. and Mitchell, J.~G. and London, Ralph~L.",
  title        = "Notes on the Design of {E}uclid",
  journal      = sigplan # rs77,
  year         = 1977,
  month        = mar,
  volume       = 12,
  number       = 3,
  pages        = "11--18",
  keywords     = "euclid, verification, system programming language,
    reliability, pascal, aliasing, data encapsulation, parameterized types,
    visibility of names, machine dependencies, legality assertions, storage
    allocation, language design",
  abstract     = "Euclid is a language for writing system programs that are to
    be verified.  We believe that verification and reliability are closely
    related, because if it is hard to reason about programs using a language
    feature, it will be difficult to write programs that use it properly.  This
    paper discusses a number of issues in the design of Euclid, including such
    topics as the scope of names, aliasing, modules, type-checking, and the
    confinement of machine dependencies; it gives some of the reasons for our
    expectation that programming in Euclid will be more reliable (and will
    produce more reliable programs) than programming in Pascal, on which Euclid
    is based.", 
  location     = "https://doi.org/10.1145/800022.808307"
}

@Article{scaiisr,
  author       = "Lew, Ken~S. and Dillon, Tharam~S. and Forward, Kevin~E.",
  title        = "Software Complexity and Its Impact on Software Reliability",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1645--1655",
  month        = nov,
  keywords     = "module coupling, software complexity, software design,
    software reliability, information content, complexity metrics, information
    flow graphs, system decomposition, software fault tolerance",
  abstract     = "",
  location     = "https://doi.org/10.1109/32.9052"
}

@Article{cadfcd,
  author       = "Banerjee, Jay and Kim, Won and Kim, Sung-Jo and Garza, Jorge~F.",
  title        = "Clustering a {DAG} for {CAD} Databases",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 11,
  pages        = "1684--1699",
  month        = nov,
  keywords     = "breadth-first traversal, cad databases, children-depth-first,
    traversal method, clustering, dag, depth-first traversal method, hierarchy,
    storage organization",
  abstract     = "A DAG (direct acyclic graph) is an important data structure
    which requires efficient support in CAD (computer-aided design) databases.
    It typically arise from the design hierarchy, which describes complex
    designs in terms of subdesigns.  A study is made of the properties of the
    three types of clustered sequences of nodes for hierarchies and DAGs, and
    algorithms are developed for generating the clustered sequences, retrieving
    the descendants of a given node, and inserting new nodes into existing
    clustered sequences of nodes which preserve their clustering properties.
    The performance of the clustering sequences is compared.", 
  location     = "https://doi.org/10.1109/32.9055"
}

@Article{tacttfc,
  author       = "Bergstra, Jan~A. and Dinesh, T.~B. and Field, J. and Heering, Jan",
  title        = "Towards a Complete Transformational Toolkit for Compilers",
  journal      = toplas,
  year         = 1997,
  volume       = 19,
  number       = 5,
  pages        = "639--684",
  month        = sep,
  keywords     = "compiler intermediate representation, completion, imperative
    language, partial evaluation, program transformation, term rewriting",
  abstract     = {PIM is an equational logic designed to function as a
    "transformational toolkit" for compilers and other programming tools that
    analyze and manipulate imperative languages.  It has been applied to such
    problems as program slicing, symbolic evaluation, conditional constant
    propagation, and dependence analysis.  PIM consists of the untyped lambda
    calculus extended with an algebraic data type that characterizes the
    behavior of lazy stores and generalized conditionals.  A graph form of PIM
    terms is by design closely related to several intermediate representations
    commonly used in optimizing compilers.  In this article, we show that PIM's
    core algebraic component, PIMt, possesses a complete equational
    axiomatization (under the assumption of certain reasonable restrictions on
    term formation).  This has the practical consequence of guaranteeing that
    every semantics-preserving transformation on a program representable in
    PIMt can be derived by application of PIMt rules.  We systematically derive
    the complete PIMt logic as the culmination of a sequence of increasingly
    powerful equational systems starting from a straightforward "interpreter"
    for closed PIMt terms.  This work is an intermediate step in a larger
    program to develop a set of well-founded tools for manipulation of
    imperative programs by compilers and other systems that perform program
    analysis.}, 
  location     = "https://doi.org/10.1145/265943.265944"
}

@Article{rsfftras,
  author       = "Abbott, Russell~J.",
  title        = "Resourceful Systems for Fault Tolerance, Reliability, and Safety",
  journal      = surveys,
  year         = 1990,
  volume       = 22,
  number       = 1,
  pages        = "35--68",
  month        = mar,
  keywords     = "logic programming, n-version programming, object-oriented
    programming, planning, prolog, recovery blocks, resourceful systems, fault
    tolerance, faults, mistakes, errors",
  abstract     = "Above all, it is vital to recognize that completely
    guaranteed behavior is impossible and that there are inherent risks in
    relying on computer systems in critical environments.  The unforeseen
    consequences are often the most disastrous [Neumann 1986].  Section 1 of
    this survey reviews the current state of the art of system reliability,
    safety, and fault tolerance.  The emphasis is on the contribution of
    software to these areas.  Section 2 reviews current approaches to software
    fault tolerance.  It discusses why some of the assumptions underlying
    hardware fault tolerance do not hold for software.  It argues that the
    current software fault tolerance techniques are more accurately thought of
    as delayed debugging than as fault tolerance.  It goes on to show that in
    providing both backtracking and executable specifications, logic
    programming offers most of the tools currently used in software fault
    tolerance.  Section 3 presents a generalization of the recovery block
    approach to software fault tolerance, called resourceful systems.  Systems
    are resourceful if they are able to determine whether they have achieved
    their goals or, if not, to develop and carry out alternate plans.  Section
    3 develops an approach to designing resourceful systems based upon a
    functionally rich architecture and an explicit goal orientation.", 
  location     = "https://doi.org/10.1145/78949.78951"
}

@Article{asopipl,
  author       = "Ambler, Allen~L. and Hoch, Charles~G.",
  title        = "{A} Study of Protection in Programming Languages",
  journal      = sigplan # rs77,
  year         = 1977,
  month        = mar,
  volume       = 12,
  number       = 3,
  pages        = "25--40",
  keywords     = "protection, pascal, concurrent pascal, euclid, clu, gypsy,
    abstract data types, module, scope control, security",
  abstract     = "The concept of &ldquo;protection&rdquo; in programming
    languages refers to the ability to express directly in the language the
    desired access control relationships for all objects defined in the
    language.  The use of such mechanisms as data types, scope, parameter
    passing mechanisms, routines as parameters, abstract data types, and
    capabilities in Pascal, Concurrent Pascal, Euclid, Clu, and Gypsy are
    explored via a simple example which embodies many protection problems.  The
    usefulness of language defined and enforced protection mechanisms to the
    process of formal verification is discussed.",
  location     = "https://doi.org/10.1145/800022.808309"
}

@Article{socqnwb,
  author       = "Onvural, Raif~O.",
  title        = "Survey of Closed Queueing Networks with Blocking",
  journal      = surveys,
  year         = 1990,
  volume       = 22,
  number       = 2,
  pages        = "83--121",
  month        = jun,
  keywords     = "blocking, finite-buffer capacities, markiv model, queueing
    networks, closed queueing networks", 
  abstract     = "Closed queueing networks are frequently used to model complex
    service systems such as production systems, communication systems, computer
    systems, and flexible manufacturing systems.  When limitations are imposed
    on the queue sizes (i.e., finite queues), a phenomenon called blocking
    occurs.  Queueing networks with blocking are, in general, difficult to
    treat.  Exact closed form solutions have been reported only in a few
    special cases.  Hence, most of the techniques that are used to analyze such
    queueing networks are in the form of approximations, numerical analysis,
    and simulation.  In this paper, we give a systematic presentation of the
    literature related to closed queueing networks with finite queues.  The
    results are significant for both researchers and practitioners.", 
  location     = "https://doi.org/10.1145/78919.78920"
}

@Article{tdiaeoj,
  author       = "Rinard, Martin~C. and Lam, Monica~S.",
  title        = "The Design, Implementation, and Evaluation of {J}ade",
  journal      = toplas,
  year         = 1998,
  volume       = 20,
  number       = 3,
  pages        = "483--545",
  month        = may,
  keywords     = "implicit parallelism, imperative programming, message
    passing, data model, parallelizing compilers, large-grain parallelism",
  abstract     = "Jade is a portable, implicitly parallel language designed for
    exploiting task-level concurrency.Jade programmers start with a program
    written in a standard serial, imperative language, then use Jade constructs
    to declare how parts of the program access data.  The Jade implementation
    uses this data access information to automatically extract the concurrency
    and map the application onto the machine at hand.  The resulting parallel
    execution preserves the semantics of the original serial program.  We have
    implemented Jade as an extension to C, and Jade implementations exist for s
    hared-memory multiprocessors, homogeneous message-passing machines, and
    heterogeneous networks of workstations.  In this atricle we discuss the
    design goals and decisions that determined the final form of Jade and
    present an overview of the Jade implementation.  We also present our
    experience using Jade to implement several complete scientific and
    engineering applications.  We use this experience to evaluate how the
    different Jade language features were used in practice and how well Jade as
    a whole supports the process of developing parallel applications.  We find
    that the basic idea of preserving the serial semantics simplifies the
    program development process, and that the concept of using data access
    specifications to guide the parallelization offers significant advantages
    over more traditional control-based approaches.  We also find that the Jade
    data model can interact poorly with concurrency patterns that write
    disjoint pieces of a single aggregate data structure, although this problem
    arises in only one of the applications.", 
  location     = "https://doi.org/10.1145/291889.291893",
  location     = "https://people.csail.mit.edu/rinard/paper/toplas98.pdf"
}

@Article{vdasoafgds,
  author       = "Aurenhammer, Franz",
  title        = "Voroni Diagrams --- {A} Survey of a Fundamental Geometric Data Structure",
  journal      = surveys,
  year         = 1991,
  volume       = 23,
  number       = 3,
  pages        = "345--405",
  month        = sep,
  keywords     = "algorithms, analysis of algorithms and problem complexity,
    cell complex, clustering, combinatorial algorithms, combinatorial
    complexity, combinatorics, computational geometry and object modeling,
    computer graphics, convex hull, crystal structure, discrete mathematics,
    divide-and-conquer, geometric algorithms, geometric data structure, growth
    model, higher dimensional embedding, hyperplane arrangement, k-set,
    languages and systems, motion planning, neighbor searching, nonnumerical
    algorithms and problems-geometrical problems and computations, object
    modeling, plane-sweep, proximity, randomized insertion, spanning tree,
    theory, triangulation", 
  abstract     = "This paper presents a survey of the Voronoi diagram, one of 
    the most fundamental data structures in computational geometry.  It
    demonstrates the importance and usefulness of the Voronoi diagram in a wide
    variety of fields inside and outside computer science and surveys the
    history of its development.  The paper puts particular emphasis on the
    unified exposition of its mathematical and algorithmic properties.
    Finally, the paper provides the first comprehensive bibliography on Voronoi
    diagrams and related structures.", 
  location     = "https://doi.org/10.1145/116873.116880"
}

@Article{easula,
  author       = "Attiya, Hagit and Herlihy, Maurice and Rachman, Ophir",
  title        = "Efficient Atomic Snapshots Using Lattice Agreement",
  journal      = "Distributed Computing",
  year         = 1995,
  volume       = 8,
  number       = 3,
  pages        = "131--132",
  month        = mar,
  keywords     = "lattice agreement, snapshot objects, synchronous agreement,
    asynchronous agreement",
  abstract     = "The snapshot object is an important tool for constructing
    wait-free asynchronous algorithms.  We relate the snapshot object to the
    lattice agreement decision problem.  It is shown that any algorithm for
    solving lattice agreement can be transformed into an implementation of a
    snapshot object.  The overhead cost of this transformation is only a linear
    number of read and write operations on atomic single-writer multi-reader
    registers.  The transformation uses an unbounded amount of shared memory.
    We present a deterministic algorithm for lattice agreement that used O(log2
    n) operations on 2-processor Test & Set registers, plus O(n) operations on
    atomic single-writer multi-reader registers.  The shared objects are used
    by the algorithm in a dynamic mode, that is, the identity of the processors
    that access each of the shared objects is determined dynamically during the
    execution of the algorithm.  By a randomized implementation of 2-processors
    Test & Set registers from atomic registers, this algorithm implies a
    randomized algorithm for lattice agreement that uses an expected number of
    O(n) operations on (dynamic) atomic single-writer multi-reader registers.
    Combined with our transformation this yields implementations of atomic
    snapshots with the same complexity.", 
  location     = "https://doi.org/10.1007/BF02242714"
}

@Article{xdrcr,
  author       = "Hirvisalo, Vesa and Arkko, Jari and Kuusela, Juha and Nuutila, Esko and Tamminen, Markku",
  title        = "{XE} Design Rationale:  {C}lu Revisited",
  journal      = sigplan,
  year         = 1989,
  volume       = 24,
  number       = 9,
  pages        = "72--79",
  month        = sep,
  keywords     = "language design, parameterization, generalized iterators",
  abstract     = "XE is a programming language designed and implemented at the
    Helsinki University of Technology by the ExBed project.  The design of XE
    is based on the CLU programming language.  This paper discusses differences
    between the two languages and the design decisions of XE.", 
  location     = "https://doi.org/10.1145/68127.68130"
}

@Article{asgbir,
  author       = "Click, Cliff and Paleczny, Michael",
  title        = "{A} Simple Graph-Based Intermediate Representation",
  journal      = sigplan # ir95,
  year         = 1995,
  volume       = 30,
  number       = 3,
  pages        = "35--49",
  month        = mar,
  keywords     = "graphs, static single assignment, optimizations",
  abstract     = "We present a graph-based intermediate representation (IR) 
    with simple semantics and a low-memory-cost C++ implementation.  The IR
    uses a directed graph with labeled vertices and ordered inputs but
    unordered outputs.  Vertices are labeled with opcodes, edges are unlabeled.
    We represent the CFG and basic blocks with the same vertex and edge
    structures.  Each opcode is defined by a C++ class that encapsulates
    opcode-specific data and behavior.  We use inheritance to abstract common
    opcode behavior, allowing new opcodes to be easily defined from old ones.
    The resulting IR is simple, fast and easy to use.", 
  location     = "http://www.oracle.com/technetwork/java/javase/tech/c2-ir95-150110.pdf", 
  location     = "https://doi.org/10.1145/202529.202534"
}

@Article{catalacfdcg,
  author       = "Poletto, Massimiliano and Hsieh, Wilson~C. and Engler, Dawson~R. and Kaashoek, M.~Frans",
  title        = "{`C} and {tcc}: A Language and Compiler for dynamic Code Generation",
  journal      = toplas,
  year         = 1999,
  volume       = 21,
  number       = 2,
  pages        = "324--369",
  month        = mar,
  keywords     = "ansi c, compilers, dynamic code generation, dynamic code
    optimization",
  abstract     = "Dynamic code generation allows programmers to use run-time
    information in order to achieve performance and expressiveness superior to
    those of static code.  The 'C(Tick C) language is a superset of ANSI C that
    supports efficient and high-level use of dynamic code generation.  'C
    provides dynamic code generation at the level of C expressions and
    statements and supports the composition of dynamic code at run time.  These
    features enable programmers to add dynamic code generation to existing C
    code incrementally and to write important applications (such as
    &ldquo;just-in-time&rdquo; compilers) easily.  The article presents many
    examples of how 'C can be used to solve practical problems.  The tcc
    compiler is an efficient, portable, and freely available implementation of
    'C.  tcc allows programmers to trade dynamic compilation speed for dynamic
    code quality: in some aplications, it is most important to generate code
    quickly, while in others code quality matters more than compilation speed.
    The overhead of dynamic compilation is on the order of 100 to 600 cycles
    per generated instruction, depending on the level of dynamic optimizaton.
    Measurements show that the use of dynamic code generation can improve
    performance by almost an order of magnitude; two- to four-fold speedups are
    common.  In most cases, the overhead of dynamic compilation is recovered in
    under 100 uses of the dynamic code; sometimes it can be recovered within
    one use.",
  location     = "https://doi.org/10.1145/316686.316697",
  location     = "https://web.stanford.edu/~engler/tickc.pdf"
}

@Article{tsmam,
  author       = "Daniel Hoffman and Richard~T. Snodgrass",
  title        = "Trace Specifications: Methodology and Models",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 9,
  pages        = "1243--1253",
  month        = sep,
  keywords     = "formal specification, logic, prototype, software engineering,
    trace specification, algebraic specifications, models",
  abstract     = "Precise abstract software specification is achievable by
    using formal specification languages.  However, nontrivial specifications
    are inordinately difficult to read and write.  This paper summarizes the
    trace specification language and present? the trace specification
    methodology: a set of heuristics designed to make the reading and writing
    of complex specifications manageable.  Also described is a technique for
    constructing formal, executable models from specifications written using
    the methodology.  These models are useful as proofs of specification
    consistency and as executable prototypes.  Fully worked examples of the
    methodology and the model building technique are included.", 
  location     = "http://doi.org/10.1109/32.6168"
}

@Article{ppelas,
  author       = "Bogdan Korel",
  title        = "{PELAS}---Program Error-Locating Assistant System",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 9,
  pages        = "1253--1260",
  month        = sep,
  keywords     = "debugging, dependence network, dependence relation, error
    localization, hypotheses formation, programming assistant",
  abstract     = "Error localization in program debugging is the process of
    identifying program statements which cause incorrect behavior.  A prototype
    of the error localization assistant system which guides a programmer during
    debugging of Pascal programs is described.  The system is interactive: it
    queries the programmer for the correctness of the program behavior and uses
    answers to focus the programmer's attention on an erroneous part of the
    program (in particular, it can localize a faulty statement).  The system
    differs from previous approaches in that it makes use of the knowledge of
    program structure, which is derived automatically.  The knowledge of
    program structure is represented by the dependence network which is used by
    the error-locating reasoning mechanism to guide the construction,
    evaluation, and modification of hypothesis of possible causes of the error.
    Backtracking reasoning has been implemented in the reasoning mechanism.", 
  location     = "https://doi.org/10.1109/32.6169"
}

@Article{prpvc,
  author       = "Ted Tenny",
  title        = "Program Readability: Procedures Versus Comments",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 9,
  pages        = "1271--1279",
  month        = sep,
  keywords     = "comments, experiment design, procedure format, program
    readability, pl/1, factorial experiment",
  abstract     = "A 3*2 factorial experiment was performed to compare the
    effects of procedure format (none, internal, or external) with those of
    comments (absent or present) on the readability of a PL/1 program.  The
    readability of six editions of the program, each having a different
    combination of these factors, was inferred from the accuracy with which
    students could answer questions about the program after reading it.  Both
    extremes in readability occurred in the program editions having no
    procedures: without comments the procedureless program was the least
    readable and with comments it was the most readable.", 
  location     = "https://doi.org/10.1109/32.6171"
}

@Article{asoasa,
  author       = "Vladimir Estivill-Castro and Derick Wood",
  title        = "{A} Survey of Adaptive Sorting Algorithms",
  journal      = surveys,
  year         = 1992,
  volume       = 24,
  number       = 4,
  pages        = "441--476",
  month        = dec,
  OPTkeywords  = "adaptive sorting algorithm, comparison tree, optimal
    adaptivity, randomized algorithm, sorted sequence, cook kim division,
    problem sorting, composite structure, worst-case adaptive, problem
    complexity, data storage representation, generic sort, partition sort,
    sorting algorithm, exponential search, nonnumerical algorithm,
    expected-case adaptive, statistic probabilistic algorithm",
  abstract     = "The design and analysis of adaptive sorting algorithms has
    made important contributions to both theory and practice.  The main
    contributions from the theoretical point of view are: the description of
    the complexity of a sorting algorithm not only in terms of the size of a
    problem instance but also in terms of the disorder of the given problem
    instance; the establishment of new relationships among measures of
    disorder; the introduction of new sorting algorithms that take advantage of
    the existing order in the input sequence; and, the proofs that several of
    the new sorting algorithms achieve maximal (optimal) adaptivity with
    respect to several measures of disorder.  The main contributions from the
    practical point of view are: the demonstration that several algorithms
    currently in use are adaptive; and, the development of new algorithms,
    similar to currently used algorithms that perform competitively on random
    sequences and are significantly faster on nearly sorted sequences.  In this
    survey, we present the basic notions and concepts of adaptive sorting and
    the state of the art of adaptive sorting algorithms.",
  location     = "http://doi.org/10.1145/146370.146381"
}

@Article{syslbt,
  author       = "Leslie Lamport and Lawrence~C. Paulson",
  title        = "Should Your Specification Language Be Typed?",
  journal      = toplas,
  year         = 1999,
  volume       = 21,
  number       = 3,
  pages        = "502--526",
  month        = may,
  keywords     = "set theory, specification, types, verification, logic,
    functions, operators, recursion, typed formal languages, typed set theory,
    disjoint sums, data types, higher-order logic, type theories, constructive
    type theory, expressiveness",
  abstract     = "Most specification languages have a type system.  Type
    systems are hard to get right, and getting them wrong can lead to
    inconsistencies.  Set theory can serve as the basis for a specification
    language without types.  This possibility, which has been widely
    overlooked, offers many advantages.  Untyped set theory is simple and is
    more flexible than any simple typed formalism.  Polymorphism, overloading,
    and subtyping can make a type system more powerful, but at the cost of
    increased somplexity, and such refinements can never attain the flexibility
    of having no types at all.  Typed formalisms have advantages, too, stemming
    from the power of mechanical type checking.  While types serve little
    purpose in hand proofs, they do help with mechanized proofs.  In the
    absence of verificaiton, type checking can catch errors in specifications.
    It may be possible to have the best of both worlds by adding typing
    annotations to an untyped specification language.  We consider only
    specification languages, not programming languages.", 
  location     = "https://doi.org/10.1145/319301.319317"
}

@Article{escm,
  author       = "Elaine~J. Weyuker",
  title        = "Evaluating Software Complexity Measures",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 9,
  pages        = "1357--1365",
  month        = sep,
  keywords     = "cyclomatic numbers, lines of code, software metrics, data
    flow, software science, software complexity",
  abstract     = "A set of properties of syntactic software complexity measures
    is proposed to serve as a basis for the evaluation of such measures.  Four
    known complexity measures are evaluated and compared using these criteria.
    This formalized evaluation clarifies the strengths and weaknesses of the
    examined complexity measures, which include the statement count, cyclomatic
    number, effort measure, and data flow complexity measures.  None of these
    measures possesses all nine properties, and several are found to fail to
    possess particularly fundamental properties; this failure calls into
    question their usefulness in measuring synthetic complexity.", 
  location     = "https://doi.org/10.1109/32.6178"
}

@Article{fdoda,
  author       = "Levent Orman",
  title        = "Functional Development of Database Applications",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 9,
  pages        = "1280--1292",
  month        = sep,
  keywords     = "application semantics, database applications, data semantics,
  functional development, functional model, functional specification,
  metasemantics, database application language",
  abstract     = "A highly modular and uniformly functional development
    methodology for database applications is introduced.  An event-oriented
    view of the database is adopted recording the observed events directly and
    treating the state of the environment as derived data.  The relationship
    between the observed events and the derived state of the system is
    expressed using a purely functional language.  The application systems in
    this environment are divided into their smallest possible components
    consisting of only functions and simple functional expressions.  The
    multimode of small but highly independent components generated in this
    fashion are placed in the database along with the data, to utilize the
    database management system in maintaining the application system.  The
    semantics of individual applications is captured within the data model
    serving those applications.",
  location     = "https://doi.org/10.1109/32.6172"
}

@Article{asotaocm,
  author       = "John Stephen Davis and Richard~J. LeBlanc",
  title        = "{A} Study of the Applicability of Complexity Measures",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 9,
  pages        = "1366-1372",
  month        = sep,
  keywords     = "complexity measures, software science, chunking, software
    maintenance, entropy, software forecasting",
  abstract     = "A study of the predictive value of a variety of syntax-based
    problem complexity measures is reported.  Experimentation with variants of
    chunk-oriented measures showed that one should judiciously select
    measurable software attributes as proper indicators of what one wishes to
    predict, rather than hoping for a single, all-purpose complexity measure.
    The authors have shown that it is possible for particular complexity
    measures or other factors to serve as good predictors of some properties of
    program but not for others.  For example, a good predictor of construction
    time will not necessarily correlate well with the number of error
    occurrences.  M.H.  Halstead's (1977) efforts measure (E) was found to be a
    better predictor that the two nonchunk measures evaluated, namely, T.J.
    McCabe's (1976) V(G) and lines of code, but at least one chunk measure
    predicted better than E in every case.", 
  location     = "https://doi.org/10.1109/32.6179"
}

@Article{gtdfgfosp,
  author       = "Pascal Aubry and Thierry Gautier",
  title        = "{GC}: The Data-Flow Graph Format of Synchronous Programming",
  journal      = sigplan # ir95,
  year         = 1995,
  volume       = 30,
  number       = 3,
  pages        = "83--93",
  month        = mar,
  abstract     = "Based on an abstraction of the time as a discrete logical
    time, the synchronous languages, armed with a strong semantics, enable the
    design of safe real-time applications.  Some of them are of imperative
    style, while others are declarative.  Academic and industrial teams
    involved in synchronous programming defined together three intermediate
    representations, on the way to standardization:• IC, a parallel format of
    imperative style,• GC, a parallel format of data-flow style,• OC, a
    sequential format to describe automata.In this paper, we describe more
    specifically the format GC, and its links with the synchronous data-flow
    language SIGNAL.  Thanks to the first experimentation, GC reveals itself as
    a powerful representation for graph transformations, code production,
    optimization, hardware synthesis, etc.", 
  keywords     = "synchronous languages, data-flow graphs, clocks, signal",
  location     = "https://doi.org/10.1145/202530.202538"
}

@Article{tcpiftc,
  author       = "Michael Barborak and Anton Dahbura and Miroslaw Malek",
  title        = "The Consensus Problem in Fault-Tolerant Computing",
  journal      = surveys,
  year         = 1993,
  volume       = 25,
  number       = 2,
  pages        = "171--220",
  month        = jun,
  keywords     = "computer communication networks, network operations, network
    management, network monitoring, distributed systems, distributed
    applications, network operating systems, operating systems, reliability,
    fault tolerance algorithms, design, reliability byzantine agreement,
    consensus problem, decision theory, processor membership, system
    diagnosis", 
  abstract     = "The consensus problem is concerned with the agreement on a 
    system status by the fault-free segment of a processor population in spite
    of the possible inadvertent or even malicious spread of disinformation by
    the faulty segment of that population.  The resulting protocols are useful
    throughout fault-tolerant parallel and distributed systems and will impact
    the design of decision systems to come.  This paper surveys research on the
    consensus problem, compares approaches, outlines applications, and suggests
    directions for future work.", 
  location     = "https://doi.org/10.1145/152610.152612"
}

@Article{gcfpmarq,
  author       = "Christos Faloutsos",
  title        = "Gray Codes for Partial Match and Range Queries",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 10,
  pages        = "1381--1393",
  month        = oct,
  keywords     = "distance-preserving mappings, file access, query
    optimizations, multi-attribute hashing",
  abstract     = "It is suggested that Gray codes be used to improve the
    performance of methods for partial match and range queries.  Specifically,
    the author illustrates the improved clustering of similar records that Gray
    codes can achieve with multiattribute hashing.  Gray codes are used instead
    of binary codes to map record signatures to buckets.  In Gray codes,
    successive codewords differ in the value of exactly one bit position; thus,
    successive buckets hold records with similar record signatures.  The
    proposed method achieves better clustering of similar records, thus
    reducing the I/O time.  A mathematical model is developed to derive
    formulas giving the average performance of both methods, and it is shown
    that the proposed method achieves 0-50% relative savings over the binary
    codes.  The author also discusses how Gray codes could be applied to some
    retrieval methods designed for range queries, such as the grid file and the
    approach based on the so-called z-ordering.  Gray codes are also used to
    design good distance-preserving functions, which map a k-dimensional (k-D)
    space into a one-dimensional one, in such a way that points are close in
    the k-D space are likely to be close in the 1-D space.", 
  location     = "https://doi.org/10.1109/32.6184"
}

@Article{cmarirfc,
  author       = "Brian~T. Lewis and L.~Peter Deutsch and Theodore~C. Goldstein",
  title        = "{Clarity} {MCode}:  A Retargetable Intermediate Representation for Compilation",
  journal      = sigplan # ir95,
  year         = 1995,
  volume       = 30,
  number       = 3,
  pages        = "119--128",
  month        = mar,
  keywords     = "intermediate code, interoperability, runtime systems,
    portability", 
  abstract     = "To support the compilation of Clarity, we have developed a 
    high-level, machine-independent intermediate representation that we call
    MCode (for middle code).  We use MCode to compile Clarity programs at
    execution time (i.e., on-the-fly) into SPARC1 code for the Solaris
    operating system.  This code generator is designed to be largely
    machine-independent: besides the SPARC code generator, an Intel x86 version
    is being developed.  MCode includes a small amount of optimization
    information that enables the runtime code generator to produce good quality
    code.  Our SPARC code generator produces code about as good as that
    produced by the SunPRO C compiler at the -O2 optimization level.  A
    significant advantage of MCode over native machine code is that it can be
    represented more compactly; MCode is stack based, and the encoding of most
    instructions can be a single byte.  We also support an interpreter for
    MCode that supports full interoperation with C and existing C libraries.
    Although MCode includes instructions and data structures needed to
    implement some Clarity language-specific constructs such as its exceptions
    and method calls, the core of MCode is suitable for representing code for C
    and many other languages.", 
  location     = "https://doi.org/10.1145/202529.202542"
}

@Article{aplfrts,
  author       = "Luqi and V.~Berzins and Raymond~T. Yeh",
  title        = "{A} Prototyping Language for Real-Time Software",
  journal      = tse,
  year         = 1988,
  volume       = 14,
  number       = 10,
  pages        = "1409--1423",
  month        = oct,
  keywords     = "control abstraction, data abstraction, modularity",
  abstract     = "PSDL is a language for describing prototypes of real-time
    software systems.  It is most useful for requirements analysis, feasibility
    studies, and the design of large embedded systems.  PSDL has facilities for
    recording and enforcing timing constraints, and for modeling the control
    aspects of real-time systems using nonprocedural control constraints,
    operator abstractions, and data abstractions.  The language has been
    designed for use with an associated prototyping methodology.  PSDL
    prototypes are executable if supported by a software base containing
    reusable software components in an underlying programming language (e.g.
    Ada).", 
  location     = "https://doi.org/10.1109/32.6186"
}

@Article{rtim,
  author       = "Chitnis, Sachin~V. and Satpathy, Manoranjan and Oberoi, Sundeep",
  title        = "Rationalized Three Instruction Machine",
  journal      = sigplan # ir95,
  year         = 1995,
  volume       = 30,
  number       = 3,
  pages        = "94--102",
  month        = mar,
  keywords     = "functional programming, abstract machines, control flow
    analysis, compiling, optimization, lazy evaluation, instruction set design,
    strictness analysis",
  abstract     = "The declarative nature of functional programming languages
    causes many difficulties in their efficient implementation on conventional
    machines.  The problem is much harder when the language has non-strict
    (lazy) semantics.  Abstract machines serve as an intellectual aid in
    bridging the semantic gap between such languages and the conventional von
    Neumann architecture.  However they become more and more complex with time
    as efficiency considerations force the instruction set of the machine to
    grow in size.  In this paper we explain the phenomenon in context of the
    Three Instruction Machine (TIM).  We then define a rationalized instruction
    set for TIM that allows us to view all enhancements to TIM in a uniform
    way.  This instruction set is quite close to RISC instructions and clearly
    identifies the key operations on closures.  Translation of functional
    programs to our rationalized instruction set opens up scope for various
    local and global optimizations.  We illustrate this by showing how to build
    control flow graphs and perform optimizations on it.  Lazy arguments in
    functional programs make it hard to predict evaluation order statistically.
    We define the notion of pseudo-lazy arguments to statically expose the
    control flow information, wherever possible, for doing better flow
    analysis.", 
  location     = "https://doi.org/10.1145/202529.202539"
}

@Article{atsfoiitjbl,
  author       = "Freund, Stephen~N. and Mitchell, John~C.",
  title        = "{A} Type System for Object Initialization in the {J}ava Bytecode Language",
  journal      = toplas,
  year         = 1999,
  volume       = 21,
  number       = 6,
  pages        = "1196--1250",
  month        = nov,
  keywords     = "bytecode language, java, object initialization, type
    checking",
  abstract     = "In the standard Java implementation, a Java language program
    is compiled to Java bytecode.  This bytecode may be sent across the network
    to another site, where it is then interpreted by the Java Virtual Machine.
    Since bytecode may be written by hand, or corrupted during network
    transmission, the Java Virtual Machine contains a bytecode verifier that
    performs a number of consistency checks before code is interpreted.  As
    illustrated by previous attacks on the Java Virtual Machine, these tests,
    which include type correctness, are critical for system security.  In order
    to analyze existing bytecode verifiers and to understand the properties
    that should be verified, we develop a precise specification of
    statically-correct Java bytecode, in the form of a type system.  Our focus
    in this paper is a subset of the bytecode language dealing with object
    creation and initialization.  For this subset, we prove that for every Java
    bytecode program that satisfies our typing constraints, every object is
    initialized before it is used.  The type system is easily combined with a
    previous system developed by Stata and Abadi for bytecode subroutines.  Our
    analysis of subroutines and object initialization reveals a previously
    unpublished bug in the Sun JDK bytecode verifier.", 
  location     = "https://doi.org/10.1145/330643.330646"
}

@Article{issdmifisd,
  author       = "Richard Baskerville",
  title        = "Information Systems Security Design Methods:  Implications for Information Systems Development",
  journal      = surveys,
  year         = 1993,
  volume       = 25,
  number       = 4,
  pages        = "375--414",
  month        = dec,
  abstract     = "The security of information systems is a serious issue
    because computer abuse is increasing.  It is important, therefore, that
    systems analysts and designers develop expertise in methods for specifying
    information systems security.  The characteristics found in three
    generations of general information system design methods provide a
    framework for comparing and understanding current security design methods.
    These methods include approaches that use checklists of controls, divide
    functional requirements into engineering partitions, and create abstract
    models of both the problem and the solution.  Comparisons and contrasts
    reveal that advances in security methods lag behind advances in general
    systems development methods.  This analysis also reveals that more general
    methods fail to consider security specifications rigorously.", 
  keywords     = "checklists, control integrity, risk analysis, safety,
    structured systems analysis and design, system modeling",
  location     = "https://doi.org/10.1145/162124.162127"
}

@Article{hmmbawa,
  author       = "Blume, Matthias and Appel, Andrew~W.",
  title        = "Hierarchical Modularity",
  journal      = toplas,
  year         = 1999,
  volume       = 21,
  number       = 4,
  pages        = "813--847",
  month        = jul,
  keywords     = "compilation management, linking, modularity, modules, name
    visibility, program structure",
  abstract     = "To cope with the complexity of very large systems, it is not
    sufficient to divide them into simple pieces because the pieces themselves
    will either be too numerous or too large.  A hierarchical modular structure
    is the natural solution.  In this article we explain how that approach can
    be applied to software.  Our compilation manager provides a language for
    specifying where individual modules fit into a hierarchy and how they are
    related semantically.  We pay particular attention to the structure of the
    global name space of program identifiers that are used for module linkage
    because any potential for name clashes between otherwise unrelated parts of
    a program can negatively affect modularity.  We discuss the theoretical
    issues in building software hierarchically, and we describe our
    implementation of CM, the compilation manager for Standard ML of New
    Jersey.", 
  location     = "https://doi.org/10.1145/325478.325518",
  location     = "http://people.cs.uchicago.edu/~blume/papers/cm-TOPLAS.pdf"
}

@Article{xaytilot,
  author       = "O'Brien, Kevin and O'Brien, Kathryn~M. and Hopkins, Martin and Shepherd, Arvin and Unrau, Ron",
  title        = "{XIL} and {YIL}:  The Intermediate Languages of {TOBEY}",
  journal      = sigplan # ir95,
  year         = 1995,
  volume       = 30,
  number       = 3,
  pages        = "71--82",
  month        = mar,
  keywords     = "intermediate languages, canonical representations, code
    optimization, compiler back-ends", 
  abstract     = "Typically, the choice of intermediate representation by a 
    particular compiler implementation seeks to address a specific goal.  The
    intermediate language of the TOBEY compilers, XIL, was initially chosen to
    facilitate the production of highly optimal scalar code, yet, it was easily
    extended to a higher level form YIL in order to support a new suite of
    optimizations which in most existing compilers are done at the level of
    source to source translation.  In this paper we will discuss those design
    features of XIL that were important factors in the production of optimal
    scalar code.  In addition we will demonstrate how the strength of the YIL
    abstraction lay in its ability to access the underlying low level
    representation.", 
  location     = "https://doi.org/10.1145/202529.202537"
}

@Article{sbmwobdd,
  author       = "Bryant, Randal~E.",
  title        = "Symbolic {B}oolean Manipulation with Ordered Binary-Decision Diagrams",
  journal      = surveys,
  year         = 1992,
  volume       = 24,
  number       = 3,
  pages        = "293--319",
  month        = sep,
  keywords     = "binary-decision diagrams, boolean functions, boolean algebra,
    branching programs, symbolic analysis, symbolic manipulation",
  abstract     = "Ordered Binary-Decision Diagrams (OBDDs) represent Boolean
    functions as directed acyclic graphs.  They form a canonical
    representation, making testing of functional properties such as
    satisfiability and equivalence straightforward.  A number of operations on
    Boolean functions can be implemented as graph algorithms on OBDD data
    structures.  Using OBDDs, a wide variety of problems can be solved through
    symbolic analysis.  First, the possible variations in system parameters and
    operating conditions are encoded with Boolean variables.  Then the system
    is evaluated for all variations by a sequence of OBDD operations.
    Researchers have thus solved a number of problems in digital-system design,
    finite-state system analysis, artificial intelligence, and mathematical
    logic.  This paper describes the OBDD data structure and surveys a number
    of applications that have been solved by OBDD-based symbolic analysis.", 
  location     = "https://doi.org/10.1145/136035.136043",
  location     = "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1217&context=compsci"
}

@Manual{tlt,
  title        = "The \LaTeX{}2HTML Translator",
  author       = "Nikos Drakos",
  organization = "Computer Based Learning Unit, University of Leeds",
  year         = 1996,
  month        = "7 " # jun,
  keywords     = "latex, html, documentation",
  location     = "http://www.latex2html.org/"
}

@TechReport{apapssewm,
  author       = "Ernst~W. Mayr and Richard~J. Anderson and Peter~H. Hochschild", 
  title        = "{A} Programming and Problem-Solving Seminar",
  institution  = csd # "Stanford University",
  year         = 1985,
  number       = "CS-TR-85-1072",
  address      = sca,
  month        = oct,
  keywords     = "integer bricks, scheduling, presburger arithmetic, graphics,
    parallel computation bottelnecks",
  abstract     = "This report contains edited transcripts of the discussions
    held in Stanford's course CS204, Problem Seminar, during winter quarter
    1984.  The course topics consisted of five problems coming from different
    areas of computer science.  The problems were discussed in class and solved
    and programmed by the students working in teams.", 
  location     = "http://i.stanford.edu/TR/CS-TR-85-1072.html"
}

@TechReport{mmlo,
  author       = "Sergei Romanenko and Peter Setsoft",
  title        = "Moscow {ML} Language Overview",
  institution  = "Russian Academy of Sciences",
  year         = 1996,
  address      = "Moscow, Russia",
  month        = "1 " # jul,
  keywords     = "ml, functional programming",
  abstract     = "This is a compact reference to the language implemented by
    Moscow ML, a subset of Standard ML.  For reference material on Standard ML,
    see Milner, Tofte, Harper and MacQueen: The Definition ofStandard ML, The
    MIT Press 1997.  Moscow ML implements parts of the SML Basis Library.
    Section 14 of this manual lists all structure, type, constructor, value,
    function, and exception identifiers defined by Moscow ML.", 
  location     = "https://pdfs.semanticscholar.org/b3b9/88556dbe706cf1ab8cd6e0a95c36a04ad93f.pdf"
}

@TechReport{hefim,
  author       = "Steven Deering",
  title        = "Host Extensions for {IP} Multicasting",
  institution  = "Network Working Group",
  year         = 1989,
  type         = "Request for Comment",
  number       = 1112,
  address      = "Stanford University",
  abstract     = "This memo specifies the extensions required of a host
    implementation of the Internet Protocol (IP) to support multicasting.  It
    is the recommended standard for IP multicasting in the Internet.
    Distribution of this memo is unlimited.", 
  month        = aug,
  keywords     = "ip, multicasting, host group addresses, multicast ip
    datagrams, internet group management protocol",
  location     = "https://www.rfc-editor.org/rfc/pdfrfc/rfc1112.txt.pdf"
}

@TechReport{t7p,
  author       = "David Gries",
  title        = "The 711 Problem",
  institution  = dcs # "Cornell University",
  year         = 1982,
  number       = "82-493",
  address      = "Cornell, N.Y.",
  month        = may,
  keywords     = "puzzles, pascal, saddle-back search",
  abstract     = "Write a program that, given two positive integer M and N,
    will find 4 integers, called b, c, d, and e, satisfying (1) 0 <= b, c, d, e
    <= N, (2) b + c + d + e = M, and (3) b*c*d*e = M.  Call such a tuple (b, c,
    d, e) a solution.  If no solution exist, indicate that in some fashion.",
  location     = "https://ecommons.cornell.edu/handle/1813/6333"
}

@TechReport{otctbuidtis,
  author       = "David Garlan and Gail Kaiser and David Notkin",
  title        = "On the Criteria To Be Used In Composing Tools Into Systems",
  institution  = "Tektronix Laboratories",
  year         = 1988,
  number       = "TR 88-08-09",
  month        = aug,
  keywords     = "system decomposition, tools, shared data structures, abstract
    data types"
}

@TechReport{itl,
  author       = "Christopher~W. Fraser and David~R. Hanson",
  title        = "Installing {\tt lcc}",
  institution  = "AT\&T Bell Laboratories",
  year         = 1992,
  address      = mhnj,
  month        = "15 " # sep,
  keywords     = "lcc, compilers, c",		  
  location     = "http://drh.github.io/lcc/current/doc/install.html"
}

@TechReport{tblcr,
  author       = "Piti Disyatat",
  title        = "The Bank Lending Channel Revisited",
  institution  = "Bank for International Settlements",
  year         = 2010,
  type         = "BIS Working Papers",
  number       = 297,
  address      = "Basel, Switzerland",
  month        = feb,
  keywords     = "monetary policy, bank lending,channel, bank capital, credit,
    money", 
  abstract     = "A central proposition in research on the role that banks play
    in the transmission mechanism is that monetary policy imparts a direct
    impact on deposits and that deposits, insofar as they constitute the supply
    of loanable funds, act as the driving force of bank lending.  This paper
    argues that the emphasis on policy-induced changes in deposits is
    misplaced.  A reformulation of the bank lending channel is proposed that
    works primarily through the impact of monetary policy on banks' balance
    sheet strength and risk perception.  Such a recasting implies, contrary to
    conventional wisdom, that greater reliance on market-based funding enhances
    the importance of the channel.  The framework also shows how banks,
    depending on the strength of their balance sheets, could act either as
    absorbers or amplifiers of shocks originating in the financial system.", 
  location     = "http://www.bis.org/publ/work297.htm"
}

@TechReport{crmtr,
  author       = "Barbara Liskov and Russell Atkinson and Toby Bloom and Eliot
  Moss and J.~Craig Shaffert and Robert Scheifler and Alan Snyder",
  title        = "{CLU} Reference Manual",
  institution  = lcs # mit,
  month        = oct,
  year         = 1979,
  number       = "MIT-LCS-TR-225",
  address      = cama,
  keywords     = "clu, data abstraction, programming language",
  abstract     = "This document serves both as an introduction to CLU and as a
    language reference manual.  Sections 1 through 4 present an overview of the
    language.  These sections highlight the essential features of CLU, and
    discuss how CLU differs from other, more conventional, languages.",
  location     = "http://publications.csail.mit.edu/lcs/specpub.php?id=793"
}

@TechReport{tdotepl,
  author       = "Richardson, Joel E. and Carey, Michael J. and Schuh, Daniel T.",
  title        = "The Design of the {E} Programming Language",
  institution  = dcs # uwisc,
  year         = 1989,
  number       = "TR 824",
  address      = madw,
  keywords     = "database languages, iterators, persistance, schemas, c++",
  abstract     = "E is an extension of C++ designed for writing software 
    systems to support persistent applications.  Originally designed as a
    language for implementing database systems, E has evolved into a general
    persistent programming language.  E was the first C++ extension to support
    transparent persistence, the first C++ implementation to support generic
    classes, and remains the only C++ extension to provide general-purpose
    iterators.  In addition to its contributions to the C++ programming domain,
    work on E has made several contributions to the file of persistent
    languages in general, including several distinct implementations of
    persistence.  This paper describes the main features of E and shows through
    examples how E addresses many of the problems that arise in building
    persistent systems.", 
  location     = "https://minds.wisconsin.edu/handle/1793/59078"
}

@TechReport{bvcufpdcfdia,
  author       = "FBI",
  title        = "Bitcoin Virtual Currency:  Unique Features Present Distinct Challenges for Deterring Illicit Activity",
  institution  = "Cyber Intelligence and Criminal Intelligence Sections, Directorate of Intelligence, FBI",
  year         = 2012,
  type         = "Intelligence Assessment",
  month        = "24 " # apr,
  keywords     = "bitcoin, malware, money services business, money transmitter,
    peer-to-peer networking, public key cryptography, real money, virtual
    currency, zeus trojan",
  location     = "https://cryptome.org/2012/05/fbi-bitcoin.pdf"
}

@TechReport{lmpr,
  author       = "Alan Bawden and Richard Greenblatt and Jack Holloway and Thomas Knight and David Moon and Daniel Weinreb",
  title        = "{LISP} Machine Progress Report",
  institution  = "Artificial Intelligence Laboratory, " # mit,
  year         = 1977,
  type         = "Memo",
  number       = 444,
  address      = cma,
  month        = aug,
  keywords     = "implementation, system language, i/o, data representation,
    program representation, control structures, storage organization, editing",
  abstract     = "This informal paper introduces the LISP Machine, describes
    the goals and current status of the project, and explicates some of the key
    ideas.  It covers the LISP machine implementation, LISP as a system
    language, input/output, representation of data, representation of programs,
    control structures, storage organization, garbage collection, the editor,
    and the current status of the work.", 
  location     = "https://dspace.mit.edu/handle/1721.1/5751"
}

@InBook{cafpltam,
  author       = "Luca Cardelli",
  title        = "Combinators and Functional Programming Languages",
  chapter      = "The Amber Machine",
  publisher    = "Springer",
  year         = 1986,
  editor       = "G.~Cousineau and P.-L. Curien and B.~Robinet",
  pages        = "48--70",
  volume       = 242,
  series       = lncs,
  address      = "Berlin",
  keywords     = "virtual machines",
  keywords     = "The Amber machine is a stack machine designed as an
    intermediate language for compiling higher-order languages.  The current
    version is specialized for the Amber language.  The machine supports a set
    of basic and structured data types, functional closures, signals, bitmap
    graphics, persistent objects and meta-level execution.  The latter is
    needed as the Amber compiler is entirely written in Amber (above the Amber
    machine level) and needs to switch level when executing a program it has
    just compiled.  A set of implementation strategies are admissible for this
    machine, including byte-code interpretation, threaded code interpretation
    and compilation to native code.  The current implementation is based on a
    byte-code interpreter and a onespace compacting collector, and runs on a
    Macintosh.", 
  location     = "https://doi.org/10.1007/3-540-17184-3_39"
}
		  
@Misc{biftc,
  author       = "Kragen Javier Sitaker",
  OPTtitle     = "Bytecode Interpreters for Tiny Computers",
  howpublished = "mailing list",
  year         = 2007,
  month        = sep,
  keywords     = "squeak, smalltalk, basic, p-code, byte codes, forth picbit",
  location     = "http://www.wulfden.org/downloads/Forth_Resources/ByteCodeInterpretters_4_TinyComputers.pdf"
}

@Misc{fuuar,
  author       = "Danny Yoo",
  title        = "F*dging Up a Racket",
  howpublished = "{\tt hashcollision.org}",
  keywords     = "racket, brainfuck, language implementation, planet",
  location     = "http://www.hashcollision.org/brainfudge/"
}

@Misc{htoyt,
  author       = "John~W. Chinneck",
  title        = "How to Organize Your Thesis",
  howpublished = "Web page",
  year         = 1999,
  month        = "29 " # sep,
  keywords     = "thesis, research",
  location     = "http://www.sce.carleton.ca/faculty/chinneck/thesis.html"
}

