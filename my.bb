.so bibtex.header
		  
@Article{pvsame,
  author       = "Boehm, Barry~W. and Gray, Terence~E. and Seewaldt, Thomas",
  title        = "Prototyping Versus Specifying:  {A} Multiproject Experiment",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 3,
  pages        = "290-302",
  month        = may,
  keywords     = "prototyping, specifying, requirements analysis, software
    engineering, software engineering education, software management, software
    metrics, cocomo, user interfaces",
  abstract     = "In this experiment, seven software teams developed versions
    of the same small-size (2000-4000 source instruction) application software
    product.  Four teams used the Specifying approach.  Three teams used the
    Prototyping approach.  The main results of the experiment were the
    following.  1) Prototyping yielded products with roughly equivalent
    performance, but with about 40 percent less code and 45 percent less
    effort.  2) The prototyped products rated somewhat lower on functionality
    and robustness, but higher on ease of use and ease of learning.  3)
    Specifying produced more coherent designs and software that was easier to
    integrate.  The paper presents the experimental data supporting these and a
    number of additional conclusions.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010238"
}
@Article{acsosapbhfi,
  author       = "Arnold, Matthew and Fink, Stephen and Sarkar, Vivek and Sweeney, Peter~F.",
  title        = "{A} Comparative Study of Static and Profile-Based Heuristics for Inlining",
  journal      = sigplan # " (" # pot # "Workshop on Dynamic and Adaptive
		  Compilation and Optimization - Dynamo '00)",
  year         = 2000,
  volume       = 35,
  number       = 7,
  pages        = "52--64",
  month        = jul,
  keywords     = "call graphs, inlining, program optimization, static analysis,
    dynamic analysis",
  abstract     = "In this paper, we present a comparative study of static and 
    profile-based heuristics for inlining.  Our motivation for this study is to
    use the results to design the best inlining algorithm that we can for the
    Jalapeño dynamic optimizing compiler for Java [6].  We use a well-known
    approximation algorithm for the KNAPSACK problem as a common
    “meta-algorithm” for the inlining heuristics studied in this paper.  We
    present performance results for an implementation of these inlining
    heuristics in the Jalapeño dynamic optimizing compiler.  Our performance
    results show that the inlining heuristics studied in this paper can lead to
    significant speedups in execution time (up to 1.68x) even with modest
    limits on code size expansion (at most 10%).",  
  location     = "http://dx.doi.org/10.1145/351403.351416"
}

@Article{cfsrmc,
  author       = "Iannino, Anthony and Musa, John~D. and Okumoto, Kazuhira and Littlewood, Bev",
  title        = "Criteria for Software Reliability Model Comparisons",
  journal      = tse,
  year         = 1983,
  volume       = 8,
  number       = 3,
  pages        = "12--16",
  month        = jul,
  keywords     = "model comparisons, predictive validity, software failures,
    software reliability, capability, assumption quality, applicability,
    simplicity",
  abstract     = "A set of criteria is proposed for the comparison of software
    reliability models.  The intention is to provide a logically organized
    basis for determining the superior models and for the presentation of model
    characteristics.  It is hoped that in the future, a software manager will
    be able to more easily select the model most suitable for his/her
    requirements from among the preferred ones.", 
  location     = "http://dx.doi.org/10.1145/1010891.1010893"
}

@Article{dotpedm,
  author       = "Barach, David~R. and Taenzer, David~H. and Wells, Robert~E.",
  title        = "Design of the {PEN} Editor Display Module",
  journal      = sotm,
  year         = 1981,
  volume       = 16,
  number       = 6,
  pages        = "130--136",
  month        = jun,
  keywords     = "software design, terminal handling, optimization",
  abstract     = "PEN, a new portable video editor, uses a number of simple but
    effective techniques.  Most are not new, but are unavailable in the
    literature.  We will describe our goals for PEN's display module, discuss
    implementation alternatives and describe in detail the techniques used in
    the editor.", 
  location     = "http://dx.doi.org/10.1145/800209.806464"
}
@Book{dsdi,
  author       = "Daniel~C. Dennett",
  title        = "Darwin's Dangerous Idea",
  publisher    = "Simon \& Schuster",
  year         = 1995,
  address      = nyny,
  keywords     = "evolution, darwin, scientific debate",
  location     = "QH 375 D45"
}

@Article{rtpt,
  author       = "Thomas~H. {Cheatham, Jr.}",
  title        = "Reusability Through Program Transformation",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 5,
  pages        = "574--588",
  month        = sep,
  keywords     = "programming environments, porgram transformations, rapid
    prototyping, reusability, specification languages",
  abstract     = "We describe a methodology and supporting programming
    environment that provide for reuse of abstract programs.  Abstract programs
    are written using notations and constructs natural to the problem domain in
    a language realized by syntactic extension of a base language.  Program
    transformations are employed to refine an abstract program into its
    concrete counterpart.  We discuss the use of the methodology in the setting
    of rapid prototyping and custom tailoring.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010282"
}

@Article{arajg,
  author       = "James Gosling",
  title        = "{A} Redisplay Algorithm",
  journal      = sotm,
  year         = 1981,
  volume       = 16,
  number       = 6,
  pages        = "123--129",
  month        = jun,
  keywords     = "dynamic programming",
  abstract     = "This paper presents an algorithm for updating the image
    displayed on a conventional video terminal.  It assumes that the terminal
    is capable of doing the usual insert/delete line and insert/delete
    character operations.  It takes as input a description of the image
    currently on the screen and a description of the new image desired and
    produces a series of operations to do the desired transformation in a
    near-optimal manner.  The algorithm is interesting because it applies
    results from the theoretical string-to-string correction problem (a
    generalization of the problem of finding a longest common subsequence), to
    a problem that is usually approached with crude ad-hoc techniques.", 
  location     = "http://dx.doi.org/10.1145/872730.806463"
}

@Article{otlbpitf,
  author       = "Achugbue, James~O.",
  title        = "On the Line Breaking Problem in Text Formatting",
  journal      = sotm,
  year         = 1981,
  volume       = 16,
  number       = 6,
  pages        = "117--122",
  month        = jun,
  keywords     = "line breaking, text formatting, dynamic programming",
  abstract     = "A basic problem in text formatting is that of determining the
    break points for separating a string of words into lines to obtain a
    formatted paragraph.  When formatted text is required to be aligned with
    both the left and right margins, the choice of break points greatly affects
    the quality of the formatted document.  This paper presents and discusses
    solutions to the line breaking problem.  These include the usual
    line-by-line method, a dynamic programming approach, and a new algorithm
    which is optimal and runs almost as fast as the line-by-line method.", 
  location     = "http://dx.doi.org/10.1145/800209.806462"
}

@Article{esopk,
  author       = "Soloway, Elliot and Ehrlich, Kate",
  title        = "Emperical Studies of Programming Knowledge",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 5,
  pages        = "595--609",
  month        = sep,
  keywords     = "cognitive models of programming, novice/expert differences,
    program comprehension, software psychology",
  abstract     = "We suggest that expert programmers have and use two types of 
    programming knowledge: 1) programming plans, which are generic program
    fragments that represent stereotypic action sequences in programming, and
    2) rules of programming discourse, which capture the conventions in
    programming and govern the composition of the plans into programs.  We
    report here on two empirical studies that attempt to evaluate the above
    hypothesis.  Results from these studies do in fact support our claim.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010283"
}

@Article{prtpt,
  author       = "Boyle, James~M. and Muralidharan, Monagur~N.",
  title        = "Program Reusability through Program Transformation",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 5,
  pages        = "574--588",
  month        = sep,
  keywords     = "abstract programming, canonical forms, optimization, program
    transformation, pure applicative lisp, rewrite rules, stepwise refinement,
    tampr",
  abstract     = "How can a program written in pure applicative LISP be reused
    in a Fortran environment? One answer is by automatically transforming it
    from LISP into Fortran.  In this paper we discuss a practical application
    of this technique-one that yields an efficient Fortran program.  We view
    this process as an example of abstract programming, in which the LISP
    program constitutes an abstract specification for the Fortran version.  The
    idea of strategy-a strategy for getting from LISP to Fortran-is basic to
    designing and applying the transformations.  One strategic insight is that
    the task is easier if the LISP program is converted to ``recursive''
    Fortran, and then the recursive Fortran program is converted to
    nonrecursive standard Fortran.  Another strategic insight is that much of
    the task can be accomplished by converting the program from one canonical
    form to another.  Developing a strategy also involves making various
    implementation decisions.  One advantage of program transformation
    methodology is that it exposes such decisions for examination and review.
    Another is that it enables optimizations to be detected and implemented
    easily.  Once a strategy has been discovered, it can be implemented by
    means of rewrite-rule transformations using the TAMPR program
    transformation system.  The transformational approach to program reuse
    based on this strategy has a measure of elegance.  It is also practical-the
    resulting Fortran program is 25 percent faster than its compiled LISP
    counterpart, even without extensive optimization.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010281"
}

@Article{tioeaiaidps,
  author       = "Hammer, Michael and Ilson, Richard and Anderson, Tim and Gilbert, Edward and Good, Michael and Niamir, Bahram and Rosentein, Larry and Schoichet, Sandor",
  title        = "The Implementation of {E}tude, An integrated and Interactive Document Production System",
  journal      = sotm,
  year         = 1981,
  volume       = 16,
  number       = 6,
  pages        = "117--122",
  month        = jun,
  keywords     = "software design, user-interface design, document
    representation",
  abstract     = "Etude is an experimental text processing system that is being
    developed in order to formulate and evaluate new approaches to the design
    of user interfaces for office automation tools.  The primary design goal
    for Etude is to provide the user with substantial functionality in the
    editing and formatting of documents in the context of a system that is easy
    to learn and use.", 
  location     = "http://dx.doi.org/10.1145/800209.806465"
}

@Article{aisercdcall,
  author       = "Ben-David, Amram and Ben-Porath, Moshe~I. and Loeb, Jonah~Z. and Rich, Michael",
  title        = "An Industrial Software Engineering Retraining Course:  Development Considerations and Lessons Learned",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "748--755",
  month        = nov,
  keywords     = "",
  abstract     = "Israel Aircraft Industries has recently been conducting a novel
    six-month intensive course to retrain practicing engineers to become
    software engineers working on embedded computer systems.  The first course
    was concluded in January 1982 and the second course began in November 1982.
    This paper describes the objectives, educational philosophy, course
    content, and practical experience of the first course.  It also describes
    how the second course was modified as a result of the lessons learned from
    the successes and failures of the first course.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010303"
}

@Article{acgpoi,
  author       = "Corrigan, Neil~B. and Starkey, J.~Denbigh",
  title        = "{A} Concurrent General Purpose Operator Interface",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "738--748",
  month        = nov,
  keywords     = "computer graphics, concurrent pascal, concurrent programming,
    interactive system, man-machine interface, operator interface, process
    control",
  abstract     = "Compact interactive control consoles are rephcing traditional
    control rooms as operator interfaces for physical processes.  In the irust
    major application of concurrent programming outside the area of operating
    systems, this paper presents a design for a general purpose operator
    interface which uses a color graphics terminal with a touch-sensitive
    screen as the control console.  Operators interact with a process through a
    collection of application-dependent displays generated interactively by
    users familiar with the physical process.  The use of concurrent
    programming results in a straightforward and reliable design which may
    easily be extended to support multiple devices of varying types in the
    control console.  An implementation of the Operator Interface in Concurrent
    Pascal currently in progress is also discussed.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010302"
}

@Article{eoerbufcp,
  author       = "Kang~G. Shin and Yann-Hang Lee",
  title        = "Evaluation of Error Recovery Blocks Used for Cooperating Processes",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "692--700",
  month        = nov,
  keywords     = "backward error recovery, conversation scheme, domino effect,
    pseudorecovery points and line(s), recovery block(s), recovery line(s),
    rollback propagations",
  abstract     = "Three alternatives for implementing recovery blocks (RB's) 
    are conceivable for backward error recovery in concurrent processing.
    These are the asynchronous, synchronous, and the pseudorecovery point
    implementations.  Asynchronous RB's are based on the concept of maximum
    autonomy in each of concurrent processes.  Consequently, establishment of
    RB's in a process is made independently of others and unbounded rollback
    propagations become a serious problem.  In order to completely avoid
    unbounded rollback propagations, it is necessary to synchronize the
    establishment of recovery blocks in all cooperating processes.  Process
    autonomy is sacrificed and processes are forced to wait for commitments
    from others to establish a recovery line, leading to inefficiency in time
    utilization.  As a compromise between asynchronous and synchronous RB's we
    propose to insert pseudorecovery points (PRP's) so that unbounded rollback
    propagations may be avoided while maintaining process autonomy.  We
    developed probabilistic models for analyzing these three methods under
    standard assumptions in computer performance analysis, i.e., exponential
    distributions for related random variables.  With these models we have
    estimated 1) the interval between two successive recovery lines for
    asynchronous RB's, 2) mean loss in computation power for the synchronized
    method, and 3) additional overhead and rollback distance in case PRP's are
    used.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010298"
}

@Article{rtem,
  author       = "Bernhard Plattner",
  title        = "Real-Time Execution Monitoring",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "756--764",
  month        = nov,
  keywords     = "debugging, monitor, performance evaluation, process
    interaction, process monitor, real-time monitoring, timing",
  abstract     = "Today's programming methodology emphasizes the study of static
    aspects of programs.  In practice, however, monitoring a program in
    execution, i.e., monitoring a process, is routinely done by any programmer
    whose task it is to produce a reliable piece of software.  There are two
    reasons why one might want to examine the dynamic aspects of a program:
    first, to evaluate the performance of a program, and hence to assess its
    overall behavior; and second, to demonstrate the presence of programming
    errors, isolate erroneous program code, and correct it.  This latter task
    is commonly called ``debugging a program'' and requires a detailed insight
    into the innards of a program being executed.  Today, many computer systems
    are being used to measure and control real-world processes.  The pace of
    execution of these systems and their control programs is therefore bound to
    timing constraints imposed by the real-world process.  As a step towards
    solving the problems associated with execution monitoring of real-time
    programs, we develop a set of appropriate concepts and define the basic
    requirements for a real-time monitoring facility.  As a test case for the
    theoretical treatment of the topic, we design hardware and software for an
    experimental real-time monitoring system and describe its implementation.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010304"
}

@Article{dcobnfgpc,
  author       = "Alan Mainwaring and David~E. Culler",
  title        = "Design Challenges of Virtual Networks:  Fast, General-Purpose Communication",
  journal      = ppopp99,
  year         = 1999,
  volume       = 34,
  number       = 8,
  pages        = "119--130",
  month        = aug,
  keywords     = "virtual networks, high-performance clusters, direct network
    access, application programming interfaces, system resource management,
    protocol architecture and implementation",
  abstract     = "Virtual networks provide applications with the illusion of 
    having their own dedicated, high-performance networks, although network
    interfaces posses limited, shared resources.  We present the design of a
    large-scale virtual network system and examine the integration of
    communication programming interface, system resource management, and
    network interface operation.  Our implementation on a cluster of 100
    workstations quantifies the impact of virtualization on small message
    latencies and throughputs, shows full hardware performance is delivered to
    dedicated applications and time-shared workloads, and shows robust
    performance under demanding workloads that overcommit interface
    resources.", 
  location     = "http://dx.doi.org/10.1145/329366.301115"
}

@Article{aeiojsrmi,
  author       = "Maassen, Jason and {van Nieuwpoort}, Rob and Veldema, Ronald and Bal, Henri~E. and Plaat, Aske",
  title        = "An Efficient Implementation of {J}ava's {R}emote {M}ethod {I}nvocation",
  journal      = ppopp99,
  year         = 1999,
  volume       = 34,
  number       = 8,
  pages        = "173--182",
  month        = aug,
  keywords     = "java, rmi, performance, native-code compilation",
  abstract     = "Java offers interesting opportunities for parallel computing.
    In particular, Java Remote Method Invocation provides an unusually flexible
    kind of Remote Procedure Call.  Unlike RPC, RMI supports polymorphism,
    which requires the system to be able to download remote classes into a
    running application.  Sun's RMI implementation achieves this kind of
    flexibility by passing around object type information and processing it at
    run time, which causes a major run time overhead.  Using Sun's JDK 1.1.4 on
    a Pentium Pro/Myri.net cluster, for example, the latency for a null RMI
    (without parameters or a return value) is 1228 &mu;sec, which is about a
    factor of 40 higher than that of a user-level RPC.  In this paper, we study
    an alternative approach for implementing RMI, based on native compilation.
    This approach allows for better optimization, eliminates the need for
    processing of type information at run time, and makes a light weight
    communication protocol possible.  We have built a Java system based on a
    native compiler, which supports both compile time and run time generation
    of marshallers.  We find that almost all of the run time overhead of RMI
    can be pushed to compile time.  With this approach, the latency of a null
    RMI is reduced to 34 &mu;sec, while still supporting polymorphic RMIs (and
    allowing interoperability with other JVMs).", 
  location     = "http://dx.doi.org/10.1145/301104.301120"
}

@Article{cmobst,
  author       = "Udi Manber",
  title        = "Concurrent Maintenance of Binary Search Trees",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "777--784",
  month        = nov,
  keywords     = "concurrent algorithms, data structures, distributed
    algorithms, locking, transactions, trees",
  abstract     = "The problem of providing efficient concurrent access for 
    independent processes to a dynamic search structure is the topic of this
    paper.  We develop concurrent algorithms for search, update, insert, and
    delete in a simple variation of binary search trees, called external trees.
    The algorithm for deletion, which is usually the most difficult operation,
    is relatively easy in this data structure.  The advantages of the data
    structure and the algorithms are that they are simple, flexible, and
    efficient, so that they can be used as a part in the design of more
    complicated concurrent algorithms where maintaining a dynamic search
    structure is necessary.  In order to increase the efficiency of the
    algorithms we introduce maintenance processes that independently reorganize
    the data structure and relieve the user processes of nonurgent operations.
    We also discuss questions of transactions in a dynamic environment and
    replicated copies of the data structure.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010306"
}

@Article{mfdabiat,
  author       = "Steven~M. German",
  title        = "Monitoring for Deadlock and Blocking in {A}da Tasking",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "764--777",
  month        = nov,
  keywords     = "concurrent algorithms, concurrent programming languages,
    correctness proofs of concurrent programs, deadlock detection, exceptions,
    program transformations, semantics of ada tasking, state graph models, task
    identifiers", 
  abstract     = "We present a deadlock monitoring algorithm for Ada tasking
    programs which is based on transforming the source program.  The
    transformations introduce a new task called the monitor, which receives
    information from all other tasks about their tasking activities.  The
    monitor detects deadlocks consisting of circular entry calls as well as
    some noncircular blocking situations.  The correctness of the program
    transformations is formulated and proved using an operational state graph
    model of tasking.  The main issue in the correctness proof is to show that
    the deadlock monitor algorithm works correctly without having simultaneous
    information about the state of the program.  In the course of this work, we
    have developed some useful techniques for programming tasking applications,
    such as a method for uniformly introducing task identifiers.  We argue that
    the ease of finding and justifying program transformations is a good test
    of the generality and uniformity of a programming language.  The complexity
    of the full Ada language makes it difficult to safely apply
    transformational methods to arbitrary programs.  We discuss several
    problems with the current semantics of Ada's tasks.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010305"
}

@Article{apodaca,
  author       = "Rugina, Radu and Rinard, Martin",
  title        = "Automatic Parallelization of Divide and Conquer Algorithms",
  journal      = ppopp99,
  year         = 1999,
  volume       = 34,
  number       = 8,
  pages        = "72--83",
  month        = aug,
  keywords     = "parallelization, region analysis, pointer analysis, bounds
    analysis, initial value analysis, correlation analysis",
  abstract     = "Divide and conquer algorithms are a good match for modern
    parallel machines: they tend to have large amounts of inherent parallelism
    and they work well with caches and deep memory hierarchies.  But these
    algorithms pose challenging problems for parallelizing compilers.  They are
    usually coded as recursive procedures and often use pointers into
    dynamically allocated memory blocks and pointer arithmetic.  All of these
    features are incompatible with the analysis algorithms in traditional
    parallelizing compilers.This paper presents the design and implementation
    of a compiler that is designed to parallelize divide and conquer algorithms
    whose subproblems access disjoint regions of dynamically allocated arrays.
    The foundation of the compiler is a flow-sensitive, context-sensitive, and
    interprocedural pointer analysis algorithm.  A range of symbolic analysis
    algorithms build on the pointer analysis information to extract symbolic
    bounds for the memory regions accessed by (potentially recursive)
    procedures that use pointers and pointer arithmetic.  The symbolic bounds
    information allows the compiler to find procedure calls that can execute in
    parallel without violating the data dependences.  The compiler generates
    code that executes these calls in parallel.  We have used the compiler to
    parallelize several programs that use divide and conquer algorithms.  Our
    results show that the programs perform well and exhibit good speedup.", 
  location     = "http://dx.doi.org/10.1145/329366.301111"
}

@Article{amfcvsed,
  author       = "Victor~R. Basili and David~M. Weiss",
  title        = "A Methodology for Collecting Valid Software Engineering Data",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "728--738",
  month        = nov,
  keywords     = "data collection, data collection methodology, error analysis,
    error classification, software engineering experiments",
  abstract     = "An effective data collection method for evaluating software
    development methodologies and for studying the software development process
    is described.  The method uses goal-directed data collection to evaluate
    methodologies with respect to the claims made for them.  Such claims are
    used as a basis for defining the goals of the data collection, establishing
    a list of questions of interest to be answered by data analysis, defining a
    set of data categorization schemes, and designing a data collection form.
    The data to be collected are based on the changes made to the software
    during development, and are obtained when the changes are made.  To ensure
    accuracy of the data, validation is performed concurrently with software
    development and data collection.  Validation is based on interviews with
    those people supplying the data.  Results from using the methodology show
    that data validation is a necessary part of change data collection.
    Without it, as much as 50 percent of the data may be erroneous.
    Feasibility of the data collection methodology was demonstrated by applying
    it to five different projects in two different environments.  The
    application showed that the methodology was both feasible and useful.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010301",
  location     = "http://www.cs.umd.edu/projects/SoftEng/ESEG/papers/82.21.pdf"
}

@Article{bcafpp,
  author       = "Lee, Jaejin and Padua, David~A. and Midkiff, Samuel~P.",
  title        = "Basic Compiler Algorithms for Parallel Programs",
  journal      = ppopp99,
  year         = 1999,
  volume       = 34,
  number       = 8,
  pages        = "1--12",
  month        = aug,
  keywords     = "delay set analysis, concurrent control flow graphs,
    concurrent static single-assignment form, copy propagation, dead-code
    elimination, global value numbering, cse, ",
  abstract     = "Traditional compiler techniques developed for sequential
    programs do not guarantee the correctness (sequential consistency) of
    compiler transformations when applied to parallel programs.  This is
    because traditional compilers for sequential programs do not account for
    the updates to a shared variable by different threads.  We present a
    concurrent static single assignment (CSSA) form for parallel programs
    containing cobegin/coend and parallel do constructs and post/wait
    synchronization primitives.  Based on the CSSA form, we present copy
    propagation and dead code elimination techniques.  Also, a global value
    numbering technique that detects equivalent variables in parallel programs
    is presented.  By using global value numbering and the CSSA form, we extend
    classical common subexpression elimination, redundant load/store
    elimination, and loop invariant detection to parallel programs without
    violating sequential consistency.  These optimization techniques are the
    most commonly used techniques for sequential programs.  By extending these
    techniques to parallel programs, we can guarantee the correctness of the
    optimized program and maintain single processor performance in a
    multiprocessor environment.", 
  location     = "http://dx.doi.org/10.1145/301104.301105"
}

@Article{omfold,
  author       = "Stefanovi{\' c}, Darko and McKinley, Kathryn~S. and Moss, J.~Eliot~B.",
  title        = "On Models for Object Lifetime Distributions",
  journal      = sigplan # " (" # pot # " Second International Symposium on Memory Management, ISMM '00)",
  year         = 2001,
  volume       = 36,
  number       = 1,
  pages        = "137--142",
  month        = jan,
  keywords     = "object lifetimes, lifetime distributions, garbage collection
    modeling, storage management", 
  abstract     = "Analytical models of memory object lifetimes are appealing
    because having them would enable mathematical analysis or fast simulation
    of the memory management behavior of programs.  In this paper, we
    investigate models for object lifetimes drawn from programs in
    object-oriented languages such as Java and Smalltalk.  We present certain
    postulated analytical models and compare them with observed lifetimes for
    58 programs.  We find that observed lifetime distributions do not match
    previously proposed object lifetime models, but do agree in salient shape
    characteristics with the gamma distribution family used in statistical
    survival analysis for general populations.", 
  location     = "http://dx.doi.org/10.1145/362426.362477"
}

@Article{cdpmfs,
  author       = "Haj-Yihia, Jawad and Asher, Yosi Ben and Rotem, Efraim and Yasin, Ahmad and Ginosar, Ran",
  title        = "Compiler-Directed Power Management for Superscalars",
  journal      = "ACM Transactions on Architecture and Code Optimization",
  year         = 2015,
  volume       = 11,
  number       = 4,
  pages        = "48:1--48:21",
  month        = jan,
  keywords     = "static analysis, power management, power demand modeling, cpu
    architectures, power distribution networks",
  abstract     = "Modern superscalar CPUs contain large complex structures and
    diverse execution units, consuming wide dynamic power range.  Building a
    power delivery network for the worst-case power consumption is not energy
    efficient and often is impossible to fit in small systems.  Instantaneous
    power excursions can cause voltage droops.  Power management algorithms are
    too slow to respond to instantaneous events.  In this article, we propose a
    novel compiler-directed framework to address this problem.  The framework
    is validated on a 4th Generation Intel® Core™ processor and with simulator
    on output trace.  Up to 16% performance speedup is measured over baseline
    for the SPEC CPU2006 benchmarks.",
  location     = "http://dx.doi.org/10.1145/2685393"
}

@Article{oret,
  author       = "Ntafos, Simon~C.",
  title        = "On Required Element Testing",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "795--803",
  month        = nov,
  keywords     = "data-flow analysis, required element testing, testing
    strategies", 
  abstract     = "In this paper we introduce two classes of program testing
    strategies that consist of specifying a set of required elements for the
    program and then covering those elements with appropriate test inputs.  In
    general, a required element has a structural and a functional component and
    is covered by a test case if the test case causes the features specified in
    the structural component to be executed under the conditions specified in
    the functional component.  Data flow analysis is used to specify the
    structural component and data flow interactions are used as a basis for
    developing the functional component.  The strategies are illustrated with
    examples and some experimental evaluations of their effectiveness are
    presented.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010308"
}

@Article{iaotfgcfj,
  author       = "Domani, Tamar and Kolodner, Elliot~K. and Lewis, Ethan and
    Salant, Eliot~E. and Barabash, Katherine and Lahan, Itai and Levanoni,
    Yossi and Petrank, Erez and Yanorer, Igor", 
  title        = "Implementing an On-the-fly Garbage Collector for {J}ava",
  journal      = sigplan # " (" # pot # " Second International Symposium on Memory Management, ISMM '00)",
  year         = 2001,
  volume       = 36,
  number       = 1,
  pages        = "155--166",
  month        = jan,
  keywords     = "java, programming languages, memory management, garbage
    collection, concurrent garbage collection, on-the-fly garbage collection",
  abstract     = "Java uses garbage collection (GC) for the automatic
    reclamation of computer memory no longer required by a running application.
    GC implementations for Java Virtual Machines (JVM) are typically designed
    for single processor machines, and do not necessarily perform well for a
    server program with many threads running on a multiprocessor.  We designed
    and implemented an on-the-fly GC, based on the algorithm of Doligez, Leroy
    and Gonthier [13, 12] (DLG), for Java in this environment.  An on-the-fly
    collector, a collector that does not stop the program threads, allows all
    processors to be utilized during collection and provides uniform response
    times.  We extended and adapted DLG for Java (e.g., adding support for weak
    references) and for modern multiprocessors without sequential consistency,
    and added performance improvements (e.g., to keep track of the objects
    remaining to be traced).  We compared the performance of our implementation
    with stop-the-world mark-sweep GC.  Our measurements show that the
    performance advantage for our collector increases as the number of threads
    increase and that it provides uniformly low response times.", 
  location     = "http://dx.doi.org/10.1145/362426.362484"
}

@Article{upgist,
  author       = "Sirer, Emin G{\" u}n and Bershad, Brian~N.",
  title        = "Using Production Grammars in Software Testing",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "1--13",
  month        = jan,
  keywords     = "testing, virtual machines, production grammars, test
    generation, comparative testing, self-describing test cases",
  abstract     = "Extensible typesafe systems, such as Java, rely critically on
    a large and complex software base for their overall protection and
    integrity, and are therefore difficult to test and verify.  Traditional
    testing techniques, such as manual test generation and formal verification,
    are too time consuming, expensive, and imprecise, or work only on abstract
    models of the implementation and are too simplistic.  Consequently,
    commercial virtual machines deployed so far have exhibited numerous bugs
    and security holes.In this paper, we discuss our experience with using
    production grammars in testing large, complex and safety-critical software
    systems.  Specifically, we describe lava, a domain specific language we
    have developed for specifying production grammars, and relate our
    experience with using lava to generate effective test suites for the Java
    virtual machine.  We demonstrate the effectiveness of production grammars
    in generating complex test cases that can, when combined with comparative
    and variant testing techniques, achieve high code and value coverage.  We
    also describe an extension to production grammars that enables concurrent
    generation of certificates for test cases.  A certificate is a behavioral
    description that specifies the intended outcome of the generated test case,
    and therefore acts as an oracle by which the correctness of the tested
    system can be evaluated in isolation.  We report the results of applying
    these testing techniques to commercial Java implementations.  We conclude
    that the use of production grammars in combination with other automated
    testing techniques is a powerful and effective method for testing software
    systems, and is enabled by a special purpose language for specifying
    extended production grammars.", 
  location     = "http://dx.doi.org/10.1145/331963.331965"
}

@Article{ujrtaelp,
  author       = "Dale Parson",
  title        = "Using Java Reflection to Automate Extension Langugae Parsing",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "67--80",
  month        = jan,
  keywords     = "reflection, embedded languages, scripting languages, tcl,
    java, c++",
  abstract     = "An extension language is an interpreted programming language
    designed to be embedded in a domain-specific framework.  The addition of
    domain-specific primitive operations to an embedded extension language
    transforms that vanilla extension language into a domain-specific language.
    The LUxWORKS processor simulator and debugger from Lucent uses Tcl as its
    extension language.  After an overview of extension language embedding and
    LUxWORKS experience, this paper looks at using Java reflection and related
    mechanisms to solve three limitations in extension language - domain
    framework interaction.  The three limitations are gradual accumulation of
    ad hoc interface code connecting an extension language to a domain
    framework, over-coupling of a domain framework to a specific extension
    language, and inefficient command interpretation.  Java reflection consists
    of a set of programming interfaces through which a software module in a
    Java system can discover the structure of classes, methods and their
    associations in the system.  Java reflection and a naming convention for
    primitive domain operations eliminate ad hoc interface code by supporting
    recursive inspection of a domain command interface and translation of
    extension language objects into domain objects.  Java reflection,
    name-based dynamic class loading, and a language-neutral extension language
    abstraction eliminate language over-coupling by transforming the specific
    extension language into a run-time parameter.  Java reflection and command
    objects eliminate inefficiency by bypassing the extension language
    interpreter for stereotyped commands.  Overall, Java reflection helps to
    eliminate these limitations by supporting reorganization and elimination of
    handwritten code, and by streamlining interpretation.", 
  location     = "http://www.cs.tufts.edu/~nr/cs257/archive/dale-parson/dsl99lux.ps.gz"
}

@Article{aasohpaiv,
  author       = "Higashino, Teruo and Mori, Masaaki and Sugiyama, Yuji and Taniguchi, Kenichi and Kasami, Tadao",
  title        = "An Algebraic Specification of {HDLC} Procedures and Its Verification",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "825--836",
  month        = nov,
  keywords     = "algebraic specifications, church-rosser property, hdlc
    procedures, term rewriting system, verification",
  abstract     = "It is well known that algebraic specification methods are 
    promising for specifying programs and for verifying their various
    properties formally.  In this paper, an algebraic specification of
    information transfer procedures of high-level data link control (HDLC)
    procedures is presented and some of the main properties of the
    specification are shown.  First, we introduce abstract states, state
    transition functions, and output functions corresponding to elementary
    notions extracted from the description of HDLC procedures in ISO 3309-1979
    (E) and ISO 4335-1979 (E).  Second, we show axioms which represent the
    relations between the values of functions before and after the state
    transitions.  Then, it is proved that the specification is ``consistent,''
    ``sufficiently complete,'' and ``nonredundant.'' Also it is shown that an
    implementation which realizes the specification is naturally derived.  In
    the last section, verification of various properties of HDLC procedures is
    formulated in the same framework as the algebraic specification, and some
    verification examples are presented.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010311"
}

@Article{fra,
  author       = "Elliott, Conal and Hudak, Paul",
  title        = "Functional Reactive Animation",
  journal      = sigplan # " (" # pot # "Second ACM SIGPLAN International Conference on Functional Programming, ICFP '97)",
  year         = 1997,
  volume       = 32,
  number       = 8,
  pages        = "263--273",
  month        = aug,
  keywords     = "functional programming, reactive programming, animation",
  abstract     = "Fran (Functional Reactive Animation) is a collection of data
    types and functions for composing richly interactive, multimedia
    animations.  The key ideas in Fran are its notions of behaviors and events.
    Behaviors are time-varying, reactive values, while events are sets of
    arbitrarily complex conditions, carrying possibly rich information.  Most
    traditional values can be treated as behaviors, and when images are thus
    treated, they become animations.  Although these notions are captured as
    data types rather than a programming language, we provide them with a
    denotational semantics, including a proper treatment of real time, to guide
    reasoning and implementation.  A method to effectively and efficiently
    perform event detection using interval analysis is also described, which
    relies on the partial information structure on the domain of event times.
    Fran has been implemented in Hugs, yielding surprisingly good performance
    for an interpreter-based system.  Several examples are given, including the
    ability to describe physical phenomena involving gravity, springs,
    velocity, acceleration, etc.  using ordinary differential equations.", 
  location     = "http://dx.doi.org/10.1145/258949.258973"
}

@Article{dsec,
  author       = "Leijen, Daan and Meijer, Erik",
  title        = "Domain Specific Embedded Compilers",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "109--122",
  month        = jan,
  keywords     = "haskell, embedded languages, little languages, phantom
    types",
  abstract     = "Domain-specific embedded languages (DSELs) expressed in 
    higher-order, typed (HOT) languages provide a composable framework for
    domain-specific abstractions.  Such a framework is of greater utility than
    a collection of stand-alone domain-specific languages.  Usually, embedded
    domain specific languages are build on top of a set of domain specific
    primitive functions that are ultimately implemented using some form of
    foreign function call.  We sketch a general design pattern/or embedding
    client-server style services into Haskell using a domain specific embedded
    compiler for the server's source language.  In particular we apply this
    idea to implement Haskell/DB, a domain specific embdedded compiler that
    dynamically generates of SQL queries from monad comprehensions, which are
    then executed on an arbitrary ODBC database server.", 
  location     = "http://dx.doi.org/10.1145/331963.331977", 
  location     = "https://www.usenix.org/events/dsl99/full_papers/leijen/leijen.pdf"
}

@Article{shlrs,
  author       = "Dennis~W. Leinbaugh",
  title        = "Selectors: High-Level Resource Schedulers",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "810--825",
  month        = nov,
  keywords     = "nonprocedural langauge, process synchronization, protected
  resource, resource scheduling, resource sharing, starvation",
  abstract     = "Resource sharing problems can be described in three basically
    independent modular components.  The constraints the resource places upon
    sharing because of physcal limitations and consistency requirements.  The
    desired ordering of resource requests to achieve efficiency-either
    efficiency of resource utilization or efficiency of processes making the
    requests.  Modifications to the ordering to prevent starvation of processes
    waiting for requests which might otherwise never receive service.  A
    high-level nonprocedural language to specify these components of resource
    sharing problems is described.  General deadlock and starvation properties
    of selectors are proven.  Solutions to several classic resource sharing
    problems are shown to illustrate the expressiveness of this language.
    Proof techniques for this high-level language are introduced to show how to
    prove particular selectors are or are not deadlock and starvation free.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010310"
}

@Article{vveis,
  author       = "James Jennings and Eric Beuscher",
  title        = "Verischemelog: {V}erilog Embedded in {S}cheme",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "109--122",
  month        = jan,
  keywords     = "scheme, verilog, macros, extension languages, embedded
    languages, hardware description languages",
  abstract     = "Verischemelog (pronounced with 5 syllables, 
    ver-uh-scheme-uh-log) is a language and programming environment embedded in
    Scheme for designing digital electronic hardware systems and for
    controlling the simulatin of these circuits.  Simulation is performed by a
    separate program, often a commercial product.  Verischemelog compiles to
    Verilog, an industry standard language accepted by several commercial and
    public domain simulators.  Because many design elements are easily
    parameterized, design engineers currently write scripts which generate
    hardware description code in Verilog.  These scripts work by textual
    substitution, and are typically ad-hoc and quite limited.  Preprocessors
    for Verilog, on the other hand, are hampered by their macro-expansion
    languages, which support few data types and lack procedures.  Verischemelog
    obviates the need for scripts and prepocessors by providing a hardware
    description language with list-based syntax, and Scheme to manipulate it.
    An interactive development environment gives early and specific feedback
    about errors, and structured access to the compiler and run-time
    environment provide a high degree of reconfigurability and extensibility of
    Verischemelog.", 
  location     = "http://usenix.org/publications/library/proceedings/dsl99/full_papers/jennings/jennings.pdf"
}

@Article{cctvpfcfsm,
  author       = "Mohammed~C. Gouda",
  title        = "Closed Covers:  To Verify Progress for Communicating Finite State Machines",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "846--855",
  month        = nov,
  keywords     = "communicating finite state machines, communication progress,
    communication protocols, verification techniques, automata, data
    structures, protocols, resource management, system recovery",
  abstract     = {Consider communicating finite state machines which exchange
    messages over unbounded FIFO channels.  We discuss a technique to verify
    that the communication between a given pair of such machines will progress
    indefinitely; this implies that the communication is free from deadlocks
    and unspecified receptions.  The technique is based on finding a set of
    global states for the communicating pair such that the following two
    conditions (along with other conditions) are satisfied: 1) the initial
    global state is in that set; and 2) starting from any global state in that
    set, an "acyclic version" of the communicating pair must reach a global
    state in that set.  We call such a set a closed cover, and show that the
    existence of a closed cover for a communicating pair is sufficient to
    guarantee indefinite communication progress.  We also show that in many
    practical instances, if the communication is guaranteed to progress
    indefinitely, then the existence of a closed cover is necessary.},
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010313",
  location     = "http://www.cs.utexas.edu/~gouda/papers/journal/10-whole.pdf"
}

@Article{aooassl,
  author       = "Giuseppe Serazzi and Maria Caizarossa",
  title        = "Adaptive Optimization of a System's Load",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  month        = nov,
  pages        = "837--845",
  keywords     = "adaptive control, adaptive scheduling algorithm, asymptotic
    bound analyasis, load balancing, real-time performance optimization",
  abstract     = "Applications of modeling techniques based on queueing theory
    to computer system performance analysis normally assume the existence of
    steady-state conditions.  However, these conditions are often violated
    since the unpredictable composition of workload causes peaks having highly
    variable intensities and durations.  Furthermore, computer system
    performance is highly dependent on how the system reacts to workload
    fluctuations.  Automatic control mechanisms are required to take care of
    the high variance of resource demands.  Real-time optimization of the
    overall performance of a computer system requires the introduction of
    adaptive control on the controlled functions, An adaptive scheduling
    algorithm which controls the input of the system in order to maximize a
    given performance criterion, such as the system throughput, is presented.
    The system load is adjusted depending on the characteristics of both the
    mix of jobs in execution and the mix of jobs submitted to the system and
    waiting in the input queue.  The asymptotic analysis of the performance
    bounds provides useful information about the limits on the performance
    indexes that can be achieved with a multiclass workload.  The evaluation of
    the adaptive control system is performed through simulation experiments
    using data collected from two real workloads.  This technique could be used
    to optimize the throughput of a centralized system as well as for the
    automatic load balancing in a distributed environment.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010312"
}

@Article{acm,
  author       = "Khayat, Mohammad G.",
  title        = "{A} Concurrency Measure",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "804--810",
  month        = nov,
  keywords     = "compatibility, concurrency control, degree of concurrency,
    dining philosophers problem, interprocess communication, maximal
    compatibility, parallel processing, readers/writers problem,
    synchronization policies, update synchronization",
  abstract     = "With the new advents of technology and the availability of 
    microprocessors and minicomputers, parallel and distributed processing is
    gaining widespread acceptability.  In such systems resources are shared
    among a number of processes.  Accesses to the resources must be
    synchronized in order to guarantee proper operation of a system.  In this
    research work, a measure, called maximal compatibility, is developed to
    measure the degree of concurrency (parallelism) a synchronization policy
    achieves.  A set of accesses is considered compatible if it only contains
    accesses that are permitted to occur simultaneously.  A policy is maximally
    compatible if it allows every compatible set of accesses to occur
    simultaneously and if the maximum number of requests is always satisfied
    without allowing incompatible accesses to occur simultaneously.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010309"
}

@Article{dore,
  author       = "Janusz~A. Brzozowski",
  title        = "Derivatives of Regular Expressions",
  journal      = jacm,
  year         = 1964,
  volume       = 11,
  number       = 4,
  pages        = "481--494",
  month        = oct,
  keywords     = "symbolic manipulation, algebraic manipulation",
  abstract     = "",
  location     = "http://dx.doi.org/10.1145/321239.321249"
}

@Article{cpnala,
  author       = "David~B. Benson",
  title        = "Counting Paths:  Nondeterminism as Linear Algebra",
  journal      = tse,
  year         = 1984,
  volume       = "SE-10",
  number       = 6,
  pages        = "785--794",
  month        = nov,
  keywords     = "convergent iterative programs, deterministic divergence,
    nondeterministic divergence, nondeterministic programs, nonnegative
    matrices, semirings, computer errors, concurrent computing, control
    systems, convergence, design engineering, distributed computing, linear
    algebra, operating systems, programming profession, redundancy",
  abstract     = "Nondeterminism is considered to be ignorance about the actual
    state transition sequence performed during a computation.  The number of
    distinct potential paths from state i to j forms a matrix [nij].  The
    behavior of a nondeterministic program is defined to be this multiplicity
    matrix of the state transitions.  The standard programming constructs have
    behaviors defined in terms of the behaviors of their constituents using
    matrix addition and multiplication only.  The spectral radius of the matrix
    assigned to an iterating component characterizes its convergence.  The
    spectral radius is shown to be either 0 or else >= 1.  The program
    converges iff the spectral radius is zero, diverges deterministically iff
    the spectral radius is one, and has a proper nondeterministic divergence
    iff the spectral radius exceeds one.  If the machine has an infinite number
    of states the characterization of convergence is given graph theoretically.
    The spectral radii of synchronous and interleaved parallel noncommunicating
    systems are easily computed in terms of the spectral radii of the
    components.", 
  location     = "http://dx.doi.org/10.1109/TSE.1984.5010307"
}

@Article{dsodiws,
  author       = "Fern{\' a}ndez, Mary and Suciu, Dan and Tatarinov, Igor",
  title        = "Declarative Specification of Data-Intensive Web Sites",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "135--148",
  month        = jan,
  keywords     = "domain-specific languages, functional languages,
    semistructured data, query languages, template languages",
  abstract     = "Integrated information systems are often realized as 
    data-intensive Web sites, which integrate data from multiple data sources.
    We present a system, called STRUDEL, for specifying and generating
    data-intensive Web sites.  STRUDEL separates the tasks of accessing and
    integrating a site's data sources, building its structure, and generating
    its HTML representation.  STRUDEL's declarative query language, called
    StruQL, supports the first two tasks.  Unlike ad-hoc database queries, a
    StruQL query is a software artifact that must be extensible and reusable To
    support more modular and reusable site definition queries, we extend StruQL
    with functions and describe how the new language, FunStruQL, better
    supports common site-engineering tasks, such as choosing a strategy for
    generating the site's pages dynamically and/or statically To substantiate
    STRUDEL's benefits, we describe the re-engineering of a production Web site
    using FunStruQL and show that the new site is smaller, more reusable, and
    unlike the original site, can be analyzed and optimized.", 
  location     = "http://dx.doi.org/10.1145/331960.331979"
}

@Article{narwf,
  author       = "Robert~W. Floyd",
  title        = "Nondeterministic Algorithms",
  journal      = jacm,
  year         = 1967,
  volume       = 14,
  number       = 4,
  pages        = "636--644",
  month        = oct,
  keywords     = "nondeterminism, algorithms, program transforms",
  abstract     = "Programs to solve combinatorial search problems may often be 
    simply written by using multiple-valued functions.  Such programs, although
    impossible to execute directly on conventional computers, may be converted
    in a mechanical way into conventional backtracking programs.  The process
    is illustrated with algorithms to find all solutions to the eight queens
    problem on the chessboard, and to find all simple cycles in a network.", 
  location     = "http://dx.doi.org/10.1145/321420.321422"
}

@Article{biagcs,
  author       = "Lindstrom, Gary",
  title        = "Backtracking in a Generalized Control Setting",
  journal      = toplas,
  year         = 1979,
  volume       = 1,
  number       = 1,
  pages        = "8--26",
  month        = jul,
  keywords     = "backtracking, coroutines, nondeterministic programming,
    simulation, control structures, pascal",
  abstract     = "Backtracking is a powerful conceptual and practical
    programming language control structure.  However, its application in
    general has been limited to global control over recursive programs.  In
    this paper we explore the coherence and utility of applying backtracking in
    a more general control setting, namely, block-structured coroutines.  The
    following criteria are proposed for such a control combination to be judged
    successful: (i) retention of each control form's individual semantics; (ii)
    coherent semantics for each legal application of the combination; (iii)
    nonpreeminence of either control form, and (iv) facilitation of genuinely
    novel programming effects.  The attainability of these criteria is
    assessed, with the aid of an informal language design and three
    illustrative applications: (i) a dual tree walk program using
    coroutine-managed backtracking subsystems; (ii) a context-free language
    intersection tester using bilevel hierarchical backtracking, and (iii) an
    optimizing computer job scheduler using backtracking in a simulation
    language context.  Full programs are given for each example, phrased in a
    Pascal extension offering both coroutines and backtracking (expressed
    through nondeterministic control).", 
  location     = "http://dx.doi.org/10.1145/357062.357063"
}

@Article{eeoartsfams,
  author       = "Blake, Ben~A. and Schwan, Karsten",
  title        = "Experimental Evaluation of a Real-Time Scheduler for a Multiprocessor System",
  journal      = tse,
  year         = 1991,
  volume       = 17,
  number       = 1,
  pages        = "34--44",
  month        = jan,
  keywords     = "bin packing, deadline, distributed scheduling",
  abstract     = "A description is given of the design, implementation, and
    experimental evaluation of a multiprocessor scheduler used with robotics
    applications and other real-time programs.  The scheduler makes decisions
    concerning both the assignment of processes and the scheduling of these
    processes on each processor such that a near-optimal numer of processor
    deadlines is satisfied.  It assumes that process execution times,
    deadlines, and earliest possible start times are known.", 
  location     = "http://dx.doi.org/10.1109/32.67577"
}

@Article{aalfosl,
  author       = "Guyer, Samuel~Z. and Lin, Calvin",
  title        = "An Annotation Language for Optimizing Software Libraries",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "39--52",
  month        = jan,
  keywords     = "performance annotations, library optimization",
  abstract     = "This paper introduces an annotation language and a compiler
    that together can customize a library implementation for specific
    application needs.  Our approach is distinguished by its ability to exploit
    high level, domain-specific information in the customization process.  In
    particular, the annotations provide semantic information that enables our
    compiler to analyze and optimize library operations as if they were
    primitives of a domain-specific language.  Thus, our approach yields many
    of the performance benefits of domain-specific languages, without the
    effort of developing a new compiler for each domain.This paper presents the
    annotation language, describes its role in optimization, and illustrates
    the benefits of the overall approach.  Using a partially implemented
    compiler, we show how our system can significantly improve the performance
    of two applications written using the PLAPACK parallel linear algebra
    library.", 
  location     = "http://dx.doi.org/10.1145/331960.331970",
  location     = "http://www.cs.tufts.edu/~sguyer/publications/dsl99.pdf"
}

@Article{sams,
  author       = "Robert~F. Rosen",
  title        = "Supervisory and Monitor Systems",
  journal      = surveys,
  year         = 1969,
  volume       = 1,
  number       = 1,
  pages        = "37--54",
  month        = mar,
  keywords     = "executive systems, supervisory systems, operating systems,
    monitors, history, tutorial, command language, interrupts, software",
  abstract     = "A survey of the development of executive systems, covering
    primitive as well as more refined concepts, is presented.  It is arranged
    chronologically, from the early 1950s through the present time, and is
    based upon representative systems of each period which where in active use
    at several installations and which implicitly defined the them existing
    state-of-the-art.  The material is presented in a progression from the
    simple to the most complex developments, in the same way they  
    occurred during the period considered.", 
  location     = "http://dx.doi.org/10.1145/356540.356544"
}

@Article{asopanatsp,
  author       = "David Harel",
  title        = "And/Or Programs:  A New Approach to Structured Programming",
  journal      = toplas,
  year         = 1980,
  volume       = 2,
  number       = 1,
  pages        = "1--17",
  month        = jan,
  keywords     = "alternation, and/or programs, program verification,
    structured programming, textual complexity",
  abstract     = "A simple tree-like programming/specification language is 
    presented.  The central idea is the dividing of conventional programming
    constructs into the two classes of and and or subgoaling, the subgoal tree
    itself constituting the program.  Programs written in the language can, in
    general, be both nondeterministic and parallel.  The syntax and semantics
    of the language are defined, a method for verifying programs written in it
    is described, and the practical significance of programming in the language
    assessed.  Finally, some directions for further research are indicated.", 
  location     = "http://dx.doi.org/10.1145/357084.357085"
}

@Article{dcapbde,
  author       = "Tai, Kuo-Chung and Carver, Richard~H. and Obaid, Evelyn~E.",
  title        = "Debugging Concurrent {A}da Programs by Deterministic Execution",
  journal      = tse,
  year         = 1991,
  volume       = 17,
  OPTnumber    = 1,
  pages        = "45--63",
  month        = jan,
  keywords     = "ada, debugging, concurrency, execution traces, deterministic
    execution", 
  abstract     = "A language-based approach to deterministic execution
    debugging of concurrent Ada programs is presented.  The approach is to
    define synchronization (SYN) -sequences of a concurrent Ada program in
    terms of Ada language constructs and to replay such SYN-sequences without
    the need for system-dependent debugging tools.  It is shown how to define a
    SYN-sequence of a concurrent Ada program in order to provide sufficient
    information for deterministic execution.  It is also shown how to transform
    a concurrent Ada program P so that the SYN-sequences of previous executions
    of P can be replayed.  This transformation adds an Ada task to P that
    controls program execution by synchronizing with the original tasks in P.
    A brief description is given of the implementation of tools supporting
    deterministic execution debugging of concurrent Ada programs.", 
  location     = "http://dx.doi.org/10.1109/32.67578"
}

@Article{acsl,
  author       = "Li, Du and Muntz, Richard~R.",
  title        = "{A} Collaboration Specification Language",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "149--162",
  month        = jan,
  keywords     = "computer-supported cooperative work, declarative
    specifications, concurrency control, session control, roles",
  abstract     = "COCA (Collaborative Objects Coordination Architecture) was
    proposed as a novel means to model and support collaborations over the
    Internet.  Our approach separates coordination policies from user
    interfaces and the policies are specified in a logic-based language.  Over
    the past year, both the collaboration model and the specification language
    have been substantially refined and evaluated through our experience in
    building real-life collaboration systems.  This paper presents the design
    of the specification language and illustrates the main ideas with a few
    simple design examples.  Semantics, implementation, runtime support, and
    applications are also covered but not as the focus of this paper.", 
  location     = "http://dx.doi.org/10.1145/331960.331980"
}

@Article{halfpvlsd,
  author       = "Bonachea, Dan and Fisher, Kathleen and Rogers, Anne and Smith, Frederick",
  title        = "Hancock: A Language For Processing Very Large-Scale Data",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "xxx--yyy",
  month        = jan,
  keywords     = "domain specific languages, stream processing, high-level
    languages, data mining",
  abstract     = "A signature is an evolving customer profile computed from
    call records.  AT&T uses signatures to detect fraud and to target
    marketing.  Code to compute signatures can be difficult to write and
    maintain because of the volume of data.  We have designed and implemented
    Hancock, a C-based domain-specific programming language for describing
    signatures.  Hancock provides data abstraction mechanisms to manage the
    volume of data and control abstractions to facilitate looping over records.
    This paper describes the design and implementation of Hancock, discusses
    early experiences with the language, and describes our design process.",  
  location     = ""
}

@Article{asoatsm,
  author       = "McKinney, J. M.",
  title        = "A Survey of Analytical Time-Sharing Models",
  journal      = surveys,
  year         = 1969,
  volume       = 1,
  number       = 2,
  pages        = "105--116",
  month        = jun,
  keywords     = "time-sharing, queueing analysis, mathematical time-sharing
    studies, scheduling algorithm, operating systems, multiprogramming
    systems",
  abstract     = "Queueing models of time-sharing algorithms have been
  appearing in the literature with increasing frequency.  This survey 
    delineates the parameters distinguishing different analytic models and 
    presents the research results of most of the papers to date.  The analysis
    techniques for various round-robin and multiple-level queue models both
    with and without priorities are emphasized.  The results indicated provide
    the system designer with a number of degrees of freedom with which to
    synthesize a time-shared processing system and point out needed research 
    directions.  An annotated bibliography is provided.",
  location     = "http://dx.doi.org/10.1145/356546.356549"
}

@Article{aattuopisp,
  author       = "Griswold, Ralph~E. and Hanson, David~R.",
  title        = "An Alternative to the Use of Patterns in String Processing",
  journal      = toplas,
  year         = 1980,
  volume       = 2,
  number       = 2,
  pages        = "153--172",
  month        = apr,
  keywords     = "string processing, pattern matching, programming languages,
    snobol4, icon, generators",
  abstract     = "SNOBOL4 is best known for its string processing facilities,
    which are based on patterns as data objects.  Despite the demonstrated
    success of patterns, there are many shortcomings associated with their use.
    The concept of patterns in SNOBOL4 is examined and problem areas are
    discussed.  An alternative method for high-level string processing is
    described.  This method, implemented in the programming language Icon,
    employs generators, which are capable of producing alternative values.
    Generators, coupled with a goal-driven method of expression evaluation,
    provide the string processing facilities of SNOBOL4 without the
    disadvantages associated with patterns.  Comparisons between SNOBOL4 and
    Icon are included and the broader implications of the new approach are
    discussed.", 
  location     = "http://dx.doi.org/10.1145/357094.357096"
}

@Article{tgoiimals,
  author       = "Maurice~V. Wilkes",
  title        = "The Growth of Interest in Microprogramming:  A Literature Survey",
  journal      = surveys,
  year         = 1969,
  volume       = 1,
  number       = 3,
  pages        = "139--145",
  month        = sep,
  keywords     = "microprogramming, machine architecture, optimization",
  abstract     = "The literature is surveyed beginning with the first paper
    published in 1951.  At that time microprogramming was proposed primarily as
    a means for designing the control unit of an otherwise conventional digital
    computer, although the possible use of a read/write control memory was
    noted.  The survey reveals the way in which interest has successively
    developed in the following aspects of the subject: stored logic, the
    application of microprogramming to the design of a range of computers,
    emulation, microprogramming in support of software, the read/white control
    memories.  The bibliography includes 55 papers.", 
  location     = "http://dx.doi.org/10.1145/356551.356553"
}

@Article{mrsurc,
  author       = "Daniel~G. Bobrow",
  title        = "Managing Reentrant Structures Using Reference Counts",
  journal      = toplas,
  year         = 1980,
  volume       = 2,
  number       = 3,
  pages        = "369--273",
  month        = jul,
  keywords     = "storage management, garbage collection, reference counting",
  abstract     = "Automatic storage management requires that one identify
    storage unreachable by a user's program and return it to free status.  One
    technique maintains a count of the references from user's programs to each
    cell, since a count of zero implies the storage is unreachable.  Reentrant
    structures are self-referencing; hence no cell in them will have a count of
    zero, even though the entire structure is unreachable.  A modification of
    standard reference counting can be used to manaage the deallocation of a
    large class of frequently used reentrant structures, including two-way and
    circularly linked lists.  All the cells of a potentially reentrant
    structure are considered as part of a single group for deallocation
    purposes.  Information associated with each cell specifies its group
    membership.  Internal references (pointers from one cell of the group to
    another) are not reference counted.  External references to any cell of
    this group are counted as references to the group as a whole.  When the
    external reference count goes to zero, all the cells of the group can be
    deallocated.  This paper describes several ways of specifying group
    membership, properties of each implementation, and properties of mutable
    and immutable group membership.", 
  location     = "http://dx.doi.org/10.1145/357103.357104"
}

@Article{saarinfs,
  author       = "Jason Gait",
  title        = "Stability, Availability, and Response in Network File Service",
  journal      = tse,
  year         = 1991,
  volume       = 17,
  number       = 2,
  OPTpages     = "133--140",
  month        = feb,
  keywords     = "competition to respond, duplicate message exceptions,
    throughput, redundancy",
  abstract     = "A network file system called Multifile is described.  It 
    meets response, availability, and stability requirements as primitive
    functions.  Multifile has a high degree of responsiveness because its
    component parts compete among themselves to service file requests; it has
    high availability because it maintains multiple copies of files; and it
    exhibits stable behavior over wise range of system parameters.  The
    responsiveness of Multifile to read requests improves as the number of
    pages per request rises, implying that read ahead pages can profitably be
    cached at client sites.  The throughput of Multifile improves as the
    request size increases and as the number of clients increases.  As server
    load increases, the responsiveness of Multifile to read requests is stable
    in most configurations.  The throughput of writes is unstable as the number
    of pages in the wire request rises, implying that write back pages should
    not be cached at client sites.  The scale of events in file service is
    dominated by disk activity, so lost message exceptions do not occur
    frequently enough to affect file service; however, duplicate message
    exceptions are a factor in performance.", 
  location     = "http://dx.doi.org/10.1109/32.67594"
}

@Article{mrjpgh,
  author       = "Peterson, John and Hager, Greg",
  title        = "Monadic Robotics",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "95--108",
  month        = jan,
  keywords     = "robotics, functional reactive programming, monads, functional
    programming, haskell, software abstraction, frob",
  abstract     = "We have developed a domain specific language for the 
    construction of robot controllers, Frob (Functional ROBotics).  The
    semantic basis for Frob is Functional Reactive Programming, or simply FRP,
    a purely functional model of continuous time, interactive systems.  FRP is
    built around two basic abstractions: behaviors, values defined continuously
    in time, and events, discrete occurances in time.  On this foundation, we
    have constructed abstractions specific to the domain of robotics.  Frob
    adds yet another abstraction: the task, a basic unit of work defined by a
    continuous behavior and a terminating event.This paper examines two
    interrelated aspects of Frob.  First, we study the design of systems based
    on FRP and how abstractions defined using FRP can capture essential
    domain-specific concepts for systems involving interaction over time.
    Second, we demonstrate an application of monads, used here to implement
    Frob tasks.  By placing our task abstraction in a monadic framework, we are
    able to organize task semantics in a modular way, allowing new capabilities
    to be added without pervasive changes to the system.We present several
    robot control algorithms specified using Frob.  These programs are clear,
    succinct, and modular, demonstrating the power of our approach.", 
  location     = "http://dx.doi.org/10.1145/331963.331976"
}

@Article{aepss,
  author       = "Selby, Richard~W. and Basili, Victor~R.",
  title        = "Analyzing Error-Prone System Structure",
  journal      = tse,
  year         = 1991,
  volume       = 17,
  number       = 2,
  pages        = "141--152",
  month        = feb,
  keywords     = "emperical measurement and evaluation, error analysis,
    software inspections, software metrics, system decomposition, system
    strength and coupling",
  abstract     = "Using measures of data interaction called data bindings, the
    authors quantify ratios of coupling and strength in software systems and
    use the ratios to identify error-prone system structures.  A 148000 source
    line system from a prediction environment was selected for empirical
    analysis.  Software error data were collected from high-level system design
    through system testing and from field operation of the system.  The authors
    use a set of five tools to calculate the data bindings automatically and
    use a clustering technique to determine a hierarchical description of each
    of the system's 77 subsystems.  A nonparametric analysis of variance model
    is used to characterize subsystems and individual routines that had either
    many or few errors or high or low error correction effort.  The empirical
    results support the effectiveness of the data bindings clustering approach
    for localizing error-prone system structure.", 
  location     = "http://dx.doi.org/10.1109/32.67595"
}

@Article{lsfogfsa,
  author       = "Cohen, Doron~J. and Gotlieb, C. C.",
  title        = "A List Structure Form of Grammars for Syntatic Analysis",
  journal      = surveys,
  year         = 1970,
  volume       = 2,
  number       = 1,
  pages        = "65--82",
  month        = mar,
  keywords     = "grammars, parsing, data structures, lists, syntax-directed
    compilation, graphs, top-down parsing, bottom-up parsing, backtracking,
    context free grammars, bnf form",
  abstract     = "The syntax graph is a representation for grammars in list
    structure form, in which printers link the various components and
    alternatives of a production.  Rules for constructing the syntax graph are
    explicitly stated.  When this structure is used the algorithms for
    syntactic analysis become particularly simple.  Two algorithms for
    top-to-bottom parsing without backtracking are given, and one algorithm
    with backtracking, all of which can e used on any context-free grammar.
    From the syntax graph a reversed graph can be defined, and this naturally
    leads to a simple algorithm for bottom-to-top parsing.", 
  location     = "http://dx.doi.org/10.1145/356561.356565"
}

@Article{aeipe,
  author       = "Jaydev Misra",
  title        = "An Exercise in Program Explanation",
  journal      = toplas,
  year         = 1981,
  volume       = 3,
  number       = 1,
  pages        = "104--109",
  month        = jan,
  keywords     = "prime sieves, stepwise refinement, formal development",
  abstract     = "A combination of program-proving and stepwise refinement is
    used to develop and explain an algorithm which uses a version of the sieve
    method for computing primes.",
  location     = "http://dx.doi.org/10.1145/357121.357128"
}

@Article{wiafpnafp,
  author       = "John Longley",
  title        = "When is a Functional Program Not a Functional Program?",
  journal      = sigplan # " (" # pot # "Second ACM SIGPLAN " # icfp # ", ICFP '99)",
  year         = 1999,
  volume       = 32,
  number       = 9,
  pages        = "1--7",
  month        = sep,
  keywords     = "sequentially realizable functionals, functional algorithms",
  abstract     = "In an impure functional language, there are programs whose
    behaviour is completely functional (in that they behave extensionally on
    inputs), but the functions they compute cannot be written in the purely
    functional fragment of the language.  That is, the class of programs with
    functional behaviour is more expressive than the usual class of pure
    functional programs.  In this paper we introduce this extended class of
    functional programs by means of examples in Standard ML, and explore what
    they might have to offer to programmers and language implementors.After
    reviewing some theoretical background, we present some examples of
    functions of the above kind, and discuss how they may be implemented.  We
    then consider two possible programming applications for these functions:
    the implementation of a search algorithm, and an algorithm for exact
    real-number integration.  We discuss the advantages and limitations of this
    style of programming relative to other approaches.  We also consider the
    increased scope for compiler optimizations that these functions would
    offer.", 
  location     = "http://dx.doi.org/10.1145/317636.317775"
}

@Article{jfde,
  author       = "Nakatani, Lloyd~H. and Ardis, Mark~A. and Olsen, Robert~G. and Pontrelli, Paul~M.",
  title        = "Jargons for Domain Engineering",
  journal      = dsl99,
  year         = 2000,
  volume       = 35,
  number       = 1,
  pages        = "15--24",
  month        = jan,
  keywords     = "domain engineering, domain-specific languages, software
    engineering",
  abstract     = "In the Family-oriented Abstraction, Specification and 
    Translation (FAST) domain engineering process for software production, a
    member of a software product family is automatically generated from a model
    expressed in a DSL.  In practice, the time and skill needed to make the
    DSLs proved to be bottlenecks.  FAST now relies on jargons, a kind of
    easy-to-make DSL that domain engineers who are not language experts can
    quickly make themselves.  We report our experiences with jargons in the
    FAST process, and describe the benefits they provide above and beyond
    conventional DSLs for software production and other purposes.", 
  location     = "http://dx.doi.org/10.1145/331960.331966"
}

@Article{aefdfts,
  author       = "James~M. Purtilo and Pankaj Jalote",
  title        = "An Environment for Developing Fault-Tolerant Software",
  journal      = tse,
  year         = 1991,
  volume       = "SE-17",
  number       = 2,
  pages        = "153--159",
  month        = feb,
  keywords     = "module interconnection language, n-version programming,
    recovery block, software bus, software fault tolerance",
  abstract     = "An environment that supports execution of programs using both
    N-version programming and recovery blocks in a uniform manner is described.
    For N-version programming, the system offers an easy and flexible way of
    specifying the target machines for the separate versions.  The basic unit
    of fault tolerance supported by this system is at the procedure or function
    level.  Each such program unit can be packaged as its own task, and
    different fault tolerance techniques can subsequently be employed, even
    within the same application.  The environment also allows versions to be
    written in different programming languages and executed on different
    machines.  This enhances the independence between the different versions,
    making the fault tolerance techniques more effective.  This environment has
    been developed for use on Unix-based hosts and currently runs on a network
    of Sun and DEC workstations", 
  location     = "http://dx.doi.org/10.1109/32.67596"
}

@Article{aapnwtiov,
  author       = "Martin Rem",
  title        = "Associons:  {A} Program Notation with Tuples Instead of Variables",
  journal      = toplas,
  year         = 1981,
  volume       = 3,
  number       = 3,
  pages        = "251--262",
  month        = jul,
  keywords     = "programming languages, data structures, content-retrievable
    tuples, associons, closure statement, concurrency, associative addressing",
  abstract     = "A program notation without variables is proposed.  The state
    of a computation is recorded as a set of associons. Each associon is a
    tuple of names representing a relation between the entities with those
    names.  The state of the computation can be changed by the creation of new
    associons representing new relations deducible from those already recorded.
    The building block prescribing such deductions is called the closure
    statement. The notation proposed is the result of our search for a basic
    statement the execution of which may employ more concurrency than is the
    case for the traditional assignment statement.  Some possible extensions to
    the notation are discussed.",
  location     = "http://dx.doi.org/10.1145/357139.357142"
}

@Article{vmpjd,
  author       = "Denning, Peter~J.",
  title        = "Virtual Memory",
  journal      = surveys,
  year         = 1970,
  volume       = 28,
  number       = 1,
  pages        = "153--189",
  month        = sep,
  keywords     = "virtual memory, one-level store, memory allocation, storage
    allocation, dynamic storage allocation, segmentation, paging, replacement
    algoritms, storage fragmentation, thrashing, working set",
  abstract     = "The need for automatic storage allocation arises from the 
    desire for program modularity, machine independence, and resource sharing.
    Virtual memory is an elegant way of achieving these objectives.  In a
    virtual memory, the addresses a program may use to identify information are
    distinguished from the addresses the memory system uses to identify
    physical storage sites, and program-generated addresses are translated
    automatically to the corresponding machine addresses.  Two principal
    methods for implementing virtual memory, segmentation and paging, are
    compared and contrasted.  Many contemporary implementations have
    experienced one or more of these problems: poor utilization of storage,
    thrashing, and high costs associated with loading information into memory.
    These and subsidiary problems are studied from a theoretic view, and are
    shown to be controllable by a proper combination of hardware and memory
    management policies.", 
  location     = "http://dx.doi.org/10.1145/356571.356573"
}

@Article{tyohslasepi,
  author       = "Krzysztof~R. Apt",
  title        = "Ten Years of {H}oare's Logic: {A} Survey---Part {I}",
  journal      = toplas,
  year         = 1981,
  volume       = 3,
  number       = 4,
  pages        = "431--483",
  month        = oct,
  keywords     = "Hoare's logic, partial correctness, total correctness, 
    soundness, Cook completeness, expressiveness, arithmetical interpretation,
    while programs, recursive procedures, variable declarations, subscripted
    variables, call-by-name, call-by-value, call-by-variable, static scope,
    dynamic scope, procedures as parameters", 
  abstract     = "A survey of various results concerning Hoare's approach to 
    proving partial and total correctness of programs is presented.  Emphasis
    is placed on the soundness and completeness issues.  Various proof systems
    for while programs, recursive procedures, local variable declarations, and
    procedures with parameters, together with the corresponding soundness,
    completeness, and incompleteness results, are discussed.", 
  location     = "http://dx.doi.org/10.1145/357146.357150"
}

@Article{autss,
  author       = "Foster, Caxton~C.",
  title        = "An Unclever Time-Sharing System",
  journal      = surveys,
  year         = 1971,
  volume       = 3,
  number       = 1,
  pages        = "23--48",
  month        = mar,
  keywords     = "time sharing, operating system, tutorial, command
    language, scheduling",
  abstract     = "This paper describes the internal structure of a time-sharing
    system in some detail.  This system is dedicated to providing remote
    access, and has a simple file structure.  It is intended for use in a
    university type environment where there are many short jobs that will
    profit from one- or two-second turnaround.  Despite its simplicity, this
    system can serve as a useful introduction to the problems encountered by
    the designers of any time-sharing system.  Included are a discussion of the
    command language, the hardware organization toward which the design is
    oriented, the general internal organization, the command sequences, the CPU
    scheduler, handling of interrupts, the assignment of core space, execution
    and control of the user's program, backup storage management, and the
    handling of errors.", 
  location     = "http://dx.doi.org/10.1145/356583.356585"
}

@Article{sapcfsulm,
  author       = "Nishida, Fujio and Takamatsu, Shinobu and Fujita, Yoneharu and Tani, Tadaski",
  title        = "Semi-Automatic Program Construction From Specifications Using Library Modules",
  journal      = tse,
  year         = 1991,
  volume       = 17,
  number       = 9,
  pages        = "853--871",
  month        = sep,
  keywords     = "automatic programming, formal specifications, software tools,
    subroutines, maps, library modules, program generation, refinement system",
  abstract     = "A method of semiautomatic specification refinement and 
    program generation using library modules, is described.  Users write their
    specifications and modify and rearrange them so that they can be refined
    with the aid of the library modules.  When a specification is given, a
    refinement system, called MAPS (module-aided program construction system)
    searches for library modules applicable to the given specification,
    replaces the specification with a more detailed description written in the
    operation part of the modules, and converts the refined specification into
    a program written in a programming language designated by the user.
    Case-like expressions or pseudo-natural language expressions are used for
    describing user's specifications and specifications for library modules", 
  location     = "http://dx.doi.org/10.1109/32.92909"
}

@Article{sidp,
  author       = "Schneider, Fred~B.",
  title        = "Synchronization in Distributed Programs",
  journal      = toplas,
  year         = 1982,
  volume       = 4,
  number       = 2,
  pages        = "125--148",
  month        = apr,
  keywords     = "logical clocks, synchronization, distributed semaphores,
    guarded commands, monotonic predicates, phase transitions",
  abstract     = "A technique for solving synchronization problems in 
    distributed programs is described.  Use of this technique in environments
    in which processes may fail is discussed.  The technique can be used to
    solve synchronization problems directly, to implement new synchronization
    mechanisms (which are presumably well suited for use in distributed
    programs), and to construct distributed versions of existing
    synchronization mechanisms.  Use of the technique is illustrated with
    implementations of distributed semaphores and a conditional message-passing
    facility.", 
  location     = "http://dx.doi.org/10.1145/357162.357163"
}

@Book{natrbp,
  author       = "Rober~B. Parker",
  title        = "Now and Then",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2007,
  address      = nyny,
  keywords     = "the trickster, murrdaar",
  location     = "PS 3566.A6868 N69"
}

@Book{sdrbp,
  author       = "Rober~B. Parker",
  title        = "School Days",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2005,
  address      = nyny,
  keywords     = "slaughter de jour, murrdaar",
  location     = "PS 3566.A6868 N69"
}

@Book{osid,
  author       = "Thomas~W. Doeppner",
  title        = "Operating Systems in Depth",
  publisher    = "Wiley",
  year         = 2011,
  keywords     = "operating systems, multithreaded programming, processor
    management, file systems, memory management, security, networking,
    distributed file systems",
  location     = "QA 76.76.O63 D64"
}

@Book{aiama,
  author       = "Stuart Russell and Peter Norvig",
  title        = "Artificial Intelligence: {A} Modern Approach",
  publisher    = "Prentice Hall",
  year         = 2010,
  address      = srnj,
  edition      = "third",
  keywords     = "artificial intelligence, agents, search, constraint
    satisfaction, first-order logic, inference, planning, knowledge
    representations, uncertainty, probabilistic reasoning, decision making,
    leaning, natural language processing, perception, robotics",
  location     = "Q 335 R86"
}

@Book{isppap,
  author       = "Robert~J. Schalkoff",
  title        = "Intelligent Systems:  Principles, Pradigms, and Pragmatics",
  publisher    = "Jones and Bartlett",
  year         = 2011,
  address      = "Sudbury, " # MA,
  keywords     = "search, constraint satisfaction, natural language
    understanding, production systems, soar, uncertainty, fuzzy systems,
    planning, neural networks, learning, evolutionary computing",
  location     = "QA 76.76 I58 S323"
}

@Book{tiloeb,
  author       = "David Bromwich",
  title        = "The Intellectual Life of Edmund Burke",
  publisher    = "Harvard University Press",
  year         = 2014,
  address      = cma,
  keywords     = "edmund burke, aesthetics, the revolutionary war, democracy,
    political thought, politics",
  location     = "DA 506 B9 B69"
}

@Book{tips,
  author       = "Paul Vaderlind and Richard~K. Guy and Loren~C. Larsen",
  title        = "The Inquisitive Problem Solver",
  publisher    = "The Mathematical Association of America",
  year         = 2002,
  address      = "Washington, D.C.",
  keywords     = "mathematics, problems, problem solving",
  location     = "QA 43.V28 2002"
}

@Book{bbrbp,
  author       = "Robert~B. Parker",
  title        = "Bad Business",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2004,
  address      = nyny,
  keywords     = "financial chicanery, murrdaar",
  location     = "PS 3566.A686 B34"
}

@Book{hifh,
  author       = "Helen Macdonald",
  title        = "{H} Is for Hawk",
  publisher    = "Grove Press",
  year         = 2014,
  address      = nyny,
  keywords     = "hawks, death, history",
  location     = "QL 696.F3 M324"
}

@Book{apc,
  author       = "Peter Carey",
  title        = "Amnesia",
  publisher    = "Knopf",
  year         = 2015,
  address      = nyny,
  keywords     = "hackers",
  location     = "PR 9619.3 C36 A83"
}

@Book{hmrbp,
  author       = "Robert~B. Parker",
  title        = "Hush Money",
  publisher    = "G.~P. Putnam's Sons",
  year         = 1999,
  address      = nyny,
  keywords     = "politics, outery, hypocrisy, murrdaar",
  location     = "PS 3566.A686 H87"
}

@Book{prbp,
  author       = "Robert~B. Parker",
  title        = "Potshot",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2001,
  address      = nyny,
  keywords     = "real estate, murrdaar",
  location     = "PS 3566.A686 P68"
}

@Book{tbaoon,
  author       = "Stephen Pinker",
  title        = "The Better Angels of our Nature",
  publisher    = "Penguin",
  year         = 2011,
  address      = nyny,
  keywords     = "violence, pacification, civilization, humanitarianism,
    warfare, rights, psychology, moral systems, politics",
  location     = "HM 111.6 P57"
}

@Book{rrju,
  author       = "John Updike",
  title        = "Rabbit Redux",
  publisher    = "Knopf",
  year         = 1971,
  address      = nyny,
  keywords     = "sucking in the 60s",
  location     = "PS 3571.P4"
}

@Book{srbp,
  author       = "Robert~B. Parker",
  title        = "Sixkill",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2011,
  address      = nyny,
  keywords     = "wha happened?, murrdaar",
  location     = "PS 3566.A686 S57"
}

@Book{tpwg,
  author       = "William Gibson",
  title        = "The Peripheral",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2014,
  address      = nyny,
  keywords     = "the future is now",
  location     = "PS 3557 I2264 P47"
}

@Book{igdeb,
  author       = "Eric Broug",
  title        = "Islamic Geometric Design",
  publisher    = "Thames \& Hudson",
  year         = 2013,
  address      = nyny,
  keywords     = "design, art, geometry",
  location     = "NK 1270 B7613"
}

@Book{jmhgu,
  author       = "Harlow Giles Unger",
  title        = "John Marshall",
  publisher    = "Da Capo Press",
  year         = 2014,
  address      = boma,
  keywords     = "john marshall, revolutionary america, federalism, the supreme
    court",
  location     = "KF 8745.M3 U54"
}

@Book{fmtgp,
  author       = "Alexander~A. Stepanov and Daniel~E. Rose",
  title        = "From Mathematics to Generic Programming",
  publisher    = aw,
  year         = 2015,
  address      = usrnj,
  keywords     = "generic programming, abstract algebra, gcd, cryptography",
  location     = "QA 76.6245 S74"
}

@Book{cttahyop,
  author       = "Haruki Murakami",
  title        = "Colorless Tsukuru Tazaki and His Years of Pilgrimage",
  publisher    = "Knopf",
  year         = 2014,
  address      = nyny,
  keywords     = "mystery",
  location     = "PL 856 U673 S5513"
}

@Book{srbp1990,
  author       = "Robert~B. Parker",
  title        = "Stardust",
  publisher    = "G.~P. Putnam's Sons",
  year         = 1990,
  address      = nyny,
  keywords     = "herassment, murrdaar",
  location     = "PS 3566.A686 S7"
}

@Book{tgc1,
  author       = "John Kenneth Galbraith",
  title        = "The Great Crash 1929",
  publisher    = "Mariner Books",
  year         = 1997,
  address      = boma,
  keywords     = "the great crash, economics, politics, finance, wall street,
    human nature",
  location     = "HB 3717 1929.G32 1997"
}

@Book{tholk,
  author       = "George~H. Marcus and William Whitaker",
  title        = "The Houses of Louis Kahn",
  publisher    = yup,
  year         = 2013,
  address      = nhco,
  keywords     = "lewis kahn, architecture, houses",
  location     = "NA 737.K32 M35"
}

@Book{tlats,
  author       = "Lan Cao",
  title        = "The Lotus and the Storm",
  publisher    = "Viking",
  year         = 2014,
  address      = nyny,
  keywords     = "vietnam, history, duplicity, diaspora",
  location     = "PS 3553.A5823 L68"
}

@Book{dagbs,
  author       = "Bruce Schneier",
  title        = "Data and Goliath",
  publisher    = "W. W. Norton",
  year         = 2015,
  address      = nyny,
  keywords     = "data surveillance, nsa, edward snowdon, privacy, security, 
    internet",
  location     = "HM 846.S362"
}

@Book{smrbp,
  author       = "Robert~B. Parker",
  title        = "Sudden Mischief",
  publisher    = "G.~P. Putnam's Sons",
  year         = 1998,
  address      = nyny,
  keywords     = "bad decisions, murrdaar",
  location     = "PS 3566.A686 S83"
}

@Book{naja,
  author       = "Jane Austen",
  title        = "Northanger Abbey",
  publisher    = "Anchor Books",
  year         = 2013,
  address      = nyny,
  keywords     = "innocence, impressionable youth, metafiction",
  location     = "PR 4034 N7"
}

@Book{tarbp,
  author       = "Robert~B. Parker",
  title        = "Thin Air",
  publisher    = "G.~P. Putnam's Sons",
  year         = 1995,
  address      = nyny,
  keywords     = "delusion",
  location     = "PS 3566.A686 T47"
}

@Book{pdra,
  author       = "Renata Adler",
  title        = "Pitch Dark",
  publisher    = "NYRB",
  year         = 2013,
  address      = nyny,
  keywords     = "women in travel",
  location     = "PS 3551 D63 P5"
}

@Book{fgnh,
  author       = "Nick Hornby",
  title        = "Funny Girl",
  publisher    = "Riverhead Books",
  year         = 2014,
  address      = nyny,
  keywords     = "comedy, careerism, television entertainments",
  location     = "PR 6058 O689 F86"
}

@Book{nadbe,
  author       = "Barbara Ehrenreich",
  title        = "Nickel and Dimed",
  publisher    = "Metropolitian Books",
  year         = 2001,
  address      = nyny,
  keywords     = "minimum wage, unskilled labor, poverty, class warefare,
    waitressing, maid service, retail clerks",
  location     = "HD 4918 E375"
}

@Book{wswrbp,
  author       = "Robert~B. Parker",
  title        = "Widow's Walk",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2003,
  address      = nyny,
  keywords     = "murrdaar, hidden shame",
  location     = "PS 3566 A686 W53"
}

@InBook{lphoor,
  author       = "Hamdy~A. Taha",
  title        = "Handbook of Operations Research",
  chapter      = "II-1: Linear Programming",
  publisher    = "Van Nostrand Reinhold",
  year         = 1978,
  editor       = "Joseph~J. Moder and Salah~E. Elmaghraby",
  pages        = "85--119",
  address      = nyny,
  keywords     = "linear programming, the simplex method, duality theory,
    sensitivity analyses",
  location     = "T 57.6.H35"
}

@TechReport{rsurr,
  author       = "Fr{\' e}d{\' e}ric Boussinot",
  title        = "{RC} Semantics using Rewriting Rules",
  institution  = "Centre de Math{\' e}matiques Appliqu{\' e}es, Ecole des Mines
  de Paris",
  year         = 1992,
  number       = "18--92",
  address      = "Sophia-Antipolis, France",
  month        = "23 " # sep,
  keywords     = "rewriting rules, semantics, rc, reactive semantics",
  abstract     = "This paper describes a formal semantics for a new
     programming language called reactive C.  This language is an extension of
     C to program reactive systems i.e.  systems that react to sequences of
     activations from the external world.  Reactive statements are introduced
     to code these systems.  The semantics of reactive statements is described
     in an operational framework using conditional rewriting rules.", 
  location     = "http://www-sop.inria.fr/meije/rp/RapportsRecherche/rapport18-92.pdf"
}

@TechReport{pbacus4,
  author       = "Mario Wolczko and Randall~B. Smith",
  title        = "Prototype-Based Application Construction Using {S}elf 4.0",
  institution  = "Sun Microsystems Laboratories",
  year         = 1995,
  number       = "SMLI 95-0257",
  address      = mvca,
  keywords     = "self, prototypical programming",
  location     = "https://www.cs.ucsb.edu/~urs/oocsb/self/release/Self-4.0/manuals/tutorial.ps.gz"
}

@InProceedings{eyawtkasbwata,
  author       = "David, Tudor and Guerraoui, Rachid and Trigonakis, Vasileios",
  title        = "Everything You Always Wanted to Know About Synchronization but Were Afraid to Ask",
  booktitle    = port # "Twenty-Fourth ACM Symposium on Operating System Principles",
  year         = 2013,
  pages        = "33--48",
  address      = "Framington, Pennsylvania",
  month        = "3--6 " # nov,
  keywords     = "synchronization, machine architecture, operon, xeon",
  abstract     = "This paper presents the most exhaustive study of 
    synchronization to date.  We span multiple layers, from hardware
    cache-coherence protocols up to high-level concurrent software.  We do so
    on different types of architectures, from single-socket -- uniform and
    non-uniform -- to multi-socket -- directory and broadcast-based --
    many-cores.  We draw a set of observations that, roughly speaking, imply
    that scalability of synchronization is mainly a property of the hardware.",
  location     = "http://dx.doi.org/10.1145/2517349.2522714"
}

@InProceedings{oteogij,
  author       = "Ran Shaham, Elliot~K. Kolodner and Mooly Sagiv",
  title        = "On the Effectiveness of {GC} in {J}ava",
  booktitle    = pot # "International Symposium on Memory Management",
  year         = 2000,
  pages        = "12--17",
  address      = "Minneapolis, MN",
  month        = "15--16 " # oct,
  keywords     = "java, garbage collection, dynamic analysis",
  abstract     = "We study the effectiveness of garbage collection (GC)
    algorithms by measuring the time difference between the actual collection
    time of an object and the potential earliest collection time for that
    object.  Our ultimate goal is to use this study in order to develop static
    analysis techniques that can be used together with GC to allow earlier
    reclamation of objects.  The results may also be used to pinpoint
    application source code that could be rewritten in a way that would allow
    more timely GC.  Specifically, we compare the objects reachable from the
    root set to the ones that are actually used again.  The idea is that GC
    could reclaim unused objects even if they are reachable from the root set.
    Thus, our experiments indicate a kind of upper bound on storage savings
    that could be achieved.  We also try to characterize these objects in order
    to understand the potential benefits of various static analysis algorithms.
    The Java Virtual Machine (JVM) was instrumented to measure objects that are
    reachable, but not used again, and to characterize these objects.
    Experimental results are shown for the SPECjvm98 benchmark suite.  The
    potential memory savings for these benchmarks range from 23% to 74%.", 
  location     = "http://dx.doi.org/10.1145/362422.362430"
}

@InProceedings{dmdcsm,
  author       = "Watabe, Kazuo and Sakata, Shiro and Maeno, Kazutoshi and Fukuoka, Hideyuki and Ohmori, Toyoko",
  title        = "Distributed Multiparty Desktop Conferencing System: {MERMAID}",
  booktitle    = pot # "1990 ACM Conference on Computer-Supported Cooperative Work (CSCW '90)",
  year         = 1990,
  pages        = "27--38",
  address      = laca,
  month        = "7--10 " # oct,
  keywords     = "client-server, shared workspaces, video conferencing",
  abstract     = "This describes a distributed multiparty desktop conferencing
    system (MERMAID) and presents its preliminary brief evaluation, obtained as
    a result of daily use.  MERMAID, which is designed based on group
    collaboration system architecture, provides an environment for widely
    distributed participants, seated at their desks, to hold real-time
    conferences by interchanging information through video, voice, and
    multimedia documents.  This system is implemented by using narrow-band
    ISDN, high-speed data network, and UNIX-based EWSs with electronic writing
    pads, image scanners, video cameras, microphone-installed loudspeakers,
    etc.  The system provides participants with the means for sharing
    information in such multimedia forms as video images, voice, text,
    graphics, still images, and hand drawn figures.", 
  location     = "http://dx.doi.org/10.1145/99332.99338"
}

@InProceedings{jadfml,
  author       = "Grande, Johan and Boudol, G{\' e}rard and Serrano, Manuel",
  title        = "Jthread, a deadlock-free mutex library",
  booktitle    = pot # "17th International Symposium on and Practice of Declarative Programming",
  year         = 2015,
  pages        = "149--160",
  address      = "Siena, Italy",
  month        = "14--16 " # jul,
  keywords     = "mutual exclusion, deadlock prevention, deadlock avoidance,
    concurrency control, concurrent programming",
  abstract     = "We design a mutex library for Hop -- a dialect of Scheme
    which supports preemptive multithreading and shared memory -- that mixes
    deadlock prevention and deadlock avoidance to provide an easy to use,
    expressive, and safe locking function.  This requires an operation to
    acquire several mutexes simultaneously, for which we provide a
    starvation-free algorithm.  Choosing a formal definition of
    starvation-freedom leads us to identify the concept of asymptotic deadlock.
    Preliminary observations seem to show that our library has negligible
    impact on the performance of real-life applications.  Our work could be
    applied to other languages such as Java.", 
  location     = "http://dx.doi.org/10.1145/2790449.2790523"
}

@Misc{tpbadtkla,
  author       = "Peter {Van Roy} and Seif Haridi",
  title        = "Teaching Programming Broadly and Deeply:  The Kernel Language Approach",
  howpublished = "lecture slides",
  year         = 2002,
		  
  month        = "17 " # jul,
  keywords     = "programming, teaching"
}
