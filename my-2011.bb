.so bibtex.header

@Article{csessitng,
  author       = "Satoshi Matsuoka and Kazushige Saga and Mutsumi Aoyagi",
  title        = "Coupled-Simulation {e-Science} Support in the {NAREGI} Grid",
  journal      = ieeec,
  year         = 2008,
  volume       = 41,
  number       = 11,
  pages        = "42--49",
  month        = nov,
  keywords     = "coupled nanoscience applications, mediator framework,
    coscheduling",
  abstract     = "NAREGI's middleware stack provides comprehensive support for
    coupled applications in the nanoscience discipline.  The authors describe
    several mechanisms that are application-area agnostic and can be applied to
    other disciplines, such as weather and climate simulations, multiresolution
    simulation in life sciences, and other complex systems.", 
  location     = "http://dx.doi.org/10.1109/MC.2008.449"
}

@Article{sbccfdga,
  author       = "Craig Lee and George Percivall",
  title        = "Standards-Based Computing Capabilities for Distributed Geospatial
 Applications ",
  journal      = ieeec,
  year         = 2008,
  volume       = 41,
  number       = 11,
  pages        = "50--57",
  month        = nov,
  keywords     = "geocomuting architecture, web processing, workflow
    management",
  abstract     = "Researchers face increasingly large repositories of 
    geospatial data stored in different locations and in various formats.  To
    address this problem, the Open Geospatial Consortium and the Open Grid
    Forum are collaborating to develop standards for distributed geospatial
    computing.",
  location     = "http://dx.doi.org/10.1109/MC.2008.468"
}

@Article{escatbr,
  author       = "Joel Saltz and Tahsin Kurc and Shannon Hastings and Stephen 
    Langella and Scott Oster and David Ervin and Ashish Sharma and Tony Pan and
    Metin Gurcan and Justin Permar and Renato Ferreira and Philip Payne and
    Umit Catalyurek and Enrico Caserta and Gustavo Leone and
    Michael~C. Ostrowski and Ravi Madduri and Ian Foster and Subhashree
    Madhavan and Kenneth H. Buetow and Krishnakant Shanbhag and Eliot Siegel",
  title        = "{e-Science}, {caGrid}, and Translational Biomedical Research",
  journal      = ieeec,
  year         = 2008,
  volume       = 41,
  number       = 11,
  pages        = "58--66",
  month        = nov,
  keywords     = "cagrid, caintegrator, translational research",
  abstract     = "Translational research projects target a wide variety of 
    diseases, test many different kinds of biomedical hypotheses, and employ a
    large assortment of experimental methodologies.  Diverse data, complex
    execution environments, and demanding security and reliability requirements
    make the implementation of these projects extremely challenging and require
    novel e-Science technologies.",
  location     = "http://dx.doi.org/10.1109/MC.2008.459"
}

@Article{esifdmb,
  author       = "Ron Perrott and Terry Harmer and Rhys Lewis",
  title        = "{e-Science} Infrastructure for Digital Media Broadcasting",
  journal      = ieeec,
  year         = 2008,
  volume       = 41,
  number       = 11,
  pages        = "67--72",
  month        = nov,
  keywords     = "media distribution, virtual organization, content managment",
  abstract     = "Because digital media management and distribution
    technologies face some of the same challenges that e-Science aims to
    address, this technology is a viable solution to meet the broadcasting
    domain's rigorous demands.", 
  location     = "http://dx.doi.org/10.1109/MC.2008.458"
}

@Article{emmhwltp,
  author       = "Alastair~J. Walker",
  title        = "Enterprise Maturity Models: Have We Lost the Plot?",
  journal      = ieeec,
  year         = 2008,
  volume       = 41,
  number       = 11,
  pages        = "96--98",
  month        = nov,
  keywords     = "iso 9000, cmmi, maturity models",
  abstract     = "For models of enterprise maturity to regain credibility, we
    must provide a renewed and predictably unpopular emphasis on the delivered
    information items' quality.",
  location     = "http://dx.doi.org/10.1109/MC.2008.462"
}

@Article{evlm,
  author       = "Lawrence Mandel",
  title        = "Eclipse Validators",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "74--79",
  month        = dec,
  keywords     = "eclipse, validators, plug-ins",
  location     = "http://www.drdobbs.com/tools/184405940"
}

@Article{rambk,
  author       = "Brian Kelley",
  title        = "Relational Algebra \& {M}etakit",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "65--68",
  month        = dec,
  keywords     = "databases, relational operations",
  location     = "http://www.drdobbs.com/article/printableArticle.jhtml?articleId=184405933&dept_url=/"
}

@Article{rtsrc,
  author       = "William Nagel",
  title        = "Real-Time Systems \& {RT} {CORBA}",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "70--72",
  month        = dec,
  keywords     = "mutex, priority propagation, thread pools",
  location     = "http://www.drdobbs.com/cpp/184405941"
}

@Article{drmaa,
  author       = "Fr{\' e}d{\' e}ric Parient{\' e}",
  title        = "Distributed Resource Management Application {API}",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "60--64",
  month        = dec,
  keywords     = "job completion",
  location     = "http://www.drdobbs.com/database/184405932"
}

@Article{abtwa,
  author       = "Hugo Troche",
  title        = "Automating Batch Tasks with {A}nt",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "56--59",
  month        = dec,
  keywords     = "ant, task management, custom tasks",
  location     = "http://www.drdobbs.com/database/184405931"
}

@Article{asoci,
  author       = "Miciej Sobczak",
  title        = "{A} Simple {O}racle Call Interface",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "52--55",
  month        = dec,
  keywords     = "c++, library development",
  location     = "http://www.drdobbs.com/database/184405930"
}

@Article{pijmp,
  author       = "Michael Pilone",
  title        = "Plug-Ins \& {J}ava",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "46--50",
  month        = dec,
  keywords     = "interfaces, dynmaic loading",
  location     = "http://www.drdobbs.com/java/184405929"
}

@Article{ircg,
  author       = "D.~Ryan Stephens",
  title        = "Information Retrieval \& Computatational Geometery",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "42--45",
  month        = dev,
  keywords     = "information retreival, computational geometery, similarity
    measures",
  location     = "http://www.drdobbs.com/article/printableArticle.jhtml?articleId=184405928&dept_url=/"
}

@Article{jscad,
  author       = "Ken North",
  title        = "Java, {SQL}, {Cloudscape}, and {Derby}",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "38--40",
  month        = dec,
  keywords     = "performance, concurrency, scalability, database container",
  location     = "http://www.drdobbs.com/database/184405927"
}

@Article{tfdss,
  author       = "Steve Summers",
  title        = "The {Firebird} {DBMS}",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "32--37",
  month        = dec,
  keywords     = "triggers, events, database",
  location     = "http://www.drdobbs.com/184405926"
}

@Article{ddrc,
  author       = "David~J. Berube",
  title        = "Databases \& Dynamic {Ruby} Classes",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "24--30",
  month        = dec,
  keywords     = "inheritance, dynamic languages",
  location     = "http://www.drdobbs.com/article/printableArticle.jhtml?articleId=184405925&dept_url=/"
}
		  
		  
@inproceedings{ewspfbainsrs,
  author       = "Mike Afergan and Joel Wein and Amy LaMeyer",
  title        = "Experience with Some Principles for Building an
		  {I}nternet-Scale Reliable System",
  booktitle    = "Second Workshop on Real, Large Distributed Systems (WORLD
		  '05)",
  year         = 2005,
  month        = "13 " # dec,
  address      = sfca,
  keywords     = "large systems, reliability, design guidlines",
  abstract     = "We discuss the design methodology used to achieve
		  commercial-quality reliability in the Akamai content delivery
		  network. The network consists of 15,000+ servers in 1,100+
		  networks and spans 65+ countries. Despite the scale of the
		  Akamai CDN and the unpredictable nature of the underlying
		  Internet, we seek to build a system of extremely high
		  reliability. We present some simple principles we use to
		  assure high reliability, and illustrate their application. As
		  there is some similarity-in-spirit between our implementation
		  and recent trends in the research literature, we hope that
		  sharing our experiences will be of value to a broad
		  community.",
  location     = "http://www.akamai.com/en/resources/pdf/technical_publications/ExperiencewithsomePrinciplesforBuildinganInternetScaleReliableSystem.pdf"
}

@inproceedings{dmcoso,
  author       = "Mustaque Ahamad and Francisco Jose Torres-Rojas and Rammohan
    Kordale and Jasjit Singh and Shawn Smith",
  title        = "Detecting Mutual Consistency of Shared Objects",
  booktitle    = pot # "1994 First Workshop on Mobile Computing Systems and Applications",
  year         = 1994,
  month        = "8--9 " # dec,
  address      = "Santa Cruz, " # CA,
  pages        = "44--50",
  keywords     = "causal consistency",
  abstract     = "In systems that support disconnected operations, shared
    objects must be cached at client sites to ensure that the objects are
    accessible while the client is disconnected.  It is desirable that objects
    cached at a client site are mutually consistent with respect to the level
    of consistency provided by the system.  We present a new technique for
    detecting mutual consistency of objects and show how it can be used to
    support causal consistency, which is appropriate in systems that support
    disconnected operations.", 
  location     = "http://www.cc.gatech.edu/systems/projects/COBS/cache.ps.gz"
}

@InProceedings{tasfoz,
  author       = "David~J. Duke and Roger Duke",
  title        = "Towards a Semantics for {O}bject-{Z}",
  booktitle    = pot # "Third International Symposium of VDM Europe",
  year         = 1990,
  editor       = "Dines Bj{\o}rner and C.~A.~R. Hoare and Hans Langmaack",
  pages        = "244--261",
  series       = lncs,
  volume       = 428,
  publisher    = "Springer",
  address      = "Kiel, Germany",
  month        = "17--21 " # apr,
  keywords     = "classes, history invariants, schema semantics, carriers",
  abstract     = "Object-Z is a notation based on Z but with extensions to 
    more fully support an object-oriented style of specification.  Object-Z
    uses the class concept to incorporate a description of an object's state
    with related operations.  In this paper we introduce an underlying
    set-theoretic model for classes and so give a formal semantics for classes
    which extends the semantics of schemas in Z.  Our model for a class is
    based on the idea of a history which captures the sequence of operations
    and state changes undergone by an instance (object) of the class.  Part of
    the specification of a class can involve predicates which restrict the
    possible histories of an object.", 
  location     = "isbn 3-540-52513-0"
}

@InProceedings{acofret,
  author       = "Berndt Bellay and Harald Gall",
  title        = "{A} Comparison of Four Reverse Engineering Tools",
  booktitle    = pot # "Fourth Working Conference on Reverse Engineering",
  year         = 1997,
  editor       = "Ira~D. Baxter and Alex Quilici and Chris Verhoef",
  pages        = "2--11",
  publisher    = "IEEE Computer Society Press",
  address      = "Amsterdam, The Netherlands", 
  month        = "6--8 " # oct,
  keywords     = "tool assesment, extensibility",
  abstract     = "Reverse engineering tools support software engineers in the 
    process of analyzing and understanding complex software systems during
    maintenance activities.  The functionality of such tools varies from
    editing and browsing capabilities to the generation of textual and
    graphical reports.  There are several commercial reverse engineering tools
    on the market providing different capabilities and supporting specific
    source code languages.  We evaluated four reverse engineering tools that
    analyze C source code: Refine/C, Imagix4D, Sniff+, and Rigi.  We
    investigated the capabilities of these tools by applying them to a
    commercial embedded software system as a case study.  We identified
    benefits and shortcomings of these four tools and assessed their
    applicability for embedded software systems, their usability, and their
    extensibility."
}

@InProceedings{aiosmm,
  author       = "David MacQueen",
  title        = "An Implementation of {S}tandard {ML} Modules",
  booktitle    = pot # "ACM Conference on LISP and Functional Programming",
  year         = 1988,
  pages        = "213--223",
  address      = "Snowbird, Utah",
  month        = "25--27 " # jul,
  keywords     = "modules, signature matching, functors, sharing, type
    checking",
  abstract     = "Standard ML includes a set of module constructs that support
    programming in the large.  These constructs extend ML's basic polymorphic
    type system by introducing the dependent types of Martin Löf's
    Intuitionistic Type Theory.  This paper discusses the problems involved in
    implementing Standard ML's modules and describes a practical, efficient
    solution to these problems.  The representations and algorithms of this
    implementation were inspired by a detailed formal semantics of Standard ML
    developed by Milner, Tofte, and Harper.  The implementation is part of a
    new Standard ML compiler that is written in Standard ML using the module
    system.",
  location     = "http://dx.doi.org/10.1145/62678.62704"
}

@InProceedings{casptplsfia,
  author       = "Ian Stoica and Robert Morris and David Karger and M.~Frans
    Kaashoek and Hari Blakrishnan",
  title        = "Chord: {A} Scalable Peer-to-Peer Lookup Service for Internet Applications",
  booktitle    = pot # "2001 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications",
  year         = 2001,
  pages        = "149--160",
  publisher    = acmp,
  address      = sdca,
  month        = "27--31 " # aug,
  keywords     = "distributed hash functions, p2p networks, small worlds",
  abstract     = "A fundamental problem that confronts peer-to-peer
    applications is to efficiently locate the node that stores a particular
    data item.  This paper presents Chord, a distributed lookup protocol that
    addresses this problem.  Chord provides support for just one operation:
    given a key, it maps the key onto a node.  Data location can be easily
    implemented on top of Chord by associating a key with each data item, and
    storing the key/data item pair at the node to which the key maps.  Chord
    adapts efficiently as nodes join and leave the system, and can answer
    queries even if the system is continuously changing.  Results from
    theoretical analysis, simulations, and experiments show that Chord is
    scalable, with communication cost and the state maintained by each node
    scaling logarithmically with the number of Chord nodes.",
  location     = "http://pdos.csail.mit.edu/6.824/papers/stoica-chord.pdf"
}

@InProceedings{ascan,
  author       = "Sylvia Ratnasamy and Paul Francis and Mark Handley and
    Richard Karp and Scott Shenker",
  title        = "{A} Scalable Content-Addressable Network",
  booktitle    = pot # "Conference on Applications, Technologies,
    Architectures, and Protocols for Computer Communications", 
  year         = 2001,
  pages        = "161--172",
  publisher    = acmp,
  address      = sdca,
  month        = "27--31 " # aug,
  keywords     = "content-addressable networks, multi-coordinate spaces,
    distributed hash table",
  abstract     = "Hash tables - which map keys onto values - are an essential
    building block in modern software systems.  We believe a similar
    functionality would be equally valuable to large distributed systems.  In
    this paper, we introduce the concept of a Content-Addressable Network (CAN)
    as a distributed infrastructure that provides hash table-like functionality
    on Internet-like scales.  The CAN is scalable, fault-tolerant and
    completely self-organizing, and we demonstrate its scalability, robustness
    and low-latency properties through simulation.", 
  location     = "http://www.sigcomm.org/sigcomm2001/p13-ratnasamy.pdf"
}

@InProceedings{adpfcbcwc,
  author       = "Frederick Knabe",
  title        = "{A} Distributed Protocol for Channel-Based Communication with Choice",
  booktitle    = pot # "4th International PARLE Conference on Parallel
    Architectures and Languages Europe",
  year         = 1992,
  editor       = "Daniel Etiemble and Jean-Claude Syre",
  pages        = "947--948",
  series       = lncs,
  volume       = 605,
  publisher    = sv,
  address      = "Paris, France",
  month        = "15--18" # jun,
  keywords     = "channels, starvation, csp",
  location     = "http://www.cs.virginia.edu/~knabe/parle92.ps.gz"
}

@InProceedings{tmavtst,
  author       = "Peter~C. Bates and Mark~E. Segal",
  title        = "Touring Machine: {A} Video Telecommunications Software Testbed",
  booktitle    = pot # "First International Workshop on Network and Operating
    System Support for Digital Audio and Video",
  year         = 1990,
  address      = beca,
  month        = nov,
  keywords     = "multimedia, group communication",
  location     = "http://comet.lehman.cuny.edu/griffeth/Papers/touring93.pdf"
}

@InProceedings{smvmpiaade,
  author       = "Amotz Bar-Noy and Danny Dolev",
  title        = "Shared-Memory vs. Message-Passing in an Asynchronous Distributed Environment",
  booktitle    = pot # "Eighth Annual" # podc,
  year         = 1989,
  editor       = "Piotr Rudnicki",
  pages        = "307--318",
  publisher    = acmp,
  keywords     = "shared memory, message passing, asynchrony"
}

@Article{teox,
  author       = "J{\' e}r{\^ o}me Sim{\' e}on and Philip Wadler",
  title        = "The Essence of {XML}",
  journal      = sigplan # " (" # pot # "30th ACM SIGPLAN-SIGACT symposium on"
		  # popl # ")",
  year         = 2003,
  pages        = "1--13",
  number       = 1,
  volume       = 38,
  month        = jan,
  keywords     = "",
  abstract     = "The World-Wide Web Consortium (W3C) promotes XML and related
    standards, including XML Schema, XQuery, and XPath.  This paper describes a
    formalization of XML Schema.  A formal semantics based on these ideas is
    part of the official XQuery and XPath specification, one of the first uses
    of formal methods by a standards body.  XML Schema features both named and
    structural types, with structure based on tree grammars.  While structural
    types and matching have been studied in other work (notably XDuce, Relax
    NG, and a previous formalization of XML Schema), this is the first work to
    study the relation between named types and structural types, and the
    relation between matching and validation.", 
  location     = "http://homepages.inf.ed.ac.uk/wadler/papers/xml-essence/xml-essence.pdf"
}

@Article{dsdes,
  author       = "Dennis~E. Shasha and Phillippe Bonnet",
  title        = "Database Systems",
  journal      = ddj,
  year         = 2004,
  volume       = 29,
  number       = 12,
  pages        = "16--22",
  month        = dec,
  keywords     = "transactional semantics, querying",
  location     = "http://www.drdobbs.com/article/printableArticle.jhtml?articleId=184405923&dept_url=/"
}

@Article{rbacfagsuodas,
  author       = "Vineela Muppavarapu and Anil~L.Pereira and Soon~M. Chung",
  title        = "Role-based access control for a Grid system using {OGSA}-{DAI} and {Shibboleth}",
  journal      = "The Journal of Supercomputing",
  year         = 2010,
  volume       = 52,
  number       = 2,
  pages        = "154--179",
  month        = nov,
  keywords     = "grid computing, role-based authentication",
  abstract     = "In this paper, we propose a new role-based access control 
    (RBAC) system for Grid data resources in the Open Grid Services
    Architecture Data Access and Integration (OGSA-DAI).  OGSA-DAI is a widely
    used framework for integrating data resources in Grids.  However,
    OGSA-DAI's identity-based access control causes substantial administration
    overhead for the resource providers in virtual organizations (VOs) because
    of the direct mapping between individual Grid users and the privileges on
    the resources.  To solve this problem, we used the Shibboleth, an attribute
    authorization service, to support RBAC within the OGSA-DAI.  In addition,
    access control policies need to be specified and managed across multiple
    VOs.  For the specification of access control policies, we used the Core
    and Hierarchical RBAC profile of the eXtensible Access Control Markup
    Language (XACML); and for distributed administration of those policies and
    the user-role assignments, we used the Object, Metadata and Artifacts
    Registry (OMAR).  OMAR is based on the e-business eXtensible Markup
    Language (ebXML) registry specifications developed to achieve interoperable
    registries and repositories.  Our RBAC system provides scalable and
    fine-grain access control and allows privacy protection.  It also supports
    dynamic delegation of rights and user-role assignments, and reduces the
    administration overheads for the resource providers because they need to
    maintain only the mapping information from VO roles to local database
    roles.  Moreover, unnecessary mapping and connections can be avoided by
    denying invalid requests at the VO level.  Performance analysis shows that
    our RBAC system adds only a small overhead to the existing security
    infrastructure of OGSA-DAI.",
  location     = ""
}

@Article{cieat,
  author       = "Henry~G. Baker",
  title        = "{CLOStrophobia}: Its Etiology and Treatment",
  journal      = "ACM OOPS Messenger",
  year         = 1991,
  volume       = 2,
  number       = 4,
  pages        = "4--15",
  month        = oct,
  keywords     = "clos, multiple inheritance, metaprotocol, optimizations",
  abstract     = "The Common Lisp Object System (CLOS) has received some
    praise and some criticism, both deserved.  One of the most controversial
    features of standard CLOS is its linearly-ordered class precedence list,
    which is used to linearly order the execution of its combination methods.
    In addition to the problems already known regarding the linear ordering of
    superclasses, we show that the standard CLOS class precedence ordering
    produces gratuitously complex and non-intuitive behavior.  We then show
    that a slight modification of the standard ordering rules produces a linear
    ordering which can achieve most of the goals of CLOS more efficiently, and
    without impacting most programs.  We describe a subset of CLOS called
    Static CLOS which preserves much of the praise due CLOS, while eliminating
    some of the criticism.  Static CLOS is tuned for delivery of debugged code,
    rather than for prototype development.  This delivery CLOS determines as
    many methods as possible at compile-time using type inference techniques.
    While these techniques generally result in faster-executing code, the space
    requirements can grow quite large.  We argue that this space explosion can
    be partially ameliorated through the use of our modified class precedence
    ordering.",
  location     = "http://home.pipeline.com/~hbaker1/CLOStrophobia.html"
}

@Article{esfeds,
  author       = "Miroslav Sveda and Radimir Vrba",
  title        = "Executable Specifications for Embedded Distributed Systems",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "138--140",
  month        = jan,
  keywords     = "specification languages, attribute grammars, prolog,
    prototyping",
  abstract     = "Designers can use hardware components and an executable
    specification language to efficiently prototype embedded distributed
    systems.",
  location     = "http://www.fit.vutbr.cz/~sveda/texty/COMPUTERr1138.pdf.pdf"
}

@Article{sdrt1l,
  author       = "Barry Boehm and Victor~R. Basili",
  title        = "Software Defect Reduction Top 10 List",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "135--137",
  month        = jan,
  keywords     = "checklists, software development",
  abstract     = "Software's complexity and accelerated development schedules
    make avoiding defects difficult. These 10 techniques can help reduce the
    flaws in your code.",
  location     = "http://dx.doi.org/10.1109/2.962984"
}

@Article{citnm,
  author       = "Hal Berghel",
  title        = "Cyberprivacy in the New Millennium",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "132--134",
  month        = jan,
  keywords     = "cookies, identity theft",
  abstract     = "E-mail is indispensable for most of us, but one penalty of
    its convenience is its negative impact on individual privacy.",
  location     = "http://dx.doi.org/10.1109/2.962982"
}

@Article{direfame,
  author       = "Maribeth Back and Rich Gold and Anne Balsamo and Mark Chow
    and Matt Gorbet and Steve Harrison and Dale MacDonald and Scott Minneman",
  title        = "Designing Innovative Reading Experiences for a Museum Exhibition",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "80--87",
  month        = jan,
  keywords     = "reading, museum exhibit design, user interaction",
  abstract     = "In 1998, the Tech Museum of Innovation in San Jose invited
    the Research in Experimental Documents (RED) group at Xerox Corporation's
    Palo Alto Research Center to develop an exhibit for its Center of the Edge
    Gallery.  RED convenes researchers skilled in video production, mechanical
    engineering, interface design, architecture, cultural theory, sound
    engineering, cartooning, writing, lighting, programming, industrial design,
    and graphic arts to design and build real working objects and prototypes.
    It explores new document genres within emerging media through hands-on
    experimentation.  RED searches for projects that influence the real world,
    using public reaction to gain insight into a project's effectiveness and
    speculative design process.  The Tech Museum focuses on current technology
    rather than science.  Its 250 exhibits are interactive, original, or
    custom-made.  Reading remains central to our technological society, and the
    authors show how digital technology facilitates an array of exciting
    reading experiences.  The exhibit encourages people to consider the genesis
    of the text they read and ask how technology might change what, where, and
    how they read.",
  location     = "http://dx.doi.org/10.1109/2.970581"
}

@Article{fanstati,
  author       = "Richard Lindheim and William Swartout",
  title        = "Forging a New Simulation Technology at the {ICT}",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "72--79",
  month        = jan,
  keywords     = "simulations, story telling",
  abstract     = "Under the auspices of the US Army Simulation, Training, and
    Instrumentation Command, USC's Institute for Creative Technologies (ICT)
    focuses on developing the art and technology for providing compelling yet
    synthetic experiences so participants react as if the simulations are real.
    ICT will bring verisimilitude--the quality or state of appearing to be
    true--to synthetic experiences.  The Mission Rehearsal Exercise project
    seeks to create a virtual reality-training environment in which soldiers
    confront dilemmas that impel them to decide in real time under stressful
    circumstances.  By using a simulator so that soldiers see the consequences
    of their actions and decision-making skills, the Army expects to better
    prepare its troops for dealing with similar dilemmas in the real world.
    ICT's objective is to build a special partnership with the entertainment
    industry and academia.  With the Experience Learning System, the authors
    plan to develop a simulation training system for the Army that overcomes
    current simulation shortcomings while playing a complementary role with its
    legacy simulation systems.  Ultimately, the Army seeks to implement a
    net-worked, immersive system benefiting from the creativity of
    entertainment industry artists and virtual reality technology.",
  OPTlocation  = ""
}

@Article{totbati,
  author       = "Scott Hamilton",
  title        = "Thinking Outside the Box at the {IHMC}",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "61--71",
  month        = jan,
  keywords     = "cognitive prostheses, human-machine interfaces, data mining,
    knowledge modeling, concept maps, software agents",
  abstract     = "A decade ago, artificial intelligence research came under
    fire for being overhyped.  Several projects now being conducted at The
    Institute for Human and Machine Cognition (IHMC) in Pensacola, Florida, may
    stimulate an AI renaissance.  The author analyzes IHMC's human-centered
    computing approach to research and demonstrates how this approach embraces
    an interrelated collection of practical AI applications.  IHMC applies
    technology to next-generation interfaces, knowledge modeling and sharing,
    intelligent agents, data mining, and extending human cognition.  Scientists
    and researchers from diverse fields like computer science and engineering,
    medicine and cognitive psychology, statistics and mathematics, and the
    social sciences and philosophy are studying the complex phenomenon of human
    cognition.  They aim to develop cognitive prostheses for augmenting our
    human capabilities and supplementing our human limitations.  The IHMC's
    founders believed that the traditional academic architectonic by which
    universities divide knowledge reflected a focus on specialization that
    harmed cutting-edge research.  The author describes how the interwoven
    research projects reflect the institute's interdisciplinary vision.", 
  location     = ""
}

@Article{fpistcaad,
  author       = "David Harel",
  title        = "From Play-In Scenarios to Code: An Achievable Dream",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "53--60",
  month        = jan,
  keywords     = "system modeling, oo analysis and design, structured analysis,
    structured design, specifying requirements, sequence charts",
  abstract     = "The author describes a scheme for developing complex
    reactive systems.  The scheme makes it possible to go from a user-friendly
    requirements capture method, called play-in scenarios, via a rich language
    for describing message sequencing to full behavioral descriptions of system
    parts, and from there to final implementation.  The author's proposal
    combines ideas that have been known for a long time with more recent ones.
    Central to the proposal is a cyclic process of verifying the system against
    requirements and synthesizing system parts from the requirements.  The
    article focuses on the languages, methods, and computerized tools that
    allow smooth but rigorous transitions between the scheme's various stages.
    In contrast to database systems, this article concentrates on systems that
    have a dominant reactive, event-driven facet for which modeling and
    analyzing behavior is the most crucial and problematic issue.", 
  location     = ""
}

@Article{sdcwacmc,
  author       = "Brett Warneke and Matt Last and Brian Liebowitz and Kristofer S.~J. Pister",
  title        = "Smart Dust: Communicating with a Cubic-Millimeter Computer",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "44--51",
  month        = jan,
  keywords     = "smart dust, milimeter scale computing, microrobotics, optical
    communications",
  abstract     = "The University of California, Berkeley's Smart Dust project
    explores whether an autonomous sensing, computing, and communication system
    can be packed into a cubic-millimeter mote (a small particle or speck) to
    form the basis of integrated, massively distributed sensor networks.  The
    authors selected an arbitrary size for their sensor systems to explore
    microfabrication technology's limitations.  Because of its discrete size,
    substantial functionality, connectivity, and anticipated low cost, Smart
    Dust will facilitate innovative methods for microfabrication technology and
    interact with the environment, providing more information from more places
    less intrusively.  Smart Dust requires evolutionary and revolutionary
    advances in miniaturization, integration, and energy management.  Designers
    use microelectromechanical systems to build small sensors, optical
    communication components, and power supplies, whereas microelectronics
    provides increasing functionality in smaller areas, with lower energy
    consumption.Research in the wireless sensor network area is growing rapidly
    in academia and industry.  The authors look toward programming walls and
    furniture, and some day even insects and dust.", 
  OPTlocation  = ""
}

@Article{nfsaan,
  author       = "Victor~V. Zhirnov and Daniel J.~C. Herr",
  title        = "New Frontiers: Self-Assembly and Nanoelectronics",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 1,
  pages        = "34--43",
  month        = jan,
  keywords     = "self-assembly, information theory, nanofabrication",
  abstract     = "In a quest for semiconductor materials and processes,
    researchers focus on self-assembly, drawing from chemistry, biology,
    material science, and electrical engineering.  In nature, self-organization
    and self-assembly are holistic processes.  The tools and methods for
    synthesizing living matter represent the union of several disciplines (from
    mathematics and information theory; physics, chemistry, and biology; to
    philosophy and endogenetics).  Engineers aim to apply living processes to
    improve the quality of life.  The authors consider opportunities for and
    barriers to realizing practical applications of self-assembly from the
    perspectives of information theory, synergetics, and selected areas of
    physical and life sciences.When an electronic device's features are large,
    the process is metabolic-like and economically controlled.  As the features
    shrink to nanometers, manufacturers pay a high price for the morphological
    information required to maintain system fidelity.  This article shows how
    today's researchers can apply self-assembly principles to fabricate simple,
    uniform arrays of small quantum dots.  The authors inspire readers to look
    to the future when we can use self-assembly to fabricate nanoelectronic
    device architectures.", 
  location     = "http://dx.doi.org/10.1109/2.963443"
}

@Article{acotghmsos,
  author       = "Neal~H. Walfield and Marcus Brinkmann",
  title        = "{A} critique of the {GNU} {H}urd multi-server operating system",
  journal      = sigops,
  year         = 2007,
  volume       = 41,
  number       = 4,
  pages        = "30--39",
  month        = jul,
  keywords     = "name spaces, abstractions, translators",
  abstract     = "The GNU Hurd's design was motivated by a desire to rectify a
    number of observed shortcomings in Unix.  Foremost among these is that many
    policies that limit users exist simply as remnants of the design of the
    system's mechanisms and their implementation.  To increase extensibility
    and integration, the Hurd adopts an object-based architecture and defines
    interfaces, in particular those for the composition of and access to name
    spaces, that are virtualizable.  This paper is first a presentation of the
    Hurd's design goals and a characterization of its architecture primarily as
    it represents a departure from Unix's.  We then critique the architecture
    and assess it in terms of the user environment of today focusing on
    security.  Then follows an evaluation of Mach, the microkernel on which the
    Hurd is built, emphasizing the design constraints which Mach imposes as
    well as a number of deficiencies its design presents for multi-server like
    systems.  Finally, we reflect on the properties such a system appears to
    require.", 
  location     = "http://dx.doi.org/10.1145/1278901.1278907",
  location     = "http://dx.doi.org/10.1145/1278901.1278907"
}

@Article{tcosatn,
  author       = "Jon Kleinberg",
  title        = "The Convergence of Social and Technological Networks",
  journal      = cacm,
  year         = 2008,
  volume       = 51,
  number       = 11,
  pages        = "66--72",
  month        = nov,
  keywords     = "small worlds, decentralized search, social contagion",
  abstract     = "Internet-based data on human interaction connects scientific
    inquiry like never before.",
  location     = "http://dx.doi.org/10.1145/1400214.1400232"
}

@Article{stmwiioart,
  author       = "Calin Cascaval and Colin Blundell and Maged Michael and
    Harold~W. Cain and Peng Wu and Stefanie Chiras and Siddhartha Chatterjee",
  title        = "Software transactional memory: why is it only a research toy?",
  journal      = cacm,
  year         = 2008,
  volume       = 51,
  number       = 11,
  pages        = "40--46",
  month        = nov,
  keywords     = "software transaction memory, performance",
  abstract     = "",
  location     = "http://dx.doi.org/10.1145/1400214.1400228"
}

@Article{rwc,
  author       = "Bryan Cantrill and Jeff Bonwick",
  title        = "Real-world concurrency",
  journal      = cacm,
  year         = 2008,
  volume       = 51,
  number       = 11,
  pages        = "34--39",
  month        = nov,
  keywords     = "software design, concurrency",
  abstract     = "What does the proliferation of concurrency mean for the
    software you develop?", 
  location     = "http://dx.doi.org/10.1145/1400214.1400227"
}

@Article{pasfqaavomd,
  author       = "Chris Stolte and Diane Tang and Pat Hanrahan",
  title        = "Polaris: a system for query, analysis, and visualization of multidimensional
 databases ",
  journal      = cacm,
  year         = 2008,
  volume       = 51,
  number       = 11,
  pages        = "75--84",
  month        = nov,
  keywords     = "visualization, graphical analysis, data analysis, graphical
    algebra",
  abstract     = "During the last decade, multidimensional databases have
    become common in the business and scientific worlds.  Analysis places
    significant demands on the interfaces to these databases.  It must be
    possible for analysts to easily and incrementally change both the data and
    their views of it as they cycle between hypothesis and experimentation.  In
    this paper, we address these demands by presenting the Polaris formalism, a
    visual query language for precisely describing a wide range of table-based
    graphical presentations of data.  This language compiles into both the
    queries and drawing commands necessary to generate the visualization,
    enabling us to design systems that closely integrate analysis and
    visualization.  Using the Polaris formalism, we have built an interactive
    interface for exploring multidimensional databases that analysts can use to
    rapidly and incrementally build an expressive range of views of their data
    as they engage in a cycle of visual analysis.", 
  location     = "http://dx.doi.org/10.1145/1400214.1400234"
}

@Article{zsbft,
  author       = "Ramakrishna Kotla and Allen Clement and Edmund Wong and
    Lorenzo Alvisi and Mike Dahlin",
  title        = "Zyzzyva: speculative {B}yzantine fault tolerance",
  journal      = cacm,
  year         = 2008,
  volume       = 51,
  number       = 11,
  pages        = "86--95",
  month        = nov,
  keywords     = "byzantine faults, optimistic fault tolerance",
  location     = "http://dx.doi.org/10.1145/1400214.1400236"
}

@Article{rrtwdt,
  author       = "Dave Thomas",
  title        = "{RSS}, {R}uby, \& the {W}eb",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "26--30",
  month        = jan,
  keywords     = "rss feeds, blogging"
}

@Article{mwpaa,
  author       = "Christian Hicks and Dessislava Pachamanova",
  title        = "Metamodeling with {P}erl and {AMPL}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "16--24",
  month        = jan,
  keywords     = "optimization systems, intermediate results",
  location     = "http://www.drdobbs.com/tools/184416171"
}

@Article{uttdrts,
  author       = "Michael Hindahl",
  title        = "Using Trace to Debug Real-Time Systems",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "66--",
  month        = jan,
  keywords     = "hardware tracing, software tracing, ",
  location     = "http://drdobbs.com/embedded-systems/229100158"
}

@Article{pvvsst,
  author       = "Sam Tregar",
  title        = "Perl, {VMW}are, \& Virtual Solutions",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "60--64",
  month        = jan,
  keywords     = "build farms, scripting, virtual machines, "
}

@Article{wgajp,
  author       = "Jon Person",
  title        = "Writing {GPS} Applications",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "52--56",
  month        = jan,
  keywords     = "global positioning, positioning",
  location     = "http://drdobbs.com/embedded-systems/229100152"
}

@Article{cpbjgc,
  author       = "John Graham-Cumming",
  title        = "Cross-Platform Builds",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "48--51",
  month        = jan,
  keywords     = "gnu make"
}

@Article{avtx,
  author       = "Gerald McCobb and Jeff Kusnitz",
  title        = "Adding Voice to {XHTML}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "42--46",
  month        = jan,
  keywords     = "voice interfaces, voice dialogs, salt"
}

@Article{prwb,
  author       = "Walter Bright",
  title        = "{\em printf} Revisited",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "40--41",
  month        = jan,
  keywords     = "type safety"
}

@Article{mwmi,
  author       = "Joe Strout",
  title        = "Mixins Without Multiple Inheritance",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "37--39",
  month        = jan,
  keywords     = "semantics, mixins, data sharing"
}

@Article{epgs,
  author       = "Greg Smith",
  title        = "Extending {P}ython",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 1,
  pages        = "32--36",
  month        = jan,
  keywords     = "foreign function interface",
  location     = "http://drdobbs.com/open-source/229100149"
}

@Article{asgatl,
  author       = "Frank Drewes and BertholdHoffman and Dirk Jansens and Mark Minas",
  title        = "Adaptive Star Grammars and Their Languages",
  journal      = "Science of Computer Programming",
  year         = 2010,
  volume       = "",
  number       = "",
  pages        = "",
  month        = "",
  keywords     = "star replacement, cloning, associativity, confluence",
  abstract     = "Graph grammars may be used as specification technique for 
    different kinds of systems, specially in situations in which states are
    complex structures that can be adequately modeled as graphs (possibly with
    an attribute data part) and in which the behavior involves a large amount
    of parallelism and can be described as reactions to stimuli that can be
    observed in the state of the system.  The verification of properties of
    such systems is a difficult task due to many aspects: the systems in many
    situations involve an infinite number of states; states themselves are
    complex and large; there are a number of different computation
    possibilities due to the fact that rule applications may occur in parallel.
    There are already some approaches to verification of graph grammars based
    on model checking, but in these cases only finite state systems can be
    analyzed.  Other approaches propose over- and/or under-approximations of
    the state space, but in this case it is not possible to check arbitrary
    properties.  This work proposes a relational and logical approach to graph
    grammars that allows formal verification of systems using mathematical
    induction.  We use relational structures to define graph grammars and
    first-order logic to model graph transformations.  This approach allows
    proving properties of systems with infinite state spaces.  In this paper we
    first consider the case of simple (typed) graphs, and then we extend the
    approach to the non-trivial case of attributed graphs, that are graphs in
    which values are associated to vertices.  Attributed graph grammars are
    very interesting from a practical point of view, since it is possible to
    use variables and terms when specifying the behavior expressed by rules.
    These values (or terms) come from algebras specified as abstract data
    types.  The use of attributed graphs gives the specifier a language that is
    more suitable for specification, merging the advantages of the graphical
    representation with the standard representation of classical data types.
    We show that attributes can be smoothly integrated in our representation of
    graph grammars, giving rise to a framework to reason about attributed graph
    grammars.", 
  location     = ""
}

@Article{mtmioa,
  author       = "M. Todd Gamble and Rose Gamble",
  title        = "Monoliths to Mashups: Increasing Opportunistic Assets",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "71--79",
  month        = nov # "/" # dec,
  keywords     = "lagacy monoliths, end-user mashups",
  abstract     = "Opportunities are available resources that yield desired
    results.  An opportunity's suitability depends on who seizes it and the
    context for its use.  Opportunistic development builds hybrid software
    systems from reusable resources called opportunistic assets.  Mashups are
    Web application hybrids that consume these assets.  Monoliths are
    self-contained systems that can produce such opportunistic assets if they
    can expose key functions that are easy to mash.  A major barrier to reusing
    legacy monoliths is integration.  Elevating integration connectors to
    first-class opportunistic assets reduces this barrier by linking to and
    presenting monolith applications as opportunities for mashups.",
  location     = "http://dx.doi.org/10.1109/MS.2008.152"
}

@Article{msiip,
  author       = "Anna B{\" o}rjesson Sandberg and Lars Mathiassen",
  title        = "Managing Slowdown in Improvement Projects",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "84--89",
  month        = nov # "/" # dec,
  keywords     = "software management, people management",
  abstract     = "Unaware of the consequences, busy managers and senior
    engineers often behave in ways that hamper progress in improvement
    projects.  Change agents easily become frustrated when key colleagues are
    late to meetings, delay responding to requests for information, or don't
    make decisions as required.  However, rather than accepting the slowdown
    such behavior causes, change agents should analyze and address the
    challenges it signals.  Based on experiences in nine process improvement
    projects at Ericsson, the authors suggest how change agents can analyze
    slowdown behavior, respond by increasing the commitment and effort of key
    colleagues, and reinforce progress and results in improvement projects.",
  location     = "http://dx.doi.org/10.1109/MS.2008.151"
}

@Article{losp,
  author       = "Robert~L. Glass and Johann Rost and Matthias~S. Matook",
  title        = "Lying on Software Projects",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "90--95",
  month        = nov # "/" # dec,
  keywords     = "surveys, software management, managing people",
  abstract     = "Lying is an understudied activity, especially in the 
    software field.  Yet lying is apparently quite common.  In a 2006 survey of
    software practitioners, 86 percent of the respondents had encountered such
    lying.  The most common occurrences were in estimation and status
    reporting, with those forms of lying happening on 50 percent of projects,
    some respondents saying even 100 percent.  Respondents said that when lying
    happens, developers at the bottom level of the management hierarchy are
    most aware of the lying; they often know it's happening even when their
    management doesn't.  Respondents also provided numerous suggestions on how
    to diminish or eliminate lying.  However, many suggested that it's human
    nature to lie and that little can be done about it.",
  location     = "http://dx.doi.org/10.1109/MS.2008.150"
}

@Article{rwadarort,
  author       = "Viswa Viswanathan",
  title        = "Rapid Web Application Development: {A} {R}uby on {R}ails Tutorial",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "98--106",
  month        = nov # "/" # dec,
  keywords     = "web development, ruby, frameworks",
  abstract     = "Ruby on Rails is a powerful Web application development
    framework based on the dynamic object-oriented programming language Ruby.
    With several popular Web sites based on it, its prominence is rapidly
    rising.  Ruby on Rails fully supports Web 2.0 and Web services and enables
    extremely rapid development.  It incorporates several important features of
    programming in the large and is well suited for quickly developing even
    large, complex applications.  A small Web application that also uses Ajax
    and Web services provides an introduction to Ruby on Rails.",
  location     = "http://dx.doi.org/10.1109/MS.2008.156"
}

@Article{sctosd,
  author       = "{\v Z}eljko Obrenovi{\' c} and Dragan Ga{\v s}evi{\' c} and Anton Eli{\" e}ns",
  title        = "Stimulating Creativity through Opportunistic Software Development",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "64--70",
  month        = nov # "/" # dec,
  keywords     = "creativity, rapid prototyping",
  abstract     = "Opportunities are available resources that yield desired
    results.  An opportunity's suitability depends on who seizes it and the
    context for its use.  Opportunistic development builds hybrid software
    systems from reusable resources called opportunistic assets.  Mashups are
    Web application hybrids that consume these assets.  Monoliths are
    self-contained systems that can produce such opportunistic assets if they
    can expose key functions that are easy to mash.  A major barrier to reusing
    legacy monoliths is integration.  Elevating integration connectors to
    first-class opportunistic assets reduces this barrier by linking to and
    presenting monolith applications as opportunities for mashups.",
  location     = "http://dx.doi.org/10.1109/MS.2008.152"
}

@Article{boaricbsd,
  author       = "Barry Boehm and Jesal Bhuta",
  title        = "Balancing Opportunities and Risks in Component-Based Software Development",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "56--63",
  month        = nov # "/" # dec,
  keywords     = "icm process framework, concurrent engineering, risk-driven
    commitment milestones, software integration risks, cots",
  abstract     = "The increasingly rapid change in information technology
    makes it essential for software development projects to continuously
    monitor and adapt to new sources of opportunity and risk.  Software
    projects and organizations can increase their success rates in software
    development by better assessing and balancing their opportunities and
    risks.  The authors summarize the Incremental Commitment Model (ICM), a
    process framework for improved project monitoring and decision making based
    on balancing opportunities and risks.  They give an example of how the ICM
    framework can improve component-based development choices based on
    assessment of opportunities and risks.  They show how different
    opportunistic solutions result from different stakeholder value
    propositions.  They elaborate on the risks involved in architectural
    mismatches among components, present a tool called the Integration Studio
    (iStudio) that enables projects to assess the most common sources of
    architectural mismatch between components.  Finally, they present
    representative examples of its use.",
  location     = "http://dx.doi.org/10.1109/MS.2008.145"
}

@Article{sscmtatf,
  author       = "Sriram Balasubramaniam and Grace~A. Lewis and Soumya Simanta and Dennis~B. Smith",
  title        = "Situated Software: Concepts, Motivation, Technology, and the Future",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "50--55",
  month        = nov # "/" # dec,
  keywords     = "mashups, situated software",
  abstract     = "Situated software, a type of opportunistic software, is 
    created by a small subset of users to fulfill a specific purpose.  For
    example, business users have been creating situated software through
    mashups, which combine data from multiple sources on internal systems or
    the Internet.  Situated software can change the way users access, perceive,
    and consume information, and can allow users to finally focus on what to do
    with information, rather than where to find it or how to get to it.
    However, situated software also has limitations.  This article identifies
    situated software's role, provides examples of its use, traces the
    Internet's role in its rapid evolution, outlines areas where it is
    appropriate, describes its limitations, and presents enablers for adopting
    situated software in an enterprise.",
  location     = "http://dx.doi.org/10.1109/MS.2008.159"
}

@Article{paoriisuc,
  author       = "Slinger Jansen and Sjaak Brinkkemper and Ivo Hunink and Cetin Demir",
  title        = "Pragmatic and Opportunistic Reuse in Innovative Start-up Companies",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "42--49",
  month        = nov # "/" # dec,
  keywords     = "software extensions, component integration, cots",
  abstract     = "Reusing software components and services lets software
    vendors quickly develop innovative applications and products.  According to
    current literature and experience reports, software development can't
    integrate functionality successfully without formal component and service
    selection and integration procedures.  Here, the authors discuss two
    start-up companies that have each developed a product using a pragmatic
    approach to third-party functionality reuse and integration.  Developing
    products and services pragmatically places requirements on the relationship
    between the software developer and the third-party functionality provider.
    The authors discuss the architectural impacts of decisions made during
    integration.  These experiences show other software developers how to speed
    up product development with minimal risk.",
  location     = "http://dx.doi.org/10.1109/MS.2008.159"
}

@Article{ossdmsfwsa,
  author       = "Cornelius Ncube and Patricia Oberndorf and Anatol~W. Kark",
  title        = "Opportunistic Software Systems Development: Making Systems from What's Available",
  journal      = ieees,
  year         = 2008,
  volume       = 25,
  number       = 6,
  pages        = "38--41",
  month        = nov # "/" # dec,
  keywords     = "ossd",
  abstract     = "Despite all the difficulties encountered in each incarnation
    of software reuse, we persist along the path of trying to figure out how
    we're going to create systems that meet the ever-increasing demand for
    capability and, with it, complexity and sheer size.  Opportunistic software
    systems development is a reality today and for the foreseeable future, as
    the five articles in IEEE Software 's November/December 2008 special issue
    on OSSD demonstrate.  This special issue aims to gather together insights
    into the viability, or perhaps the inevitability, of OSSD and to bring
    forward the most effective practices known today.  Another goal is to point
    the way to what needs to be done to make OSSD more accessible to all
    practitioners.  The editors hope to help the software community realize the
    importance of this new trend and the many aspects of it that have yet to be
    conquered.",
  location     = "http://dx.doi.org/10.1109/MS.2008.155"
}

@Article{ppotcp,
  author       = "Jim Haungs",
  title        = "Pair Programming on the {C3} Project",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 2,
  pages        = "118--119",
  month        = feb,
  keywords     = "pair programming, smalltalk, software managment",
  location     = "http://faculty.salisbury.edu/~xswang/Research/Papers/SERelated/PP/r2118.pdf"
}

@Article{udmmtbcp,
  author       = "Gediminas Adomavicius and Alexander Tuzhilin",
  title        = "Using Data Mining Methods to Build Customer Profiles",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 2,
  pages        = "74--82",
  month        = feb,
  keywords     = "customer profiles, rule discovery, personalization, rule
    validation, validation operators, experiments",
  abstract     = "Personalization--the ability to provide content and services
    tailored to individuals' preferences and behavior--is an important
    marketing tool.  The authors developed an approach that uses information
    from customers' transactional histories to construct individual profiles
    containing facts about the customer and rules describing that customer's
    behavior.  They used data mining methods to derive behavioral rules from
    the data.  They also developed a method for validating customers' profiles
    to separate good rules from bad. They implemented the profile construction
    and validation methods using the 1:1Pro system.  Including personal
    behavioral rules in customers' profiles makes this approach unique.Focusing
    on statistical validity and acceptability to an expert, the authors explain
    how to judge the quality of rules stored in customers' profiles.  Their
    objective is to incorporate the concept of effectiveness in 1:1Pro.  The
    authors propose combining the constraint specification, data mining, and
    rule validation stages into one system.",
  location     = ""
}

@Article{dgsidc,
  author       = "James Joshi and Arif Ghafoor and Walid~G. Aref and Eugene~H. Spafford",
  title        = "Digital Government Security Infrastructure Design Challenges",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 2,
  pages        = "66--72",
  month        = feb,
  keywords     = "information security, multidomain security",
  abstract     = "Designing security systems for a digital government's
    multidomain environment requires balancing between providing convenient
    access and monitoring permissions.  Information Age technologies provide
    enormous opportunities for a government to transform its functions into the
    digital arena.  The authors view a digital government as an amalgam of
    heterogeneous information systems that exchange high-volume information
    among government agencies and public and private sectors engaged in
    government business.  Several US government agencies have adopted
    information technologies and spear-headed the search for improved services
    and decision-making processes.  These agencies aim to modernize the
    government's fragmented service-centric information infrastructure.  The
    accumulating evidence indicates that electronically improving information
    flow and the decision-making process provides increased efficiency,
    streamlined functionalities, and more effective use of government
    resources.",
  location     = "http://dx.doi.org/10.1109/2.970579"
}

@Article{mgdab,
  author       = "Athman Bouguettaya and Mourad Ouzzani and Brahim Medjahed and Jerry Cameron",
  title        = "Managing Government Databases",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 2,
  pages        = "56--64",
  month        = feb,
  keywords     = "distributed ontologies, co-databases",
  abstract     = "The information revolution has led organizations to rely on 
    databases to conduct their daily business.  The authors explore Indiana's
    digital government project and explain how using Web-based techniques to
    retrieve data can help disadvantaged citizens become self-reliant.  The
    authors recommend that empowering novice and experienced users to submit
    queries over database networks provides a sophisticated infrastructure that
    supports flexible tools for managing and accessing Internet databases.
    They propose using distributed ontologies of information repositories to
    meet this challenge.  They suggest an organization and segmentation of
    databases based on simple ontologies that describe coherent slices of the
    information space.  These distributed ontologies filter interactions,
    accelerate information searches, and permit data sharing in a tractable
    manner.  The authors describe how strengthening database management
    technology renders improved service.", 
  location     = "http://dx.doi.org/10.1109/2.970579"
}

@Article{sdatedcp,
  author       = "Jos{\' e} Luis Ambite and Yigal Arens and Eduard Hovyand
    Andrew Philpot and Luis Gravano and Vasileios Hatzivassiloglou and Judith Klavans",
  title        = "Simplifying Data Access: The {E}nergy {D}ata {C}ollection Project",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 2,
  pages        = "47--54",
  month        = feb,
  keywords     = "information integration, ontology construction",
  abstract     = "Using technology developed at the University of Southern
    California's Information Sciences Institute and Columbia University's
    Department of Computer Science and its Center for Research on Information
    Access, the Digital Government Research Center seeks to make government
    statistical data more accessible through the Internet.  The authors face
    major challenges of integrating dispersed data compiled at different times
    and for different purposes and over-coming the Web browser paradigm's
    limitations to disseminate complex information derived from multiple
    sites.Collaborating with government experts, the DGRC analyzes advanced
    information systems; develops standards, interfaces, and a shared
    infrastructure; and manages pilot systems.  To address access problems, the
    authors developed a unified, Web-based user interface for querying and
    presenting statistical information.  Their robust, portable, and efficient
    interface prototype facilitates user access to data from multiple sources
    and agencies.",
  location     = "http://dx.doi.org/10.1109/2.970578"
}

@Article{eiegtaca,
  author       = "Massimo Mecella and Carlo Batini",
  title        = "Enabling {I}talian {E}-Government through a Cooperative Architecture",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 2,
  pages        = "40--45",
  month        = feb,
  keywords     = "unitary networks, cooperative development",
  abstract     = "In 1993, the Italian government created the Authority for 
    Information Technology in the Public Administration to promote innovation
    by defining the criteria for implementing and managing the Italian Public
    Administration's information systems.  Its Unitary Network provides
    interconnection services to individual public administrations (PAs).  A
    more ambitious objective is implementing a secure intranet that connects
    all Italian PAs.  Developing an evolutionary architecture to integrate
    large heterogeneous systems poses another challenge.  Although these
    systems support vertical applications, exporting their services requires
    reengineering their technological services and administrative processes.
    The goal is to establish an architecture that coordinates information
    exchange among government information systems while maintaining each
    organization's autonomy.  The authors emphasize the importance of
    cooperation among administrations to develop an iterative, cyclic process
    considering the constraints imposed by organizational differences in size,
    culture, and management rules." 
}

@Article{powrisr,
  author       = "Steve Lawrence and David~M. Pennock and Gary William Flake
    and Robert Krovetz and Frans~M. Coetzee and Eric Glover and Finn {\AA}rup
    Nielsen and Andries Kruger and C.~Lee Giles",
  title        = "Persistence of {W}eb References in Scientific Research",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 2,
  pages        = "26--31",
  month        = feb,
  keywords     = "link rot, web resource references, urls",
  abstract     = "Invalid URLs can lead to important data loss as cited works
    and research findings gradually disappear from circulation.  The lack of
    persistence of Web references leads researchers to question whether
    publications should even include URL citations.  To minimize the future
    loss of information, the authors review new long-term strategies for
    managing Internet resources and suggest several ways to improve citation
    practices.  Their analysis of references to Web resources in 270,977
    computer science publications revealed that URL citations have increased,
    but many are now invalid.  The authors were, however, able to relocate most
    invalid Web references using two searches.  They analyzed the missing links
    and identified reasons why URLs become invalid."
}

@Article{itusdb,
  author       = "Drew Barnett and Anthony~J. Massa",
  title        = "Inside the u{IP} Stack",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "61--65",
  month        = feb,
  keywords     = "wireless sensor networks, network stacks",
  location     = "http://drdobbs.com/embedded-systems/184405971"
}

@Article{eutem,
  author       = "Timothy~E. Meehan and Norman Carr",
  title        = "Extending {UML}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "56--60",
  month        = feb,
  keywords     = "user interfaces, extended activity semantics, xas",
  location     = "http://drdobbs.com/184405965"
}

@Article{afdsss,
  author       = "Sergei Savchenko",
  title        = "Algorithms for Dymamic Shadows",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "50--55",
  month        = feb,
  keywords     = "planar shadows, computer graphics, scene rendering,
    projective textures, shadow volumes, shadow maps, priority maps",
  location     = "http://www.drdobbs.com/184405964"
}

@Article{alhw,
  author       = "Hew Wolff",
  title        = "Automatic Localization",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "47--49",
  month        = feb,
  keywords     = "localization, testing, translation, human factors",
  OPTlocation  = ""
}

@Article{baewspi,
  author       = "Michael Pilone",
  title        = "Building an {E}clipse Web-Search Plug-In",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "43--46",
  month        = feb,
  keywords     = "plug-in development, eclipse, deployment",
  location     = "http://drdobbs.com/web-development/184405962"
}

@Article{jcx5a,
  author       = "Snezana Sucurovic and Zoran Jovanovic",
  title        = "Java Cryptography \& {X}.509 Authentication",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "40--42",
  month        = feb,
  keywords     = "cryptographic architecture",
  location     = "http://drdobbs.com/184405961"
}

@Article{raaws,
  author       = "Ian Macdonald",
  title        = "Ruby/{A}mazon \& {A}mazon Web Services",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "30--34",
  month        = feb,
  keywords     = "web services, ruby",
  location     = "http://drdobbs.com/showArticle.jhtml?articleID=184405959"
}

@Article{saejp,
  author       = "James Pasley",
  title        = "{SOA}s and {ESB}s",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "24--29",
  month        = feb,
  keywords     = "service-oriented architecture, enterprise service bus,
    project integration, core services, business services, service policies,
    service implementation",
  OPTlocation  = ""
}

@Article{jwsaa,
  author       = "Eric~J. Bruno",
  title        = "Java Web Services \& Application Architectures",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 2,
  pages        = "16--22",
  month        = feb,
  keywords     = "service tier, service development, web services",
  location     = "http://drdobbs.com/java/229100159"
}

@Article{gswgwt,
  author       = "Dan Frost",
  title        = "Getting started with {G}oogle Web Toolkit",
  journal      = "Pro Linux Magazine",
  year         = 2008,
  number       = 96,
  pages        = "72--75",
  month        = nov,
  keywords     = "web development, gwt"
}

@Article{wtraa,
  author       = "Bashar Nuseibeh",
  title        = "Weaving Together Requirements and Architectures",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "115--119",
  month        = mar,
  keywords     = "software management",
  abstract     = "Software development organizations often choose between
    alternative starting points-requirements or architectures.  This invariably
    results in a waterfall development process that produces artificially
    frozen requirements documents for use in the next step in the development
    life cycle.  Alternatively, this process creates systems with constrained
    architectures that restrict users and handicap developers by resisting
    inevitable and desirable changes in requirements.  The spiral life-cycle
    model addresses many drawbacks of a waterfall model by providing an
    incremental development process, in which developers repeatedly evaluate
    changing project risks to manage unstable requirements and funding.  An
    even finer-grain spiral life cycle reflects both the realities and
    necessities of modern software development.  Such a life cycle acknowledges
    the need to develop software architectures that are stable, yet adaptable,
    in the presence of changing requirements.  The cornerstone of this process
    is that developers craft a system's requirements and its architecture
    concurrently, and interleave their development",
  location     = "http://mcs.open.ac.uk/ban25/papers/computer2001.pdf"
}

@Article{ptfesd,
  author       = "Frank Vahid and Tony Givargis",
  title        = "Platform Tuning for Embedded Systems Design",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "112--114",
  month        = mar,
  keywords     = "systems-on-chip, hardware platforms",
  abstract     = "Parameterized SOC platforms solve numerous problems that 
    face system designers.  With platforms ranging from IP to IC variants and
    tuning tasks ranging from simple parameter configuration to aggressive
    architectural transformations, platform tuning issues can be daunting.
    UCR's Dalton Project shows that platform tuning can increase performance
    and reduce power consumption for system-on-chip embedded platforms",
  location     = "http://www.cs.ucr.edu/~vahid/courses/269_s01/comp01_dalton.pdf"
}

@Article{talitwc,
  author       = "Paul~G. Shotsberger and Ron Vetter",
  title        = "Teaching and Learning in the Wireless Classroom",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "110--111",
  month        = mar,
  keywords     = "wireless access, real-time learning",
  abstract     = "Wireless networks now support Web browsing, e-mail, 
    real-time chat, and access to remote computing resources.  With the
    increasing use of small portable computers, this emerging communications
    infrastructure will enable many new Internet applications.  Two innovative
    projects at the University of North Carolina at Wilmington are currently
    exploring how educators can use portable handheld computers with wireless
    Internet access to improve teaching and learning in both local and wide
    area network environments", 
  location     = "http://dx.doi.org/10.1109/2.910902"
}

@Article{mamfmc,
  author       = "Paolo Bellavista and Antonio Corradi and Cesare Stefanelli",
  title        = "Mobile Agent Middleware for Mobile Computing",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "73--81",
  month        = mar,
  keywords     = "mobility middleware, naming services, soma",
  abstract     = "Mobile computing requires an advanced infrastructure that
    integrates support protocols, mechanisms, and tools to dynamically
    reallocate and trace mobile users and terminals and permit coordination of
    mobile entities.  Solutions to these issues require compliance with
    standards to interoperate with different systems and legacy components and
    a reliable security infrastructure based on standard cryptographic
    mechanisms and tools.  The secure and open mobile agent (SOMA) distributed
    programming framework implements three mobile computing services-user
    virtual environment (UVE), mobile virtual terminal (MVT), and virtual
    resource management (VRM).  UVE provides users with a uniform view of their
    working environments independent of current locations and specific
    terminals.  MVT extends traditional terminal mobility by preserving the
    terminal execution state for restoration at new locations.  VRM allows
    mobile users and terminals to maintain access to resources and services by
    requalifying the bindings and moving specific resources or services to
    permit load balancing and replication.  The authors' implementation of
    their mobility middleware confirmed that a layered, modular, mobile
    agent-based service infrastructure can support a range of mobile computing
    requirements.  They conclude that SOMA's UVE, MVT, and VRM service layer
    provides a flexible middleware that application designers can use to deploy
    Internet services in an environment where users, terminals, resources, and
    services are all mobile.", 
  location     = "http://wudu-lia.deis.unibo.it/echo_hidden_file.php?id_hidden_file=7"
}

@Article{vakdsis,
  author       = "Chaomei Chen and Ray~J. Paul",
  title        = "Visualizing a Knowledge Domain's Intellectual Structure",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "65--71",
  month        = mar,
  keywords     = "knowledge visualization",
  abstract     = "To make knowledge visualizations clear and easy to interpret,
    the authors have developed a method that extends and transforms traditional
    author co-citation analysis (ACA) by extracting structural patterns from
    the scientific literature and representing them in a 3D knowledge
    landscape.  Integrating citation and co-citation patterns provides a rich,
    ecological representation of a knowledge domain.  Users can apply
    visualizations to discover patterns and make valuable connections among
    data.  The authors' approach extends conventional ACA by integrating
    structured modeling and information visualization techniques to provide a
    3D knowledge landscape based on citation patterns.Their four-step procedure
    introduces Pathfinder network scaling to replace multidimensional scaling.
    It also integrates Pathfinder and factor analysis to visualize specialties
    in the underlying domain knowledge and visualizes the citation frequency of
    scientists to track changes in their influence over time.This knowledge
    visualization approach identifies intellectual groupings based on extending
    the traditional ACA, augmenting the existing document- and concept-centered
    approaches to knowledge visualization.  The 3D knowledge landscape has
    practical implications in knowledge visualization, digital libraries,
    domain analysis, and subject domains, providing powerful tools for tracking
    intuitively scientific knowledge.",
  location     = "http://dx.doi.org/10.1109/2.910895"
}

@Article{sitmhid,
  author       = "James~A. Landay and Brad~A. Myers",
  title        = "Sketching Interfaces: Toward More Human Interface Design",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "56--64",
  month        = mar,
  keywords     = "silk, annotation, widgets, usability",
  abstract     = "Today people expect computers to perform not only obvious
    computational tasks but also to assist in people-oriented tasks.  This
    shift is causing user-interface (UI) researchers to explore methods that
    bend computers to people's way of interacting by supporting ambiguity,
    creativity, and informal communication that combines many of the benefits
    of paper-based sketching with the merits of current electronic
    tools.Researchers at the University of California, Berkeley and Carnegie
    Mellon University have designed, implemented, and evaluated an informal
    sketching tool, SILK (Sketching Interfaces Like Krazy).  During the early
    phases of UI design, designers need the freedom to sketch design ideas
    quickly, the ability to test designs by interacting with them, and the
    flexibility to fill in design details as they make choices.  Besides
    refining design details as graphic artists deliberate, SILK supports
    story-boards-sketches that illustrate how design elements behave, how a
    dialog box appears when the user activates a button.  Designers can present
    story-boards to colleagues, customers, or end users to show how an
    interface will behave.A usability evaluation of the implemented SILK system
    demonstrated that it is an effective tool for early creative design and for
    communicating design ideas effectively to engineers.",
  location     = "http://dx.doi.org/10.1109/2.910892"
}

@Article{uifvd,
  author       = "Ravin Balakrishnan and George~W. Fitzmaurice and Gordon Kurtenbach",
  title        = "User Interfaces for Volumetric Displays",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "37--45",
  month        = mar,
  keywords     = "nonhaptic interfaces, 3d navigation",
  abstract     = "Although still in the prototype stage, three-dimensional
    volumetric displays present unique interface challenges.  Current display
    technologies limit our ability to view and interact with 3D computer
    graphics because we typically view 3D data on a 2D system that cannot
    display the depth dimension.  Volumetric displays hold the promise of
    enhancing 3D graphics realism by providing all the depth cues humans
    require.  Incorporating everyday gestures to delineate subportions of the
    working volume, the authors use physical mockups to consider potentially
    viable displays and associated input mechanisms.  Researchers can use
    high-fidelity mockups and props to glimpse the future with minimal
    prototyping effort, before the display and input technologies mature.  The
    authors' mockups elucidate a range of design challenges and
    volumetric-display opportunities, revealing a rich set of alternative
    user-interface design options.  However, more evaluation must be conducted
    before it's possible to harness the full potential of interacting with
    volumetric displays.", 
  location     = "http://dx.doi.org/10.1109/2.910892"
}

@Article{pedgui,
  author       = "David~L. Hecht",
  title        = "Printed Embedded Data Graphical User Interfaces",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "47--55",
  month        = mar,
  keywords     = "dataglyph, data embedding, block codes",
  abstract     = "Printed embedded data graphical user interfaces (PEDGUIs)
    generalize the interaction domain to images and objects to enable
    interaction with passive objects and active displays throughout user
    environ-ments.  Embedded data helps establish the selection location,
    gesture, and identity or context of the chosen substrate and links to other
    resources.A key element for PEDGUI systems is imprinting machine-readable
    encoding and elec-tronic capture of images containing the embedded data for
    machine interpretation of user interaction.Work at Xerox focuses on
    developing embedded data technology that provides substantial data capacity
    and local and global spatial address capability with good aesthetics and
    graphical integration with line art, text, and pictorial documents in color
    or black and white.Embedded data technology, user-interface research, and
    emerging commercial developments provide a substantial foundation for novel
    applications inviting widespread practical use."
}

@Article{tzepdm,
  author       = "Jonathan~J. Hull and Peter~E. Hart",
  title        = "Toward Zero-Effort Personal Document Management",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "30--35",
  month        = mar,
  keywords     = "document storage, automatic copies",
  abstract     = "Effective document management in the Information Age must
    require nearly zero effort, be economically reasonable, offer efficient
    retrieval methods, and satisfy users' concerns about security and
    privacy.During the past three years, the California Research Center has
    evaluated a radically simple approach to personal document management
    called Save everything!To achieve zero-effort document capture, the authors
    modified conventional printers, digital copiers, and fax machines to
    automatically save representations of every document processed.  Their
    approach exploits users' familiarity with their personal document
    collection to retrieve documents without using filenames, paths, or
    keywords.  The authors report a case study that demonstrates how Save
    everything! has proven to be an effective and cost-efficient tool for
    integrating document capture into daily work practices.", 
  location     = "http://dx.doi.org/10.1109/2.910892"
}

@Article{tpodp,
  author       = "Su-Shing Chen",
  title        = "The Paradox of Digital Preservation",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 3,
  pages        = "24--28",
  month        = mar,
  keywords     = "entropy, workflow, metadata",
  abstract     = "Preserving digital information is a problem plagued by short
    media life, obsolete hardware and software, slow read times of old media,
    and defunct Web sites.  The paradox is: We want to maintain digital
    information intact, but we also want to be able to access this information
    in a dynamic use context.Chen explains that we lack proven methods to
    ensure that the digital information will continue to exist, that we will be
    able to access this information using improved technology tools, or that
    accessible information is authentic and reliable.The author asserts that
    failing to address the problems of preserving information in digital form
    is analogous to fostering cultural and intellectual poverty and squandering
    potential long-term gains that we should rightfully receive as a return on
    our professional, personal, and economic investments in information
    technology.  Finding a solution to the tension between the creation context
    and the use context constitutes an important challenge.",
  location     = "http://dx.doi.org/10.1109/2.910891"
}

@Article{safdtsviwa,
  author       = "Nenad Jovanovic and Christopher Kruegel and Engin Kirda",
  title        = "Static Analysis for Detecting Taint-Style Vulnerabilities in Web Applications",
  journal      = "Journal of Computer Security",
  year         = 2010,
  volume       = 18,
  number       = 5,
  pages        = "861--907",
  month        = sep,
  keywords     = "php, software security, web security, secure programming,
    static analysis, abstract execution, sql injection",
  abstract     = "The number and the importance of web applications have
    increased rapidly over the last years.  At the same time, the quantity and
    impact of security vulnerabilities in such applications have grown as well.
    Since manual code reviews are time-consuming, error-prone and costly, the
    need for automated solutions has become evident.  In this paper, we address
    the problem of vulnerable web applications by means of static source code
    analysis.  More precisely, we use flow-sensitive, interprocedural and
    context-sensitive data flow analysis to discover vulnerable points in a
    program.  In addition to the taint analysis at the core of our engine, we
    employ a precise alias analysis targeted at the unique reference semantics
    commonly found in scripting languages.  Moreover, we enhance the quality
    and quantity of the generated vulnerability reports by employing an
    iterative two-phase algorithm for fast and precise resolution of file
    inclusions.  The presented concepts are targeted at the general class of
    taint-style vulnerabilities and can be easily applied to the detection of
    vulnerability types such as SQL injection, cross-site scripting (XSS), and
    command injection.  We implemented the presented concepts in Pixy, a
    high-precision static analysis tool aimed at detecting cross-site scripting
    and SQL injection vulnerabilities in PHP programs.  To demonstrate the
    effectiveness of our techniques, we analyzed a number of popular,
    open-source web applications and discovered hundreds of previously unknown
    vulnerabilities.  Both the high analysis speed as well as the low number of
    generated false positives show that our techniques can be used for
    conducting effective security audits."
}

@Article{sdeefmoej,
  author       = "Magne J{\o}rgensen and Barry Boehm and Stan Rifkin",
  title        = "Software Developent Effort Estimation: Formal Models or Expert Judgment?",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = 2,
  pages        = "14--19",
  month        = mar # "/" # apr,
  keywords     = "software development, formal models, cocomo",
  abstract     = "Which is better for estimating software project resources:
    formal models, as instantiated in estimation tools, or expert judgment? Two
    luminaries, Magne Jorgensen and Barry Boehm, debate this question.",
  location     = ""
}

@Article{mutat,
  author       = "Catharina Riedemann and Regine Freitag",
  title        = "Modeling Usage: Techniques and Tools",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = 2,
  pages        = "14--19",
  month        = mar # "/" # apr,
  keywords     = "use cases, user stories, use scenario",
  abstract     = "This review of four usage-modeling techniques clarifies key
    elements of each technique and their strengths and weaknesses from the
    perspective of usage-centered development.  It also points to tools where
    appropriate.  Finally, the authors argue for applying a template-supported
    use scenario integrating the three approaches.",
  location     = "http://dx.doi.org/10.1109/MS.2009.41"
}

@Article{moalsbaacs,
  author       = "Santonu Sarkar and Shubha Ramachandran and G.~Sathish Kumar
    and Madhu~K. Iyengar and K. Rangarajan and Saravanan Sivagnanam",
  title        = "Modularization of a Large-Scale Business Application: {A} Case Study",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = 2,
  pages        = "28--35",
  month        = mar # "/" # apr,
  keywords     = "case study, modular design, modularization, software design,
    rearchitecting", 
  abstract     = "Large software systems, developed over several years, are 
    the backbone of industries such as banking, retail, transportation, and
    telecommunications.  With multiple bug fixes and feature enhancements,
    these systems gradually deviate from the intended architecture and
    deteriorate into unmanageable monoliths.  This article presents a case
    study of a banking application besot with such problems and the
    modularization approach that the company adopted as a solution.  It also
    highlights benefits unearthed as a result of this reengineering exercise.",
  location     = "http://dx.doi.org/10.1109/MS.2009.42"
}

@Article{tdvsrisap,
  author       = "Philippe Kruchten and Rafael Capilla and Juan Carlos Due{\~ n}as",
  title        = "The Decision View's Role in Software Architecture Practice",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = 2,
  pages        = "36--42",
  month        = mar # "/" # apr,
  keywords     = "architectural representation, architectural design, design
    rationale", 
  abstract     = "A decision view provides a useful complement to the 
    traditional sets of architectural views and viewpoints.  It gives an
    explanatory perspective that illuminates the reasoning process itself and
    not solely its results.  The decision view documents aspects of the
    architecture that are hard to reverse-engineer from the software itself and
    that are often left tacit.  The decision view and the decisions that it
    captures embody high-level architectural knowledge that can be transferred
    to other practitioners and merged when systems are merged, and they offer
    useful support for maintaining large, long-lived software-intensive
    systems.  This article leads readers through a succession of epiphanies:
    from design to architecture, then architecture representation to
    architecture design methods, and finally to architectural design
    decisions.",
  location     = "http://dx.doi.org/10.1109/MS.2009.52"
}

@Article{sadracfims,
  author       = "Antony Tang and Jun Han and Rajesh Vasa",
  title        = "Software Architecture Design Reasoning: {A} Case for Improved Methodology
 Support ",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = 2,
  pages        = "43--49",
  month        = mar # "/" # apr,
  keywords     = "design reasoning, arel, software design",
  abstract     = "Software architecture design is a critical aspect of
    developing large-scale software systems.  However, the practice of
    architecture design reasoning is immature, partly because of a lack of
    practical methodology support.  The authors discuss why capturing design
    rationale, the elements of design reasoning, is useful and how developers
    use it in architecture design.  They demonstrate architecture design
    reasoning's application with a UML-based modeling method called
    Architecture Rationale and Elements Linkage.",
  location     = "http://dx.doi.org/10.1109/MS.2009.46"
}

@Article{ocwcusf,
  author       = "Dirk Riehle and John Ellenberger and Tamir Menahem and Boris
    Mikhailovski and Yuri Natchetoi and Barak Naveh and Thomas Odenwald",
  title        = "Open Collaboration within Corporations Using Software Forges",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = 2,
  pages        = "52--58",
  month        = mar # "/" # apr,
  keywords     = "open collaboration, software forges, software management",
  abstract     = "A software forge is a tool platform for collaborative
    software development, similar to integrated CASE environments.  Unlike CASE
    tools, however, software forges have been designed for the software
    development practices of the open source community.  The authors discuss
    their experiences using a software forge to bring open source best
    practices into corporations.  They present the design principles and
    benefits of a firm-internal software forge and include a case study of how
    one project at SAP benefitted significantly from being on the forge.",
  location     = "http://dx.doi.org/10.1109/MS.2009.44"
}

@Article{eossiawcd,
  author       = "Christiane Gresse {von Wangenheim} and Jean Carlo Rossa Hauck
    and Aldo {von Wangenheim}",
  title        = "Enhancing Open Source Software in Alignment with {CMMI}-{DEV}",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = 2,
  pages        = "59--67",
  month        = mar # "/" # apr,
  keywords     = "project management, management tools",
  abstract     = "To provide comprehensive, low-cost tool support for project
    monitoring and control for small organizations in particular, the authors
    compare the most popular free/open source Web-based project management
    applications against their compliance to CMMI-DEV.  Based on this analysis,
    they implement a set of enhancements to dotProject, including Earned Value
    Management, and evaluate the resulting application with respect to its
    CMMI-compliance.  Their initial experiences applying the tool in an R&D
    organization indicate that it helps establish a systematic project
    monitoring and control process by supporting or automating tasks.  In this
    way, it presents an open, flexible, and free tool-integration solution for
    project management, illustrating that open-source tools might be appealing,
    especially for small organizations.", 
  location     = "http://dx.doi.org/10.1109/MS.2009.34"
}

@Article{samiaciobp,
  author       = "William~N. Robinson and Sandeep Purao",
  title        = "Specifying and Monitoring Interactions and Commitments in Open Business
 Processes ",
  journal      = ieees,
  year         = 2009,
  volume       = 26,
  number       = "2",
  pages        = "72--79",
  month        = mar # "/" # apr,
  keywords     = "interaction protocols, workflow nets, process grammars",
  abstract     = "Business processes are increasingly complex and open because
    they rely on services that are distributed geographically and across
    organizations.  So, they're prone to several points of failure.
    Monitoring, therefore, remains an important concern.  A new approach
    specifies and monitors interactions among heterogeneous services by
    tracking their commitments.  This approach extends recent research that
    views business process design as a composition of interaction protocols.
    It specifies and monitors policies and commitments as a way to monitor
    service-level agreements and recover from process failures.",
  location     = "http://dx.doi.org/10.1109/MS.2009.48"
}

@Article{dwotsc1f,
  author       = "Jingyue Li and Reidar Conradi and Christian Bunse and Marco
  Torchiano and Odd Petter N. Slyngstad and Maurizio Morisio",
  title        = "Development with Off-the-Shelf Components: 10 Facts",
  journal      = ieees,
  year         = 2006,
  volume       = 26,
  number       = 2,
  pages        = "80--87",
  month        = mar # "/" # apr,
  keywords     = "software management, software development, ",
  abstract     = "Several empirical studies have been conducted on issues
    related to the development of systems using commercial off-the-shelf and
    open source software components.  The results demonstrate a discrepancy
    between academic theory and industrial practices regarding the use of
    components.  One reason is that researchers have empirically evaluated only
    a few theoretical methods; so, industrial practitioners have no reason to
    adopt them.  Another reason might be that researchers have specified the
    application contexts of only a small number of theories in sufficient
    detail to avoid misleading users.  Academic researchers often hold false
    assumptions about industry.  For example, research on requirement
    negotiations often assumes that a client will be interested in, and be
    capable of, discussing a project's technical details.  However, in practice
    this is usually not true.  In addition, the quality of a component in the
    final system is often attributed solely to component quality before
    integration, ignoring quality improvements by integrators during component
    integration.",
  location     = "http://dx.doi.org/10.1109/MS.2009.33"
}

@Article{asfefn,
  author       = "Rich Unger",
  title        = "{A} Sound File Editor for {Netbeans}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 3,
  pages        = "48--52",
  month        = mar,
  keywords     = "ides",
  location     = "http://drdobbs.com/java/184405998?pgno=2"
}

@Article{6bcjp,
  author       = "Sergiy Kyrylkov",
  title        = "64-Bit Computing \& {JVM} Performance",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 3,
  pages        = "24--27",
  month        = mar,
  keywords     = "java, performance evaluation",
  location     = "http://drdobbs.com/high-performance-computing/184405993"
}

@Article{i6bo,
  author       = "Anatoliy Kuznetsov",
  title        = "Integer 64-Bit Optimizations",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 3,
  pages        = "36--38",
  month        = mar,
  keywords     = "bit counting, parallel programming, lexicographical
    comparison, binary distances",
  location     = "http://drdobbs.com/high-performance-computing/184405995"
}

@Article{hpmlmp,
  author       = "Mick Pont",
  title        = "High-Performance Math Libraries",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 3,
  pages        = "39--41",
  month        = mar,
  keywords     = "blas, linpack, fast fourier transforms",
  location     = "http://drdobbs.com/cpp/184405996"
}

@Article{pwcic,
  author       = "Christopher Diggins",
  title        = "Programming with Contracts in " # cpp,
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 3,
  pages        = "42--43",
  month        = mar,
  keywords     = "contracts",
  location     = "http://drdobbs.com/cpp/184405997"
}

@Article{maswj,
  author       = "Michael Pilone",
  title        = "Making a Scene with {Java3D}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 3,
  pages        = "44--47",
  month        = mar,
  keywords     = "scenegraph, computer graphcs",
  location     = "http://drdobbs.com/architecture-and-design/184403964"
}

@Article{afttcis,
  author       = "Herb Sutter",
  title        = "{A} Fundamental Turn Toward Concurrency in Software",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 3,
  pages        = "16--22",
  month        = mar,
  keywords     = "moores law, concurrent programming",
  location     = "http://drdobbs.com/web-development/184405990"
}

@Article{sffc,
  author       = "Efraim Berkovich",
  title        = "Summations for Fast Counting",
  journal      = ccppuj,
  year         = 2003,
  volume       = 19,
  number       = 1,
  pages        = "38--43",
  month        = jan,
  keywords     = "summations",
  location     = "http://drdobbs.com/184401597"
}

@Article{cpar,
  author       = "Timothy~M. Shead",
  title        = "Contract Programming and {RTTI}",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 1,
  pages        = "31--37",
  month        = jan,
  keywords     = "contract programming, rtti",
  location     = "http://drdobbs.com/184401608"
}

@Article{adiotidp,
  author       = "Eric Niebler",
  title        = "{A} Different Interpretation of the Interpreter Design Pattern",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 1,
  pages        = "26--30",
  month        = jan,
  keywords     = "interpreter pattern, partial evaluation",
  location     = "http://drdobbs.com/184401605"
}

@Article{tisykidtce,
  author       = "Leor Zolman",
  title        = "Thinking in {STL}:  You Know It Don't Come Easy",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 1,
  pages        = "20--25",
  month        = jan,
  keywords     = "software design",
  location     = "http://drdobbs.com/cpp/184401609?pgno=6"
}

@Article{awoccc,
  author       = "Brad King and William~J. Schroeder",
  title        = "Automated Wrapping of Complex " # cpp # " Code",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 1,
  pages        = "14--18",
  month        = jan,
  keywords     = "cable",
  location     = "http://drdobbs.com/184401607"
}

@Article{cswsaxfexp,
  author       = "David Nash",
  title        = "Combining {STL} with {SAX} and XPath for Effective {XML} Parsing",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 1,
  pages        = "6--12",
  month        = jan,
  keywords     = "class templates, xpath, sax, xml",
  location     = "http://drdobbs.com/cpp/184401603"
}

@Article{ecaaa,
  author       = "B.~Ramakrishna Rau and Michael~S. Schlansker",
  title        = "Embedded Computer Architecture and Automation",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 4,
  pages        = "75--83",
  month        = apr,
  keywords     = "embedded computing, system specialization, automation, ",
  abstract     = "Exploring the emergence of embedded computing, the authors
    predict that the computer industry will develop significantly different
    computer architectures at the system and processor levels as well as a wide
    range of off-the- shelf (OTS) and custom designs.  Automation of computer
    architecture will revolutionize performance and functionality.  The authors
    probe three features of embedded computer architecture.  They show that
    specialization increases performance and reduces manufacturing costs, that
    customization permits specialization when no specialized OTS product is
    available, and that automation reduces design costs.  The costs of
    implementing system-on-chip designs, along with the need for more
    customization, will lead to the automation of computer architecture, whose
    practicality and effectiveness the authors demonstrate using their program-
    in, chip-out architecture synthesis system.  The authors affirm that the
    distinct product, market, and application requirements of embedded
    computing will lead to special-purpose, heterogeneous, and irregular system
    and processor architecture.", 
  location     = "http://dx.doi.org/10.1109/2.917544", 
  location     = "http://www.hpl.hp.com/research/papers/RauIEEE.pdf"
}

@Article{smpgss,
  author       = "Gurindar~S. Sohi and Amir Roth",
  title        = "Speculative Multithreaded Processors",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 4,
  pages        = "66--73",
  month        = apr,
  keywords     = "parallelism extraction, threaded computation, ",
  abstract     = "Although novel functionality in the 1990s played a dominant
    role in processor design, the authors predict that implementation will
    dominate over functionality.  Designing, debugging, and verifying
    monolithic designs that use hundreds of millions of transistors will be
    very difficult, and increasing wire delays will make intrachip
    communication and clock distribution costly.  Consequently, some computer
    architects advocate shifting from high-performance to high-throughput
    processing, using distributed components to conquer design-process
    complexity and exploit communication locality to solve wire delays.
    Multithreaded architectures can extract parallelism from a sequential
    program via thread-level speculation, making it flexible to operate in
    multiple-program, high-throughput and single-program, high-performance
    environments.  Speculation is the key factor.  Multithreaded processors
    that support concurrent execution of multiple threads on a single chip may
    dominate some application uses in the next decade.  Simultaneous
    multithreading uses monolithic designs with shared resources among the
    threads.  Multithreading seeks to divide programs into data-independent
    parallel threads.  Before speculative multithreading becomes commonplace in
    mainstream processors, technologies must be developed for conveying thread
    information from software to hardware.  Likewise, algorithms for thread
    selection and management and hardware and software to support the
    simultaneous execution of speculative and nonspeculative threads must also
    be devised.", 
  location     = "http://dx.doi.org/10.1109/2.917544"
}

@Article{ildpjes,
  author       = "James~E. Smith",
  title        = "Instruction-Level Distributed Processing",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 4,
  pages        = "59--65",
  month        = apr,
  keywords     = "wire delays, power consumption, on-chip multithreading,
    virtual machines, instruction sets",
  abstract     = "For nearly 20 years, microarchitecture research has
    emphasized instruction-level parallelism (ILP), which improves performance
    by increasing the number of instructions per cycle.  In striving for such
    parallelism, researchers have exploited advances in chip technology to
    develop complex, hardware-intensive processors.  This trend has resulted in
    high intellectual complexity in the increasingly intricate schemes for
    squeezing performance out of second- and third-order effects.  To simplify
    these increasingly complex designs, developers can borrow distributed-
    systems methods and apply them at the processor level to solve load
    balance, resource allocation, and communication problems.  The current
    focus on ILP will likely shift to instruction-level distributed processing,
    emphasizing inter-instruction communication with dynamic optimization and a
    tight interaction between hardware and low-level software.  To help find
    runtime parallelism, orchestrate distributed hardware resources, and
    implement power conservation strategies, an additional layer of
    abstraction-- the virtual machine layer--will likely become an essential
    ingredient.  Finally, new instruction sets may be necessary to better focus
    on instruction-level communication and dependence, rather than computation
    and independence as is commonly done today.",
  location     = "http://dx.doi.org/10.1109/2.917541"
}

@Article{pafcadc,
  author       = "Trevor Mudge",
  title        = "Power: {A} First-Class Architectural Design Constraint",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 4,
  pages        = "52--58",
  month        = apr,
  keywords     = "cmos logic, power equations, power consumption",
  abstract     = "With Internet use growing exponentially and information
    technology consuming about 8 percent of power in the US, limiting power
    consumption presents a critical computing issue.  If the IT component
    continues to grow exponentially without check, it will soon require more
    power than all other uses combined.  Concurrent with the rapid growth in
    power consumption, an alarming growth in the chip die's power density has
    been noted.  For example, despite process and circuit improvements, the
    Alpha model 21364's power density has reached approximately 30 watts per
    square centimeter-- three times that of a typical hot plate.  Obviously,
    trading high power for high performance cannot continue.  Reducing power
    consumption will require adding architectural improvements to process and
    circuit improvements.  Thus, elevating power to a first-class constraint
    must be a priority early in the design stage when architectural tradeoffs
    are made as designers perform cycle-accurate simulation.",
  location     = "http://dx.doi.org/10.1109/2.917539"
}

@Article{tctbnditna,
  author       = "Tsugio Makimoto and Kazuhiko Eguchi and Mitsugu Yoneyama",
  title        = "The Cooler the Better: New Directions in the Nomadic Age",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 4,
  pages        = "38--42",
  month        = apr,
  keywords     = "soc",
  abstract     = "In this historic view of the cool chip's impact on today's
    mobile lifestyle, the authors describe how the cool chip will play an
    integral role in building a better future society.  The high-performance,
    reduced-power-consumption cool chip will inaugurate the nomadic age,
    leading to smaller and lighter electronic devices, with higher intelligence
    and lower cost.  Emphasizing energy conservation in semiconductor devices,
    the authors assert that the cooler the better will become a catch
    phrase.Cool-chip technological advances will break the language barrier.
    Hitachi has demonstrated a prototype portable-translation machine, which
    enables communication among people who speak different languages.  The
    advanced cool chip will play a crucial role in realizing Dick Tracy's
    watch, potentially the ultimate nomadic tool provided the price is
    affordable.  Combining communication networks and digital consumer
    products, based on cool chips, will provide temporal and spatial freedom
    and contribute to reducing urban congestion, pollution, and energy
    consumption.",
  location     = "http://dx.doi.org/10.1109/2.917535"
}

@Article{istbomc,
  author       = "William~R. Hamburgen and Deborah~A. Wallach and
  Marc~A. Viredaz and Lawrence~S. Brakmo and Carl~A. Waldspurger and
    Joel~F. Bartlett and Timothy Mann and Keith~I. Farkas", 
  title        = "Itsy: Stretching the Bounds of Mobile Computing",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 4,
  pages        = "28--36",
  month        = apr,
  keywords     = "personal computing devices, mobile computing",
  abstract     = "Built to explore the possibilities, demands, and limitations
    of mobile computing, Compaq's Itsy pocket computer research prototype
    strives to attain high performance with minimal power consumption, size,
    and weight.  Itsy's design incorporates a rich feature set to support
    user-interface and applications research and the flexibility to add new
    capabilities.  Daughtercards provide comprehensive expansion capability,
    and Itsy supports the Linux operating system with extensions for a flash
    file system, resource sharing, and power management.  Itsy has sufficient
    processing power and memory capacity to run cycle-hungry applications such
    as continuous speech recognition, a full-fledged Java virtual machine, and
    real-time MPEG-1 movie decoding.A useful tool for exploring the bounds of
    mobile computing, Itsy is powerful and flexible enough for applications,
    systems work, and power studies.  Designers inside and outside Compaq have
    built daughtercards for the pocket computer, including CMOS cameras, a
    PCM-CIA adapter with a large battery, a low-powered radio, and memory
    expansion cards.", 
  location     = "http://dx.doi.org/10.1109/2.917534"
}

@Article{nsdacfaidp,
  author       = "Peter Druschel and Mark~B. Abbott and Michael~A. Pagels and Larry~L. Peterson",
  title        = "Network Subsystem Design: {A} Case for an Integrated Data Path",
  journal      = ieeen,
  year         = 1993,
  volume       = 7,
  number       = 4,
  pages        = "8--17",
  month        = jul,
  keywords     = "workstation hardware performance, caches, data movement,
    end-to-end design, data streaming, integration",
  abstract     = "",
  location     = ""
}

@Article{ecwv,
  author       = "Werner Vogels",
  title        = "Eventually Consistent",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 1,
  pages        = "40--44",
  month        = jan,
  keywords     = "consistency",
  abstract     = "Building reliable distributed systems at a worldwide scale
    demands trade-offs between consistency and availability.",
  location     = "http://dx.doi.org/10.1145/1435417.1435432"
}

@Article{tlrt6b,
  author       = "John Mashey",
  title        = "The long road to 64 bits",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 1,
  pages        = "45--53",
  month        = jan,
  keywords     = "system architecture, backward portability",
  location     = "http://dx.doi.org/10.1145/1435417.1435431"
}

@Article{erdtsp,
  author       = "Tapan~S. Parikh",
  title        = "Engineering rural development",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 1,
  pages        = "54--63",
  month        = jan,
  keywords     = "civil society",
  abstract     = "Information systems enable rural development by increasing
    the accountability of nongovernmental organizations.", 
  location     = "http://dx.doi.org/10.1145/1435417.1435433"
}

@Article{wsfvhasiu,
  author       = "Dawn~N. Jutla and Dimitri Kanevsky",
  title        = "{wisePad} services for vision-, hearing-, and speech-impaired users",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 1,
  pages        = "64--69",
  month        = jan,
  keywords     = "augmented reality",
  abstract     = "They promise mobile information access and assistive Web
    services for tens of millions worldwide.", 
  location     = "http://dx.doi.org/10.1145/1435417.1435434"
}

@Article{cciec,
  author       = "Joan Feigenbaum and David~C. Parkes and David~M. Pennock",
  title        = "Computational challenges in e-commerce",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 1,
  pages        = "70--74",
  month        = jan,
  keywords     = "resource allocation, knowledge integration, security",
  abstract     = "Economic and social sciences will drive Internet protocols
    and services into the future.",
  location     = "http://dx.doi.org/10.1145/1435417.1435435"
}

@Article{scfmr,
  author       = "Ariel Shamir and Shai Avidan",
  title        = "Seam carving for media retargeting",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 1,
  pages        = "77--85",
  month        = jan,
  keywords     = "image processing",
  abstract     = "Traditional image resizing techniques are oblivious to the 
    content of the image when changing its width or height.  In contrast, media
    (i.e., image and video) retargeting take s content into account.  For
    example, one would like to change the aspect ratio of a video without
    making human figures look too fat or too skinny, or change the size of an
    image by automatically removing unnecessary portions while keeping the
    important features intact.  We propose a simple operator; we term seam
    carving to support image and video retargeting.  A seam is an optimal 1D
    path of pixels in an image, or a 2D manifold in a video cube, going from
    top to bottom, or left to right.  Optimality is defined by minimizing an
    energy function that assigns costs to pixels.  We show that computing a
    seam reduces to a dynamic programming problem for images and a graph
    min-cut search for video.  We demonstrate that several image and video
    operations, such as aspect ratio correction, size change, and object
    removal, can be recast as a successive operation of the seam carving
    operator.", 
  location     = "http://dx.doi.org/10.1145/1435417.1435437"
}

@Article{vavsacv,
  author       = "Jeffrey Heer and Fernanda~B. Vi{\' e}gas and Martin Wattenberg",
  title        = "Voyagers and voyeurs: Supporting asynchronous collaborative visualization",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 1,
  pages        = "87--97",
  month        = jan,
  keywords     = "visualization, collaborative systems",
  abstract     = "This article describes mechanisms for asynchronous
    collaboration in the context of information visualization, recasting
    visualizations as not just analytic tools, but social spaces.  We
    contribute the design and implementation of sense.us, a Web site supporting
    asynchronous collaboration across a variety of visualization types.  The
    site supports view sharing, discussion, graphical annotation, and social
    navigation and includes novel interaction elements.  We report the results
    of user studies of the system, observing emergent patterns of social data
    analysis, including cycles of observation and hypothesis, and the
    complementary roles of social navigation and data-driven exploration.",
  location     = "http://dx.doi.org/10.1145/1435417.1435439"
}

@Article{cmatb,
  author       = "Thomas Becker",
  title        = cpp # " Metaprogramming Applied",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 2,
  pages        = "49--53",
  month        = feb,
  keywords     = "default function arguments",
  location     = "http://drdobbs.com/184401610"
}

@Article{temms,
  author       = "Miro Samek",
  title        = "The Embedded Mindset",
  journal      = ccppuj,
  year         = 2001,
  volume       = 21,
  number       = 2,
  pages        = "39--45",
  month        = feb,
  keywords     = "embedded programming, real-time systems",
  location     = "http://drdobbs.com/184401620"
}

@Article{tcgsd,
  author       = "Steve Dewhurst",
  title        = "Two " # cpp # " Gotchas",
  journal      = ccppuj,
  year         = 2001,
  volume       = 21,
  number       = 2,
  pages        = "32--37",
  month        = feb,
  keywords     = "casting, void *, object hierarchies",
  location     = "http://drdobbs.com/184401613"
}

@Article{pgfvccc,
  author       = "Aart Bik and Milind Girkar and Paul Grey and Xinmin Tian",
  title        = "Programming Guidelines for Vectorizing {C}/" # cpp # " Compilers",
  journal      = ccppuj,
  year         = 2001,
  volume       = 21,
  number       = 2,
  pages        = "26--31",
  month        = feb,
  keywords     = "data dependence, data alignment",
  location     = "http://drdobbs.com/184401611"
}

@Article{twpm,
  author       = "John Torjo",
  title        = "Testing with Paired Messages",
  journal      = ccppuj,
  year         = 2001,
  volume       = 21,
  number       = 2,
  pages        = "14--21",
  month        = feb,
  keywords     = "messages, logging, object design",
  location     = "https://www.ddj.com/cpp/184401621"
}

@Article{amcic,
  author       = "Zlatko Marcok",
  title        = "Automated Memory Checking in {C}",
  journal      = ccppuj,
  year         = 2001,
  volume       = 21,
  number       = 2,
  pages        = "6--13",
  month        = feb,
  keywords     = "memory overrun, memory leaks, memory management",
  location     = "http://drdobbs.com/184401618"
}

@Article{haesp4trwc,
  author       = kmoo,
  title        = "Handles and Exception Safety, Part 4: Tracking References without Counters",
  journal      = ccppuj,
  year         = 2001,
  volume       = 21,
  number       = 2,
  pages        = "57--62",
  month        = feb,
  keywords     = "reference counting",
  location     = "http://drdobbs.com/184401616"
}

@Article{atsfdfiowv,
  author       = "Avik Chauduri and Prasad Naldurg and Sriram Rajamani",
  title        = "{A} Type System for Data-Flow Integrity on {W}indows {V}ista",
  journal      = sigplan,
  year         = 2008,
  volume       = 43,
  number       = 12,
  pages        = "9--20",
  month        = dec,
  keywords     = "dynamic access control, data-flow integrity, hybrid type
    system, explicit substitution",
  abstract     = "The Windows Vista operating system implements an interesting
    model of multi-level integrity.  We observe that in this model, trusted
    code must participate in any information-flow attack.  Thus, it is possible
    to eliminate such attacks by statically restricting trusted code.  We
    formalize this model by designing a type system that can efficiently
    enforce data-flow integrity on Windows Vista.  Typechecking guarantees that
    objects whose contents are statically trusted never contain untrusted
    values, regardless of what untrusted code runs in the environment.  Some of
    Windows Vista's runtime access checks are necessary for soundness; others
    are redundant and can be optimized away.",
  location     = "http://www.cs.umd.edu/~avik/papers/tsdfiwv.pdf"
}

@Article{veosirp,
  author       = "Nikhil Swamy and Michael Hicks",
  title        = "Verified enforcement of stateful information release policies",
  journal      = sigplan,
  year         = 2008,
  volume       = 43,
  number       = 12,
  pages        = "21--31",
  month        = dec,
  keywords     = "declassification, certified evaluation, state modifying
    policies, dependent types, affine types, singleton types",
  abstract     = "Many organizations specify information release policies to 
    describe the terms under which sensitive information may be released to
    other organizations.  This paper presents a new approach for ensuring that
    security-critical software correctly enforces its information release
    policy.  Our approach has two parts.  First, an information release policy
    is specified as a security automaton written in a new language called AIR.
    Second, we enforce an AIR policy by translating it into an API for programs
    written in lAIR, a core formalism for a functional programming language.
    lAIR uses a novel combination of dependent, affine, and singleton types to
    ensure that the API is used correctly.  As a consequence we can certify
    that programs written in lAIR meet the requirements of the original AIR
    policy specification.",
  location     = "http://dx.doi.org/10.1145/1513443.1513448"
}

@Article{plapafsatyr,
  author       = "Marco Pistoia and {\' U}lfar Erlingsson",
  title        = "Programming languages and program analysis for security: a three-year
 retrospective ",
  journal      = sigplan,
  year         = 2008,
  volume       = 43,
  number       = 12,
  pages        = "32--39",
  month        = dec,
  keywords     = "program analysis, programming language, application security,
  security, program analysis, programming languages, language-based security",
  abstract     = "Software security has been traditionally enforced at the 
    level of operating systems.  However, operating systems have become
    increasingly large and complex, and it is very difficult--if not
    impossible--to enforce software security solely through them.  Moreover,
    operating-system security allows dealing primarily with access-control
    policies on resources such as files and network connections.  However,
    attacks may happen at both lower and higher levels of abstraction, and may
    target the internal behavior of applications, such as today's Web-based
    applications.  Therefore, defenses must offer protection at the level of
    applications.  Language-based security is the area of research that studies
    how to enforce application-level security using programming-language and
    program-analysis techniques.  This area of research has become very active
    with the advent of Web applications.  In 2006, the ACM SIGPLAN has
    introduced a new yearly forum entirely dedicated to the discussion of
    language-based-security research: Programming Languages and Analysis for
    Security (PLAS).  This paper is a three-year survey of PLAS papers that
    discusses the progress made in the area of language-based security.",
  location     = "http://dx.doi.org/10.1145/1513443.1513449"
}

@Article{aevodm,
  author       = "William~E. Wright",
  title        = "An Efficient Video-on-Demand Model",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 5,
  pages        = "64--70",
  month        = may,
  keywords     = "disk parameters, algorithms, storage layout, disk storage",
  abstract     = "The author proposes a design for an efficient
    video-on-demand system that uses a practical, technologically sophisticated
    model to serve the home movie-viewing needs of a wide audience, including
    meeting peak demand for popular, newly released films.  In this VoD model,
    each customer's VoD terminal connects to a television set and the network.
    Using the network, the customer contacts the VoD provider to request a
    movie at a specific time.  The movie plays without interruption unless the
    user decides to pause it.  The VoD network's bandwidth permits data
    transfer at a rate equal to or exceeding the rate at which the TV consumes
    the data.  The terminal buffer's large capacity permits uninterrupted movie
    playing.  The system includes the scheduling algorithm, buffer policy,
    file-storage lay-out, and a feedback mechanism for denying new requests
    when the system becomes nearly saturated.  OEID--one-way elevator with
    interleaving and delayed start--includes a one-way elevator algorithm for
    each disk for each round and provides double buffering for each video
    stream.  Other features include interleaved movie file storage and
    transmission of a warning message when the terminal nears starvation.
    Interleaving with delayed start offers the optimal strategy for storing
    movie files on disks because it permits maximum overlap of the read
    operations--seek, latency, and transfer-- over all disks, whereas striping
    overlaps only the transfer component.  Also, OEID permits an almost
    perfectly balanced workload over all disks, on every round, regardless of
    movie popularity.", 
  location     = "http://dx.doi.org/10.1109/2.920614"
}

@Article{afpfecsp,
  author       = "Patricia~K. Lawlis and Kathryn~E. Mark and Deborah~A. Thomas
    and Terry Courtheyn", 
  title        = "{A} Formal Process for Evaluating {COTS} Software Products",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 5,
  pages        = "58--63",
  month        = may,
  keywords     = "software evaluation, ",
  abstract     = "A software-product evaluation process grounded in 
    mathematics and decision theory can effectively determine product quality
    and suitability with less risk and at lower cost than conventional methods.
    Thus, the authors seek to develop a formal process for effective
    software-product evaluation to assess commercial-off-the-shelf product
    quality and suitability before purchase.  They propose a requirements-based
    COTS product evaluation process, RCPEP, that ensures a quality outcome,
    then demonstrate its use in a case study of a US Air Force product for a
    large, component-based training-management system.  The authors describe
    how, unlike a typical ad hoc product evaluation, RCPEP relies on
    user-defined requirements to determine product suitability and quality.
    RCPEP identifies every product that addresses the requirements, conducts a
    trade study to narrow the list to serious candidates, and evaluates the
    remaining candidates using hands-on scenarios.  An ad hoc process does not
    adhere to strict controls that ensure all candidate products receive
    identical evaluations and generate comparable results.  In contrast,
    RCPEP's hands-on evaluation includes several controls that ensure the
    evaluation does not compromise the results' validity.  The Air Force case
    study confirmed the authors' expectation that the simplest form of decision
    analysis, weighted averages, could effectively evaluate COTS products.
    RCPEP succeeded because it relied on user-defined requirements, contained a
    sufficient number of evaluators to obtain valid quantitative results, and
    adhered to the controls.  The authors believe that RCPEP will be effective
    for all forms of COTS product evaluations and could mature into an industry
    standard.", 
  location     = "http://dx.doi.org/10.1109/2.920613"
}

@Article{hiscnq,
  author       = "Richard Baskerville and Linda Levine and Jan Pries-Heje and
    Balasubramaniam Ramesh and Sandra Slaughter",
  title        = "How {I}nternet Software Companies Negotiate Quality",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 5,
  pages        = "51--57",
  month        = may,
  keywords     = "",
  abstract     = "Regardless of their market niche, most companies feel
    pressured to release software faster: within 12 to 18 months for
    non-Internet companies and as quickly as three to six months for Web
    ventures.  To achieve these short cycles, companies like Microsoft and
    Netscape have adopted techniques that can halve traditional development
    times: Lean production tailors work processes, tool use, methods, and
    project management to eliminate waste and rework.  Fast cycle time mandates
    using development processes that require only a fraction of the time and
    resources ordinary processes consume.  As the scramble to innovate reduces
    development time, companies must seek nontraditional approaches to software
    quality.  Both Microsoft and Netscape, for example, improve quality, reduce
    costs, and decrease production time on their large projects by applying
    prototyping techniques perfected on small projects.  To identify what
    drives and characterizes Internet-speed development, researchers at
    Carnegie Mellon University, Georgia State University, and the Software
    Engineering Institute interviewed software developers and project managers
    at nine companies that use these practices.  This study, part of an ongoing
    project, revealed three important trends.  Time drives development
    decisions based on pressures to reach market first.  Quality depends on
    whether or not practices like parallel QA are in place, the importance
    customers place on quality, and developers' skill levels.  Finally,
    development processes adjust as companies tweak their methods to achieve
    higher quality.", 
  location     = "http://dx.doi.org/10.1109/2.920612"
}

@Article{semfcbs,
  author       = "Sahra Sedigh-Ali and Arif Ghafoor and Raymond~A. Paul",
  title        = "Software Engineering Metrics for {COTS}-Based Systems",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 5,
  pages        = "44--50",
  month        = may,
  keywords     = "cots, risk management, quality, metrics, capability maturity
    models",
  abstract     = "Large projects rely increasingly on commercial off-the-shelf
    components, a trend that emphasizes the need for adequate metrics to
    quantify component quality.  Handling the growth of these COTS-based
    systems requires new approaches to quality and risk management.  The
    authors offer software-engineering metrics to aid developers and managers
    in analyzing their quality-improvement initiatives' return on investment
    and to facilitate the modeling of cost and quality.  They assert that
    large-scale component reuse or COTS component acquisition can generate
    savings in development resources, which can be applied to improve quality
    and enhance reliability, availability, and maintenance.  Further, metrics
    play a critical role in identifying risks that involve performance,
    reliability, adaptability, scheduling, and product evaluation.  COTS
    products change rapidly, and research on COTS-based- system development is
    still in the early stages.  Given that cost-effectiveness and quality
    provide the major factors in deciding for or against component acquisition,
    the authors see an urgent need for empirical and analytical research that
    will lead to more accurate cost and quality models for these systems.", 
  location     = "http://dx.doi.org/10.1109/2.920611"
}

@Article{adwac,
  author       = "Martin~L. Griss and Gilda Pour",
  title        = "Accelerating Development with Agent Components",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 5,
  pages        = "37--43",
  month        = may,
  keywords     = "agents, multiagent communication",
  abstract     = "This analytical survey reveals that software engineering
    methodologies and development strategies must support the construction of
    enterprise systems that assemble flexible components written at different
    times by various developers.  Component-based software engineering offers
    an attractive alternative for building Web-based enterprise application
    systems.  It develops and evolves software from reusable components and
    assembles them within appropriate software architectures.  The
    component-based software development approach promises large-scale software
    reuse, which reduces development cost and time to market, and enhances the
    reliability, maintainability, and quality of enterprise software systems.
    Agent-oriented software engineering offers opportunities for developing and
    maintaining Web-based enterprise systems at Internet speed.Driven by goals
    and plans rather than procedural code, agents encapsulate business or
    domain knowledge.  They differ from each other by the knowledge they have
    and the roles they play.",
  location     = "http://dx.doi.org/10.1109/2.920610"
}

@Article{seita,
  author       = "Bertrand Meyer",
  title        = "Software Engineering in the Academy",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 5,
  pages        = "28--35",
  month        = may,
  keywords     = "software professionals, curriculum development, inverted
    curriculum",
  abstract     = "The lack of a universally accepted definition of software
    engineering makes teaching the discipline a challenge.  A textbook
    definition of the term might read something like this: the body of methods,
    tools, and techniques intended to produce quality software. Rather than
    emphasizing quality alone, we could distinguish software engineering from
    programming by defining it as follows: the development of possibly large
    systems intended for use in production environments, over a possibly long
    period, worked on by possibly many people, and possibly undergoing many
    changes. In this definition, development includes management, maintenance,
    validation, documentation, and so forth.  Given the shortage of qualified
    personnel and the ongoing search for excellent developers, educational
    institutions must strive to train students who will, upon graduation, take
    their place in the top tier.  By teaching them fundamental thought leavened
    with practical experience, these establishments can help prepare these
    students for a long-term professional growth that synchronizes smoothly
    with the discipline's progress-- for, while technology evolves, the
    concepts remain.", 
  location     = "http://dx.doi.org/10.1109/2.920608"
}

@Article{ppirpm,
  author       = "Atsushi Kara",
  title        = "Protecting Privacy in Remote-Patient Monitoring",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 5,
  pages        = "24--27",
  month        = may,
  keywords     = "internet security protocol, encryption, key exchange, crisis
    detection", 
  abstract     = "Audio-video-based remote-patient monitoring via the Internet
    raises privacy issues that only clearly defined confidentiality and
    authentication requirements for secure Internet communication can address.
    MPEG compression technologies can transmit high-quality audio-video via the
    Internet so that a family member can use an office PC or wireless mobile
    terminal to monitor a bedridden patient's image and vital signs while a
    caregiver runs errands.  However, such systems raise privacy concerns.
    Transmitting unprotected audio-visual signals, compressed in a standard
    format, over the Internet carries the risk that someone can monitor these
    transmissions, accidentally or intentionally.  For medical and healthcare
    applications, security issues in the Internet's transport and network
    layers cause the most concern.  Although encryption can protect data, using
    such technology for remote-patient monitoring should not compromise
    Internet accessibility and performance.  Patient-monitoring applications
    require excellent performance and quality of service to provide accurate
    live information to the monitoring side.  Thus, the performance of the
    end-to-end Internet infrastructure itself must be the subject of future
    study.", 
  location     = "http://dx.doi.org/10.1109/2.920607"
}

@Article{ncoef,
  author       = "Michael~W. Pashea",
  title        = "Numerical Computation of Elliptic Functions",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "22--31",
  month        = may,
  keywords     = "rectification, elliptic functions, periodicity, numeric
    computation",
  location     = "http://drdobbs.com/cpp/184406067"
}

@Article{nbtc,
  author       = "John Graham-Cumming",
  title        = "Na{\" \i}ve {B}ayesian Text Classification",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "16--20",
  month        = may,
  keywords     = "text classification, bayesian statistics",
  location     = "http://drdobbs.com/tools/184406064"
}

@Article{oq,
  author       = "Timothy Rolfe",
  title        = "Optimal Queens",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "32--37",
  month        = may,
  keywords     = "backtracking algorithms, java threads",
  location     = "http://drdobbs.com/java/184406068"
}

@Article{amspssa,
  author       = "Macgregor~K. Phillips",
  title        = "{A} Multifield Single-Pass {S}hell Sort Algorithm",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "38--41",
  month        = may,
  keywords     = "sorting algorithms, ",
  location     = "http://drdobbs.com/architecture-and-design/184406069"
}

@Article{pbea,
  author       = "John~M. Boyer",
  title        = "Planarity by Edge Addition",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "42--45",
  month        = may,
  keywords     = "graph algorithms, planarity",
  location     = ""
}

@Article{prib,
  author       = "Steven~F. Lott and Robert Lucente",
  title        = "Processing Rows in Batches",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "46--49",
  month        = may,
  keywords     = "database processing, fork and split, scanning",
  location     = "http://drdobbs.com/184406071"
}

@Article{tmaci,
  author       = "Hrvoje Lukatela and John Russell",
  title        = "TileShare: Maps as Computer Images",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "50--53",
  month        = may,
  keywords     = "compression, morton order, angular coordinate encoding,
    discrete mercator projection",
  location     = "http://drdobbs.com/architecture-and-design/184406072"
}

@Article{p24d,
  author       = "Phillip Eby",
  title        = "Python 2.4 Decorators",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "54--57",
  month        = may,
  keywords     = "objects, functions, decorator arguments",
  location     = "http://drdobbs.com/web-development/184406073"
}

@Article{mtmp,
  author       = "Craig Szydlowski",
  title        = "Multithreaded Technology \& Multicore Processors",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "58--60",
  month        = may,
  keywords     = "dual core cpus, cpu architecture, parallelism, multicore",
  location     = "http://drdobbs.com/architecture-and-design/184406074"
}

@Article{botcg,
  author       = "Gigi Sayfan",
  title        = "Battle of the Code Generators",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "61--65",
  month        = may,
  keywords     = "code generations, templates",
  location     = ""
}

@Article{eccl,
  author       = "Greg Bednarek",
  title        = "Eclipse \& Custom Class Loaders",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 5,
  pages        = "78--81",
  month        = may,
  keywords     = "java class loading, eclipse ide",
  location     = "http://drdobbs.com/java/184406080"
}

@Article{caitiocac,
  author       = "Randy Meyers and Dr. Thomas Plum",
  title        = "Complex Arithmetic: In the Intersection of {C} and " # cpp,
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 3,
  pages        = "44--49",
  month        = mar,
  keywords     = "c99, common features",
  location     = "http://drdobbs.com/cpp/184401628"
}

@Article{tbcfcac,
  author       = "Gene Michael Stover",
  title        = "The {B}oehm Collector for {C} and " # cpp,
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 3,
  pages        = "39--43",
  month        = mar,
  keywords     = "garbage collection, c, destructors, ",
  location     = "http://drdobbs.com/184401632"
}

@Article{ttmw,
  author       = "Matthew Wilson",
  title        = "True Typedefs",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 3,
  pages        = "35--38",
  month        = mar,
  keywords     = "typedefs, template programming, wrappers",
  location     = "http://drdobbs.com/184401633"
}

@Article{cet,
  author       = "Angelika Langer and Klaus Kreft",
  title        = cpp # " Expression Templates",
  journal      = cppuj,
  year         = 2003,
  volume       = 21,
  number       = 3,
  pages        = "27--34",
  month        = mar,
  keywords     = "expression templates, arithmetic expressions, compile-time
    evaluation, evaluations, traits",
  location     = "http://drdobbs.com/184401627"
}

@Article{qpfestahfm,
  author       = "Miro Samek",
  title        = "Quantum Programming for Embedded Systems:  Toward a Hassle-Free Multithreading",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 3,
  pages        = "18--26",
  month        = mar,
  keywords     = "actors, active objects, design automation tools, ",
  location     = "http://drdobbs.com/184401630"
}

@Article{eadc,
  author       = "Stephan Gr{\" u}nfelder",
  title        = "Easy Analog Data Compression",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 3,
  pages        = "6--16",
  month        = mar,
  keywords     = "adaptive delta encoding, prediction, decompression",
  location     = "http://drdobbs.com/cpp/184401624?pgno=3"
}

@Article{bsbg,
  author       = "Walker White and Christoph Koch and Johannes Gehrke and Alan Demers",
  title        = "Better Scripts, Better Games",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 3,
  pages        = "42--47",
  month        = mar,
  keywords     = "concurrency patterns, game-aware runtimes, state-effect
    pattern, restrictediteration pattern, scripting language",
  abstract     = "Smarter, more powerful scripting languages will improve game
    performance while making gameplay development more efficient.",
  location     = "http://dx.doi.org/10.1145/1467247.1467262"
}

@Article{rhvitda,
  author       = "Abigail Sellen and Yvonne Rogers and Richard Harper and Tom Rodden",
  title        = "Reflecting Human Values in the Digital Age",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 3,
  pages        = "58--66",
  month        = mar,
  keywords     = "human-computer interactions, value systems",
  abstract     = "HCI experts must broaden the field's scope and adopt new
    methods to be useful in 21st-century sociotechnical environments.",
  location     = "http://dx.doi.org/10.1145/1467247.1467265"
}

@Article{sitmapa,
  author       = "David Harel",
  title        = "Statecharts in the making: a personal account",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 3,
  pages        = "67--75",
  month        = mar,
  keywords     = "statecharts, software design, software tools, semantic
  definitions",
  abstract     = "How avionics work led to a graphical language for reactive
    systems where the diagrams themselves define the system's behavior.",
  location     = "http://dx.doi.org/10.1145/1467247.1467274"
}

@Article{pcpms,
  author       = "Madhu Sudan",
  title        = "Probabilistically checkable proofs",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 3,
  pages        = "76--84",
  month        = mar,
  keywords     = "combinatorial optimizations",
  abstract     = "Can a proof be checked without reading it?",
  location     = "http://dx.doi.org/10.1145/1467247.1467267"
}

@Article{tptboecc,
  author       = "Venkatesan Guruswami and Atri Rudra",
  title        = "Error correction up to the information-theoretic limit",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 3,
  pages        = "87--95",
  month        = mar,
  keywords     = "reed-solomon codes, error correction, multivariate decoding",
  abstract     = "Ever since the birth of coding theory almost 60 years ago,
    researchers have been pursuing the elusive goal of constructing the best
    codes, whose encoding introduces the minimum possible redundancy for the
    level of noise they can correct.  In this article, we survey recent
    progress in list decoding that has led to efficient error-correction
    schemes with an optimal amount of redundancy, even against worst-case
    errors caused by a potentially malicious channel.  To correct a proportion
    ρ(say 20%) of worst-case errors, these codes only need close to a
    proportion ρ of redundant symbols.  The redundancy cannot possibly be any
    lower information theoretically.  This new method holds the promise of
    correcting a factor of two more errors compared to the conventional
    algorithms currently in use in diverse everyday applications.",
  location     = "http://dx.doi.org/10.1145/1467247.1467269"
}

@Article{ladebinocm,
  author       = "Radu Grosu and Scott~A. Smolka and Flavio Corradini and Anita
    Wasilewska and Emilia Entcheva and Ezio Bartocci",
  title        = "Learning and detecting emergent behavior in networks of cardiac myocytes",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 3,
  pages        = "97--105",
  month        = mar,
  keywords     = "quadtree, linear superposition logic, model checking,
    learning",
  abstract     = "We address the problem of specifying and detecting emergent
    behavior in networks of cardiac myocytes, spiral electric waves in
    particular, a precursor to atrial and ventricular fibrillation.  To solve
    this problem we: (1) apply discrete mode abstraction to the cycle-linear
    hybrid automata (CLHA) we have recently developed for modeling the behavior
    of myocyte networks; (2) introduce the new concept of spatial superposition
    of CLHA modes; (3) develop a new spatial logic, based on spatial
    superposition, for specifying emergent behavior; (4) devise a new method
    for learning the formulae of this logic from the spatial patterns under
    investigation; and (5) apply bounded model checking to detect the onset of
    spiral waves.  We have implemented our methodology as the EMERALD tool
    suite, a component of our EHA framework for specification, simulation,
    analysis, and control of excitable hybrid automata.  We illustrate the
    effectiveness of our approach by applying EMERALD to the scalar electrical
    fields produced by our CELLEXCITE simulation environment for excitable-cell
    networks.", 
  location     = "http://dx.doi.org/10.1145/1467247.1467271"
}

@Article{efcpjl,
  author       = "Jim Larson",
  title        = "Erlang for concurrent programming",
  journal      = cacm,
  year         = 2009,
  volume       = 52,
  number       = 3,
  pages        = "48--56",
  month        = mar,
  keywords     = "concurrency, abstracting protocols, scalability",
  abstract     = "Designed for concurrency from the ground up, the Erlang
    language can be a valuable tool to help solve concurrent problems.",
  location     = "http://dx.doi.org/10.1145/1467247.1467263"
}

@Article{adflsdp,
  author       = "Eric Riedel and Christos faloutsos and Garth~A. Gibson and
    David Nagle",
  title        = "Active Disks for Large-Scale Data Processing",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 6,
  pages        = "68--74",
  month        = jun,
  keywords     = "embedded processing, image registration",
  abstract     = "Active disk systems leverage the aggregate processing power of net-worked disks to offer increased processing throughput for large-scale data mining tasks.  As processor performance increases and memory cost decreases, system intelligence continues to move away from the CPU and into peripherals.  The authors propose using an active disk storage device that combines on-drive processing and memory with software downloadability to allow disks to execute application-level functions directly at the device.With active disks, application-specific functions access the excess computation power in drives.  Active disks combine the requisite processing power of general-purpose disk-drive microprocessors with the special-purpose functionality of end-user programmability.The authors' experiment showed that active disks can accelerate an existing database system by moving data-intensive processing to the disks, thereby reducing the server CPU's processing load.  The active disk approach eliminates the need for the PC processor, its memory subsystem, and I/O backplane, which makes active disks relatively inexpensive.  The development of new data-intensive algorithms requires large amounts of disk space and high data-transfer rates for various processing tasks, with richer database structures, new content, new data sources, and novel applications for collected data.  The authors contend that active disks can meet these needs while offering the parallelism available in large storage systems.",
  location     = "http://dx.doi.org/10.1109/2.928624"
}

@Article{xsiodads,
  author       = "Len Seligman and Arnon Rosenthal",
  title        = "{XML}'s Impact on Databases and Data Sharing",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 6,
  pages        = "59--67",
  month        = jun,
  keywords     = "data sharing, databases, semistructured data, ",
  abstract     = "The Extensible Markup Language, HTML's likely successor for
    capturing Web content, has generated a lot of interest.  Created by the
    World Wide Web Consortium to address HTML's limitations, XML resembles
    HTML's format but offers users a more extensible language.  It lets
    information publishers invent their own tags for applications.
    Alternatively, they can work with organizations to define shared tag sets
    that promote interoperability and help separate content from presentation.
    While XML addresses content, Cascading Style Sheets, the Extensible
    Stylesheet Language, and Extensible HTML handle presentation separately.
    XML also supports data validation.  XML's advantages over HTML include
    support for multiple views of the same content for different user groups
    and media; selective, field-sensitive queries over the Internet and
    intranets; a visible semantic structure for Web information; and a standard
    data and document interchange infrastructure.  Using XML and related tools
    often eliminates problems associated with heterogeneous data structures.
    Like any new technology, XML has generated exaggerated claims.  It does not
    come close to eliminating the need for database management systems or
    solving large organizations' data-sharing problems.  Although XML hype has
    raised unrealistic expectations, the language does reduce the data-sharing
    obstacles among diverse applications and databases by providing a common
    format for expressing data structure and content.", 
  location     = ""
}

@Article{btwitmd,
  author       = "Subhasis Saha and Mark Jamtgaard and John Villasenor",
  title        = "Bringing the Wireless Internet to Mobile Devices",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 6,
  pages        = "54--58",
  month        = jun,
  keywords     = "wap, imode, middleware, internet markup languages",
  abstract     = "Mapping Internet content to mobile wireless devices requires
    new technologies, standards, and innovative solutions that minimize cost
    and maximize efficiency.  The wireless Internet must deliver information in
    a suitable format to handheld device users--regardless of location and
    connectivity.  Although the exact form in which high-speed wireless data
    services will develop is uncertain, the authors predict an improvement over
    today's data rates.  Current mobile devices suffer from small displays,
    limited memory, limited processing power, low battery power, and
    vulnerability to inherent wireless net-work transmission problems.  To
    address these issues, a group of leading wireless and mobile communications
    companies have developed the wireless application protocol for transmitting
    wireless information and telephony ser-vices on mobile handheld devices.
    Whereas HTTP sends its data in text for-mat, WAP uses Wireless Markup
    Language to create and deliver content in a compressed binary format that
    provides efficiency and security.  Middleware, an alternative to manually
    replicating content, seamlessly translates a Web site's existing content to
    mobile devices that support operating systems, markup languages,
    microbrowsers, and protocols.  The authors predict that middleware such as
    Relational Markup Language will be critical to bringing Internet content to
    wireless devices, and they anticipate that open standards based on this or
    similar techniques will gain acceptance.", 
  location     = "http://dx.doi.org/10.1109/2.928622"
}

@Article{laiahwmn,
  author       = "Yu-Chee Tseng and Shih-Lin Wu and Wen-Hwa Liao and Chih-Min
    Chao", 
  title        = "Location Awareness in Ad Hoc Wireless Mobile Networks",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 6,
  pages        = "46--52",
  month        = jun,
  keywords     = "location awareness, routing protocols, ",
  abstract     = "Advances in wireless communications and small, portable 
    computing devices have made mobile computing possible.  Networks composed
    of repositioning mobile hosts require location awareness to provide new
    geographic services and maximize routing efficiency and quality of service.
    One mobile computing implementation creates a manet--a mobile ad hoc
    network that consists of mobile hosts that roam at will and communicate
    with one another.  Manet research focuses on unicast, collective
    communication, and quality-of-service routing.  Operating in a physical
    geometric space, manets must exploit location information.  Thus, each
    mobile host uses a positioning device to determine its current physical
    location.Given that wireless networks can operate in a 3D physical
    environment, it's inevitable that mobile applications will exploit mobile
    hosts' location information.  Developers of emerging geographic services
    based on manets must learn how to increase positioning accuracy and
    establish a connection between location information and the vast sea of Web
    data.", 
  location     = "http://dx.doi.org/10.1109/2.928621"
}

@Article{altvosrw,
  author       = "David~G. Leeper",
  title        = "{A} Long-Term View of Short-Range Wireless",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 6,
  pages        = "39--44",
  month        = jun,
  keywords     = "short-range wireless, pans, untrawideband",
  abstract     = "Economic forces and physical laws are driving the growth of 
    a new wireless infrastructure that will become as ubiquitous as lighting
    and power infrastructures are today.  Many expect that the next-generation
    cellular systems built upon this foundation will bring fast, nearly
    ubiquitous, wireless data connections to users.  At the heart of this new
    infrastructure lies short-range wireless, a complementary class of emerging
    technologies meant primarily for indoor use over very short distances.  SRW
    links will offer peak speeds of tens or even hundreds of megabits per
    second-- at very low cost and with very low power--to many closely spaced
    users.  In its base set of applications, SRW technologies will provide
    cableless connections among the portable devices people wear and carry
    daily, including cell phones, headsets, PDAs, laptop computers, digital
    cameras, audio and video players, and health monitoring devices.  Given
    that SRW links will be unlicensed, and that owners of individual premises
    rather than government authorities will grant installation permissions, SRW
    business models may differ radically from those of traditional telecom
    carriers.  Some carriers may see SRW as a threat and actively oppose it,
    while others may see it as a powerful complement to their current
    technologies.", 
  location     = "http://dx.doi.org/10.1109/2.928620"
}

@Article{ossdao,
  author       = "Ming-Wei Wu and Ying-Dar Lin",
  title        = "Open Source Software Development: An Overview",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 6,
  pages        = "33--38",
  month        = jun,
  keywords     = "open source, licensing models, linux distributions",
  abstract     = "Although some challenge the value of open source software
    development, its popularity is undisputed.  This overview of open source
    licensing and development models describes the movement's main principles.
    Whereas proprietary vendors use a closed-source model to develop their
    software, release it to the public, and anticipate a profit, the open
    source movement-- although still profitable-- relies on different
    practices.  Open source projects invite everyone capable of writing code to
    join in, leading to robust software and diverse business models.  However,
    having multiple participants requires extensive coordination, ranging from
    standardizing software to offering other benefits.  Inexpensive even when
    packaged and sold by a third-party vendor, open source software frees
    developers and hardware manufacturers from following a closed-source
    software vendor's specifications.  Open source software has also proven
    highly reliable as well, thanks to the continuing efforts of the
    programming community that develops it.  Although free software provides
    unprecedented flexibility, stability, and freedom of choice, various
    distributions tend to compete and imitate one another.  This fragmentation
    will likely be the most prominent hurdle facing open source software's
    future.", 
  location     = "http://dx.doi.org/10.1109/2.928619"
}

@Article{mca,
  author       = "Kurt Geihs",
  title        = "Middleware Challenges Ahead",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 6,
  pages        = "24--31",
  month        = jun,
  keywords     = "enterprise application integration, qos, nomadic mobility,
    ubiquitous computing, internet applications, asynchronous interaction,
    shared memory",
  abstract     = "New application requirements--including the need to support
    enterprise application integration, Internet applications, quality of
    service, nomadic mobility, and ubiquitous computing--challenge established
    middleware design principles.  Meeting these challenges will lead to a
    major middleware design and development phase that requires new insights
    into distributed system technology.  A middleware layer seeks to hide the
    underlying networked environment's complexity by, for example, insulating
    applications from explicit protocol handling, disjoint memories, data
    replication, network faults, and parallelism.  Middleware masks the
    heterogeneity of computer architectures, operating systems, programming
    languages, and networking technologies to facilitate application
    programming and management.  The transition to new-generation middleware
    systems poses several questions.  What is the most appropriate programming
    model for diverse application scenarios? Can we build customizable,
    configurable, and flexible middleware frameworks for inherently
    heterogeneous environments? What middleware features and infrastructure
    services will mobile ubiquitous computing require? These issues frame the
    agenda for future middleware research and generate open research problems
    requiring building applications atop new middleware prototypes.",
  location     = "http://dx.doi.org/10.1109/2.928618" 
}

@Article{ppice,
  author       = "Behrooz Parhami",
  title        = "Puzzling Problems in Computer Engineering",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "26--29",
  month        = mar,
  keywords     = "pedagogy, course development",
  abstract     = "University faculty have designed an engaging puzzle-based
    freshman seminar intended to motivate and retain computer engineering
    students.", 
  location     = "http://dx.doi.org/10.1109/MC.2009.95"
}

@Article{isssgm,
  author       = "Gary Marchionini and Ryen~W. White",
  title        = "Information-Seeking Support Systems",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "30--32",
  month        = mar,
  keywords     = "information seeking",
  abstract     = "Seeking information for learning, decision making, and other
    complex mental activities that take place over time requires tools and
    support services that aid people in managing, analyzing, and sharing
    retrieved information.", 
  location     = "http://dx.doi.org/10.1109/MC.2009.88"
}

@Article{po1mcissams,
  author       = "Peter Pirolli",
  title        = "Powers of 10: Modeling Complex Information-Seeking Systems at Multiple Scales",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "33--40",
  month        = mar,
  keywords     = "sensemaking, exploratory search, human-information
    interaction, web navigation",
  abstract     = "New models of information-seeking support systems offer two
    advantages: They move us from prescientific conceptual frameworks about
    information seeking to more rigorous scientific theories and predictive
    models while, at the same time, expanding the kinds of things we study and
    develop.",
  location     = "http://dx.doi.org/10.1109/MC.2009.94"
}

@Article{cisgg,
  author       = "Gene Golovchinsky and Pernilla Qvarfordt and Jeremy Pickens",
  title        = "Collaborative Information Seeking",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "52--59",
  month        = mar,
  keywords     = "collaboration, information seeking",
  abstract     = "An examination of the roles and dimensions of collaborative
    search reveals new opportunities for information-seeking support tools.", 
  location     = "http://dx.doi.org/10.1109/MC.2009.73"
}

@Article{bkwsbks,
  author       = "{m}.~{c}. {s}chraefel",
  title        = "Building Knowledge: What's beyond Keyword Search?",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "52--59",
  month        = mar,
  keywords     = "annotation, note taking, visualizations, facetted search,
    serendipity",
  abstract     = "The success of the search engine may be our Newtonian
    paradigm for the Web. It enables us to do so much information discovery
    that it is difficult to imagine what we cannot do with it.", 
  location     = "http://dx.doi.org/10.1109/MC.2009.69"
}

@Article{ecadfisss,
  author       = "Diane Kelly and Susan Dumais and Jan~O. Pedersen",
  title        = "Evaluation Challenges and Directions for Information-Seeking Support Systems",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "60--66",
  month        = mar,
  keywords     = "dynamic test corpora, longitudinal design, evaluation
    models",
  abstract     = "ISSSs provide an exciting opportunity to extend previous
    information-seeking and interactive information retrieval evaluation models
    and create a research community that embraces diverse methods and broader
    participation.", 
  location     = "http://dx.doi.org/10.1109/MC.2009.82"
}

@Article{i1meai,
  author       = "Denis Baggi and Goffredo Haus",
  title        = "{IEEE} 1599: Music Encoding and Interaction",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "84--87",
  month        = mar,
  keywords     = "music dsl, standards",
  abstract     = "IEEE Std 1599 allows interaction with music content such as
    notes and sounds in video applications and in any interactive device.",
  location     = "http://dx.doi.org/10.1109/MC.2009.85"
}

@Article{cpsww,
  author       = "Wayne Wolf",
  title        = "Cyber-physical Systems",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "88--89",
  month        = mar,
  keywords     = "control theory, efficiency",
  abstract     = "Sophisticated control-computing codesign provides
    unprecedented performance and efficiency levels for cyber-physical
    systems.",  
  location     = "http://dx.doi.org/10.1109/MC.2009.81"
}

@Article{btttia,
  author       = "Itamar Arel and Scott Livingston",
  title        = "Beyond the {T}uring Test",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "90--91",
  month        = mar,
  keywords     = "ai, artificial general intelligence",
  abstract     = "Creating an artificial general intelligence roadmap could
    help researchers realize AI's original goal.", 
  location     = "http://dx.doi.org/10.1109/MC.2009.67"
}

@Article{oiidw,
  author       = "Rajan Samtani",
  title        = "Ongoing Innovation in Digital Watermarking",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "92--94",
  abstract     = "Watermarking-based applications can help content owners
    balance business requirements with consumer choice.", 
  month        = mar,
  keywords     = "content protection, watermarking, drm",
  location     = "http://dx.doi.org/10.1109/MC.2009.93"
}

@Article{isogtsb,
  author       = "Klaus-Dieter Lange",
  title        = "Identifying Shades of Green: The {SPECpower} Benchmarks",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "95--97",
  month        = mar,
  keywords     = "power measurement",
  abstract     = "To drive energy efficiency initiatives, SPEC established
    SPECpower_ssj2008, the first industry-standard benchmark for measuring
    power and performance characteristics of computer systems.", 
  location     = "http://dx.doi.org/10.1109/MC.2009.84"
}

@Article{taoonh,
  author       = "Neville Holmes",
  title        = "The Automation of Originality",
  journal      = ieeec,
  year         = 2009,
  volume       = 42,
  number       = 3,
  pages        = "98--100",
  month        = mar,
  keywords     = "copyright, plagiarism, personality",
  abstract     = "When originality is automated, what becomes of personality?",
  location     = "http://dx.doi.org/10.1109/MC.2009.97"
}

@Article{haesp5r,
  author       = kmoo,
  title        = "Handles and Exception Safety, Part 5: Review",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 4,
  pages        = "49--54",
  month        = apr,
  keywords     = "exception safety, storage management",
  location     = "http://drdobbs.com/cpp/184401640"
}

@Article{cecwt,
  author       = "Thomas Becker",
  title        = "Creating Efficient Code with Templates",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 4,
  pages        = "39--43",
  month        = apr,
  keywords     = "loop unrolling, c++, template programming",
  location     = "http://drdobbs.com/184401634"
}

@Article{cscism,
  author       = "Grum Ketema",
  title        = "Creating {STL} Containers in Shared Memory",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 4,
  pages        = "35--38",
  month        = apr,
  keywords     = "shared storage, data structures, stl containers, allocators",
  location     = "http://drdobbs.com/184401639"
}

@Article{wmmsms,
  author       = "Miro Samek",
  title        = "Who Moved My State?",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 4,
  pages        = "28--34",
  month        = apr,
  keywords     = "event-action paradigm, object-oriented programming,
    finite-state machines",
  location     = "http://drdobbs.com/184401643"
}

@Article{glddwc,
  author       = "John~F. Hubbard",
  title        = "Generating {L}inux Device Drivers with {CodeSketch}",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 4,
  pages        = "6--16",
  month        = apr,
  keywords     = "device drivers, systems programming, code generation",
  location     = "http://drdobbs.com/cpp/184401637?pgno=1"
}

@Article{eecwabs,
  author       = "Simon Case and Nader Azarmi and Marcus Thint and Takeshi Ohtani",
  title        = "Enhancing {E}-Communities with Agent-Based Systems",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 7,
  pages        = "64--69",
  month        = jul,
  keywords     = "agen architectures, distributed mediation, personal
    assistants, reflective adaptation",
  abstract     = "Traditionally, the term community refers to a location where
    people with common interests gather to share experiences, ask questions, or
    collaborate.  Because they are present in the same locale, members can meet
    easily to learn from each other by sharing their explicit knowledge and
    revealing information about their successes and failures.  E-communities
    can use Web technologies to provide geographically disparate groups with
    the same sense of community.  To thrive, these virtual communities require
    software agents that perform many of the functions that print resources and
    membership services provide to traditional communities.  The authors'
    studies have shown that intelligent software agents, in the role of
    personal agents, can effectively provide data sharing, personalized
    services, and pooled knowledge while maintaining user privacy and promoting
    interaction in e-communities.  Future research should include further
    investigation of several topics, including automatic learning of short- and
    long-term user interests, improving information retrieval accuracy, and
    ontology management.  Successful deployment of multi-IDIoMS systems
    requires addressing ontology management--an issue that generally plagues
    the Internet.  However, recognizing and efficiently collating information
    about similar topics within heterogeneous data sources remain difficult
    issues to resolve.  Using XML and other standards can mitigate some
    concerns, but it does not provide a solution to other key issues,
    especially with regard to legacy data.  Nonetheless, the authors believe
    that their agent-based information management system provides a powerful
    application for use in complex, distributed Internet e-communities.",
  location     = "http://dx.doi.org/10.1109/2.933505"
}

@Article{uacgtdaa,
  author       = "John~E. Laird",
  title        = "Using a Computer Game to Develop Advanced {AI}",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 7,
  pages        = "70--75",
  month        = jul,
  keywords     = "",
  abstract     = "In computer games, designers can use artificial intelligence
    to control individual characters, provide strategic direction to character
    groups, dynamically change parameters to make the game appropriately
    challenging, or produce play-by-play commentary.  Computer games offer an
    inexpensive, reliable, and surprisingly accessible environment for
    conducting research in human-level AI design, often--as in the case of
    Quake II--with built-in AI interfaces.  The author's work with the game's
    Quakebot demonstrated that researchers can successfully pursue serious
    study of autonomous AI agents within the context of computer games.  This
    research directly applies to computer-generated forces, which require
    modeling realistic, entity-level behavior.  Studying the impact of changes
    in reaction time, tactics level, and perceptual and motor skills on
    over-all Quake II game performance helped to model these behaviors.  From
    its scoring method, which rewards the highest number of kills, it's obvious
    that Quake II epitomizes violent computer games.  The author does not,
    however, believe that the future of AI in games lies in creating ever more
    realistic arenas for violence.  Thus, he is pursuing further research
    within the context of creating computer games that emphasize the drama that
    arises from social interactions between humans and computer characters.",
  location     = "http://dx.doi.org/10.1109/2.933506"
}

@Article{aaafaari,
  author       = "Henry Lieberman and Elizabeth Rozenweig and Push Singh",
  title        = "Aria: An Agent for Annotating and Retrieving Images",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 7,
  pages        = "57--62",
  month        = jul,
  keywords     = "annotating images, image searching",
  abstract     = "Although modern photography has come a long way, the process
    of making and using photographs still requires more effort than it should.
    Using software agents rather than human labor can help reduce some of this
    tedium.Aria is an interface agent designed to assist users by proactively
    looking for opportunities for image annotation and retrieval.  Although it
    doesn't completely automate image annotation and retrieval, Aria
    dramatically reduces user interface overhead, which can lead to
    better-annotated image libraries and fewer missed opportunities for image
    use.The authors designed Aria's interface agent to facilitate--rather than
    fully automate--the textual annotation and retrieval process.  The agent's
    role lies not so much in automatically performing the annotation and
    retrieval but in detecting opportunities for performing these functions and
    alerting the user to those opportunities.  The agent can also, when
    appropriate, help the user complete the operations.Future work will center
    on taking advantage of more opportunities to use context to determine
    appropriate situations for image annotation, image library browsing, and
    retrieval.  The authors are often asked how their approach will scale to
    large image collections.  Keywords could relate to ontologies and knowledge
    bases to do inheritance or simple inference searches.  Aria's retrieval
    technology treats image sets as an unstructured database, but perhaps a
    better method would be to look at sets of pictures as linked networks.  In
    the long run, the authors seek to capture and use commonsense knowledge
    about typical picture-taking situations.", 
  location     = "http://dx.doi.org/10.1109/2.933504"
}

@Article{tcjmb,
  author       = "Jeffrey~M. Bradshaw and Niranjan Suri and Alberto~J. Ca{\~
    n}as and Robert Davis and Kenneth Ford and Robert Hoffman and Renia Jeffers
    and Thomas Reichherzer",
  title        = "Terraforming Cyberspace",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 7,
  pages        = "48--56",
  month        = jul,
  keywords     = "grid agents, protecting agents, policy-based agent
    management",
  abstract     = "Cyberspace currently offers a lonely, dangerous, and 
    relatively impoverished environment for software agents, which do not
    easily sustain rich, long-term, peer-to- peer relationships.  No social
    safety net helps agents when they get stuck or prevents them from setting
    the network on fire when they go awry.  Agents remain cut off from most of
    the world in which humans operate, and severe practical restrictions limit
    when and where they can go.  The first passerby who finds the power switch
    can unceremoniously terminate an agent's existence.  The authors advocate
    not only making agents smarter and stronger but also making the environment
    in which they operate more capable of sustaining various forms of agent
    life and civilization.  As a new kind of environment for human beings,
    cyberspace is now woefully primitive.  Most of our electronically built
    space is a rat's nest of bewildering pathways of indeterminate destination,
    much like medieval Rome.  Those who are designing and building cyberspace
    might benefit from the example of the humanist Popes of the Renaissance,
    who used the cittá ideale concepts to produce connectivity and impart
    legibility to their city's layout.",
  location     = "http://dx.doi.org/10.1109/2.933503"
}

@Article{suacs,
  author       = "Edmund~H. Durfee",
  title        = "Scaling Up Agent Coordination Strategies",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 7,
  pages        = "39--46",
  month        = jul,
  keywords     = "agent coordination, coordination stress, pursuit problems",
  abstract     = "Exactly what an intelligent agent is and in what sense a 
    computational agent can behave intelligently remain the subjects of
    considerable debate.  However, most researchers and developers would agree
    that coordination is an intelligent agent's central concern.  Without
    coordination, agents can unintentionally waste their efforts, squander
    resources, or fail to accomplish objectives that require collective effort.
    Advances in agent-oriented software engineering make it possible to develop
    complex, distributed systems, but the component agents must be able to act
    and interact flexibly.  Characterizing agent population properties, their
    task environments, and their collective behavior are key to understanding
    the capabilities and limitations of coordination strategies that support
    flexible component agent interaction.  Researchers face the challenge of
    developing a better-- preferably quantifiable--understanding of exactly how
    far different strategies can scale along the dimensions required to apply
    intelligent agent systems to increasingly challenging problems.", 
  location     = "http://dx.doi.org/10.1109/2.933502"
}

@Article{pnaisa,
  author       = "Manoj Parameswaran and Anjana Susarla and Andrew~B. Whinston",
  title        = "{P2P} Networking: An Information-Sharing Alternative",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 7,
  pages        = "31--38",
  month        = jul,
  keywords     = "decentralized networks, content-based addressing, p2p
    multicasting, traffic redistribution, p2p communities",
  abstract     = "The Internet's phenomenal impact and subsequent growth
    stemmed primarily from the open, public, worldwide networking it offers.
    Peer-to-peer computing offers a radically new way of isolating and focusing
    on the networking aspect as the business model's mainstay.  A P2P network
    distributes information among the member nodes instead of concentrating it
    at a single server.  P2P networking thus offers unique advantages that will
    make it a more effective alternative to several existing client-server
    e-commerce applications-if it can mature into a secure and reliable
    technology.  The key to realizing P2P's promise lies in the availability of
    enhanced services such as structured methods for classifying and listing
    shared information, verification and certification of information,
    effective content distribution schemes, and security features.  P2P offers
    a superior alternative to the client-server model for at least a subset of
    that technology's applications, as evidenced by the phenomenal success of
    P2P music-sharing networks versus centralized MP3 servers.  Even so, it is
    unlikely that P2P networks will replace the client-server paradigm.
    Rather, P2P will offer exciting new possibilities in distributed
    information processing.",
  location     = "http://dx.doi.org/10.1109/2.933501"
}

@Article{acuorp,
  author       = "Giorgio Buttazzo",
  title        = "Artificial Consciousness: Utopia or Real Possibility?",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 7,
  pages        = "24--30",
  month        = jul,
  keywords     = "science-fiction robots, turing test, self-awareness",
  abstract     = "Given the current pace of advances in artificial
    intelligence and neural computing, the possibility of building smart
    machines that could compete with human intelligence now seems more likely
    than ever.  Many researchers believe that artificial consciousness is
    possible and that, in the future, it will emerge in complex computing
    machines.  The strongest motivation for constructing a self-aware machine
    is the innate human desire to discover new horizons and enlarge science's
    frontiers.  Further, developing an artificial brain based on biological
    brain principles would open the door to immortality.  Freed from a fragile
    and degradable body, a being with synthetic organs, including an artificial
    brain, could represent humanity's next evolutionary step.  Such a new
    species could quickly colonize the universe, search for alien
    civilizations, survive to the death of the solar system, control the energy
    of black holes, and move at the speed of light by transmitting to other
    planets the information necessary for replication.  As has proven the case
    with all important human discoveries, the real problem will be keeping
    technology under control.  Should self-aware computers become possible, we
    must ensure that we use them for human progress and not for catastrophic
    aims.", 
  location     = "http://dx.doi.org/10.1109/2.933500"
}

@Article{radtbbfca,
  author       = "Hyun-Gul Roh and Myeongjae Jeon and Jin-Soo Kim and Joonwon Lee",
  title        = "Replicated Abstract Data Types:  Building Blocks for Collaborative Applications",
  journal      = "Journal of Parallel and Distributed Computing",
  year         = 2001,
  volume       = 71,
  number       = 3,
  pages        = "354--368",
  month        = mar,
  keywords     = "distributed data structures, optimistic replication,
    replicated abstract types, optimistic algorithm, collaboration",
  abstract     = "For distributed applications requiring collaboration, 
    responsive and transparent interactivity is highly desired.  Though such
    interactivity can be achieved with optimistic replication, maintaining
    replica consistency is difficult.  To support efficient implementations of
    collaborative applications, this paper extends a few representative
    abstract data types (ADTs), such as arrays, hash tables, and growable
    arrays (or linked lists), into replicated abstract data types (RADTs).  In
    RADTs, a shared ADT is replicated and modified with optimistic operations.
    Operation commutativity and precedence transitivity are two principles
    enabling RADTs to maintain consistency despite different execution orders.
    Especially, replicated growable arrays (RGAs) support
    insertion/deletion/update operations.  Over previous approaches to the
    optimistic insertion and deletion, RGAs show significant improvement in
    performance, scalability, and reliability.",
  location     = "http://dx.doi.org/10.1016/j.jpdc.2010.12.006"
}

@Article{dfsapfseba,
  author       = "Bhavani Thuraisingham",
  title        = "Directions for Security and Privacy for Semantic {E}-Business Applications",
  journal      = cacm,
  year         = 2005,
  volume       = 48,
  number       = 12,
  pages        = "71--73",
  month        = dec,
  keywords     = "xml rdf, knowledge management, e-business, privacy, 520",
  abstract     = "Developing secure semantic e-business applications requires
    focusing first on securing the Semantic Web, knowledge management, and
    e-business processes.",
  location     = "http://dx.doi.org/10.1145/1101779.1101812"
}
 
@Article{ettswpcas,
  author       = "Espen Andersen",
  title        = "Edging Toward the Semantic Web:  Protocols Curation, and Seeds",
  journal      = "Ubiquity",
  year         = 2010,
  month        = nov,
  keywords     = "technology development, 520",
  abstract     = "The evolution from an interactive Internet (often called Web
    2.0) toward a more intelligent, semantic web will not happen as a result of
    dramatic new inventions or jointly agreed standards, but through a gradual
    evolution and recombination of existing technologies.  To get to a Web 3.0,
    we will need to first create (and maybe be satisfied with) a Web 2.5, and
    that will happen through the gradual evolution of effective, user-based
    interaction protocols (based on user dialogues) and the use of queries as
    information passing mechanisms.", 
  location     = "http://dx.doi.org/10.1145/1880066.1891342"
}

@Article{jsa,
  author       = "Amit Chaturvedi",
  title        = "Java \& Static Analysis",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "25--30",
  month        = jul,
  keywords     = "java, static analysis, bytecode analysis, software testing",
  location     = "http://drdobbs.com/java/184406143"
}

@Article{jaaa,
  author       = "J. Benton",
  title        = "Java Annotations and {apt}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "31--37",
  month        = jul,
  keywords     = "annotations, meta annotations, boilerplate code.",
  location     = "http://drdobbs.com/java/184406144"
}

@Article{sjaws,
  author       = "Raphael Mudge",
  title        = "Scripting {J}ava Applications with Sleep",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "38--40",
  month        = jul,
  keywords     = "scriptable code, script management",
  location     = "http://drdobbs.com/java/184406145"
}

@Article{jbpt,
  author       = "Paul Tremblett",
  title        = "Java \& {B}luetooth",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "41--44",
  month        = jul,
  keywords     = "device drivers, link control, serial port, object exchange
    protocol", 
  location     = "http://drdobbs.com/java/184406146"
}

@Article{hpdmij,
  author       = "Charles Lamb",
  title        = "High-Performance Data Management in {J}ava",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "45--49",
  month        = jul,
  keywords     = "data management, concurrent trees, cache management,
    performance", 
  location     = "http://drdobbs.com/java/184406147"
}

@Article{jrjcd,
  author       = "Juan~C. Due{\~ n}as and Manuel Santillan and Jose Luis Ruiz",
  title        = "{JMX} Redux",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "50--57",
  month        = jul,
  keywords     = "monitoring, managment, mbeans, web services, ",
  location     = "http://drdobbs.com/java/229100213"
}

@Article{cssjf,
  author       = "Tor Norbye",
  title        = "{Cascading Style Sheets} \& {JavaServer} Faces",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "58--61",
  month        = jul,
  keywords     = "class selectors, style sheets, style properties",
  location     = "http://drdobbs.com/java/184406148"
}

@Article{eesjt,
  author       = "Ryan Barr",
  title        = "Examining {Enerjy}'s {J}ava Toolkit",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "62--65",
  month        = jul,
  keywords     = "code analyzer, performance profiler, memory profiler, thread
    profiler", 
  location     = "http://drdobbs.com/java/184406149"
}

@Article{idvrld,
  author       = "Linden Decarmo",
  title        = "Inside Digital Video Recorders",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "66--68",
  month        = jul,
  keywords     = "dvrs, device control",
  location     = "http://drdobbs.com/open-source/184406150"
}

@Article{fbcwofdpi,
  author       = "Andrew Schulman",
  title        = "Finding Binary Clones with Opstrings \& Function Digests: Part {I}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "69--73",
  month        = jul,
  keywords     = "file fingerprints, function fingerprints",
  location     = "http://drdobbs.com/184406152"
}

@Article{ssdm,
  author       = "Don Morgan",
  title        = "Surround Sound",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 7,
  pages        = "78--82",
  month        = jul,
  keywords     = "quad sound, sound processing, hilbert transform, dolby b, ",
  location     = "http://drdobbs.com/java/184406155"
}

@Article{wpcfaa,
  author       = "Xiaoguang Qi and Brian~D. Davidson",
  title        = "Web Page Classification: Features and Algorithms",
  journal      = surveys,
  year         = 2009,
  volume       = 41,
  number       = 2,
  pages        = "12:1--12:31",
  month        = feb,
  keywords     = "categorization, web mining, algorithms, performance, design",
  abstract     = "Classification of Web page content is essential to many tasks
    in Web information retrieval such as maintaining Web directories and
    focused crawling.  The uncontrolled nature of Web content presents
    additional challenges to Web page classification as compared to traditional
    text classification, but the interconnected nature of hypertext also
    provides features that can assist the process.  As we review work in Web
    page classification, we note the importance of these Web-specific features
    and algorithms, describe state-of-the-art practices, and track the
    underlying assumptions behind the use of information from neighboring
    pages.",
  location     = "http://dx.doi.org/10.1145/1459352.1459357",  
  location     = "http://www.cse.lehigh.edu/~xiq204/pubs/classification-survey/LU-CSE-07-010.pdf"
}

@Article{fpmitiocac,
  author       = "Randy Meyers and Thomas Plum",
  title        = "Floating-Point Math:  In the Intersection of {C} and " # cpp,
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 5,
  pages        = "39--42",
  month        = may,
  keywords     = "math routines, c99",
  location     = "http://drdobbs.com/184401653"
}

@Article{aifdcs,
  author       = "Daniel Lawrence",
  title        = "An Idea for Dynamic {C} Strings",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 5,
  pages        = "35--37",
  month        = may,
  keywords     = "strings, libraries",
  location     = "http://drdobbs.com/architecture-and-design/184401650"
}

@Article{assat,
  author       = "Edward Elliott",
  title        = "{A} Secure Storage Allocator Template",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 5,
  pages        = "25--33",
  month        = may,
  keywords     = "stl, storage allocators, security, scrub policy, allocation
    policy",
  location     = "http://drdobbs.com/184401646"
}

@Article{tgietsli,
  author       = "Eric~D. Crahen",
  title        = "The Guard Idiom: Enhancing the Scoped Locking Idiom",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 5,
  pages        = "20--24",
  month        = may,
  keywords     = "polling",
  location     = "http://drdobbs.com/184401644"
}

@Article{etcjl,
  author       = "John LaPlante",
  title        = "Efficient Thread Coordination",
  journal      = ccppuj,
  year         = 2003,
  volume       = 21,
  number       = 5,
  pages        = "6--18",
  month        = may,
  keywords     = "polling, blocking, thread control, latency, concurrency",
  location     = "http://drdobbs.com/184401649"
}

@Article{rwtwod,
  author       = "Ralph~R. Swick",
  title        = "{RDF}: Weaving the Web of Discovery",
  journal      = "netWorker",
  year         = 1999,
  volume       = 3,
  number       = 2,
  pages        = "21--25",
  month        = jun,
  keywords     = "rdf, owl, semantic web",
  abstract     = {As the volume of material on the World Wide Web continues to
    mushroom, existing methods of indexing are no longer adequate.  The
    Resource Description Framework, or RDF, functions as a search engine
    "turbocharger" that enables a new level of automated processing and linking
    of materail on Web sites},
  location     = "http://dx.doi.org/10.1145/302497.302505"
}

@Article{oatsw,
  author       = "Ian Horrocks",
  title        = "Ontologies and the {S}emantic {W}eb",
  journal      = cacm,
  year         = 2008,
  volume       = 51,
  number       = 12,
  pages        = "58--67",
  month        = dec,
  keywords     = "rdf, owl, ontologies, semantic web",
  abstract     = "How ontologies provide the semantics, as explained here with
    the help of Harry Potter and his owl Hedwig.", 
  location     = "http://dx.doi.org/10.1145/1409360.1409377"
}

@Article{ovmas,
  author       = "Akrivi Katifori and Constantin Halatsis and George Lepouras
    and Costas Vassilakis and Eugenia Giannopoulou",
  title        = "Ontology Visualization Methods--A Survey",
  journal      = surveys,
  year         = 207,
  volume       = 39,
  number       = 4,
  pages        = "10:1--10:43",
  month        = oct,
  keywords     = "information search and retrieval, information interfaces and
    presentation, user interfaces, graphical user interfaces, computer
    graphics, interaction techniques, design, ongology, visualizations",
  abstract     = "Ontologies, as sets of concepts and their interrelations in 
    a specific domain, have proven to be a useful tool in the areas of digital
    libraries, the semantic web, and personalized information management.  As a
    result, there is a growing need for effective ontology visualization for
    design, management and browsing.  There exist several ontology
    visualization methods and also a number of techniques used in other
    contexts that could be adapted for ontology representation.  The purpose of
    this article is to present these techniques and categorize their
    characteristics and features in order to assist method selection and
    promote future research in the area of ontology visualization.",
  location     = "http://disi.unitn.it/~p2p/RelatedWork/Matching/a10-katifori.pdf",
  location     = "http://dx.doi.org/10.1145/1287620.1287621"
}

@Article{lsfuc,
  author       = "Jeffrey Hightower and Gaetano Borriello",
  title        = "Location Systems for Ubiquitous Computing",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 8,
  pages        = "57--66",
  month        = aug,
  keywords     = "location-sensing techniques, active badges, sensor fusion, ad
    hoc location sensing",
  abstract     = "This survey and taxonomy of location systems for
    mobile-computing applications describes a sepectrum of current products and
    explores the latest research in the field",
  location     = "http://dx.doi.org/10.1109/2.940014"
}

@Article{iascs,
  author       = "Mike Addlesee and Rupert Curwen and Steve Hodges and Joe
    Newman and Pete Steggles and Andy Ward and Andy Hopper",
  title        = "Implementing a Sentient Computing System",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 8,
  pages        = "50--56",
  month        = aug,
  keywords     = "location sensing, current enbodiment, spatial monitoring",
  abstract     = "Sentient computing systems, which can change their behavior
    based on a model of the environment they construct using sensor data, may
    hold the key to managing tomorrow's device-rich mobile networks.  As
    computer users become increasingly mobile and the diversity of devices with
    which they interact increases, the authors note that the overhead of
    configuring and personalizing these systems must also increase.  A natural
    solution to this problem involves creating devices and applications that
    appear to cooperate with users, reacting as though they are aware of the
    context and manner in which they are being used, and recon-figuring
    themselves appropriately.  At AT &T Laboratories Cambridge, the authors
    built a system that uses sensors to update a model of the real world.  The
    model describes the world much as users themselves would, and they can use
    it to write programs that react to changes in the environment according to
    their preferences.  The authors call their approach sentient computing
    because the applications appear to share the user's perception of the
    environment.  Sentient computing systems create applications that appear to
    perceive the world, making it easy to configure and personalize networked
    devices in ways that users can easily understand.  But sentient computing
    offers more than a solution to the problems of con-figuration and
    personalization.  When people interact with computer systems in this way,
    the environment itself becomes the user interface--a natural goal for
    human-computer interaction.",
  location     = "http://dx.doi.org/10.1109/2.940013"
}

@Article{whplttw,
  author       = "Salil Pradhan and Cyril Brignone and Jun-Hong Cui and Alan
    McReynolds and Mark~T. Smith",
  title        = "Websigns: Hyperlinking Physical Locations to the {W}eb",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 8,
  pages        = "42--48",
  month        = aug,
  keywords     = "markup languages",
  abstract     = "First-generation mobile computing technologies typically use
    protocols such as WAP and i-mode to let PDAs, smart phones, and other
    wireless devices with Web browsers access the Internet, thereby freeing
    users from the shackles of their desktops.  Users could, the authors
    assert, benefit from having access to devices that combine the advantages
    of wireless technology and ubiquitous computing to provide a transparent
    linkage between the physi-cal world around them and the resources available
    on the Web.  In the CoolTown research program at Hewlett-Packard
    Laboratories, the authors are building ubiquitous computing systems that
    sense physical entities in the environment and map them to a Web browser.
    The websign system provides an alternative way to map e-services using a
    simple form of augmented reality.  Typical augmented reality systems
    require users to wear a cumbersome see-through head-mounted display to view
    computer-generated images imposed on the physical environment.  In
    contrast, the websign system uses commonly available Internet-enabled
    wireless devices such as PDAs or smart phones equipped with client
    software, a positioning system such as GPS, and a digital compass to
    visualize services for physical entities.  From a deployment perspective,
    the system is more scalable for outdoor applications than using physical
    short-range beacons.  The lack of commonly available and deployed indoor
    positioning technologies has hindered indoor deployment, but the authors
    are currently evaluating a promising technology from the Massachusetts
    Institute of Technology for use as the underlying indoor positioning
    system.  They are also conducting further user studies that explore how to
    better augment reality with virtual beacons and tags.",
  location     = ""
}

@Article{uadliacstg,
  author       = "Nigel Davies and Keith Cheverst and Keith Mitchell and Alon Efrat",
  title        = "Using and Determining Location in a Context-Sensitive Tour Guide",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 8,
  pages        = "35--41",
  month        = aug,
  keywords     = "information modeling, location-based function",
  abstract     = "The Lancaster Guide project, initiated in 1997, explores the
    issues that arise from developing and deploying context-sensitive
    applications--specifically, a tour guide for the city of Lancaster, UK.
    Motivated by the work on Georgia Tech's CyberGuide, the authors envisioned
    a system that could provide tailor-made tours for visitors by adapting its
    behavior to changes in a user's location.  In contrast to the CyberGuide
    project, the Lancaster Guide adopted a network-centric approach.  In Guide,
    the systems obtain information through a high-speed wireless network
    deployed throughout the target city.  After implementing the Guide system
    in 1999, the authors ran a series of field trials involving members of the
    general public to explore their reactions to using these methods of
    locating and identifying objects.  Two Guide features generated particular
    interest among researchers and engineers developing similar systems: the
    choice of positioning technology--beacons that broadcast using an IEEE
    802.11 wireless network combined with user input--and the techniques used
    for generating custom tours for electronic city-guide systems.  To work
    effectively, Guide relies not only on technology but also on assistance
    from users.  This partnership offers in-creased accuracy while fostering a
    relationship between end users and the Guide system.  The authors seek to
    create a more engaging and compelling experience than might otherwise be
    possible if they relied on technology alone.  They believe their techniques
    are applicable to a wide range of location-based applications, especially
    those that use cellular location systems.  Work continues on porting the
    Guide system to the Compaq IPAQ PDA, which would allow exploration of
    system development and usability issues for a new class of devices.", 
  location     = "http://dx.doi.org/10.1109/2.940011"
}

@Article{pamecwadb,
  author       = "Timothy~A. Budd",
  title        = "Protecting and Managing Electronic Content with a Digital Battery",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 8,
  pages        = "24--30",
  month        = aug,
  keywords     = "drm, digital content, content distribution",
  abstract     = "The traditional system of rights, royalties, and limits on 
    reproduction of intellectual property has worked for books, records, motion
    pictures, and other physical media largely because of the difficulty and
    expense that reproducing them entailed.  Currently, Napster, Gnutella, and
    other peer-to-peer sharing services have stretched if not broken this
    model, posing such a dire financial threat to content providers that the
    Recording Industry Association of America and five recording companies
    recently brought suit against Napster.  If a consumer can duplicate a
    digital artifact and share it with a friend, the producer loses any profit
    from the duplicated artifact and any way to measure the duplicated item's
    relative popularity.  Without a revenue stream or a means for measuring
    popularity, a producer cannot offer artists appropriate remuneration.
    Without payment, artists have little incentive for creating new work.
    Fortunately, technology--which helped create this problem--can also provide
    its solution.  A digital library can protect intellectual properties by
    making unauthorized duplication impossible or at least extremely difficult,
    tracking each use of a given work while ensuring the user's anonymity, and
    allowing itself to be implemented inexpensively while remaining transparent
    to the consumer.  The digital battery's best chance for success stems from
    its theoretical ease of use, ubiquity, and low cost.  As Napster has shown,
    consumers have few qualms about using pirated artifacts.  Nor does guilt
    over the economic plight of artists appear to create a compelling obstacle
    to unauthorized copying.  If, however, systems that incorporate digital
    batteries can provide consumers with access to items they desire, and do so
    in a way that's not overly intrusive, there may yet be hope for rescuing
    industries that depend on digital content.", 
  location     = "http://dx.doi.org/10.1109/2.940009"
}

@Article{ardud,
  author       = "Ralf Holly",
  title        = "{A} Reusable {{D}}uff Device",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 8,
  pages        = "73--74",
  month        = aug,
  keywords     = "duff's device, c programming",
  location     = "http://drdobbs.com/184406208"
}

@Article{aschollhm,
  author       = "William Nagel",
  title        = "An {STL}-Compatible Hybrid of Liked List \& Hash Map",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 8,
  pages        = "69--72",
  month        = aug,
  keywords     = "stl, performance",
  location     = "http://drdobbs.com/cpp/184406207"
}

@Article{ntniotfl,
  author       = "L.~Blunt Jackson",
  title        = "{NPTL}:  The New Implementation of Threads for {L}inux",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 8,
  pages        = "62--66",
  month        = aug,
  keywords     = "threads",
  location     = "http://drdobbs.com/cpp/184406207"
}

@Article{fbcwofdpii,
  author       = "Andrew Schulman",
  title        = "Finding Binary Clones with Opstrings \& Function Digests: Part {II}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 8,
  pages        = "56--61",
  month        = aug,
  keywords     = "binary code, duplicate detection",
  location     = "http://drdobbs.com/184406203"
}

@Article{ttdpaf,
  author       = "Alexander Frey",
  title        = "The {TMS} Development Platform",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 8,
  pages        = "34--39",
  month        = aug,
  keywords     = "software development, platform development",
  location     = "http://drdobbs.com/architecture-and-design/184406199"
}

@Article{temf,
  author       = "Frank Budinsky",
  title        = "The {E}clipse Modeling Framework",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 8,
  pages        = "28--32",
  month        = aug,
  keywords     = "model definitions, model frameworks, emf, code generation,
    object persistence",
  location     = "http://www.ddj.com/open-source/184406198"
}

@Article{sisd,
  author       = "Steve Dewhurst",
  title        = "Split Idioms",
  journal      = ccppuj,
  year         = 2001,
  volume       = 12,
  number       = 6,
  pages        = "49--55",
  month        = jun,
  keywords     = "virtual functions",
  location     = "http://drdobbs.com/article/print?articleId=184401397",
  location     = "http://semantics.org/publications/01_06_splitIdioms.pdf"
}

@Article{moitb,
  author       = "Thomas Becker",
  title        = "More on Iterators",
  journal      = ccppuj,
  year         = 2001,
  volume       = 12,
  number       = 6,
  pages        = "38--48",
  month        = jun,
  keywords     = "iterators, stl, categories, traits"
}

@Article{cl,
  author       = "Randy Meyers",
  title        = "Compound Literals",
  journal      = ccppuj,
  year         = 2001,
  volume       = 12,
  number       = 6,
  pages        = "33--37",
  month        = jun,
  keywords     = "constants, literals, compound literals",
  location     = "http://drdobbs.com/184401404"
}

@Article{irmpuc,
  author       = "Qiang Liu",
  title        = "Implementing Reusable Mathematical Procedures using " # cpp,
  journal      = ccppuj,
  year         = 2001,
  volume       = 12,
  number       = 6,
  pages        = "22--29",
  month        = jun,
  keywords     = "function pointers, member function pointers, function
    object",
  location     = "http://drdobbs.com/184401402"
}

@Article{tgfeiu,
  author       = "Scot Meyers",
  title        = "Three Guidlines for Effective Iterator Usage",
  journal      = ccppuj,
  year         = 2001,
  volume       = 12,
  number       = 6,
  pages        = "10--19",
  month        = jun,
  keywords     = "stl, iterators, best practices",
  location     = "http://drdobbs.com/184401406"
}

@Article{smkd,
  author       = "Jan Pieper and Savitha Srinivasan and Byron Dom",
  title        = "Streaming-Media Knowledge Discovery",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 9,
  pages        = "68--74",
  month        = sep,
  keywords     = "page detection, indexing, metadata crawling, interfaces",
  abstract     = "The Multimedia Knowledge Discovery group at IBM Almaden 
    Research Center explores technologies that help locate streaming media on
    the Web, build effective indexing and classification tools for streaming
    media, and develop compelling streaming-media applications.  The authors'
    ongoing work, motivated by the Web's role as an ever-increasing information
    source and knowledge repository, focuses on locating, analyzing, and
    indexing Web-based streaming media.Frequently, knowledge management
    applications and information portals synthesize unstructured text
    information from the Web, intranets, and partner sites.  Given this
    context, the authors routinely crawl a statistically significant number of
    Web pages, detect those that contain streaming-media links, crawl the media
    links to extract associated metadata, then use the crawl data to build a
    resource list for Web media.  They have used these crawl data findings to
    build a media indexing application that uses content-based indexing
    methods.Searching multiple live-broadcast channels with the indexing
    application lets users locate relevant multimedia resources on the Web.
    Providing on-demand access to these media reduces the time spent consuming
    nonrelevant information from a streaming-media channel.Work on indexing
    video archives inspires several directions for future research.  For
    example, existing genre-classification and topic-detection methods require
    processing and analyzing large parts of a document, which presents a
    greater challenge when performed on live streams.  Scalability plays an
    important role in deploying such systems, given the amount of computation
    required for simultaneous processing of multiple live streams.
    Fortunately, rapid progress in hardware and networking will enable
    deployment of such systems soon.", 
  location     = "http://dx.doi.org/10.1109/2.947094"
}

@Article{kbuifdv,
  author       = "Andreas Girgensohn and John Boreczky and Lynn Wilcox",
  title        = "Keyframe-Based User Interfaces for Digital Video",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 9,
  pages        = "61--65",
  month        = sep,
  keywords     = "directory listings, video summaries, clip browsing",
  abstract     = "To meet the diverse needs of business, education, and 
    personal video users, the authors developed three visual interfaces that
    help identify potentially useful or relevant video segments.  In such
    interfaces, keyframes¿still images automatically extracted from video
    footage¿can distinguish videos, summarize them, and provide access points.
    Well-chosen keyframes enhance a listing's visual appeal and help users
    select videos.Keyframe selection can vary depending on the application's
    requirements: A visual summary of a video-captured meeting may require only
    a few highlight keyframes, a video editing system might need a keyframe for
    every clip, while a browsing interface requires an even distribution of
    keyframes over the video's full length.The authors conducted user studies
    for each of their three interfaces, gathering input for subsequent
    interface improvements.  The studies revealed that finding a similarity
    measure for collecting video clips into groups that more closely match
    human perception poses a challenge.  Another challenge is to further
    improve the video-segmentation algorithm used for selecting keyframes.  A
    new version will provide users with more information and control without
    sacrificing the interface's ease of use.", 
  location     = "http://dx.doi.org/10.1109/2.947093"
}

@Article{sti3mcs,
  author       = "Ingo Elsen and Frank Hartung and Uwe Horn and Markus Kampmann
    and Liliane Peters",
  title        = "Streaming Technology in {3G} Mobile Communication Systems",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 9,
  pages        = "46--52",
  month        = sep,
  keywords     = "mobile communications, mobile streaming, content protection,
    interactive media",
  abstract     = "Currently, three incompatible proprietary solutions-offered 
    by RealNetworks, Microsoft, and Apple-dominate the Internet streaming
    software market.  In the near future, third-generation mobile communication
    systems will extend the scope of today's Internet streaming solutions by
    introducing standardized streaming services that target the mobile user's
    specific needs.  3G systems will provide high-quality streamed Internet
    content to the rapidly growing mobile market.  These systems will offer
    value-added applications as well, supported by an underlying network that
    combines streaming services with a range of unique mobile-specific
    services.  Mobile-application scenarios present many challenges, such as
    how to provide spectrum-efficient streaming services over varied
    radio-access networks to different types of end-user terminals.  The
    authors assert that their standards-based Interactive Media
    platform, recently tested in several field trials, addresses these
    challenges by using an architecture that fits seamlessly into 3G
    mobile-communication systems.  An integral part of this architecture is a
    streaming proxy, which acts on both the service and transport levels.",
  location     = "http://dx.doi.org/10.1109/2.947089"
}

@Article{asarpfmod,
  author       = "Gavin B. Horn and Per Knudsgaard and Soren B. Lassen and
    Michael Luby and Jens Eilstrup Rasmussen",
  title        = "{A} Scalable and Reliable Paradigm for Media on Demand",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 9,
  pages        = "40--45",
  month        = sep,
  keywords     = "media on demand, multicast transmission, pyramid
    broadcasting, harmonic broadcasting, scalability, reliability, unicast",
  abstract     = "The challenges for streaming media today include the high
    data rates and significant bandwidth required for the uninterrupted
    delivery of high-quality music and video.  Building a scalable and reliable
    system for on-demand and live streaming in this environment has proven
    difficult.By definition, a media-on-demand system lets clients freely
    access and play back media without interruption after a given start-up
    latency.  The authors' system keeps the server's outgoing bandwidth
    independent of the number of clients, and each client behaves independently
    of other clients.Although most codecs tolerate a certain amount of data
    loss, a high loss rate can significantly affect playback quality.  Even
    with router assistance to aggregate acknowledgments, for a sufficiently
    heterogeneous network and a large enough audience, at least one client will
    lose almost every packet.  This requires retransmission, which causes
    delays and results in massive reception of duplicate packets.The authors'
    MoD system uses forward error correction codes to recover lost data.  FEC
    uses the same redundant data to allow multiple clients to recover from
    different packet losses.",
  location     = "http://dx.doi.org/10.1109/2.947088"
}

@Article{sccjm,
  author       = "John Morris and Gareth Lee and Kris Parker and Gary
    A. Bundell and Chiou Peng Lam",
  title        = "Software Component Certification",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 9,
  pages        = "30--39",
  month        = sep,
  keywords     = "self-certification, test specification",
  abstract     = "Most current process-based methods for certifying software 
    require software publishers totake oaths concerning which development
    standards and processes they will use. Jeffrey Voas, among others, has
    suggested that independent agencies, software certification laboratories
    (SCLs), should take on a product certification role.  The authors accept
    that this approach may work well for certain software distribution models,
    but they also observe that it cannot be applied to all software
    development.Third-party SCLs would add unnecessarily to the costs that
    small developers incur by speculating on the success of a given component.
    However, supplying complete test sets with components incurs little
    additional cost because component authors must generate the tests in the
    first place.  Any extra effort adds value to a component because a tested
    component certainly offers a more marketable commodity.The authors believe
    that while SCLs have a place in large or safety-critical software projects,
    there will always be small commercial-software developments for which
    failure represents a moderate cost.  In such cases, the cost of generating
    and inspecting tests can be justified.", 
  location     = "http://dx.doi.org/10.1109/2.947086"
}

@Article{scae,
  author       = "V{\' a}clav Rajlich and Norman Wilde and Michelle Buckellew and
    Henry Page", 
  title        = "Software Cultures and Evolution",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 9,
  pages        = "24--28",
  month        = sep,
  keywords     = "software cultures, system partitioning, modularity",
  location     = "http://dx.doi.org/10.1109/2.947084",
  abstract     = "Working effectively with legacy code requires understanding
     a legacy computer program's culture: the combination of programmer
     background, hardware environment, and programming techniques that guided
     its creation.  Software systems typically pass through a series of stages.
     During the development stage, software developers create a functioning
     version of the code.  An evolution stage follows, during which
     developmental efforts focus on extending system capabilities to meet user
     needs.  The servicing stage restricts development to minor repairs and
     simple functional changes.  The phase-out stage essentially freezes the
     system, but it still produces value.  Finally, in the close down stage,
     developers withdraw the system and possibly replace it.Effective
     comprehension requires viewing a legacy program as an artifact of the
     circumstances in which it was developed.  This information can be
     important in determining appropriate strategies for the program's
     transition from the evolution stage to the servicing or phase-out stage." 
}

@Article{tvoccp,
  author       = "Fong Pong and Michel Dubois",
  title        = "The Verification of Cache Coherence Protocols",
  journal      = surveys,
  year         = 1997,
  volume       = 29,
  number       = 1,
  pages        = "82--126",
  month        = mar,
  keywords     = "memory structures, performance analysis, formal models",
  abstract     = "In this article we present a comprehensive survey of various
    approaches for the verification of cache coherence protocols based on state
    enumeration, (symbolic model checking, and symbolic state models.  Since
    these techniques search the state space of the protocol exhaustively, the
    amount of memory required to manipulate that state information and the
    verification time grow very fast with the number of processors and the
    complexity of the protocol mechanisms.  To be successful for systems of
    arbitrary complexity, a verification technique must solve this so-called
    state space explosion problem.  The emphasis of our discussion is on the
    underlying theory in each method of handling the state space explosion
    problem, and formulationg and checking the safety properties (e.g., data
    consistency) and the liveness properties (absence of deadlock and
    livelock).  We compare the efficiency and discuss the limitations of each
    technique in terms of memory and computation time.  Also, we discuss issues
    of generality, applicability, automaticity, and amenity for existing tools
    in each class of methods.  No method is truly superior because each method
    has its own strengths and weaknesses.  Finally, refinements that can
    further reduce the verification time and/or the memory requirement are also
    discussed.",
  location     = ""
}

@Article{sodes,
  author       = "Robert Oshana",
  title        = "Software Optimization \& {DSP} Embedded Systems",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "71--74",
  month        = sep,
  keywords     = "machine-independent optimizations, performance optimizations,
    latency techniques, resource allocation, memory optimizations, power
    optimizations",
  location     = "http://drdobbs.com/184406248"
}

@Article{fbcwofdpiii,
  author       = "Andrew Schulman",
  title        = "Finding Binary Clones With Opstrings \& Function Digests: Part {III}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "64--70",
  month        = sep,
  keywords     = "stop lists, clones, errors",
  location     = "http://drdobbs.com/architecture-and-design/184406247"
}

@Article{twa,
  author       = "Sean Dawson and Dristen Kerr",
  title        = "Testing Web Applications",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "60--63",
  month        = sep,
  keywords     = "testing, jwebunit",
  location     = "http://drdobbs.com/tools/184406246"
}

@Article{cetlk,
  author       = "Halld{\' o}r {\' I}sak Gylfason and G{\' \i}sli Hj{\' a}lmtysson",
  title        = "{C}++ exceptions \& the {L}inux Kernel",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "50--53",
  month        = sep,
  keywords     = "exception handling, runtime support, system calls, try blocks",
  location     = "http://drdobbs.com/cpp/229100146"
}

@Article{tefi,
  author       = "Craig Szydlowski",
  title        = "The Extensible Firmware Interface",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "46--48",
  month        = sep,
  keywords     = "boot sequences",
  location     = "http://www.ddj.com/184406244"
}

@Article{ipwcpafs,
  author       = "Anthony Aue",
  title        = "Improving Performance With Custom Pool Allocators for {STL}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "40--45",
  month        = sep,
  keywords     = "policies",
  location     = "http://drdobbs.com/cpp/184406243"
}

@Article{hpiowjn,
  author       = "Brian Pontarelli",
  title        = "High-Performance {I}/{O} With {J}ava {NIO}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "32--39",
  month        = sep,
  keywords     = "standard i-o, nio, performance",
  location     = "http://drdobbs.com/java/184406242"
}

@Article{iminv,
  author       = "Narendra Venkataraman",
  title        = "Inside Mobile {IP}",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "24--30",
  month        = sep,
  keywords     = "mobility, foreign agent, nat, wireless",
  location     = "http://drdobbs.com/mobility/184406240"
}

@Article{mj3a,
  author       = "Oscar Vivall and Tom Thompson",
  title        = "Mobile {J}ava \& {3D} Apps",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 9,
  pages        = "14--23",
  month        = sep,
  keywords     = "jsr 184",
  location     = ""
}

@Article{wcsiu,
  author       = kmoo,
  title        = "Which Container Should {I} Use?",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 8,
  pages        = "58--62",
  month        = aug,
  keywords     = "stl, vectors, deques, linked lists, performance, iterator
    invalidation",  
  location     = ""
}

@Article{wyoi,
  author       = "Thomas Becker",
  title        = "Writing Your Own Iterators",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 8,
  pages        = "51--54",
  month        = aug,
  keywords     = "custom iterators, stl, iterators to members",
  location     = "http://drdobbs.com/184401417"
}

@Article{oaatp,
  author       = "Steve Dewhurst",
  title        = "One at a Time, Please",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 8,
  pages        = "46--50",
  month        = aug,
  keywords     = "preprocessors, inline functions, ",
  location     = "http://drdobbs.com/184401419"
}

@Article{gtcbtap,
  author       = "Cristian Vlasceanu",
  title        = "Generalizing the Concepts Behind {\tt auto\_ptr}",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 8,
  pages        = "36--45",
  month        = aug,
  keywords     = "storage management, linear logic, copy constructors, ",
  location     = "http://drdobbs.com/184401427"
}

@Article{ttamrv,
  author       = "Jaakko J{\" a}rvi",
  title        = "Tuple Types and Multiple Return Values",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 8,
  pages        = "24--35",
  month        = aug,
  keywords     = "tuples, template programming",
  location     = "http://www.ddj.com/showArticle.jhtml?articleID=184401421&queryText=%B5v"
}

@Article{acmcfwa,
  author       = "Babu George Padamadan",
  title        = "{A} Cookie Manager Class for Web Applications",
  journal      = ccppuj,
  year         = 2001,
  volume       = 19,
  number       = 8,
  pages        = "10--22",
  month        = aug,
  keywords     = "cookies, html, ",
  location     = "http://www.drdobbs.com/cpp/184401425"
}

@Article{bswwhaw,
  author       = "Sergei Gerasenko and Abhijit Joshi and Srinivas Rayaprolu and
    Kovendhan Ponnavaikko and Dharma P. Agrawal",
  title        = "Beacon Signals:  What, Why, How, and Where?",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "108--110",
  month        = oct,
  keywords     = "global positioning system, wireless lans, cellular networks,
    mobile robotics, location tracking, auditory location finder",
  location     = "http://dx.doi.org/10.1109/2.955103"
}

@Article{alaoes,
  author       = "Mike Bond and Ross Anderson",
  title        = "{API}-Level Attacks on Embedded Systems",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "67--75",
  month        = oct,
  keywords     = "cryptoprocessors, cryptographic attacks, key sharing",
  abstract     = "A growing number of embedded systems use security processors
    to distribute control, billing, and metering among devices with
    intermittent or restricted online connectivity.  The more obvious examples
    include smart cards, microcontrollers used as value counters in postal
    meters and vending machines, and cryptographic processors used in networks
    of automatic teller machines and point-of-sale equipment to encipher
    customers' personal identification numbers.Recently, a whole new family of
    attacks has been discovered on the application programming interfaces these
    security processors use.  These API attacks extend and generalize the known
    types of attack that target authentication protocols.  Such attacks present
    valid commands to the security processor but in an unexpected sequence,
    thereby obtaining results that break the security policy its designer
    envisioned.Designing security APIs is a new research field with significant
    industrial and scientific importance.  The poor design of present
    interfaces prevents many tamper-resistant processors from achieving their
    potential and leaves a disappointing dependency on procedural controls¿the
    design of which involves subtleties likely to exceed the grasp of most
    implementers.It is unclear that a generalized API will work.  The natural
    accretion of functionality presents security with one of its greatest
    enemies.  Yet, getting the API right is relevant for more than just
    cryptoprocessors.  The API is where cryptography, protocols,
    operating-system access controls, and operating procedures all come
    together¿or fail to.  It truly is a microcosm of the security engineering
    problem.",
  location     = "http://dx.doi.org/10.1109/2.955101"
}

@Article{bti4sc,
  author       = "Joan~G. Dyer and Mark Lindemann and Ronald Perez and Reiner
    Sailer and Leendert {van Doorn} and Sean~W. Smith and Steve Weingart",
  title        = "Building the {IBM} 4758 Secure Coprocessor",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "57--66",
  month        = oct,
  keywords     = "hardware design, secure boot, state retention, firmware,
    trust, authentication",
  abstract     = "The authors sought to build a secure coprocessor-defined as
    a tamper-responding device derived from the Abyss, Citadel, and 4755
    work-that would provide a single multipurpose platform third parties could
    use to develop and deploy secure coprocessor applications, with minimal IBM
    participation.  The project had several goals: ensure that the device could
    be identified externally, design the device and its soft-ware to be
    securely configurable and updatable in the field, construct the software
    architecture to accommodate layers of code from different parties, avoid
    letting the compromise of one device breach any other's security, and
    validate all these assertions through an external party.Providing an
    environment in which applications could run securely forced the designers
    to focus not only on security mechanisms and their implementation and
    management, but also on the security policies they must support.  Clearly,
    the hardware on which applications run must be secure, as must the
    operating system and run-time environment in between, while offering a
    reasonable API for applications developers.  To fix problems in the field
    and enable fast and inexpensive reaction to changing customer needs, the
    designers implemented part of the code as firmware rather than as read-only
    memory.The 4758 project achieved most of its design goals.  Currently, the
    authors are exploring other embedded processors, the addition of a network
    communication channel, and other form factors, including those appropriate
    for laptops.",
  location     = "http://dx.doi.org/10.1109/2.955100"
}

@Article{mhacs,
  author       = "Peter Bergstrom and Kevin Driscoll and John Kimball",
  title        = "Making Home Automation Communications Secure",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "50--56",
  month        = oct,
  abstract     = "Long the futuristic domain of hobbyists, home automation is 
    now moving to the mainstream.  This domain involves three significant
    technological developments:Focused subsystems consist of specific home
    features that use local information to automate desired performance, such
    as programmable thermostats that change home temperature based on a time
    schedule.Integrated whole-home behavior lets users combine safety, comfort,
    health, information, and entertainment needs into one system that, for
    example, can change environmental settings based on variable home occupant
    activities rather than a fixed time schedule.Distributed-home-automation
    applications, enabled by widespread adoption of the Internet, run
    substantially outside the home, eliminating the need for a PC and making
    these applications easy to upgrade or tailor for specific individuals and
    markets.Although these new communications technologies offer numerous
    benefits, they also open home automation to many security threats.  To
    protect against these threats within the limited resources of a typical
    home automation system, the authors have developed a family of products
    based on Honeywell's Global Home Server, a remote Web site that provides
    secure Internet access and other services to client installations.The GHS
    system is now operational, with initial product deployments in both the
    United States and Europe.  Expanding on this work, the authors are
    developing security products that use different media and processors, can
    function in aircraft as well as in homes, and run various novel
    applications.", 
  keywords     = "home servers, home products, layered defences, key
    management",
  location     = "http://dx.doi.org/10.1109/2.955099"
}

@Article{cptid,
  author       = "Dan~S. Wallach",
  title        = "Copy Protection Technology is Doomed",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "48--49",
  month        = oct,
  keywords     = "watermark, end-to-end systems",
  abstract     = "Despite how easy copying has always been, vendors continue
    selling content and people continue to buy it, even when they can get that
    content illegally.  When records and, later, radio were introduced, artists
    and record companies feared it was the end of their world.  It wasn't.
    When VCRs were introduced, they didn't destroy movie theaters¿they led to
    creation of the video rental business.  History tells us that the ease of
    digitally copying music, video, and any other media won't destroy the
    copyright holders.Now, with the ubiquity of CD burners, technology has
    again advanced, making audio CDs trivial to copy, bit for bit.  The record
    companies could potentially address this situation by creating some
    fundamental advance in how music is delivered to consumers.  Instead,
    technology companies are offering the record companies a wide variety of
    snake-oil schemes to help them maintain their previous business models.
    These schemes can be defeated¿doing so only requires that somebody study
    how they work.The only way to prevent teenage girls from freely sharing
    boy-band MP3s will be to provide a service that's reasonably priced and
    irresistibly better than free file sharing.  Any other technology, business
    model, or legal framework is simply doomed.",
  location     = "http://dx.doi.org/10.1109/2.955098"
}

@Article{pdcwth,
  author       = "C.~Brendan S.~Traw",
  title        = "Protecting Digital Content within the Home",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "42--47",
  month        = oct,
  keywords     = "content protection, constraints, licensing",
  abstract     = "Home users increasingly use digital media to access, store, 
    and display music, movies, and other entertainment content.  This trend
    represents both new business opportunities and risks for content creators
    and distributors.  These risks are magnified for digital content compared
    with its analog predecessors because of digital reproduction's lossless
    nature.  Further, the widespread availability of digital copying devices
    and the Internet gives rise to widespread, unauthorized distribution of
    content using applications and services such as Napster.Licensing and
    technological mechanisms provide a potent combination for preventing
    circumvention of content-protection systems while still accommodating
    consumer practices.Technical protection mechanisms are effective for
    preventing unsophisticated attempts to circumvent a particular
    content-protection technology that individuals typically perform.
    Conversely, licensing and other legal mechanisms work much better for
    protecting content against misuse by business entities with assets,
    employees, and distribution channels.A combination of technology and
    licensing can build a chain of solutions that effectively protect content
    as users transfer, store, and consume it on entertainment devices within
    the home.",
  location     = "http://dx.doi.org/10.1109/2.955097"
}

@Article{spwtaspm,
  author       = "Lixin Tao",
  title        = "Shifting Paradigms with the Application Service Provider Model",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "32--39",
  month        = oct,
  keywords     = "corba, java beans, micropayments",
  abstract     = "In the past four decades, several technological
    breakthroughs have made it feasible to sell computing as a service rather
    than a product.  Supercomputers and clustering technologies have made huge
    amounts of raw computing power available, while time-sharing operating
    systems have made computing resources a divisible utility.  Personal
    computers have educated generations of home and office computing users, who
    now depend on such devices.  Meanwhile, the Internet has become the world's
    largest data and computing-service delivery infrastructure, offering a new
    platform for net-work-centric computing.Recently, application service
    providers have begun marketing the ASP model, which uses the Internet or
    other wide area networks to provide online application services on a rental
    basis¿commercially delivering computing as a service.  For the ASP model to
    become the computing industry's mainstream paradigm, ASPs must make
    significant breakthroughs in networking infra-structure, computing
    technologies, and rental-based cost models and financial services.If it can
    overcome the challenges facing it, the ASP model will foster a new
    generation of distributed, component-based computing services.",
  location     = "http://dx.doi.org/10.1109/2.955095"
}

@Article{seaast,
  author       = "Julio C{\' e}sar Hern{\' a}ndez and Jos{\' e} Mar{\' \i}a
    Sierra and Arturo Ribagorda and Benjamín Ramos",
  title        = "Search Engines as a Security Threat",
  journal      = ieeec,
  year         = 2001,
  volume       = 34,
  number       = 10,
  pages        = "25--30",
  month        = oct,
  keywords     = "anonymous proxies, ftp vulnerability",
  abstract     = "Search engines index a huge number of Web pages and other
    resources.  Hackers can use these engines to make anonymous attacks, find
    easy victims, and gain the knowledge necessary to mount a powerful attack
    against a network.Further, search engines can help hackers avoid
    identification.  One reason so few hacking attempts get reported is that
    there are so many of them.  Tracerouting a hacker's IP address to its
    source often ends at a hop completely unrelated to the hacker's actual ISP
    or local network, which makes reporting the hacker to the upstream provider
    difficult.Search engines are dangerous largely because users are careless.
    In the age of DSL and broadband cable accounts, users often keep their
    machines turned on and connected to the Internet for days.  Most of them
    would be shocked to find that potential hackers target their machines up to
    several times a minute.  Most home-machine hack attempts seek to make their
    targets zombies in a distributed denial-of-service attack.  Search engines
    make discovering candidate machines almost effortless.It isn't possible to
    secure all channels against hackers trying to penetrate a vulnerable
    system.  But search engines needn't be wide-open channels that continue to
    help hackers find and penetrate weak systems.", 
  location     = "http://dx.doi.org/10.1109/2.955094"
}

@Article{asosm,
  author       = "Yehuda Afek and Hagit Attiya and Danny Dolev and Eli Gafni
    and Michael Merrit and Nir Shavit",
  title        = "Atomic Snapshots of Shared Memory",
  journal      = jacm,
  year         = 1993,
  volume       = 40,
  number       = 4,
  pages        = "873--890",
  month        = sep,
  keywords     = "shared memory, algorithms concurrency, falut tolerance,
    atomic, snapshot, consistent state",
  abstract     = "This paper introduces a general formulation of atomic
    snapshot memory, a shared memory partitioned into words written (updated)
    by individual processes, or instantaneously read (scanned) in its entirety.
    This paper presents three wait-free implementations of atomic snapshot
    memory.  The first implementation in this paper uses unbounded (integer)
    fields in these registers, and is particularly easy to understand.  The
    second implementation uses bounded registers.  Its correctness proof
    follows the ideas of the unbounded implementation.  Both constructions
    implement a single-writer snapshot memory, in which each word may be
    updated by only one process, from single-writer, n-reader registers.  The
    third algorithm implements a multi-writer snapshot memory from atomic
    n-writer, n-reader registers, again echoing key ideas from the earlier
    constructions.  All operations require theta(n^2) reads and writes to the
    component shared registers in the worst case.", 
  location     = "http://dx.doi.org/10.1145/153724.153741"
}

@Article{uhtfpa,
  author       = "Michael Lindahl",
  title        = "Using Hardware Trace for Performance Analysis",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "71--74",
  month        = oct,
  keywords     = "performance analysis, hardware trace, ",
  location     = "http://drdobbs.com/tools/184406289"
}

@Article{pcto,
  author       = "Thorsten Ottosen",
  title        = "Pointer Containers",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "68--70",
  month        = oct,
  keywords     = "exception safety, clones, data structures",
  location     = "http://drdobbs.com/cpp/184406287"
}

@Article{rmef6bp,
  author       = "Rich Newman",
  title        = "Removing Memory Errors from 64-Bit Platforms",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "63--67",
  month        = oct,
  keywords     = "porting, hardware architecture, pointers",
  location     = "http://drdobbs.com/cpp/184406286"
}

@Article{tmsmtin,
  author       = "Tom Thompson",
  title        = "The {M}ac's Move to {I}ntel",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "52--56",
  month        = oct,
  keywords     = "fat binaries, portability",
  location     = "http://drdobbs.com/open-source/184406284"
}

@Article{tetaptp,
  author       = "Andy Kaylor",
  title        = "The {Eclipse} Test and Performance Tools Platform",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "48--51",
  month        = oct,
  keywords     = "tptp, frameworks, eclipse",
  location     = "http://drdobbs.com/tools/184406283"
}

@Article{dj1p,
  author       = "Ted O'Connor and Martin Snyder",
  title        = "Developing {JSR}-168 Portlets",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "44--46",
  month        = oct,
  keywords     = "portals, web content",
  location     = "http://drdobbs.com/java/184406282"
}

@Article{itsusk,
  author       = "Joel Gyllenskog",
  title        = "Inside the {SmartDongle} {USB} Security Key",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "40--43",
  month        = oct,
  keywords     = "security, cryptography, liner congruential sequences",
  location     = "http://drdobbs.com/security/184406281"
}

@Article{evcs,
  author       = "Daniel Stoleru",
  title        = "Extended Visual Cryptography Schemes",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 20,
  pages        = "36--39",
  month        = oct,
  keywords     = "cryptography, security",
  location     = "http://drdobbs.com/security/184406280"
}

@Article{rtitw,
  author       = "Amir Herzberg and Ahmad Ibara",
  title        = "Reestablishing Trust In the Web",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "28--34",
  month        = oct,
  keywords     = "browser identification, trustbar, firefox extensions, ",
  location     = "http://drdobbs.com/web-development/184406279"
}

@Article{ppwpp,
  author       = "Michael~O. Rabin and Dennis~E. Shasha",
  title        = "Preventing Piracy While Preserving Privacy",
  journal      = ddj,
  year         = 2005,
  volume       = 30,
  number       = 10,
  pages        = "16--26",
  month        = oct,
  keywords     = "piracy, drm, superfingerprint, cryptography, ",
  location     = "http://drdobbs.com/184406277"
}

@Book{tfttjs,
  author       = "T.~J. Stiles",
  title        = "The First Tycoon",
  publisher    = "Vintage",
  year         = 2009,
  address      = nyny,
  keywords     = "cornelius vanderbilt, economic history, transportation,
    coporate development, the gilded age",
  location     = "CT 275 V23 S85"
}

@Book{arjlc,
  author       = "John~L. Casti",
  title        = "Alternate Realities",
  publisher    = "Wiley",
  year         = 1989,
  address      = nyny,
  keywords     = "mathematical modeling, cellular automata, descrete dynamics,
    catstrophe theory, chaos, competition, games, control theory, adaptation,
    chance games",
  location     = "QA 401 C358"
}

@Book{ttssgtc,
  author       = "Andrew Roberts",
  title        = "The Thinking Student's Guide to College",
  publisher    = ucp,
  year         = 2010,
  address      = chil,
  keywords     = "universities, colleges, education",
  location     = "LB 2350.5R634"
}

@Book{baptam,
  author       = "Thomas~A. Markus",
  title        = "Buildings \& Power",
  publisher    = "Routlidge",
  year         = 1993,
  address      = loen,
  keywords     = "buildings, architecture, social spaces",
  location     = "NA 500 M37"
}

@Book{opdjm,
  author       = "John Montroll",
  title        = "Origami Polyhedra Design",
  publisher    = "A K Peters, Ltd",
  year         = 2009,
  address      = "Natik, Massachusetts",
  keywords     = "origami, polyhedra",
  location     = "TT 870 M567"
}

@Book{thrtlmap,
  author       = "Kees Doets and Jan {van Eijck}",
  title        = "The Haskell Road to Logic, Maths and Programming",
  publisher    = "King's College Publications",
  year         = 2004,
  address      = loen,
  keywords     = "haskell, logic, proof, mathematical objects, sets, types,
    lists, relations, functions, induction, recursion, polynomials,
    corecursion",
  location     = ""
}

@Book{tcasinomc,
  author       = "S. S. {Van Dine}",
  title        = "The Casino Murder Case",
  publisher    = "Scribner's",
  year         = 1934,
  address      = nyny,
  keywords     = "murrdaar, the ol' switcheroo",
  location     = "PZ 3.W9384"
}

@Book{tgmccob,
  author       = "Conor Cruise O'Brien",
  title        = "The Great Melody",
  publisher    = ucp,
  year         = 1992,
  address      = chil,
  keywords     = "edmund burke, the united kingdom, the french revolution",
  location     = "DA 506 B9 O29"
}

@Book{dlpgp,
  author       = "Phillip~G. Payne",
  title        = "Dead Last",
  publisher    = "Ohio University Press",
  year         = 2009,
  address      = "Athens, Ohio",
  keywords     = "warren g harding, scandals",
  location     = "E 786 P39"
}

@Book{smfhtr,
  author       = "Fukagawa Hidetoshi and Tony Rothman",
  title        = "Sacred Mathematics",
  publisher    = pup,
  year         = 2008,
  address      = prnj,
  keywords     = "geometry, mathematics history, japanese history",
  location     = "QA 27 J3 F849"
}

@Book{dadaa,
  author       = "Amir Alexander",
  title        = "Duel at Dawn",
  publisher    = hup,
  year         = 2010,
  series       = "New Histories of Science, Technology, and Medicine",
  address      = cma,
  keywords     = "romanticism, mathematics, galois, able, bolyai, cauchy",
  location     = "QA 10.7 A44"
}

@Book{vlrt,
  author       = "Ross Thomas",
  title        = "Voodoo, Ltd.",
  publisher    = "Mysterious Press",
  year         = 1992,
  address      = nyny,
  month        = oct,
  keywords     = "murrdaar, blackmail",
  location     = "PS 3570.H58V66"
}

@Book{emposodr,
  author       = "Alexander Rosenberg",
  title        = "Economics---Mathematical Politics or Science of Diminishing Returns?",
  publisher    = ucp,
  year         = 1992,
  address      = chil,
  keywords     = "neoclassical economics, political philosophy, science
    philosophy, equilibrium theory, economic philosophy, applied mathematics", 
  location     = "HB 72.R66"
}

@Book{zhwg,
  author       = "William Gibson",
  title        = "Zero History",
  publisher    = "Putnam",
  year         = 2010,
  address      = nyny,
  keywords     = "fashion, undercurrents",
  location     = "PS 3557.I2264Z47"
}

@Book{tpoeep,
  author       = "Eduardo Porter",
  title        = "The Price of Everything",
  publisher    = "Penguin",
  year         = 2011,
  address      = nyny,
  keywords     = "economics, the fabulous free market",
  location     = "HG 223.P67"
}

@Book{amucha,
  title        = "Alphonse Mucha",
  publisher    = "Prestel",
  year         = 2009,
  editor       = "Agnes Husslein-Arco and Jean Louis Gaillmin and Michael
    Hilaire and Christiane Lange",
  address      = "Munich, Germany",
  keywords     = "art deco, alphonse mucha, slavic art",
  location     = "N 6834.5 N8 A4"
}

@Book{eatfop,
  author       = "Philip~P. Wiener",
  title        = "Evolution and the Founders of Pragmatism",
  publisher    = upp,
  year         = 1972,
  address      = phpe,
  keywords     = "evolution, pragmatism",
  location     = "B 818 W63"
}

@Book{itbbrkn,
  author       = "Rishi K. Narang",
  title        = "Inside the Black Box",
  publisher    = "John Wiley",
  year         = 2009,
  address      = "Hoboken, " # NJ,
  keywords     = "quatative trading, alpha models, risk models, transaction
    costs models, portfolio construction models",
  location     = "HG 4529.5 N37"
}

@Book{fiasco,
  author       = "Frank Partnoy",
  title        = "{F.I.A.S.C.O.}",
  publisher    = "W.~W. Norton",
  year         = 1997,
  address      = nyny,
  keywords     = "derivatives, morgan stanly, salesman, finance, wall street,
    fraud",
  location     = "HG 6024 U6 P37"
}

@Book{doeac,
  author       = "Amy Chua",
  title        = "Day of Empire",
  publisher    = "Anchor Books",
  year         = 2009,
  address      = nyny,
  price        = "$16.95",
  keywords     = "hyperpower, politics, tolerance, empire",
  location     = "JC 539 C498"
}

@Book{paipll,
  author       = "Larry Laudan",
  title        = "Progress and its Problems",
  publisher    = ucalp,
  year         = 1977,
  address      = bca,
  keywords     = "philosophy of science, history of science, science research",
  location     = "Q 125 L34"
}

@Book{nnrrj,
  author       = "Richard~R. John",
  title        = "Network Nation",
  publisher    = "Belknap Press",
  year         = 2010,
  address      = cma,
  keywords     = "telegraph, telephone, mail, politics, regulation, government
    policy, coporate governance",
  location     = "TK 5102.3 U6 J64"
}

@Book{wgfrl,
  author       = "Roger Lowenstein",
  title        = "When Genius Failed",
  publisher    = "Random House",
  year         = 2001,
  address      = nyny,
  keywords     = "finance, hedge funds, wall street, sociopaths, long-term
    capital management, the 1990s",
  location     = "HG 4930 L69"
}

@Book{tirft,
  author       = "Raymond~F. Toliver",
  title        = "The Interrogator",
  publisher    = "Schiffer Military History",
  year         = 1997,
  address      = "Atglen, " # PA,
  keywords     = "",
  location     = "D 810.S7 T65 1997"
}

@Book{aimmc,
  author       = "Cornelia Dean",
  title        = "Am {I} Making Myself Clear?",
  publisher    = hup,
  year         = 2009,
  address      = cma,
  keywords     = "journalism, science reporting, communication, public policy",
  location     = "Q 223 D43"
}

@Book{rwrbp,
  author       = "Robert~B. Parker",
  title        = "Rough Weather",
  publisher    = "Putnam",
  year         = 2008,
  address      = nyny,
  keywords     = "murrdar, tangled bloodlines",
  location     = "PS 3566.A686 R68"
}
		  
@Book{saggjhb,
  author       = "Jeffrey~H. Birnbaum and Alan~S. Murray",
  title        = "Showdown at Gucci Gulch",
  publisher    = "Random House",
  year         = 1987,
  address      = nyny,
  keywords     = "tax reform, congress, law making reagan",
  location     = "KF 6289.B57"
}
		  
@incollection{fdopc:tp,
  author	= "Luca Cardelli",
  title		= "Typeful Programming",
  booktitle	= "Formal Descriptions of Programming Concepts",
  publisher	= sv,
  year		= 1991,
  editor	= "Erich~J. Neuhold and Manfred Paul",
  pages		= "431--505",
  address	= bgr,
  keywords	= "type systems, programming languages, subtypes, polymorphism"
}

@Book{ttsa,
  author       = "J.~Scott Turner",
  title        = "The Tinkerer's Accomplace",
  publisher    = hup,
  year         = 2007,
  address      = cma,
  keywords     = "evolution, intentionality, bernard's machines, circulatory
    development, visual processing, termite hill ventilation, digestion",
  location     = "QH 375 T87"
}

@Book{cicsk,
  author       = "Sergiy Klymchuk",
  title        = "Counterexamples in Calculus",
  publisher    = "Mathmatical Association of America",
  year         = 2010,
  address      = "Washington, D.C.",
  keywords     = "calculus, problems, counterexamples, functions, limits,
    continuity, differential calculus, integral calculus",
  location     = "QA 303.2 K59"
}

@Book{ehcef,
  title        = "Edward Hopper",
  publisher    = "Skira",
  year         = 2009,
  editor       = "Carter~E. Foster",
  address      = "Milano, Italy",
  keywords     = "edward hopper, american realism, 20th century art",
  location     = "N 6537 H6 A4"
}

@Book{aadsmnad,
  author       = "Douglas~S. Massey and Nancy~A. Denton",
  title        = "American Apartheid",
  publisher    = hup,
  year         = 1993,
  address      = cma,
  keywords     = "racism, segregation, ghettos, underclass, public policy",
  location     = "E 185.61 M373"
}

@Book{astpmle,
  author       = "Madeleine L'Engle",
  title        = "{A} Swiftly Tilting Planet",
  publisher    = "Bantam Doubleday Dell",
  year         = 1981,
  address      = nyny,
  month        = jan,
  price        = "$4.99",
  keywords     = "fantasy, unicorns, time travel",
  location     = "PZ 7.L5385 Sw"
}

@Book{tamsprt,
  author       = "Ross Thomas",
  title        = "Twilight at Mac's Place",
  publisher    = "Mysterious Press",
  year         = 1990,
  address      = nyny,
  keywords     = "murrdaar, skullduggery, cons",
  location     = "PS 3570.H58 T9"
}

@Book{tomesh,
  author       = "Elisabeth Sanxay Holding",
  title        = "The Obstinate Murderer",
  publisher    = "Mead \& Co.",
  year         = 1938,
  address      = nyny,
  keywords     = "murrdaar, annoying people",
  location     = "PZ 3.H6947 Ob"
}

@Book{dsaaarwe,
  author       = "Granville Barnett and Luca {Del Tongo}",
  title        = "Data Structures and Algorithms:  Annotated Reference with Examples",
  publisher    = "DotNetSlackers",
  year         = 2008,
  keywords     = "data structures, linked lists, binary search tree, heap,
  sets, queues, avl tree, algorithms, sorting numeric, searching, strings",
  location     = "http://dotnetslackers.com/Community/files/folders/data-structures-and-algorithms/entry30283.aspx"
}

@Book{msoja,
  author       = "Jeffery Abramson",
  title        = "Minerva's Owl",
  publisher    = hup,
  year         = 2009,
  address      = cma,
  keywords     = "political theory, plato, aristotle, augustine, machiavelli,
  hobbes, locke, rousseau, kant, mill, hagel, marx",
  location     = "JA 81 A32"
}

@Book{sich,
  author       = "Carl Hiaasen",
  title        = "Star Island",
  publisher    = "Knopf",
  year         = 2010,
  address      = nyny,
  keywords     = "celebs, paparazzi",
  location     = "PS 3558.I217573"
}

@Book{tepmh,
  author       = "Michel Houellebecq",
  title        = "The Elementary Particles",
  publisher    = "Vintage",
  year         = 2001,
  price        = "$15.95",
  address      = nyny,
  keywords     = "biology, individualism",
  location     = "PQ 2668 O77 P3713"
}

@Book{wwctw,
  author       = "Martin Luther {King, Jr.}",
  title        = "Why We Can't Wait",
  publisher    = "Beacon Press",
  year         = 2010,
  address      = boma,
  keywords     = "nonviolence, birmingham, us history, race relations",
  location     = "E 185.61.K54"
}

@Book{jmjs,
  author       = "Michael~J. Sandel",
  title        = "Justice",
  publisher    = "Farrar, Straus and Giroux",
  year         = 2009,
  address      = nyny,
  keywords     = "justice, moral philosophy, utilitarianism, libertarianism,
    aristotle, rawls, kant, locke",
  location     = "JC 578.S26"
}

@Book{lmh,
  author       = "Michel Houellebecq",
  title        = "Lanzarote",
  publisher    = "Vintage",
  year         = 2004,
  address      = loen,
  keywords     = "tourism, cults",
  location     = "PQ 2668.O77 L3613"
}

@Book{wtksd,
  author       = "T.~C. Boyle",
  title        = "When the Killing's Done",
  publisher    = "Viking",
  year         = 2011,
  address      = nyny,
  keywords     = "environmentalism, invasive species",
  location     = "PS 3552.O932 W48"
}

@Book{rlrm,
  author       = "Rick Moody",
  title        = "Right Livelihoods",
  publisher    = "Little, Brown and Co.",
  year         = 2007,
  address      = nyny,
  keywords     = "delusions, trivialities, coping",
  location     = "PS 3563.05537 R54"
}

@Book{plrbp,
  author       = "Robert~B. Parker",
  title        = "Painted Ladies",
  publisher    = "G.~P. Putnam's Sons",
  year         = 2010,
  address      = nyny,
  keywords     = "art forgery, murrrdaaar",
  location     = "PS 3566.A686 P28"
}

@Book{tmcml,
  author       = "Michael Lewis",
  title        = "The Money Culture",
  publisher    = "W.~W. Norton",
  year         = 1991,
  address      = nyny,
  keywords     = "finance, wall street, disaster, lbo",
  location     = "HG 4621.L48"
}

@Book{abg,
  author       = "Barton Gellman",
  title        = "Angler",
  publisher    = "Penguin",
  year         = 2008,
  address      = nyny,
  keywords     = "dick chaney, george bush, politics",
  location     = "E 840.8 C43 G45"
}

@Book{smth,
  author       = "Tony Hillerman",
  title        = "Skeleton Man",
  publisher    = "HarperCollins",
  year         = 2004,
  address      = nyny,
  keywords     = "dna, murrdaar",
  location     = "PS 3558.I45 S47"
}

@Book{stfmlk,
  author       = "Martin Luther {King, Jr.}",
  title        = "Stride Towards Freedom",
  publisher    = "Beacon Press",
  year         = 1986,
  address      = boma,
  keywords     = "montgomery, bus boycott, nonviolence",
  location     = "F 334.M79 N4535"
}

@Book{tlatots,
  author       = "Gholam Reza Afkhami",
  title        = "The Life and Times of the Shah",
  publisher    = ucalp,
  year         = 2009,
  address      = beca,
  keywords     = "iran, mohammed reza pahlavi",
  location     = "DS 318 A653"
}

@Book{djel,
  author       = "Elmore Leonard",
  title        = "Djibouti",
  publisher    = "William Morrow",
  year         = 2010,
  address      = nyny,
  keywords     = "terrorism, pirates, murrdaar, southern africa",
  location     = "PS 6532.E55 D55"
}

@Book{tioah,
  author       = "Reinhold Niebuhr",
  title        = "The Irony of American History",
  publisher    = "Scribner's",
  year         = 1952,
  address      = nyny,
  keywords     = "irony, national power",
  location     = "E 744 N5"
}

@Book{wdwgfh,
  author       = "Martin Luther {King, Jr.}",
  title        = "Where Do We Go From Here",
  publisher    = "Beacon Press",
  year         = 2010,
  address      = boma,
  keywords     = "race relations, poverty, civil rights",
  location     = "E 185.615.K5"
}

@Book{wmh,
  author       = "Michel Houellebecq",
  title        = "Whatever",
  publisher    = "Serpent's Tail",
  year         = 2011,
  address      = loen,
  keywords     = "dispare",
  location     = "PQ 2668 O77 E8713"
}

@Book{aosvm,
  author       = "Raphael~A. Finkel",
  title        = "An Operating Systems Vade Mecum",
  publisher    = ph,
  year         = 1988,
  address      = ecnj,
  edition      = "second",
  keywords     = "operating systems",
  location     = "QA76.76.O63 F56",
  location     = "http://www.nondot.org/sabre/os/files/Misc/vade.mecum.2.pdf"
}

@Book{tesgttsw,
  author       = "Thomas~B. Passin",
  title        = "The Explorer's Guide to the Semantic Web",
  publisher    = "Manning",
  year         = 2004,
  address      = "Greenwich, Connecticut",
  keywords     = "semantic web, rdf, topic maps, web annotations, searching,
    logic ontology, agents, trust, belief",
  location     = "TK 5105.88815 P37"
}

@Book{foswt,
  author       = "Pascal Hitzler and Markus Kr{\" o}tzsch and Sebastian Rudolph",
  title        = "Foundations of Semantic Web Technologies",
  publisher    = "CRC Press",
  year         = 2010,
  address      = brfl,
  keywords     = "rdf, ontologies, owl, query language, xml",
  location     = "TK 5105.88815 H57"
}

@Book{htlsb,
  author       = "Sarah Bakewell",
  title        = "How to Live",
  publisher    = "Other Press",
  year         = 2010,
  address      = nyny,
  keywords     = "montaigne, essays",
  location     = "PQ 1643.B34"
}

@Book{ehlau,
  author       = "Walter Isaacson",
  title        = "Einstein",
  publisher    = "Simon and Schuster",
  year         = 2007,
  address      = nyny,
  keywords     = "einstein, quantum physics",
  location     = "QC 16 ES I76"
}

@Book{npr,
  author       = "Philip Roth",
  title        = "Nemesis",
  publisher    = "Houghton Mifflin Harcourt",
  year         = 2010,
  address      = boma,
  keywords     = "polo, fate, guilt, newark",
  location     = "PS 3568.0855 N46"
}

@Book{ptswts,
  author       = "Toby Segaran and Colin Evans and Jamie Taylor",
  title        = "Programming the Semantic Web",
  publisher    = "O'Reilly",
  year         = 2009,
  address      = seca,
  keywords     = "semantics, rich data framework, ontology",
  location     = ""
}

@Book{aswp,
  author       = "Grigoris Antoniou and Frank {van Harmelen}",
  title        = "A Semantic Web Primer",
  publisher    = mitp,
  year         = 2008,
  address      = cma,
  keywords     = "xml, rdf, owl, ontology, logic, inference",
  location     = "TK 5105.88815 A58"
}

@Book{eaesm,
  author       = "Sankar Muthu",
  title        = "Enlightenment Against Empire",
  publisher    = pup,
  year         = 2003,
  address      = prnj,
  keywords     = "colonialism",
  location     = "JC 359 M87"
}

@Book{aarajr,
  author       = "Richard Arum and Josipa Roksa",
  title        = "Academically Adrift",
  publisher    = ucp,
  year         = 2011,
  address      = chil,
  keywords     = "modern youth, academics, group study, evaluation",
  location     = "LA 227.4.A78"
}

@Book{jpsbbgs,
  author       = "Bill Barnhart and Gene Schlickman",
  title        = "John Paul Stevens",
  publisher    = "Northern Illinois University Press",
  year         = 2010,
  address      = "DeKalb, Illinois",
  keywords     = "justice, judges, politics",
  location     = "KF 8745.578 B37"
}

@Book{egfk,
  author       = "Federico Kereki",
  title        = "Essential {GWT}",
  publisher    = aw,
  year         = 2011,
  address      = srnj,
  keywords     = "web development, java, javascript, ajax",
  location     = "TK 5105.8885.A52K47"
}

@Book{krarrjb,
  author       = "Ronald~J. Brachman and Hector~J. Levesque",
  title        = "Knowledge Representation and Reasoning",
  publisher    = mk,
  year         = 2004,
  address      = sfca,
  keywords     = "first-order logic, knowledge expression, resolution, horn
    clauses, procedural reasoning, production systems, inheritance,
    uncertaintydiagonsis, explanation, planning",
  location     = "Q 387.B73"
}

@Book{poaip,
  author       = "Peter Norvig",
  title        = "Paradigms of Artificial Intelligence Programming",
  publisher    = mk,
  year         = 1992,
  address      = sfca,
  keywords     = "common lisp, general problem solver, eliza, symboloc
    mathematics, logic programming, object-oriented programming, knowledge
    representation, reasoning, expert systems constraint satisfaction,
    unification grammers, english grammar",
  location     = "QA 76.6 N687"
}

@Book{aipec,
  author       = "Eugene Charniak and Christopher~K. Riesbeck and Drew~V. McDermott",
  title        = "Artificial Intelligence Programming",
  publisher    = "Lawrence Erlbaum Associates",
  year         = 1980,
  address      = "Hillsdale, New Jersey",
  keywords     = "lisp, discrimination nets, agenda control structures,
    deductive information retrieval, slot and filter data bases, data
    dependencies, alternative control structures, chronological backtracking",
  location     = "Q 336.C48"
}

@Book{snf,
  author       = "Noah Feldman",
  title        = "Scorpions",
  publisher    = "Twelve",
  year         = 2010,
  address      = nyny,
  keywords     = "supreme court, politics, william douglass, felix frankfurter,
    hugo black, robert jackson, franklin roosevelt",
  location     = "KF 8744 F45"
}

@Book{ttorjm,
  author       = "John Mortimer",
  title        = "The Trials of Rumpole",
  publisher    = "Penguin",
  year         = 1979,
  address      = nyny,
  keywords     = "shoplifting, murrdaar, hate speech, identity, jelousy,
    retirement",
  location     = "PR 6025.O7552"
}

@Book{tpoai,
  author       = "Michel Houellebecq",
  title        = "The Possibility of an Island",
  publisher    = "Vintage",
  year         = 2007,
  address      = nyny,
  keywords     = "humans, trans-humans, all fall down",
  location     = "PQ 2668.077 P6713"
}

@Book{whgwdwh,
  author       = "Daniel Walker Howe",
  title        = "What Hath God Wrought",
  publisher    = oup,
  year         = 2007,
  series       = "The Oxford History of the United States",
  address      = nyny,
  keywords     = "territorial expansion, slavery, party systems, antibellum
    society, andrew jackson, john adams, whigs",
  location     = "E 338 H69"
}

@Book{tcdjo,
  author       = "Jennifer Ouellette",
  title        = "The Calculus Diaries",
  publisher    = "Penguin",
  year         = 2010,
  address      = nyny,
  keywords     = "calculus, roller coster, gambling, epidemics",
  location     = "QA 303.2.O94"
}

@Book{tpowr,
  title        = "The Papers of Will Rogers",
  publisher    = "The University of Oklahoma Press",
  year         = 1996,
  editor       = "Arthur Frank Wertheim and Barbara Blair",
  volume       = "one, The Early Years, November 1879 to April 1904",
  address      = "Norman, Oklahoma",
  keywords     = "will rogers",
  location     = "PN 2287 R74 A25"
}

@Book{tdoaoc,
  author       = "William~A. Wulf and Richard~K. Johnson and Charles~B. 
    Weinstock and Steven~O. Hobbs and Charles~M. Geschke",
  title        = "The Design of an Optimizing Compiler",
  publisher    = "Elsevier",
  year         = 1975,
  address      = nyny,
  keywords     = "bliss, compilation, optimization",
  location     = "QA 76.6.D47"
}

@Book{dotpblc,
  author       = "Benjamin~L. Carp",
  title        = "Defiance of the Patriots",
  publisher    = "Yale University Press",
  year         = 2010,
  address      = "New Haven, Connecticut",
  keywords     = "new england, american history, the tea party, sons of
    liberty, american revolution, east india company, governance",
  location     = "E 215.7.C37"
}

@Book{ttoujb,
  author       = "Julia Blackburn",
  title        = "The Three of Us",
  publisher    = "Pantheon",
  year         = 2008,
  address      = nyny,
  keywords     = "family",
  location     = "PR 6052 L3413 Z46"
}

@Book{asgja,
  author       = "George J. Akerlof and Robert~J. Shiller",
  title        = "Animal Spirits",
  publisher    = pup,
  year         = 2009,
  address      = prnj,
  keywords     = "economics, economic policy, depressions, central banking,
    finance, unemployment, inflation, savings, volatility, real estate,
    poverty",
  location     = "HB 74 P8 A494"
}

@Book{ucpdj,
  author       = "P.~D. James",
  title        = "Unnatural Causes",
  publisher    = "Popular Library",
  year         = 1967,
  address      = nyny,
  price        = "$1.75",
  keywords     = "vanity, murrdaar",
  location     = "PZ4.J2847 Un"
}

@TechReport{elpb,
  author       = "Peter Baumann",
  title        = "Enriched Languages",
  institution  = "Institut f{\" u}r Informatik der Universit{\" a}t Z{\" u}rich",
  year         = 1994,
  address      = "Z{\" u}rich, Switzerland",
  number       = "ifi-94.13",
  keywords     = "formal approaches, natural semantics, program verification",
  abstract     = "This paper is to present a very general approach how to 
    enrich imperative programming languages in the direction of wide spectrum
    languages.  The key idea is to incorporate specification assertions into
    programming languages by allowing predicates on pairs of states to appear
    wherever a statement could appear.", 
  location     = "ftp://ftp.ifi.unizh.ch/pub/techreports/TR-94/ifi-94.13.ps.gz"
}

@TechReport{tasaaccdt,
  author       = "David~M. Beazley",
  title        = "Tcl and {SWIG} as a {C}/" # cpp # " Development Tool",
  institution  = dcs # "University of Chicago",
  year         = 1998,
  address      = "Chicago, Illinois",
  keywords     = "swig, tcl, wrapping",
  location     = "http://www.swig.org/papers/Tcl98/TclChap.html"
}

@TechReport{tataa,
  author       = "Hubert Comon and Max Dauchet and R\'emi Gilleron and
    Christof L{\"o}ding and Florent Jacquemard and Denis Lugiez and Sophie
    Tison and Marc Tommasi",
  title        = "Tree Automata Techniques and Applications",
  institution  = "INRIA",
  year         = 2008,
  address      = "France",
  keywords     = "regular grammars, automata, constraints, tree set automata,
    tree transducers, unranked trees",
  location     = "https://gforge.inria.fr/frs/download.php/10994/tata.pdf"
}

@TechReport{sitap,
  author       = "C{\' e}dric Fournet and Andrew~D. Gordon",
  title        = "Stack Inspection:  Theory and Variants",
  institution  = "Microsoft Research",
  year         = 2001,
  number       = "MSR-TR-2001-103",
  address      = rewa,
  month        = dec,
  keywords     = "stack inspections, language security, program transformation,
    equational reasoning",
  abstract     = "Stack inspection is a security mechanism implemented in 
     runtimes such as the JVM and the CLR to accommodate components with
     diverse levels of trust.  Although stack inspection enables the
     fine-grained expression of access control policies, it has rather a
     complex and subtle semantics.  We present a formal semantics and an
     equational theory to explain how stack inspection affects program
     behaviour and code optimisations.  We discuss the security properties
     enforced by stack inspection, and also consider variants with stronger,
     simpler properties."
}

@TechReport{taosabac,
  author       = "Mike Barnett and Wolfram Schulte",
  title        = "The {ABCs} of Specification: {AsmL}, Behavior, and Components",
  institution  = "Microsoft Research",
  year         = 2001,
  address      = rewa,
  month        = nov,
  keywords     = "specifications, refinement, linking specifications",
  abstract     = "We show how to use AsmL, an executable specification
    language, to provide behavioral interfaces for components.  This allows
    clients to fully understand the meaning of an implementation without access
    to the source code.  AsmL implements the concept of behavioral subtyping to
    ensure the substitutability of components and provides many advanced
    specification features such as generic types, transactional semantics,
    invariants and history constraints.", 
  location     = "http://research.microsoft.com/pubs/73061/TheABCsOfSpecification(Informatica2001).pdf"
}

@MastersThesis{tposctalaafc,
  author       = "Jason~M. Griffey",
  title        = "The Perils of Strong Copyright: The American Library Association and Free Culture",
  school       = "School of Information and Library Sciences, University of
    North Carolina",
  year         = 2004,
  address      = chnc,
  month        = apr,
  keywords     = "copyright, libraries, academic serials, intellectual property",
  location     = "http://etd.ils.unc.edu/dspace/bitstream/1901/28/1/Jason+Griffey+Masters+Paper+4.0.pdf"
}

